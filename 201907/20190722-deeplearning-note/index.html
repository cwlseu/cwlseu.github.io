<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CTimes+New+Roman:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.deepindeed.cn","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":28},"copycode":false,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="学习深度学习中的一些有意思的东西">
<meta property="og:type" content="article">
<meta property="og:title" content="认识神经网络：卷积，归一化，优化和语料">
<meta property="og:url" content="http://www.deepindeed.cn/201907/20190722-deeplearning-note/index.html">
<meta property="og:site_name" content="Deepindeed">
<meta property="og:description" content="学习深度学习中的一些有意思的东西">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-07-22T15:10:12.000Z">
<meta property="article:modified_time" content="2022-09-02T20:05:26.055Z">
<meta property="article:author" content="CharlesCao">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="CV">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://www.deepindeed.cn/201907/20190722-deeplearning-note/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://www.deepindeed.cn/201907/20190722-deeplearning-note/","path":"201907/20190722-deeplearning-note/","title":"认识神经网络：卷积，归一化，优化和语料"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>认识神经网络：卷积，归一化，优化和语料 | Deepindeed</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-86501439-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-86501439-1","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>




<link rel="dns-prefetch" href="https://waline.vercel.app"><link rel="stylesheet" href="https://lib.baomitu.com/social-share.js/1.0.16/css/share.min.css">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Deepindeed</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">心有猛虎，细嗅蔷薇</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tools"><a href="/tools/" rel="section"><i class="fa fa-globe fa-fw"></i>tools</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%95%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF"><span class="nav-number">2.</span> <span class="nav-text">卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A4%E8%AF%86%E5%8D%B7%E7%A7%AF"><span class="nav-number">2.1.</span> <span class="nav-text">认识卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.2.</span> <span class="nav-text">卷积的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90"><span class="nav-number">2.3.</span> <span class="nav-text">计算复杂度分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#normalization"><span class="nav-number">3.</span> <span class="nav-text">Normalization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#batch-normalization"><span class="nav-number">3.1.</span> <span class="nav-text">Batch Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#layer-normalizaiton"><span class="nav-number">3.2.</span> <span class="nav-text">Layer Normalizaiton</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#instance-normalization"><span class="nav-number">3.3.</span> <span class="nav-text">Instance Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#group-normalization"><span class="nav-number">3.4.</span> <span class="nav-text">Group Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lrnlocal-response-normalization"><span class="nav-number">3.5.</span> <span class="nav-text">LRN（Local Response
Normalization）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">3.6.</span> <span class="nav-text">参考文献</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E5%8C%96"><span class="nav-number">4.</span> <span class="nav-text">优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95gradient-descent"><span class="nav-number">4.1.</span> <span class="nav-text">梯度下降法（Gradient Descent）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE-1"><span class="nav-number">4.2.</span> <span class="nav-text">参考文献</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">5.</span> <span class="nav-text">其他参考文献</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B"><span class="nav-number">5.1.</span> <span class="nav-text">深度学习教程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0"><span class="nav-number">5.2.</span> <span class="nav-text">计算平台</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E5%90%88"><span class="nav-number">6.</span> <span class="nav-text">常用数据集合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%B1%BB"><span class="nav-number">6.1.</span> <span class="nav-text">图像类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%B1%BB"><span class="nav-number">6.2.</span> <span class="nav-text">自然语言处理类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%AD%E9%9F%B3%E7%B1%BB"><span class="nav-number">6.3.</span> <span class="nav-text">语音类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#analytics-vidhya%E5%AE%9E%E8%B7%B5%E9%97%AE%E9%A2%98"><span class="nav-number">6.4.</span> <span class="nav-text">Analytics Vidhya实践问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#more-dataset"><span class="nav-number">6.5.</span> <span class="nav-text">more dataset</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="CharlesCao"
      src="/images/bird.png">
  <p class="site-author-name" itemprop="name">CharlesCao</p>
  <div class="site-description" itemprop="description">In me the tiger sniffs the rose.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">43</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="mailto:caowenlong92@gmail.com" title="E-Mail → mailto:caowenlong92@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/5221628" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;5221628" rel="noopener" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i>StackOverflow</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/cwlseu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;cwlseu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://pytorch.org/" title="https:&#x2F;&#x2F;pytorch.org" rel="noopener" target="_blank">Pytorch</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://cplusplus.com/reference" title="https:&#x2F;&#x2F;cplusplus.com&#x2F;reference" rel="noopener" target="_blank">CppReference</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://docs.nvidia.com/cuda/index.html" title="https:&#x2F;&#x2F;docs.nvidia.com&#x2F;cuda&#x2F;index.html" rel="noopener" target="_blank">NVIDIA CUDA</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/cwlseu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.deepindeed.cn/201907/20190722-deeplearning-note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/bird.png">
      <meta itemprop="name" content="CharlesCao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deepindeed">
      <meta itemprop="description" content="In me the tiger sniffs the rose.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="认识神经网络：卷积，归一化，优化和语料 | Deepindeed">
      <meta itemprop="description" content="学习深度学习中的一些有意思的东西">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          认识神经网络：卷积，归一化，优化和语料
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-07-22 23:10:12" itemprop="dateCreated datePublished" datetime="2019-07-22T23:10:12+08:00">2019-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-09-03 04:05:26" itemprop="dateModified" datetime="2022-09-03T04:05:26+08:00">2022-09-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/blog/" itemprop="url" rel="index"><span itemprop="name">blog</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">评论数：</span>
  
    <a title="waline" href="/201907/20190722-deeplearning-note/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/201907/20190722-deeplearning-note/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>8.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

            <div class="post-description">学习深度学习中的一些有意思的东西</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="引言">引言</h2>
<p>一个基于神经网络模型的视觉模型中，<em>卷积</em>和<em>归一化层</em>是最为耗时的两种layer。卷积数据计算密集类型，今年来大量的优化主要集中在各种设备上的卷积加速。
归一化层通过计算一个批量中的均值与方差来进行特征归一化。众多实践证明，它利于优化且使得深度网络易于收敛。批统计的随机不确定性也作为一个有利于泛化的正则化项。BN
已经成为了许多顶级计算机视觉算法的基础。添加归一化层作为提高算法性能的很好的一种策略，但由于像BN遭受数据同步延时的问题，现在逐渐被一些新的normalization方式所替代。</p>
<h2 id="卷积">卷积</h2>
<h3 id="认识卷积">认识卷积</h3>
<blockquote>
<p>卷积定义</p>
</blockquote>
<p><span class="math display">\[h(x) = f(x)*g(x) = \int_{ - \infty }^{ +
\infty } {f(t)g(x - t)dt}\]</span></p>
<p><span class="math inline">\(f(t)\)</span>先不动， <span
class="math inline">\(g(-t)\)</span>相当于<span
class="math inline">\(g(t)\)</span>函数的图像沿y轴（t=0）做了一次翻转。<span
class="math inline">\(g(x-t)\)</span>相当于<span
class="math inline">\(g(-t)\)</span>的整个图像沿着t轴进行了平移，向右平移了x个单位。他们相乘之后围起来的面积就是<span
class="math inline">\(h(x)\)</span>。</p>
<blockquote>
<p>离散卷积的定义</p>
</blockquote>
<p><span class="math display">\[h(x) = f(x)*g(x) = \sum_{\tau =
-\infty}^{+\infty}f(\tau)g(x-\tau)\]</span></p>
<p>其实，深度学习中的卷积对应于数学中的cross correlation.
从卷积的定义来看，我们当前在深度学习中训练的卷积核是<strong>翻转之后的卷积核</strong>。</p>
<p>下面是一些介绍卷积的文章和常见卷积类型统计表： * <a
target="_blank" rel="noopener" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215">A
Comprehensive Introduction to Different Types of Convolutions in Deep
Learning</a> * <a target="_blank" rel="noopener" href="https://blog.yani.io/filter-group-tutorial/">A
Tutorial on Filter Groups (Grouped Convolution)</a> * AlexNet *
MobileNet * <a
target="_blank" rel="noopener" href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">An
Introduction to different Types of Convolutions in Deep Learning</a> *
<a target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic">Convolution
arithmetic</a> * <a
target="_blank" rel="noopener" href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and
Checkerboard Artifacts</a></p>
<table>
<colgroup>
<col style="width: 34%" />
<col style="width: 20%" />
<col style="width: 22%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Convolution Name</th>
<th style="text-align: left;">参考文献</th>
<th style="text-align: left;">典型代表</th>
<th style="text-align: left;">附录</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Convolution</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">AlexNet, VGG</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">1x1</td>
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.4400">Network in Network</a></td>
<td style="text-align: left;">GoogLeNet, Inception</td>
<td style="text-align: left;">(1). Dimensionality reduction for
efficient computations;<br>(2).Efficient low dimensional embedding, or
feature pooling; <br>(3). Applying nonlinearity again after
convolution</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Dilated convolution</td>
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.07122">Multi-Scale Context Aggregation
by Dilated Convolutions</a></td>
<td style="text-align: left;">语义分割</td>
<td style="text-align: left;">support exponentially expanding receptive
fields without losing resolution or coverage.
Upsampling/poolinglayer(e.g. bilinear interpolation) is deterministic.
(a.k.a. not learnable); <br> 内部数据结构丢失, 空间层级化信息丢失;
<br>小物体信息无法重建 (假设有四个pooling layer则任何小于<span
class="math inline">\(2^4=16\)</span>pixel的物体信息将理论上无法重建。)<br><a
target="_blank" rel="noopener" href="https://www.jianshu.com/p/aa1027f95b90">如何理解空洞卷积</a></td>
</tr>
<tr class="even">
<td style="text-align: left;">Group Convolution</td>
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1605.06489.pdf">Deep Roots:Improving CNN
Efficiency with Hierarchical Filter Groups</a></td>
<td style="text-align: left;">MobileNet, <a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.05431">ResNeXt</a></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pointwise grouped convolution</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">ShuffleNet</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Depthwise separable convolution</td>
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1610.02357">Xception: Deep Learning with
Depthwise Separable Convolutions</a></td>
<td style="text-align: left;">Xception</td>
<td
style="text-align: left;">MobileNet是典型的代表，通过该卷积，大大降低了计算复杂度和模型大小。也是现在落地产品中移动端常用的操作。</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Deconvolutions</td>
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and
Checkerboard Artifacts</a></td>
<td style="text-align: left;">DSSD</td>
<td
style="text-align: left;">Deconvolution也是一种常用的上采样方式，在物体分割和多尺度检测都可用到</td>
</tr>
<tr class="even">
<td style="text-align: left;">Flattened convolutions</td>
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1412.5474">Flattened convolutional neural
networks for feedforward acceleration</a></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">computation costs due to the significant
reduction of learning parameters.</td>
</tr>
</tbody>
</table>
<h3 id="卷积的实现">卷积的实现</h3>
<p>计算卷积的方法有很多种，常见的有以下几种方法: *
滑窗：这种方法是最直观最简单的方法。但是，该方法不容易实现大规模加速，因此，通常情况下不采用这种方法
(但是也不是绝对不会用，在一些特定的条件下该方法反而是最高效的.) *
im2col: 目前几乎所有的主流计算框架包括[Caffe]<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>,
MXNet等都实现了该方法。该方法把整个卷积过程转化成了GEMM过程，而GEMM在各种BLAS库中都是被极致优化的，一般来说，速度较快.
* FFT:
傅里叶变换和快速傅里叶变化是在经典图像处理里面经常使用的计算方法，但是，在
ConvNet 中通常不采用，主要是因为在 ConvNet
中的卷积模板通常都比较小，例如3×3 等，这种情况下，FFT
的时间开销反而更大. * [Winograd]<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a>: Winograd
是存在已久最近被重新发现的方法，在大部分场景中，Winograd
方法都显示和较大的优势，目前cudnn中计算卷积就使用了该方法.</p>
<h3 id="计算复杂度分析">计算复杂度分析</h3>
<ul>
<li>假设输入<span class="math inline">\(I = R^{C_0H_0W_0}\)</span>,
卷积核大小为<span class="math inline">\(k\)</span>, 输出<span
class="math inline">\(O = R^{C_1H_1W_1}\)</span>，
则卷积过程的计算量为：</li>
</ul>
<p><span class="math display">\[(k^2C_0*H_1W_1)*C_1\]</span></p>
<p>使用Depthwise separable convolution卷积的计算量为:</p>
<p><span class="math display">\[(k^2*H_1W_1*C_0 +
C_0C_1*H_1W_1)\]</span></p>
<p>那么计算量之比为</p>
<p><span class="math display">\[
\frac{(k^2*H_1W_1*C_0 + C_0C_1*H_1W_1)}{(k^2C_0*H_1W_1)*C_1}
=\frac{1}{C_1} + \frac{1}{k^2} \approx \frac{1}{k^2}
\]</span></p>
<p>一般情况下，<span class="math inline">\(k^2 &lt;&lt; C_1\)</span>,
所以当<span
class="math inline">\(k=3\)</span>的时候，计算量之比约为原来的<span
class="math inline">\(\frac{1}{9}\)</span>.</p>
<ul>
<li>假设input的<span class="math inline">\(H_0 = W_0\)</span>，用<span
class="math inline">\(w\)</span>表示，<span
class="math inline">\(k\)</span>是卷积核的大小，<span
class="math inline">\(p\)</span>表示填充的大小，<span
class="math inline">\(s\)</span>表示stride步长</li>
</ul>
<p><span class="math display">\[o = \frac{w - k + 2p}{s} +
1\]</span></p>
<h2 id="normalization">Normalization</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030329562.jpg"
alt="@归一化方法" /> 每个子图表示一个feature map张量，以<span
class="math inline">\(N\)</span>为批处理轴，<span
class="math inline">\(C\)</span>为通道轴，<span
class="math inline">\((H,W)\)</span>作为空间轴。其中蓝色区域内的像素使用相同的均值和方差进行归一化，并通过聚合计算获得这些像素的值。从示意图中可以看出，GN没有在N维度方向上进行拓展，因此batch
size之间是独立的，GPU并行化容易得多。</p>
<ul>
<li>batchNorm是在batch上，对NHW做归一化，对小batchsize效果不好；</li>
<li>layerNorm在通道方向上，对CHW归一化，主要对RNN作用明显；</li>
<li>instanceNorm在图像像素上，对HW做归一化，用在风格化迁移；</li>
<li>GroupNorm将channel分组，然后再做归一化；</li>
<li>SwitchableNorm是将BN、LN、IN结合，赋予权重，让网络自己去学习归一化层应该使用什么方法。</li>
</ul>
<h3 id="batch-normalization">Batch Normalization</h3>
<p>需要比较大的Batch Size，需要更强的计算硬件的支持。</p>
<blockquote>
<p>A small batch leads to inaccurate estimation of the batch statistics,
and reducing BN’s batch size increases the model error dramatically</p>
</blockquote>
<p>尤其是在某些需要高精度输入的任务中，BN有很大局限性。同时，BN的实现是在Batch
size之间进行的，需要大量的数据交换。</p>
<blockquote>
<p>batch normalization存在以下缺点：</p>
</blockquote>
<ul>
<li>对batchsize的大小比较敏感，由于每次计算均值和方差是在一个batch上，所以如果batchsize太小，则计算的均值、方差不足以代表整个数据分布；</li>
<li>BN实际使用时需要计算并且保存某一层神经网络batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其他sequence长很多，这样training时，计算很麻烦。（参考于https://blog.csdn.net/lqfarmer/article/details/71439314）</li>
</ul>
<h3 id="layer-normalizaiton">Layer Normalizaiton</h3>
<p>LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；
BN中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。</p>
<p>所以，LN不依赖于batch的大小和输入sequence的深度，因此可以用于batchsize为1和RNN中对边长的输入sequence的normalize操作。</p>
<h3 id="instance-normalization">Instance Normalization</h3>
<p>BN注重对每个batch进行归一化，保证数据分布一致，因为判别模型中结果取决于数据整体分布。</p>
<p>但是图像风格化中，生成结果主要依赖于某个图像实例，所以对整个batch归一化不适合图像风格化中，因而对HW做归一化。可以加速模型收敛，并且保持每个图像实例之间的独立。</p>
<h3 id="group-normalization">Group Normalization</h3>
<blockquote>
<p>GN does not exploit the batch dimension, and its computation is
independent of batch sizes.</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030329654.png"
alt="@BN,LN,IN,GN result comparison" />
从实验结果中可以看出在训练集合上GN的valid
error低于BN，但是测试结果上逊色一些。这个
可能是因为BN的均值和方差计算的时候，通过<em>随机批量抽样（stochastic
batch sampling)</em>引入了不确定性因素，这有助于模型参数正则化。
<strong>而这种不确定性在GN方法中是缺失的，这个将来可能通过使用不同的正则化算法进行改进。</strong></p>
<h3 id="lrnlocal-response-normalization">LRN（Local Response
Normalization）</h3>
<blockquote>
<p>动机</p>
</blockquote>
<p>在神经深武学有一个概念叫做侧抑制(lateral
inhibitio)，指的是被激活的神经元抑制相邻的神经元。
归一化的目的就是“抑制”，局部响应归一化就是借鉴侧抑制的思想来实现局部抑制，尤其是当我们使用ReLU
的时候，这种侧抑制很管用。</p>
<blockquote>
<p>好处</p>
</blockquote>
<p>有利于增加泛化能力，做了平滑处理，识别率提高1~2%</p>
<h3 id="参考文献">参考文献</h3>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167v2">Batch Normalization:
Accelerating Deep Network Training by Reducing Internal Covariate
Shift</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1607.06450">Jimmy Lei Ba, Jamie Ryan
Kiros, Geoffrey E. Hinton. Layer normalization.</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.08494.pdf">Group
Normalization</a></li>
<li><a
target="_blank" rel="noopener" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">AlexNet中提出的LRN</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.1556">VGG：Very Deep
Convolutional Networks for Large-Scale Image Recognition</a></li>
<li><a
target="_blank" rel="noopener" href="https://blog.csdn.net/liuxiao214/article/details/81037416">BatchNormalization、LayerNormalization、InstanceNorm、GroupNorm、SwitchableNorm总结</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1509.09308v2">Fast Algorithms for
Convolutional Neural Networks</a></li>
</ul>
<h2 id="优化">优化</h2>
<h3 id="梯度下降法gradient-descent">梯度下降法（Gradient Descent）</h3>
<p>梯度下降法是最早最简单，也是最为常用的最优化方法。梯度下降法实现简单，当目标函数是凸函数时，梯度下降法的解是全局解。
一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，
因为该方向为当前位置的最快下降方向，所以也被称为是"最速下降法"。最速下降法越接近目标值，步长越小，前进越慢。
梯度下降法的搜索迭代示意图如下图所示：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030329148.png"
alt="@梯度下降法的搜索迭代示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="梯度下降法的搜索迭代示意图">@梯度下降法的搜索迭代示意图</span></figcaption>
</figure>
<p>梯度下降法的缺点： * 靠近极小值时收敛速度减慢，如下图所示； *
直线搜索时可能会产生一些问题； * 可能会“之字形”地下降。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030329863.png"
alt="@梯度下降法的之字形示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="梯度下降法的之字形示意图">@梯度下降法的之字形示意图</span></figcaption>
</figure>
<h3 id="参考文献-1">参考文献</h3>
<ul>
<li><a
target="_blank" rel="noopener" href="https://www.quora.com/What-is-the-purpose-for-the-use-of-gradient-descent-in-machine-learning?__filter__=&amp;__nsrc__=2&amp;__snid3__=2889908801&amp;redirected_qid=31223828">梯度下降(gradient
descent)</a></li>
<li><a
target="_blank" rel="noopener" href="http://ruder.io/optimizing-gradient-descent/">梯度下降优化算法</a></li>
<li><a
target="_blank" rel="noopener" href="http://www.cnblogs.com/shixiangwan/p/7532830.html">常见的几种最优化方法</a></li>
</ul>
<h2 id="其他参考文献">其他参考文献</h2>
<h3 id="深度学习教程">深度学习教程</h3>
<p><a target="_blank" rel="noopener" href="https://cs231n.github.io/">CS231n: Convolutional Neural
Networks for Visual Recognition.</a></p>
<h3 id="计算平台">计算平台</h3>
<ol type="1">
<li><a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/ARM_architecture">arm平台</a></li>
<li><a
target="_blank" rel="noopener" href="https://www.acmesystems.it/arm9_toolchain">linux上编译arm交叉编译链</a></li>
<li><a
target="_blank" rel="noopener" href="http://preshing.com/20141119/how-to-build-a-gcc-cross-compiler/">How
to Build a GCC Cross-Compiler</a></li>
</ol>
<h2 id="常用数据集合">常用数据集合</h2>
<p>https://www.analyticsvidhya.com/blog/2018/03/comprehensive-collection-deep-learning-datasets/
这里我们列出了一组高质量的数据集，研究这些数据集将使你成为一个更好的数据科学家。
我们可以使用这些数据集来学习各种深度学习技术，也可以使用它们来磨练您的技能，理解如何识别和构造每个问题，考虑独特的应用场景!</p>
<h3 id="图像类">图像类</h3>
<table>
<colgroup>
<col style="width: 22%" />
<col style="width: 13%" />
<col style="width: 42%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: center;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
<td style="text-align: left;">50MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1710.09829.pdf">Dynamic Routing Between
Capsules</a></td>
<td
style="text-align: center;">手写数字识别，包含60000个训练数据及10000个测试数据，可分为10类</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://cocodataset.org/#home">MSCOCO</a></td>
<td style="text-align: left;">~25G</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.06870.pdf">Mask RCNN</a></td>
<td style="text-align: center;">COCO is a large-scale and rich for
object detection, segmentation and captioning dataset. 330K images, 1.5
million object instances, 80 object categories, 5 captions per image,
250,000 people with key points</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://www.image-net.org/">ImageNet</a></td>
<td style="text-align: left;">150GB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.05431.pdf">ResNeXt</a></td>
<td style="text-align: center;">ImageNet is a dataset of images that are
organized according to the WordNet hierarchy. WordNet contains
approximately 100,000 phrases and ImageNet has provided around 1000
images on average to illustrate each phrase. Number of Records: Total
number of images: ~1,500,000; each with multiple bounding boxes and
respective class labels</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://github.com/openimages/dataset#download-the-data">Open
Image Dataset</a></td>
<td style="text-align: left;">500GB</td>
<td style="text-align: center;"><a href="">ResNet</a></td>
<td style="text-align: center;">一个包含近900万个图像URL的数据集。
这些图像拥有数千个类别及边框进行了注释。
该数据集包含9,011219张图像的训练集，41,260张图像的验证集以及125,436张图像的测试集。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://www.visualqa.org/">VisualQA</a></td>
<td style="text-align: left;">25GB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.02711">Tips and Tricks for Visual
Question Answering: Learnings from the 2017 Challenge</a></td>
<td style="text-align: center;">图像的问答系统数据集 265,016 images, at
least 3 questions per image, 10 ground truth answers per question</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://ufldl.stanford.edu/housenumbers/">The Street View House
Numbers(SVHN)</a></td>
<td style="text-align: left;">2.5GB</td>
<td style="text-align: center;"><a href="">Distributional Smoothing With
Virtual Adversarial Training</a></td>
<td
style="text-align: center;">门牌号数据集，可用来做物体检测与识别</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
<td style="text-align: left;">170MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://openreview.net/pdf?id=S1NHaMW0b">ShakeDrop
regularization</a></td>
<td style="text-align: center;">图像识别数据集，包含
50000张训练数据，10000张测试数据，可分为10类</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a></td>
<td style="text-align: left;">30MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.04896">Random Erasing Data
Augmentation</a></td>
<td
style="text-align: center;">包含60000训练样本和10000测试样本的用于服饰识别的数据集，可分为10类。</td>
</tr>
</tbody>
</table>
<h3 id="自然语言处理类">自然语言处理类</h3>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 13%" />
<col style="width: 43%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: left;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://ai.stanford.edu/~amaas/data/sentiment/">IMDB
影评数据</a></td>
<td style="text-align: left;">80MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.09207">Learning Structured Text
Representations</a></td>
<td
style="text-align: left;">可以实现对情感的分类，除了训练集和测试集示例之外，还有更多未标记的数据。原始文本和预处理的数据也包括在内。25,000
highly polar movie reviews for training, and 25,000 for testing</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups">Twenty
Newsgroups</a></td>
<td style="text-align: left;">20MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.01781">Very Deep Convolutional Networks
for Text Classification</a></td>
<td
style="text-align: left;">包含20类新闻的文章信息，内类包含1000条数据</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://help.sentiment140.com/for-students/">Sentiment140</a></td>
<td style="text-align: left;">80MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/W17-5202">Assessing
State-of-the-Art Sentiment Models on State-of-the-Art Sentiment
Datasets</a></td>
<td style="text-align: left;">1,60,000 tweets,用于情感分析的数据集</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://wordnet.princeton.edu/">WordNet</a></td>
<td style="text-align: left;">10MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://aclanthology.info/pdf/R/R11/R11-1097.pdf">Wordnets: State
of the Art and Perspectives</a></td>
<td style="text-align: left;">117,000 synsets is linked to other synsets
by means of a small number of “conceptual relations.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://www.yelp.com/dataset">Yelp点评数据集</a></td>
<td style="text-align: left;">2.66GB JSON文件,2.9GB
SQL文件,7.5GB图片数据</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1710.00519.pdf">Attentive
Convolution</a></td>
<td
style="text-align: left;">包括470万条用户评价，15多万条商户信息，20万张图片，12个大都市。此外，还涵盖110万用户的100万条tips，超过120万条商家属性（如营业时间、是否有停车场、是否可预订和环境等信息），随着时间推移在每家商户签到的总用户数。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://nlp.cs.nyu.edu/wikipedia-data/">维基百科语料库（英语）</a></td>
<td style="text-align: left;">20MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1711.03953.pdf">Breaking The Softmax
Bottelneck: A High-Rank RNN language Model</a></td>
<td style="text-align: left;">包含4400000篇文章
及19亿单词，可用来做语言建模</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm">博客作者身份语料库</a></td>
<td style="text-align: left;">300MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1609.06686.pdf">Character-level and
Multi-channel Convolutional Neural Networks for Large-scale Authorship
Attribution</a></td>
<td
style="text-align: left;">从blogger.com收集到的19,320名博主的博客，其中博主的信息包括博主的ID、性别、年龄、行业及星座</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://statmt.org/wmt18/index.html">各种语言的机器翻译数据集</a></td>
<td style="text-align: left;">15GB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Attention Is All You
Need</a></td>
<td style="text-align: left;">包含英-汉、英-法、英-捷克、英语-
爱沙尼亚、英 - 芬兰、英-德、英 - 哈萨克、英 - 俄、英 -
土耳其之间互译的数据集</td>
</tr>
</tbody>
</table>
<h3 id="语音类">语音类</h3>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 13%" />
<col style="width: 43%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: left;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://github.com/Jakobovski/free-spoken-digit-dataset">Free
Spoken Digit Dataset</a></td>
<td style="text-align: left;">10MB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1712.00866">Raw Waveform-based Audio
Classification Using Sample-level CNN Architectures</a></td>
<td
style="text-align: left;">数字语音识别数据集，包含3个人的声音，每个数字说50遍，共1500条数据</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://github.com/mdeff/fma">Free Music Archive (FMA)</a></td>
<td style="text-align: left;">1000GB</td>
<td style="text-align: center;"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.05337.pdf">Learning to Recognize
Musical Genre from Audio</a></td>
<td
style="text-align: left;">可以用于对音乐进行分析的数据集，数据集中包含歌曲名称、音乐类型、曲目计数等信息。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://mtg.upf.edu/ismir2004/contest/tempoContest/node5.html">Ballroom</a></td>
<td style="text-align: left;">14GB</td>
<td style="text-align: center;"><a href="">A Multi-Model Approach To
Beat Tracking Considering Heterogeneous Music Styles</a></td>
<td
style="text-align: left;">舞厅舞曲数据集，可对舞曲风格进行识别。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="https://labrosa.ee.columbia.edu/millionsong/">Million Song
Dataset</a></td>
<td style="text-align: left;">280GB</td>
<td style="text-align: center;"><a href="">Preliminary Study on a
Recommender System for the Million Songs Dataset Challenge</a></td>
<td style="text-align: left;">Echo
Nest提供的一百万首歌曲的特征数据.该数据集不包含任何音频，但是可以使用他们提供的代码下载音频</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="ttp://www.openslr.org/12/">LibriSpeech</a></td>
<td style="text-align: left;">60GB</td>
<td style="text-align: center;"><a href="">Letter-Based Speech
Recognition with Gated ConvNets</a></td>
<td
style="text-align: left;">包含1000小时采样频率为16Hz的英语语音数据及所对应的文本，可用作语音识别</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
target="_blank" rel="noopener" href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/">VoxCeleb</a></td>
<td style="text-align: left;">150MB</td>
<td style="text-align: center;">VoxCeleb: a large-scale speaker
identification dataset]()</td>
<td style="text-align: left;">大型的说话人识别数据集。
它包含约1,200名来自YouTube视频的约10万个话语。
数据在性别是平衡的（男性占55％）。说话人跨越不同的口音，职业和年龄。
可用来对说话者的身份进行识别。</td>
</tr>
</tbody>
</table>
<h3 id="analytics-vidhya实践问题">Analytics Vidhya实践问题</h3>
<ul>
<li><a
target="_blank" rel="noopener" href="https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/register">Twitter情绪分析</a>
<ul>
<li>描述：识别是否包含种族歧视及性别歧视的推文。</li>
<li>大小：3MB</li>
<li>31,962 tweets</li>
</ul></li>
<li><a
target="_blank" rel="noopener" href="https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/">印度演员的年龄识别数据集</a>
<ul>
<li>描述：根据人的面部属性，识别人的年龄的数据集。</li>
<li>大小：48MB</li>
<li>19,906 images in the training set and 6636 in the test set</li>
</ul></li>
<li><a
target="_blank" rel="noopener" href="https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/">城市声音分类数据集</a>
<ul>
<li>描述：该数据集包含来自10个类的城市声音的8732个标记的声音片段，每个片段时间小于4秒。</li>
<li>大小：训练数据集3GB，训练数据集2GB。</li>
<li>8732 labeled sound excerpts (&lt;=4s) of urban sounds from 10
classes</li>
</ul></li>
</ul>
<h3 id="more-dataset">more dataset</h3>
<ul>
<li><a
target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2018-09-05-2">机器之心整理的数据集合</a></li>
<li><a
target="_blank" rel="noopener" href="https://github.com/Prasanna1991/DHCD_Dataset">DHCD_Dataset</a></li>
</ul>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://github.com/BVLC/caffe/blob/master/src/caffe/util/im2col.cpp<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>https://arxiv.org/abs/1509.09308v2<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

    </div>

    
    
    
      


    <footer class="post-footer"><div class="post-widgets">
    <div
      class="social-share"
      
        data-sites="weibo,qq,wechat,tencent,douban,qzone,linkedin,diandian,facebook,twitter,google"
      
      
        data-wechat-qrcode-title="share.title"
      
      
        data-wechat-qrcode-helper="share.prompt"
      
    >
    </div>
  </div>
  <script src="https://lib.baomitu.com/social-share.js/1.0.16/js/social-share.min.js"></script>
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>CharlesCao
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://www.deepindeed.cn/201907/20190722-deeplearning-note/" title="认识神经网络：卷积，归一化，优化和语料">http://www.deepindeed.cn/201907/20190722-deeplearning-note/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
              <a href="/tags/CV/" rel="tag"># CV</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/201907/20190714-detection/" rel="prev" title="Detection算法Overview">
                  <i class="fa fa-chevron-left"></i> Detection算法Overview
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/201908/20190809-scene-text-detection-component/" rel="next" title="自然场景文本检测与识别">
                  自然场景文本检测与识别 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CharlesCao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">473k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">13:08</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>
<script class="next-config" data-name="gitter" type="application/json">{"enable":true,"room":null}</script>
<script src="/js/third-party/chat/gitter.js"></script>
<script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@9.0.1/dist/mermaid.min.js","integrity":"sha256-CemUs9ITT7liCZpVMktcEw0BpAOZ1+mujlMB3UyuImU="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://waline.vercel.app","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":false,"libUrl":"https://unpkg.com/@waline/client@v2/dist/waline.js","locale":{"placeholder":"欢迎交流指正"},"emoji":["https://unpkg.com/@waline/emojis@1.0.1/weibo","https://unpkg.com/@waline/emojis@1.0.1/alus","https://unpkg.com/@waline/emojis@1.0.1/bilibili","https://unpkg.com/@waline/emojis@1.0.1/qq","https://unpkg.com/@waline/emojis@1.0.1/tieba","https://unpkg.com/@waline/emojis@1.0.1/tw-emoji"],"meta":["nick","mail"],"requiredMeta":["mail","nick","mail"],"login":"enable","el":"#waline","comment":true,"path":"/201907/20190722-deeplearning-note/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>

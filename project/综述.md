[1]  Krizhevsky A, Ilya S, Hinton G.E. ImageNet Classification with Deep Convolutional Neural Networks[C].in Advances In Neural Information Processing Systems, 2012, pp. 1–9.
[2]	Ren Shaoqing, He Kaiming, Girshick R et al. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks[C]. in Advances In Neural Information Processing Systems, 2015, pp. 1–10.
[3]	Chellapilla K, Puri S, Simard P. High Performance Convolutional Neural Networks for Document Processing[C]. in Tenth International Workshop on Frontiers in Handwriting Recognition, 2006, pp. 1–7.
[4]	Han Song, Pool J ,William J et al. Learning both Weights and Connections for Efficient Neural Networks[C]. NIPS, 2015, pp. 1–9.
[5]	Cireşan D.C, Meier U , Masci J et al. High-Performance Neural Networks for Visual Object Classification[C].  in Advances In Neural Information Processing Systems, 2011, p. 12.
[6]	Hinton G.E, Srivastava N,Krizhevsky A et al. Improving neural networks by preventing co-adaptation of feature detectors[J]. Computer Science, vol. 3, no. 4, pp. 212–223, 2012.
[7]	LeCun Y, Denker J.S, Solla S.A et al. Optimal Brain Damage[C], in International Conference on Neural Information, vol. 2, no. 279, pp. 598–605, 1989.
[8]	Li Wan, Zelier M , Zhang Sixin et al. Regularization of Neural Networks using DropConnect [C].  in International Conference on Machine Learning (ICML), 2013, pp. 1058–1066.
[9]	Li Zhe, Gong Boqing, Yang Tianbao. Improved Dropout for Shallow and Deep Learning[C].  in International Conference on Machine Learning (ICML) Workshop on Resource-Efficient Machine Learning, 2016, pp. 1–9.
[10]	Lebedev V , Lempitsky V. Fast ConvNets Using Group-wise Brain Damage[C]. in Computer Vision and Pattern Recognition (CVPR), 2016, pp. 2554–2564.
[11]	Mao Huizi, Han Song, Pool J et al. Exploring the Regularity of Sparse Structure in Convolutional Neural Networks[C]. in the 31st Conference on Neural Information Processing Systems, 2017, pp. 1–10.
[12]	Chen Wenlin, Wilson J. T, Tyree S et al. Compressing Neural Networks with the Hashing Trick[J]. Computer Science, pp. 2285–2294, 2015.
[13]	Zhang Xianyu, Zou Jianhua , Ming Xiang et al. Efficient and Accurate Approximations of Nonlinear Convolutional Networks[C]. in the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.
[14] Denil M, Shakibi B, Dinh L et al. Predicting Parameters in Deep Learning[C]. in International Conference on Neural Information Processing Systems, 2013, pp. 2148–2156.
[15]	Gong Yunchao, Liu Liu, Yang Ming et al. Compressing deep convolutional networks using vector quantization[J].  Computer Science, pp. 1–10, 2014.
[16]	Wu Jiaxiang, Leng Cong, Wang Yuhang et al. Quantized Convolutional Neural Networks for Mobile Devices[C], in IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 4820–4828.
[17]	Hinton G.E, Vinyals O, Dean J. Distilling the Knowledge in a Neural Network[J], Computer Science., vol. 14, no. 7, pp. 38–39, 2015.
[18]	Denton E, Zaremba W, Bruna J et al. Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation[C]. in International Conference on Neural Information, 2014, pp. 1269–1277.
[19]	Yang Zichao, Moczulski M, Denil M et al. Deep Fried Convnets[C]. in IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 1476–1483.
[20]	Lebedev V, Ganin Y, Rakhuba1 M et al. Speeding-Up Convolutional Neural Networks Using Fine-tuned CP-Decomposition[C]. in International Conference on Learning Representations, 2015, pp. 1–10.
[21]	Jaderberg M, Vedaldi A, Zisserman A. Speeding up Convolutional Neural Networks with Low Rank Expansions[J]. Computer Science, vol. 4, no. 4, pp. 1–7, 2014.
[22]	Szegedy C, Liu Wei, Jia Yangqing et al. Going deeper with convolutions[C].in the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 1–9.
[23] Lin Min, Chen Qiang, Yan Shuicheng. Network In Network[C]. in International Conference on Learning Representations, 2014, pp. 1–10.
[24]	He Kaiming, Zhang Xiangyu, Ren Shaoqing et al. Deep Residual Learning for Image Recognition[C].in Computer Vision and Pattern Recognition, 2015, vol. 7, no. 3, pp. 171–180.
[25]	Kim K.H, Hong S, Roh B et al. PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection[J/OL]. (2016-09-30)[2017-05-12]. https://arxiv.org/abs/1608.08021v3
[26]	Lin Shaohui, Ji Rongrong ,Guo Xiaowei et al. Towards Convolutional Neural Networks Compression via Global Error Reconstruction[C].  Proc. 25th Int. Jt. Conf. Artif. Intell. (IJCAI 2016), pp. 1753–1759, 2016.
[27]	Redmon J, Farhadi A. YOLO9000: Better, Faster, Stronger[C].  in Computer Vision and Pattern Recognition (CVPR), 2016.
[28]	Courbariaux M , Bengio Y et al. BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1[OL], (2016-3-17)[2017-4-10]. https://arxiv.org/abs/1602.02830
[29]	Rastegari M, Ordonez V, Redmon J et al. XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks[J] Springer Int. Publ., pp. 525–542, 2016.
[30]	Li Zefan, Ni Bingbing , Zhang Wenjun et al. Performance Guaranteed Network Acceleration via High-Order Residual Quantization[C].  in International Conference on Computer Vision(ICCV), 2017, pp. 1–9.
[31]	Lin Kevin, Yang HueiFang, Hsiao Jenhao et al. Deep Learning of Binary Hash Codes for Fast Image Retrieval Large-scale Image Search Query[C]. in IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2015, pp. 27–35.
[32]	Mu Yadong , Liu Zhu et al. Deep Hashing: A Joint Approach for Image Signature Learning[J/OL].(2016-8-12)[2017-5-12]. https://arxiv.org/abs/1608.03658
[33]	Han Song, Mao Huizi, Dally W. J.  Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding[C].in International Conference on Learning Representations, 2016, pp. 1–13.
[34]	Girshick R. Fast R-CNN[C]. in the International Conference on Computer Vision, 2015, pp. 1–9.
[35]	Liu Hong, Ji Rongrong , Wu Yongjian et al. Supervised Matrix Factorization for Cross-Modality Hashing[C]. in International Joint Conference on Artificail Intelligent(IJCAI), pp. 1767–1773, 2016.

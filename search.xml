<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>近邻查询近似算法库FLANN</title>
    <url>/202208/20160907-Flann/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>近似近邻算法在大型应用中是解决搜索的关键技术。而近似近邻算法的研究中，一部分是基于树结构实现的，一部分是基于hash算法。今FLANN是一个开源库，opencv中已经集成了该module.</p>
<ul>
<li>github: <a href="https://github.com/mariusmuja/flann.git">FLANN -
Fast Library for Approximate Nearest Neighbors</a></li>
</ul>
<h2 id="红黑树">红黑树</h2>
<p>https://blog.csdn.net/weewqrer/article/details/51866488</p>
<h3 id="用途">用途</h3>
<p>红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保。对于查找、插入、删除、最大、最小等动态操作的时间复杂度为O(lgn).常见的用途有以下几种：
- STL（标准模板库）中在set map是基于红黑树实现的。 -
Java中在TreeMap使用的也是红黑树。 -
epoll在内核中的实现，用红黑树管理事件块。 - linux进程调度Completely Fair
Scheduler,用红黑树管理进程控制块</p>
<h3 id="红黑树-vs-avl树">红黑树 VS AVL树</h3>
<p>常见的平衡树有红黑树和AVL平衡树，为什么STL和linux都使用红黑树作为平衡树的实现？大概有以下几个原因：</p>
<p>从实现细节上来讲，如果插入一个结点引起了树的不平衡，AVL树和红黑树都最多需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度</p>
<p>从两种平衡树对平衡的要求来讲，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。</p>
<p>总体来说，RB-tree的统计性能是高于AVL的</p>
<h2 id="flann概述">FLANN概述</h2>
<p>首先阐述了近似结果查询的重要性，通过实验结果分析了最有效的近似nn算法中，随机KD森林是最有效的，另外提出了一个新的方法：优先查找k-means树，尤其是针对视觉任务中常用的二进制特征，提出了多层聚类树。为了应用于大数据环境下，还有分布式环境下nn查找框架。</p>
<h2 id="相关名词定义">相关名词定义</h2>
<ol type="1">
<li>KNN(K-nearest neighbor
search)：说白了，就是从数据集合了找K个最接近的</li>
<li>RNN(radius nearest neighbor
search)：就是返回一定半径范围内的所有数据。当然这个半径有很多不同的定义。</li>
</ol>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li><a
href="http://www.cnblogs.com/eyeszjwang/articles/2429382.html">K-D
Tree</a></li>
<li><a
href="http://blog.csdn.net/zhouxuguang236/article/details/7898272">R
树简介</a></li>
<li><a
href="http://blog.csdn.net/v_JULY_v/article/details/6530142/">从B树、B+树、B*树谈到R
树</a></li>
<li><a
href="http://www.ahathinking.com/archives/136.html">线段树</a></li>
<li><a
href="https://blog.csdn.net/v_JULY_v/article/details/6285620">红黑树</a></li>
</ol>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习：玩转Caffe</title>
    <url>/201703/20170321-train-use-caffe/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>最近实验中又跟caffe打交道，虽然caffe好用，但是要想让caffe启动训练起来，还真得费一番功夫。数据处理，模型文件编写，预训练模型的选择等等。</p>
<h2 id="imagenet的数据预处理">ImageNet的数据预处理</h2>
<h3 id="常见image-list">1. 常见image list</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">root_dir=$HOME/data/VOCdevkit/</span><br><span class="line">sub_dir=ImageSets/Main</span><br><span class="line">bash_dir=&quot;$(cd &quot;$(dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot;)&quot; &amp;&amp; pwd)&quot;</span><br><span class="line">for dataset in trainval test</span><br><span class="line">do</span><br><span class="line">  dst_file=$bash_dir/$dataset.txt</span><br><span class="line">  if [ -f $dst_file ]</span><br><span class="line">  then</span><br><span class="line">    rm -f $dst_file</span><br><span class="line">  fi</span><br><span class="line">  for name in VOC2007 VOC2012</span><br><span class="line">  do</span><br><span class="line">    if [[ $dataset == &quot;test&quot; &amp;&amp; $name == &quot;VOC2012&quot; ]]</span><br><span class="line">    then</span><br><span class="line">      continue</span><br><span class="line">    fi</span><br><span class="line">    echo &quot;Create list for $name $dataset...&quot;</span><br><span class="line">    dataset_file=$root_dir/$name/$sub_dir/$dataset.txt</span><br><span class="line"></span><br><span class="line">    img_file=$bash_dir/$dataset&quot;_img.txt&quot;</span><br><span class="line">    cp $dataset_file $img_file</span><br><span class="line">    sed -i &quot;s/^/$name\/JPEGImages\//g&quot; $img_file</span><br><span class="line">    sed -i &quot;s/$/.jpg/g&quot; $img_file</span><br><span class="line"></span><br><span class="line">    label_file=$bash_dir/$dataset&quot;_label.txt&quot;</span><br><span class="line">    cp $dataset_file $label_file</span><br><span class="line">    sed -i &quot;s/^/$name\/Annotations\//g&quot; $label_file</span><br><span class="line">    sed -i &quot;s/$/.xml/g&quot; $label_file</span><br><span class="line"></span><br><span class="line">    paste -d&#x27; &#x27; $img_file $label_file &gt;&gt; $dst_file</span><br><span class="line"></span><br><span class="line">    rm -f $label_file</span><br><span class="line">    rm -f $img_file</span><br><span class="line">  done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Generate image name and size infomation.</span></span><br><span class="line">  if [ $dataset == &quot;test&quot; ]</span><br><span class="line">  then</span><br><span class="line">    $bash_dir/../../build/tools/get_image_size $root_dir $dst_file $bash_dir/$dataset&quot;_name_size.txt&quot;</span><br><span class="line">  fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Shuffle trainval file.</span></span><br><span class="line">  if [ $dataset == &quot;trainval&quot; ]</span><br><span class="line">  then</span><br><span class="line">    rand_file=$dst_file.random</span><br><span class="line">    cat $dst_file | perl -MList::Util=shuffle -e &#x27;print shuffle(&lt;STDIN&gt;);&#x27; &gt; $rand_file</span><br><span class="line">    mv $rand_file $dst_file</span><br><span class="line">  fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h3 id="生成backend为leveldb或者lmdb">2.
生成backend为leveldb或者lmdb</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env sh</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Create the imagenet lmdb inputs</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">N.B. <span class="built_in">set</span> the path to the imagenet train + val data <span class="built_in">dirs</span></span></span><br><span class="line">set -e</span><br><span class="line"></span><br><span class="line">DATA=$HOME/data/VOCdevkit</span><br><span class="line">TOOLS=$HOME/caffe/build/tools</span><br><span class="line"></span><br><span class="line">EXAMPLE=$&#123;DATA&#125;/VOC0712/lmdb</span><br><span class="line">TRAIN_DATA_ROOT=$&#123;DATA&#125;/</span><br><span class="line">VAL_DATA_ROOT=$&#123;DATA&#125;/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Set RESIZE=<span class="literal">true</span> to resize the images to 256x256. Leave as <span class="literal">false</span> <span class="keyword">if</span> images have</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">already been resized using another tool.</span></span><br><span class="line">RESIZE=true</span><br><span class="line">if $RESIZE; then</span><br><span class="line">  RESIZE_HEIGHT=256</span><br><span class="line">  RESIZE_WIDTH=256</span><br><span class="line">else</span><br><span class="line">  RESIZE_HEIGHT=0</span><br><span class="line">  RESIZE_WIDTH=0</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo &quot;Creating train lmdb...&quot;</span><br><span class="line"></span><br><span class="line">GLOG_logtostderr=1 $TOOLS/convert_imageset \</span><br><span class="line">    --resize_height=$RESIZE_HEIGHT \</span><br><span class="line">    --resize_width=$RESIZE_WIDTH \</span><br><span class="line">    --shuffle \</span><br><span class="line">    $TRAIN_DATA_ROOT \</span><br><span class="line">    $DATA/trainval.txt \</span><br><span class="line">    $EXAMPLE/voc0712_train_lmdb</span><br><span class="line"></span><br><span class="line">echo &quot;Creating val lmdb...&quot;</span><br><span class="line"></span><br><span class="line">GLOG_logtostderr=1 $TOOLS/convert_imageset \</span><br><span class="line">    --resize_height=$RESIZE_HEIGHT \</span><br><span class="line">    --resize_width=$RESIZE_WIDTH \</span><br><span class="line">    --shuffle \</span><br><span class="line">    $VAL_DATA_ROOT \</span><br><span class="line">    $DATA/test.txt \</span><br><span class="line">    $EXAMPLE/voc0712_val_lmdb</span><br><span class="line"></span><br><span class="line">echo &quot;Done.&quot;</span><br></pre></td></tr></table></figure>
<h3 id="proto中配置使用">3. proto中配置使用</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Data&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    source: &quot;/home/lixx/data/VOCdevkit/VOC0712/lmdb/voc0712_train_lmdb&quot;</span><br><span class="line">    #source: &quot; /home/lixx/data/VOCdevkit/VOC0712/voc0712_train_leveldb&quot;</span><br><span class="line">    mean_file: &quot;/home/lixx/data/VOCdevkit/VOC0712/voc0712_mean.binaryproto&quot;</span><br><span class="line">    batch_size: 16 </span><br><span class="line">    crop_size: 227 </span><br><span class="line">    # 数据类型，默认情况下为leveldb</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param&#123;</span><br><span class="line">    mirror: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中具体的参数需要参考caffe.proto文件进行查看，进行正确的配置</p>
<h2 id="训练模型">训练模型</h2>
<h3 id="学习率">1、学习率</h3>
<p>步长的选择：你走的距离长短，越短当然不会错过，但是耗时间。步长的选择比较麻烦。步长越小，越容易得到局部最优化（到了比较大的山谷，就出不去了），而大了会全局最优。一般来说，如ResNet前32k步，很大，0.1；到了后面，迭代次数增高，下降0.01，再多，然后再小一些。
<img data-src="https://cwlseu.github.io/images/linux/lr.png"
alt="@lr 随着epoch的增加变化曲线" /> ###
2、caffe训练时Loss变为nan的原因<a href="#fn1" class="footnote-ref"
id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<h4 id="由小变大易出nan">由小变大易出nan</h4>
<p><strong>原因</strong>：有小变大过程中，某个梯度值变得特别大，使得学习过程难以为继</p>
<p>例如：<code>10x10x256</code>的输入，输出如果是<code>20x20x256</code>或者<code>10x10x512</code>，如果是使用Inception-ResNet-v2或者直接进行卷积操作，很容易出现nan的情况。</p>
<blockquote>
<p>具体解决方案： - 参考<a
href="http://cwlseu.github.io/Inception">Inception的设计原则</a>重新设计网络
- 添加Batch normalization试试</p>
</blockquote>
<h4
id="使用resnet-block或者inception技术最后的结果通过bitwise-operation进行组合而不是采用按channel-concatenate进行的">使用ResNet-Block或者Inception技术，最后的结果通过Bitwise
Operation进行组合，而不是采用按channel Concatenate进行的。</h4>
<blockquote>
<p>尤其是BitWise
multi进行组合的时候，往往会产生很大的数据悬殊，会导致梯度爆炸现象从而出现Loss
为nan</p>
</blockquote>
<h3 id="梯度爆炸">3、梯度爆炸</h3>
<p><strong>原因</strong>：梯度变得非常大，使得学习过程难以继续</p>
<p><strong>现象</strong>：观察log，注意每一轮迭代后的loss。loss随着每轮迭代越来越大，最终超过了浮点型表示的范围，就变成了NaN。</p>
<p><strong>措施</strong>： -
减小solver.prototxt中的<code>base_lr</code>，至少减小一个数量级。如果有多个<code>loss layer</code>，需要找出哪个损失层导致了梯度爆炸，并在train_val.prototxt中减小该层的<code>loss_weight</code>，而非是减小通用的<code>base_lr</code>。
- 设置<code>clip gradient</code>，用于限制过大的<code>diff</code></p>
<h4 id="不当的损失函数">不当的损失函数</h4>
<p><strong>原因</strong>：有时候损失层中loss的计算可能导致NaN的出现。比如，给InfogainLoss层（信息熵损失）输入没有归一化的值，使用带有bug的自定义损失层等等。</p>
<p><strong>现象</strong>：观测训练产生的log时一开始并不能看到异常，loss也在逐步的降低，但突然之间NaN就出现了。</p>
<p><strong>措施</strong>：看看你是否能重现这个错误，在loss
layer中加入一些输出以进行调试。
示例：有一次我使用的loss归一化了batch中label错误的次数。如果某个label从未在batch中出现过，loss就会变成NaN。在这种情况下，可以用足够大的batch来尽量避免这个错误。</p>
<h4 id="不当的输入">不当的输入</h4>
<p><strong>原因</strong>：输入中就含有NaN。</p>
<p><strong>现象</strong>：每当学习的过程中碰到这个错误的输入，就会变成NaN。观察log的时候也许不能察觉任何异常，loss逐步的降低，但突然间就变成NaN了。</p>
<p><strong>措施</strong>：重整你的数据集，确保训练集和验证集里面没有损坏的图片。调试中你可以使用一个简单的网络来读取输入层，有一个缺省的loss，并过一遍所有输入，如果其中有错误的输入，这个缺省的层也会产生NaN。</p>
<h3 id="caffe-debug-info34">4、Caffe Debug info<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a><a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></h3>
<p>当我们训练过程面临nan,
loss不收敛的情况，可以打开<code>solver.prototxt</code>中的<code>debuf_info:true</code>进行查错。</p>
<pre><code>    I1109 ...]     [Forward] Layer data, top blob data data: 0.343971    
    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037
    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114
    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0
    I1109 ...]     [Forward] Layer relu1, top blob conv1 data: 0.0337982
    I1109 ...]     [Forward] Layer conv2, top blob conv2 data: 0.0249297
    I1109 ...]     [Forward] Layer conv2, param blob 0 data: 0.00875855
    I1109 ...]     [Forward] Layer conv2, param blob 1 data: 0
    I1109 ...]     [Forward] Layer relu2, top blob conv2 data: 0.0128249
    . 
    .
    .
    I1109 ...]     [Forward] Layer fc1, top blob fc1 data: 0.00728743
    I1109 ...]     [Forward] Layer fc1, param blob 0 data: 0.00876866
    I1109 ...]     [Forward] Layer fc1, param blob 1 data: 0
    I1109 ...]     [Forward] Layer loss, top blob loss data: 2031.85
    I1109 ...]     [Backward] Layer loss, bottom blob fc1 diff: 0.124506
    I1109 ...]     [Backward] Layer fc1, bottom blob conv6 diff: 0.00107067
    I1109 ...]     [Backward] Layer fc1, param blob 0 diff: 0.483772
    I1109 ...]     [Backward] Layer fc1, param blob 1 diff: 4079.72
    .
    .
    .
    I1109 ...]     [Backward] Layer conv2, bottom blob conv1 diff: 5.99449e-06
    I1109 ...]     [Backward] Layer conv2, param blob 0 diff: 0.00661093
    I1109 ...]     [Backward] Layer conv2, param blob 1 diff: 0.10995
    I1109 ...]     [Backward] Layer relu1, bottom blob conv1 diff: 2.87345e-06
    I1109 ...]     [Backward] Layer conv1, param blob 0 diff: 0.0220984
    I1109 ...]     [Backward] Layer conv1, param blob 1 diff: 0.0429201
    E1109 ...]     [Backward] All net params (data, diff): L1 norm = (2711.42, 7086.66); L2 norm = (6.11659, 4085.07) </code></pre>
<p>At first glance you can see this log section divided into two:
<code>[Forward]</code> and <code>[Backward]</code>. Recall that neural
network training is done via forward-backward propagation: A training
example (batch) is fed to the net and a forward pass outputs the current
prediction. Based on this prediction a loss is computed. The loss is
then derived, and a gradient is estimated and propagated backward using
the chain rule.</p>
<h4 id="caffe-blob-data-structure">Caffe Blob data structure</h4>
<p>Just a quick re-cap. Caffe uses Blob data structure to store
data/weights/parameters etc. For this discussion it is important to note
that <code>Blob</code> has two "parts": <code>data</code> and
<code>diff</code>. The values of the Blob are stored in the data part.
The diff part is used to store element-wise gradients for the
backpropagation step.</p>
<h4 id="forward-pass">Forward pass</h4>
<p>You will see all the layers from bottom to top listed in this part of
the log. For each layer you'll see:</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037
    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114
    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0</code></pre>
<p>Layer "conv1" is a convolution layer that has 2 param blobs: the
filters and the bias. Consequently, the log has three lines. The filter
blob (param <code>blob 0</code>) has data</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114</code></pre>
<p>That is the current L2 norm of the convolution filter weights is
0.00899. The current bias (param <code>blob 1</code>):</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0</code></pre>
<p>meaning that currently the bias is set to 0.</p>
<p>Last but not least, "conv1" layer has an output, "top" named "conv1"
(how original...). The L2 norm of the output is</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037</code></pre>
<p>Note that all L2 values for the [Forward] pass are reported on the
data part of the Blobs in question.</p>
<h4 id="loss-and-gradient">Loss and gradient</h4>
<p>At the end of the [Forward] pass comes the loss layer:</p>
<pre><code>    I1109 ...]     [Forward] Layer loss, top blob loss data: 2031.85
    I1109 ...]     [Backward] Layer loss, bottom blob fc1 diff: 0.124506</code></pre>
<p>In this example the batch loss is 2031.85, the gradient of the loss
w.r.t. <code>fc1</code> is computed and passed to <code>diff</code> part
of fc1 Blob. The L2 magnitude of the gradient is 0.1245.</p>
<h4 id="backward-pass">Backward pass</h4>
<p>All the rest of the layers are listed in this part top to bottom. You
can see that the L2 magnitudes reported now are of the diff part of the
Blobs (params and layers' inputs).</p>
<h4 id="finally">Finally</h4>
<p>The last log line of this iteration:</p>
<pre><code>    [Backward] All net params (data, diff): L1 norm = (2711.42, 7086.66); L2 norm = (6.11659, 4085.07)</code></pre>
<p>reports the total L1 and L2 magnitudes of both data and
gradients.</p>
<h4 id="what-should-i-look-for">What should I look for?</h4>
<ul>
<li>If you have nans in your loss, see at what point your data or diff
turns into nan: at which layer? at which iteration?</li>
<li>Look at the gradient magnitude, they should be reasonable. IF you
are starting to see values with e+8 your data/gradients are starting to
blow off. Decrease your learning rate!</li>
<li>See that the diffs are not zero. Zero diffs mean no gradients = no
updates = no learning.</li>
</ul>
<h2 id="tools事半功倍">Tools事半功倍</h2>
<h3 id="caffe-tools">1、caffe tools</h3>
<p><code>caffe</code>可执行文件可以有不同的选项进行选择功能，功能选择是通过功能函数指针注册的方式实现的，在<code>tools/caffe.cpp</code>中有，其中的<a
href="http://cwlseu.github.io/Cpp-Relearn">注册功能部分</a>大家有兴趣可以学习一下，这块还是很有趣的。</p>
<h3 id="分析train-log">2、分析train log</h3>
<p>在<code>caffe/tools/extra</code>下有分析log的各种脚本，你可以使用<code>gnuplot</code>继续绘制，也可以采用python的<code>matplot</code></p>
<ol type="1">
<li><p>如果想提取log的关键信息，可以查看<code>parse_log.sh</code>或者<code>parse_log.py</code></p></li>
<li><p>如果想绘制采用绘制
<code>python tools/extra/plot_training_log.py 2 examples/ooxx/result/result.png jobs/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321.log</code></p></li>
</ol>
<p>This script mainly serves as the basis of your customizations.
Customization is a must. You can copy, paste, edit them in whatever way
you want. Be warned that the fields in the training log may change in
the future. You had better check the data files and change the mapping
from field name to field index in create_field_index before designing
your own plots.</p>
<pre><code>Usage:
    ./plot_training_log.py chart_type[0-7] /where/to/save.png /path/to/first.log ...
Notes:
    1. Supporting multiple logs.
    2. Log file name must end with the lower-cased &quot;.log&quot;.
Supported chart types:
    0: Test accuracy  vs. Iters
    1: Test accuracy  vs. Seconds
    2: Test loss  vs. Iters
    3: Test loss  vs. Seconds
    4: Train learning rate  vs. Iters
    5: Train learning rate  vs. Seconds
    6: Train loss  vs. Iters
    7: Train loss  vs. Seconds</code></pre>
<h3 id="显示模型结果">3、显示模型结果</h3>
<blockquote>
<p>classification</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./build/examples/cpp_classification/classification.bin \</span><br><span class="line">  models/bvlc_reference_caffenet/deploy.prototxt \</span><br><span class="line">  models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel \</span><br><span class="line">  data/ilsvrc12/imagenet_mean.binaryproto \</span><br><span class="line">  data/ilsvrc12/synset_words.txt \</span><br><span class="line">  examples/images/cat.jpg</span><br></pre></td></tr></table></figure>
<p>The output should look like this:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">---------- Prediction <span class="keyword">for</span> examples/images/cat.jpg ----------</span><br><span class="line"><span class="number">0.3134</span> - <span class="string">&quot;n02123045 tabby, tabby cat&quot;</span></span><br><span class="line"><span class="number">0.2380</span> - <span class="string">&quot;n02123159 tiger cat&quot;</span></span><br><span class="line"><span class="number">0.1235</span> - <span class="string">&quot;n02124075 Egyptian cat&quot;</span></span><br><span class="line"><span class="number">0.1003</span> - <span class="string">&quot;n02119022 red fox, Vulpes vulpes&quot;</span></span><br><span class="line"><span class="number">0.0715</span> - <span class="string">&quot;n02127052 lynx, catamount&quot;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>ssd_detection</p>
<p><a
href="https://github.com/cwlseu/caffe/blob/ssdplus/examples/stairsnet/ssd_detect_once.py">ssd_detection脚本</a></p>
</blockquote>
<blockquote>
<p>stairsNet detection</p>
<p><a
href="https://github.com/cwlseu/caffe/blob/ssdplus/examples/stairsnet/stairsnet_detect.py">stairnet的结果展示脚本</a></p>
</blockquote>
<p>其中需要配置一些依赖文件信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># caffe的root路劲</span></span><br><span class="line">caffe_root=</span><br><span class="line">labelmap_file = <span class="string">&#x27;data/VOC0712/labelmap_voc.prototxt&#x27;</span></span><br><span class="line">model_def = <span class="string">&#x27;models/ResNet/VOC0712/OOXX_321x321/deploy.prototxt&#x27;</span></span><br><span class="line">model_weights = <span class="string">&#x27;models/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321_iter_70000.caffemodel&#x27;</span></span><br><span class="line">image_dir = <span class="string">&quot;examples/ooxx/test&quot;</span></span><br><span class="line">save_dir = <span class="string">&quot;examples/ooxx/result&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="对多个snapshot模型进行打分">4、对多个snapshot模型进行打分</h3>
<ol type="1">
<li>首先运行模型自带的score脚本,
如<code>examples/ssd/score_ssd_pascal.py</code>，该脚本会调用当前最新的model进行评测，在jobs的子目录下生成一个XXXXX_score的路径，其中包含solver.prototxt等等文件。然后ctrl+C暂停运行。</li>
<li>运行脚本<a
href="https://github.com/cwlseu/caffe/blob/ssdplus/tools/score_model.py"><code>model score script</code></a>(先去玩几个小时，时间很漫长的...)，将会在jobs的某个路径下找到生成的各个模型对应的shell脚本和log文件。</li>
</ol>
<h3 id="inference-time5">5、Inference Time<a href="#fn4"
class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></h3>
<ol type="1">
<li>(These example calls require you complete the LeNet / MNIST example
first.) time LeNet training on CPU for 10 iterations
<code>./build/tools/caffe time -model examples/mnist/lenet_train_test.prototxt -iterations 10</code></li>
<li>time LeNet training on GPU for the default 50 iterations
<code>./build/tools/caffe time -model examples/mnist/lenet_train_test.prototxt -gpu 0</code></li>
<li>time a model architecture with the given weights on no GPU for 10
iterations
<code>./build/tools/caffe time --model=models/ResNet/VOC0712/OOXX_321x321/deploy.prototxt --weights models/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321_iter_115000.caffemodel --iterations 10</code>
<img data-src="https://cwlseu.github.io/images/linux/inference_time.JPG"
alt="@inference time result" /></li>
</ol>
<h2 id="为什么要用google-protocol-buffer序列化协议6">为什么要用Google
Protocol Buffer序列化协议？<a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a></h2>
<table>
<colgroup>
<col style="width: 11%" />
<col style="width: 10%" />
<col style="width: 11%" />
<col style="width: 15%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 15%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">#</th>
<th style="text-align: center;">protobuf</th>
<th style="text-align: center;">jackson</th>
<th style="text-align: center;">xstream</th>
<th style="text-align: center;">serialization</th>
<th style="text-align: center;">hessian2</th>
<th style="text-align: center;">hessian2压缩</th>
<th style="text-align: center;">hessian 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">序列化 ns</td>
<td style="text-align: center;">1154</td>
<td style="text-align: center;">5421</td>
<td style="text-align: center;">92406</td>
<td style="text-align: center;">10189</td>
<td style="text-align: center;">26794</td>
<td style="text-align: center;">100766</td>
<td style="text-align: center;">29027</td>
</tr>
<tr class="even">
<td style="text-align: center;">反序列化ns</td>
<td style="text-align: center;">1334</td>
<td style="text-align: center;">8743</td>
<td style="text-align: center;">117329</td>
<td style="text-align: center;">64027</td>
<td style="text-align: center;">37871</td>
<td style="text-align: center;">188432</td>
<td style="text-align: center;">37596</td>
</tr>
<tr class="odd">
<td style="text-align: center;">bytes</td>
<td style="text-align: center;">97</td>
<td style="text-align: center;">311</td>
<td style="text-align: center;">664</td>
<td style="text-align: center;">824</td>
<td style="text-align: center;">374</td>
<td style="text-align: center;">283</td>
<td style="text-align: center;">495</td>
</tr>
</tbody>
</table>
<ul>
<li><p>protobuf
不管是处理时间上，还是空间占用上都优于现有的其他序列化方式。内存暂用是java序列化的1/9，
时间也是差了一个数量级，一次操作在1us左右。缺点：就是对象结构体有限制，只适合于内部系统使用。</p></li>
<li><p>json格式在空间占用还是有一些优势，是java序列化的1/2.6。序列化和反序列化处理时间上差不多，也就在5us。当然这次使用的jackson，如果使用普通的jsonlib可能没有这样好的性能，jsonlib估计跟java序列化差不多。</p></li>
<li><p>xml相比于java序列化来说，空间占用上有点优势，但不明显。处理时间上比java序列化多了一个数量级，在100us左右。</p></li>
<li><p>以前一种的java序列化，表现得有些失望</p></li>
<li><p>hessian测试有点意外，具体序列化数据上还步入json。性能上也不如jackjson，输得比较彻底。</p></li>
<li><p>hessian使用压缩，虽然在字节上有20%以上的空间提升，但性能上差了4,5倍，典型的以时间换空间。总的来说还是google
protobuf比较给力
以后在内部系统，数据cache存储上可以考虑使用protobuf。跟外部系统交互上可以考虑使用json。</p></li>
</ul>
<h2 id="开发过程中一些问题">开发过程中一些问题</h2>
<h3 id="如果一直在如下位置夯住不继续运行了的话">1.
如果一直在如下位置夯住，不继续运行了的话：</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">name: &quot;conv5_1/linear&quot;</span><br><span class="line">type: &quot;Convoluti</span><br><span class="line">I0320 15:59:15.669935 20624 layer_factory.hpp:77] Creating layer data</span><br><span class="line">I0320 15:59:15.670370 20624 net.cpp:100] Creating Layer data</span><br><span class="line">I0320 15:59:15.670387 20624 net.cpp:408] data -&gt; data</span><br><span class="line">I0320 15:59:15.670454 20624 net.cpp:408] data -&gt; label</span><br></pre></td></tr></table></figure>
<p>可能是训练数据类型是对的，但是去取过程中出现了，这个时候就要检查是不是训练数据的使用的是测试数据的地址。我就是犯了
这么错误，找了好久终于找到了。</p>
<h3
id="进行模型funetune的时候prototxt和.caffemodel一定要对应否则真的会出现各种shape-size不匹配的问题">2.
进行模型funetune的时候，prototxt和.caffemodel一定要对应，否则真的会出现各种shape
size不匹配的问题</h3>
<h3 id="编写prototxt的时候要风格统一不要layers和layer模式混用">3.
编写prototxt的时候要风格统一。不要layers和layer模式混用。</h3>
<blockquote>
<p>风格1: Layers开头，type为全部大写不带引号</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layers &#123;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">  name: &quot;drop7&quot;</span><br><span class="line">  type: DROPOUT</span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: 0.5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>风格2：layer开头，类型为首字母大写的字符串</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 20</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;xavier&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>风格3：layers和layer嵌套类型</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layers &#123;</span><br><span class="line">  layer &#123;</span><br><span class="line">    name: &quot;conv2&quot;</span><br><span class="line">    type: &quot;conv&quot;</span><br><span class="line">    num_output: 256</span><br><span class="line">    group: 2</span><br><span class="line">    kernelsize: 5</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;gaussian&quot;</span><br><span class="line">      std: 0.01</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">      value: 1.</span><br><span class="line">    &#125;</span><br><span class="line">    blobs_lr: 1.</span><br><span class="line">    blobs_lr: 2.</span><br><span class="line">    weight_decay: 1.</span><br><span class="line">    weight_decay: 0.</span><br><span class="line">  &#125;</span><br><span class="line">  bottom: &quot;pad2&quot;</span><br><span class="line">  top: &quot;conv2&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编写的时候保持风格统一就好。</p>
<h2 id="参考文献">参考文献</h2>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a
href="http://stackoverflow.com/questions/33962226/common-causes-of-NaNs-during-training">Common
causes of nans during training</a><a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a
href="http://stackoverflow.com/questions/40510706/how-to-interpret-caffe-log-with-debug-info">Caffe
debug info 的使用</a><a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><a
href="http://caffe.berkeleyvision.org/tutorial/interfaces.html">caffe
interface manual</a><a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><a
href="http://stackoverflow.com/questions/36867591/how-to-estimate-inference-time-from-average-forward-pass-time-in-caffe">estimate
Inference time from average forward pass time in caffe</a><a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>http://agapple.iteye.com/blog/859052<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>framework</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux开发标准：Linux Standard Base</title>
    <url>/201711/20171128-Std-LSB/</url>
    <content><![CDATA[<h2 id="unixlinux-标准化历史">Unix/Linux 标准化历史</h2>
<p>标准化目前已经成为 Linux 系统上的一个热门话题。实际上，在 Linux
诞生之初，这个问题就得到了重视。当 Linus 在开发 0.01 版本的 Linux
内核时，就开始关注 <code>POSIX</code> 标准的发展，他在
<code>/include/unistd.h</code> 文件中定义了几个与 <code>POSIX</code>
有关的宏，以下内容就节选自 0.01 版本内核的
<code>/include/unistd.h</code> 文件： <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* ok, this may be a joke, but I&#x27;m working on it */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _POSIX_VERSION 198808L</span></span><br></pre></td></tr></table></figure> 下面我们就从
POSIX入手开始介绍 Unix/Linux 方面的标准化发展历程。</p>
<h3 id="posix">POSIX</h3>
<p>Unix 1969 年诞生于 AT&amp;T 贝尔实验室，并在 1973 年使用 C
语言进行了重写，从此就具有了很好的可移植性。但是当 AT&amp;T 在 1984
年由于分拆而得以进入计算机领域的市场之后，却引发了 Unix
业界的一场大战。当时最为主要的两个版本是 AT&amp;T 的 System V 和伯克利的
BSD。二者在技术方面（例如终端）和文化方面都存在很多分歧，导致应用程序很难在不同的系统上平滑地进行移植，为了解决这个问题，IEEE（Institute
of Electrical and Electronic Engineers）的 1003
委员会着手开发了一系列标准，这就是后来的 <code>POSIX</code>（Portable
Operating System Interface for UNIX）标准。其目的是为那些兼容各种 UNIX
变种的应用程序制定应用程序编程接口（API）规范，从而确保这些应用程序的兼容性。这些标准后来被
ISO/IEC 采纳，成为 ISO/IEC 9945 标准。</p>
<p><code>POSIX</code> 在 15
份不同的文档中对操作系统与用户软件的接口进行了规范，主要内容包括3个部分：
* POSIX 系统调用 * POSIX 命令和工具 * POSIX 兼容测试 同时还提供了一套
POSIX 兼容性测试工具，称为 PCTS（POSIX Conformance Test Suite）。</p>
<p>后来 <code>POSIX</code> 标准又进行了很多扩充，主要包括： 1.
POSIX.1，核心服务：主要集成了 ANSI C
标准，包括进程创建和控制、信号、浮点异常、段错误、非法指令、总线错误、定时器、文件和目录操作、管道、C
标准库、I/O 端口和控制 2.
POSIX.1b，实时扩展：包括优先级调度、实时信号、时钟和定时器、信号量、消息传递、共享内存、异步和同步
I/O、内存锁 3.
POSIX.1c，线程扩展：包括线程创建和控制、线程调度、线程同步、信号处理</p>
<p><code>POSIX</code> 最初的设计目标是为 Unix System V 和 BSD Unix 等
Unix
系统上的特性制定规范，使其可以实现更好的可移植性。但是很多其他系统都也兼容<code>POSIX</code>
标准。例如，微软的 Windows NT 就兼容 <code>POSIX</code>
标准的实时部分（POSIX.1b），而 RTOS（LynxOS real-time operating
system）也与 <code>POSIX</code> 标准兼容。Windows 上可以通过安装 Windows
的 Services for UNIX 或 Cygwin 来增强对 <code>POSIX</code>
标准的兼容度。</p>
<h3 id="open-group">Open Group</h3>
<p>Open Group 是现在 Unix 商标的拥有者，其前身是 X/Open。X/Open 是 Unix
厂商在 1984 年成立的一个联盟，它试图为众多 Unix
变种定义一个安全公共子集，因此即使在 Unix
混战的年代，也得到了比较好的发展。在 1993 年，包括主要 Unix 公司在内的75
家系统和软件供应商委托 X/Open 为 Unix
制定一个统一的规范。X/Open在现有标准基础上，增加了对终端进行处理的 API
和 X11 API，并全面兼容 1989 ANSI C 标准，最终诞生了第一版本的单一
Unix规范（Single Unix Specification，简称 SUS）。 X/Open在 1996 年与
OSF（开放软件基金会）进行合并，成立了 Open Group
组织，专门从事开放标准的制定和推广工作，并对很多领域提供了认证，包括
Unix 操作系统、Motif 和 CDE（Common Desktop Environment）用户界面。
Austin Group Austin Group 是在 1998
年成立的一个合作技术工作组，其使命是开发并维护 POSIX.1 和 SUS
规范。Austin Group 开发规范的方法是"write once, adopt everywhere"，即由
Austin Group 制定的规范既会成为 IEEE POSIX 规范，又会成为 Open Group 的
技术标准规范，以后又会被采纳为 ISO/IEC
的标准。新开发的规范后来就被标准化为 ISO/IEC 9945 和IEEE Std
1003.1，并成为 SUSV3 的核心部分。
这种独特的开发模式最大限度地利用了业界领先的工作成果，将正式的标准化工作转化成了一个唯一的行为，并且吸引了广泛的参与者。Austin
Group 目前有 500 多个参与者，工作组的主席是 Open Group 的 Andrew
Josey。</p>
<h3 id="lsb">LSB</h3>
<p>在90 年代中期，Linux 也开始了自己的标准化努力。实际上，Linux
一直都试图遵守 <code>POSIX</code>
标准，因此在源代码级上具有很好的兼容性，然而对于 Linux
来说，仅仅保证源码级的兼容性还不能完全满足要求：在 Unix
时代，大部分系统都使用的是专有的硬件，软件开发商必须负责将自己的应用程序从一个平台移植到其他平台上；每个系统的生命周期也很长，软件开发商可以投入足够的资源为各个平台发布二进制文件。然而
Linux 使用的最广泛的 x86
通用平台，其发行版是如此众多，而发展却如此之快，软件开发商不可能为每个发行版都发布一个二进制文件，因此就为
Linux
上的标准化提出了一个新的要求：二进制兼容性，即二进制程序不需要重新编译，就可以在其他发行版上运行。
实际上，在 Linux 社区中第一个标准化努力是文件系统层次标准（Filesystem
Hierarchy
Standard，FHS），用来规范系统文件、工具和程序的存放位置和系统中的目录层次结构，例如
ifconfig 命令应该放在 <code>/usr/bin</code> 还是 <code>/usr/sbin</code>
目录中，光驱应该挂载到 <code>/mnt/cdrom</code> 中还是
<code>/media/cdrom</code> 中。这些需求最终共同促进了 Linux Standard
Base（LSB）项目的诞生。 LSB目前是 FSG（Free Standards
Group）中最为活跃的一个工作组，其使命是开发一系列标准来增强 Linux
发行版的兼容性，使各种软件可以很好地在兼容 LSB
标准的系统上运行，从而可以帮助软件供应商更好地在 Linux
系统上开发产品，或将已有的产品移植到 Linux 系统上。</p>
<p>LSB 以 <code>POSIX</code> 和 SUS
标准为基础，并对其他领域（例如图形）中源代码的一些标准进行了扩充，还增加了对二进制可执行文件格式规范的定义，从而试图确保
Linux 上应用程序源码和二进制文件的兼容性。</p>
<h2 id="lsb简介">LSB简介</h2>
<p>LSB是Linux Standard
Base取首字母的缩写。LSB的目标是制定标准提高Linux系统与其他相似系统的兼容性。LSB标准定义了二进制环境，符合LSB的应用程序在其中可以可以在其中运行。LSB
是 Linux 标准化领域中事实上的标准，它的图标（请参看图
1）非常形象地阐述了自己的使命：对代表自由的企鹅（Linux）制定标准。给定企鹅的体形和三维标准之后，软件开发者就可以设计并裁减出各色花样的衣服（应用程序），这样不管穿在哪只企鹅身上，都会非常合身。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/LSB/1.png"
alt="@图 1 LSB图标" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="图">@图</span> 1 LSB图标</figcaption>
</figure>
<p>在现有标准基础上，LSB
制定了应用程序与运行环境之间的二进制接口，这主要是基于以下标准： 1.
Single UNIX Specification（SUS） 2. System V Interface
Definition（SVID） 3. compilers for the Intel Itanium processor 4. C++
ABI 5. System V Application Binary Interface（ABI）</p>
<p>同时，LSB 充分吸取了 UNIX
标准化努力所取得经验和教训，回避了这些标准的一些问题。例如，<code>POSIX</code>
仅仅定义了编程接口的标准，但是它却无法保证二进制的兼容性。而诸如 OSF/1
之类的标准虽然试图解决二进制兼容性的问题，但是限制却太为严格。LSB
在二者之间达成了一个平衡，它包含了一个二进制兼容层，同时消除了
<code>POSIX</code> 与 OSF/1 之间存在分歧的地方。 LSB
对各个库提供的接口以及与每个接口相关的数据结构和常量进行了定义，图2给出了
LSB 3.1 环境中所包含的组件。这些组件包括开发者所需要的共享库（包括
C++），文件系统层次结构（FHS）、对象文件格式、命令和工具、应用程序包、用户和组、系统初始化等所采用的规范：</p>
<figure>
<img data-src="https://cwlseu.github.io/images/LSB/2.jpg"
alt="图 2 LSB 3.1规范包含的组件" />
<figcaption aria-hidden="true">图 2 LSB 3.1规范包含的组件</figcaption>
</figure>
<h2 id="lsb发展的路线图">LSB发展的路线图</h2>
<p>　 　LSB 项目最初发起于 1998 年 5 月，其项目启动宣言得到了 Linus
Torvalds、Bruce Perens、Eric Raymond
等人的签名支持，当时的目标是建立一系列构建 Linux
发行版所采用的源代码应该遵循的标准，并提供一个参考平台。 * 2000 年 5
月，LSB 成为 Free Standards Group（FSG）
的一个工作组，全面负责LSB计划。FSG
是一个独立的非盈利组织，专注于通过开发和促进标准来加速开源软件的发展。 *
2001年7月4日，LSB 1.0发布，迈出了Linux标准化道路上重要的一大步。LSB
1.0的规范仅包括了通用LSB（LSB Common）1.0.0。 *
2002年2月4日，在美国召开的LinuxWorld大会上，HP、IBM、拓林思、SuSE、Red
Hat、Caldera和Ximian公司联合发布了LSB 1.1。LSB
1.1对Linux核心功能和一些组件进行了标准化。它包括一组公共API、一个开发包和一些测试功能。LSB
1.1在1.0的基础上增加了对IA32架构处理器的支持，规范包括通用LSB
1.1.0和IA32处理器专用规范（LSB IA32）1.1.0。LSB 1.2 LSB
1.2包括了通用LSB规范及对IA32、IA64和PPC32架构处理器的专用规范。LSB 1.3
LSB 1.3在1.2的基础上又增加了对IBM S/390和S/390X的支持。规范包括通用LSB
1.3、LSB IA32 1.3、LSB IA64 1.3、LSB PPC32 1.3、LSB S390 1.3和LSB S390X
1.3。 * 2004年9月14日正式发布LSB
2.0。其最大特点是增加了对C++的二进制接口。2004年10月21日，LSB
2.0.1发布。 * 2005年7月1日， LSB 3.0发布。LSB
3.0更新了原来版本的一些基本规范和执行，特别是SUS（Single Unix
Specification，单一Unix规范）的升级。以SUS 3.0为基础。SUS
3.0同时也是IEEE 1003 1-2001标准（POSIX）和ISO/IEC 9945:2003标准。LSB
3.0中最重要的是文档的重构和LSB上层附加标准的发展。文档重构的目的是推动LSB未来的发展。LSB
3.0中另一个重要的新特点是引入了对POSIX线程和C++应用的支持，它增加了C++的应用二进制接口（ABI），用于改善代码互用性。
这一特点意义重大，因为现在的大多数应用都是用C++编写，通过在LSB中加入C++支持，使数以千计的软件开发商能以较低成本将他们的应用移植到
Linux上，由此带来Linux应用软件数量上的突飞猛进。LSB
3.0的文档结构是附加规范模块的根基，这些附加规范模块在核心LSB规范（Core
LSB
Specification）之上。这些新模块允许新功能的增加，其中一些功能甚至是被认为在LSB范围之外的。
新模块还允许LSB以外的组织通过使用 LSB确定的框架来添加新功能。LSB 3.0.0
标准文档，LSB标准发展到了3.0，结构与2.0一样。LSB 3.0 基于新的C++
二进制接口，还有其他的改进。另外还包括PAM和FHS
2.3。，以及包括加入gcc3.4，librt，一些新功能和新接口以及新命令等。 * LSB
3.1 版本的规范主要是增强了对桌面系统的标准化支持，增加了对 GTK 和 QT GUI
工具包的标准化。另外，LSB 还调整了自己的路线图，以便可以与主流的 Linux
发行商（Redhat、Novell、Asianux、Debian
等）的发行计划更好地吻合，并吸引了更多 Linux
发行商的参与，对开发工具和文档进行了改进，还与各个国家的组织（例如中国电子技术标准化研究所，CESI）进行认证方面的合作。截止到3.1版本，该规范可以支持
7 种体系结构： - IA32 - IA64 - X86_64 - PPC32 - PPC64 - S390 - S390x</p>
<ul>
<li>LSB 4.0 在 2008 年发布，它将实现更好的二进制兼容性，并增加对
Perl、Python、LAMP、Java
等语言的标准化支持。详细路线图及各个主要版本的特性如图 3 所示：</li>
</ul>
<figure>
<img data-src="https://cwlseu.github.io/images/LSB/3.jpg"
alt="图 3 LSB 主要版本的路线图" />
<figcaption aria-hidden="true">图 3 LSB 主要版本的路线图</figcaption>
</figure>
<ul>
<li>LSB 5.0 was released June 3, 2015</li>
</ul>
<h2 id="在linux上的测试结果">在Linux上的测试结果</h2>
<h3 id="ubuntu-16.04">ubuntu 16.04</h3>
<ol type="1">
<li><p>下载<code>https://ftp.linuxbase.org/pub/lsb/bundles/released-5.0.0/app-testkit/lsb-app-checker-5.0.0-3.x86_64.tar.gz</code></p></li>
<li><p>运行<code>./lsb-app-checker/bin/app-check-start.pl</code></p></li>
</ol>
<figure>
<img data-src="https://cwlseu.github.io/images/LSB/lsb-1.png"
alt="@LSB初始界面" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="LSB初始界面">@LSB初始界面</span></figcaption>
</figure>
<figure>
<img data-src="https://cwlseu.github.io/images/LSB/lsb-2.png"
alt="@LSB报告界面" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="LSB报告界面">@LSB报告界面</span></figcaption>
</figure>
<p><img data-src="https://cwlseu.github.io/images/LSB/lsb-3.png"
alt="@LSB调用接口分析界面" /> 在ubuntu16.04上安装正常，使用正常。</p>
<h3
id="cdos上安装失败出现500-internal-server-error">CDOS上安装失败，出现500
Internal Server Error</h3>
<ol type="1">
<li>安装lsb和lsb-core <img data-src="https://cwlseu.github.io/images/LSB/install_lsb.png"
alt="@安装lsb过程中出现包依赖错误" /></li>
<li>lsb-app-checker访问错误1 <img data-src="https://cwlseu.github.io/images/LSB/Templates.png"
alt="@访问错误" /> 后面经过几番折腾，已经fix掉。开始使用进行application
LSB标准检测吧。结果出现如下问题： <img data-src="https://cwlseu.github.io/images/LSB/Distros.png"
alt="@数据分析错误" /></li>
</ol>
<h2 id="参考文献">参考文献</h2>
<p>[1]. LSB 5.0 Specifications Archive:
http://refspecs.linuxbase.org/LSB_5.0.0/allspecs.shtml</p>
<p>[2]. LSB 4.1 Release Notes
https://wiki.linuxfoundation.org/lsb/lsb-41-release-notes</p>
<p>[3]. LSB 下载：https://www.linuxbase.org/download/</p>
<p>[4]. ISO/IEC 23360 Spec文档下载链接，点击I accept:
http://standards.iso.org/ittf/PubliclyAvailableStandards/c043781_to_043788_ISO_IEC_23360_2006_LSB.zip</p>
<p>[5].
LSB简介：https://www.ibm.com/developerworks/cn/linux/l-lsb-intr/index.html</p>
<p>[6]. 有关 Open Group
以及相关标准的介绍，http://www.opengroup.org/</p>
<p>[7]. Free Standards
Group（FSG）及其主持的项目的信息：http://www.freestandards.org</p>
<p>[8]. Austin Group 的更多信息 http://www.opengroup.org/austin/</p>
<p>[9]. Unix 的发展历史和标准化努力，请参考Eric S. Raymond 撰写的"The
Art of Unix
Programming"一书（http://www.faqs.org/docs/artu/index.html</p>
<p>[10]. History and Timeline
（http://www.unix.org/what_is_unix/history_timeline.html</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>standard</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记：Eigen开源库的应用</title>
    <url>/202208/20180203-Eigen-Open-Libs/</url>
    <content><![CDATA[<h2 id="eigen与c之间数据转换">Eigen与C之间数据转换</h2>
<h3 id="to-eigen">to Eigen</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span>* raw_data = <span class="built_in">malloc</span>(...);</span><br><span class="line"><span class="function">Map&lt;MatrixXd&gt; <span class="title">M</span><span class="params">(raw_data, rows, cols)</span></span>;</span><br><span class="line"><span class="comment">// use M as a MatrixXd</span></span><br><span class="line">M = M.<span class="built_in">inverse</span>();</span><br></pre></td></tr></table></figure>
<h3 id="from-eigen">from Eigen</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">MatrixXd M;</span><br><span class="line"><span class="type">float</span>* raw_data = M.<span class="built_in">data</span>();</span><br><span class="line"><span class="type">int</span> stride = M.<span class="built_in">outerStride</span>();</span><br><span class="line">raw_data[i+j*stride]</span><br></pre></td></tr></table></figure>
<h2 id="一些预备知识">一些预备知识</h2>
<h3 id="template-programming">template programming</h3>
<h3 id="levels-并行">4 levels 并行</h3>
<ul>
<li>cluster of PCs --MPI</li>
<li>multi/many-cores -- OpenMP</li>
<li>SIMD -- intrinsics for vector instructions</li>
<li>pipelining -- needs non dependent instructions</li>
</ul>
<h3 id="peak-performance">Peak Performance</h3>
<blockquote>
<p>Example： Intel Core2 Quad CPU Q9400 @ 2.66GHz (x86_64)</p>
</blockquote>
<pre><code>* pipelining → 1 mul + 1 add / cycle (ideal case)
* SSE → x 4 single precision ops at once
* frequency → x 2.66G
* peak performance: 21,790 Mflops (for 1 core)</code></pre>
<p>这就是我们优化的目标</p>
<h2 id="fused-operation-expression-template">Fused operation: Expression
Template</h2>
<p>Expression
Template是个好东西。通过编译融合嵌入的方式，减少了大量的读写和计算。</p>
<h2 id="curiously-recurring-template-pattern">Curiously Recurring
Template Pattern</h2>
<h2 id="eigen常见的坑"><a
href="https://zhuanlan.zhihu.com/p/32226967">Eigen常见的坑</a></h2>
<h3
id="编译的时候最好-deigen_mpl2_only详见-eigen">编译的时候最好-DEIGEN_MPL2_ONLY(详见:
Eigen)</h3>
<p>这是因为Eigen虽然大部分是MPL2 licensed的，但是还有少部分代码是LGPL
licensed的，如果修改了其代码，则必须开源。
这可能产生法律风险，而遭到法务部门的Complain</p>
<h3 id="要注意alignment的问题">要注意alignment的问题</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">my_program: path/to/eigen/Eigen/src/Core/DenseStorage.h:44:</span><br><span class="line">Eigen::internal::matrix_array&lt;T, Size, MatrixOptions, Align&gt;::internal::matrix_array()</span><br><span class="line">[with T = double, int Size = 2, int MatrixOptions = 2, bool Align = true]:</span><br><span class="line">Assertion `(reinterpret_cast&lt;size_t&gt;(array) &amp; (sizemask)) == 0 &amp;&amp; &quot;this assertion</span><br><span class="line">is explained here: http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html</span><br><span class="line">     READ THIS WEB PAGE !!! ****&quot;&#x27; failed.</span><br><span class="line">There are 4 known causes for this issue. Please read on to understand them and learn how to fix them.</span><br></pre></td></tr></table></figure>
<p>例如下面的代码都是有问题的，可能导致整个程序Crash。</p>
<ul>
<li>结构体含有Eigen类型的成员变量</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span> &#123;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  Eigen::Vector2d v; <span class="comment">// 这个类型只是一个例子，很多类型都有问题</span></span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line">Foo *foo = <span class="keyword">new</span> Foo;</span><br></pre></td></tr></table></figure>
<ul>
<li>Eigen类型的变量被放到STL容器中</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Eigen::Matrix2f这个类型只是一个例子，很多类型都有问题</span></span><br><span class="line">std::vector&lt;Eigen::Matrix2f&gt; my_vector;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">my_class</span> &#123; ... Eigen::Matrix2f m; ... &#125;; </span><br><span class="line">std::map&lt;<span class="type">int</span>, my_class&gt; my_map;</span><br></pre></td></tr></table></figure>
<ul>
<li>Eigen类型的变量被按值传入一个函数</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Eigen::Vector4d只是一个例子，很多类型都有这个问题</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(Eigen::Vector4d v)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>在栈上定义Eigen类型的变量(只有GCC4.4及以下版本 on
Windows被发现有这个问题，例如MinGW or TDM-GCC)</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Eigen::Quaternionf q; <span class="comment">// Eigen::Quaternionf只是一个例子，很多类型都有这个问题</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><a
href="http://eigen.tuxfamily.org/dox/group__TopicUnalignedArrayAssert.html">Explanation
of the assertion on unaligned arrays</a></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>HPC</tag>
        <tag>Template</tag>
      </tags>
  </entry>
  <entry>
    <title>Make &amp; CMake 进阶</title>
    <url>/201901/20190110-CMake-Makefile/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>当下流行的IDE，将源代码生成可执行文件的过程都封装起来，对于开发着来说方便使用。
但是对于初学者来说，蒙蔽了源代码到可执行文件过程。源代码预处理，编译，打包，链接等步骤，
才能形成IDE中的一步到位的可执行文件target。而Makefile是直白的描述一个源代码如何被操作
才能成为target的一种文件格式。而CMake是一种可以通过配置的方式生成Makefile的脚本.
如果只是简单的开发一个.cpp进行测试，Makefile是首选。
本文中不对Makefile的基本语法进行介绍，要学习基本语法可以参看陈皓老师的Makefile中文教程进行学习。</p>
<h2 id="makefile">Makefile</h2>
<h3
id="ifeq和ifneq之后要有个空格否则不识别"><code>ifeq</code>和<code>ifneq</code>之后要有个空格，否则不识别</h3>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">ifeq ($(UNAME), linux)</span><br><span class="line">     $(info <span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">      $(warning <span class="string">&quot;&quot;</span>)</span><br><span class="line">     $(error $(HAVE_SSHSERVER))</span><br><span class="line"><span class="keyword">endif</span> </span><br></pre></td></tr></table></figure>
<h3 id="定义变量">定义变量</h3>
<p><code>HAVE_THE_VALUE :=</code> # 新定义一个变量
<code>HAVE_THE_VALUE ?=</code> # 如果没有定义，则定义一个新变量
<code>HAVE_THE_VALUE +=</code> # 往变量中append数据</p>
<p>这个地方有点像pascal，不要与shell中混淆了</p>
<h3 id="变量赋值">变量赋值</h3>
<p><strong>后面一定不要有空格，回车之类的空白符号</strong>，否则可能会将你整疯了的。
就拿caffe中的Makefile.config中</p>
<p><code>USE_LEVELDB := 1</code></p>
<p><code>USE_LEVELDB := 1</code></p>
<p>这两行的区别在于，第二行赋值操作后面有一个空格。在Makefile中通过如下代码进行添加编译需要的宏。</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">ifeq</span> (<span class="variable">$(USE_LEVELDB)</span>, 1)</span><br><span class="line">  CXX_FLAGS += -DUSE_LEVELDB</span><br><span class="line"><span class="keyword">endif</span></span><br></pre></td></tr></table></figure>
<p>结果编译的时候打开的开关会与设想的不一样。</p>
<h3 id="makefile案例">Makefile案例</h3>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment">#! Makefile</span></span><br><span class="line"></span><br><span class="line">SRCS := PAPI_flops.c</span><br><span class="line">OBJECTS := <span class="variable">$(<span class="built_in">patsubst</span> %.c, %.o, <span class="variable">$(SRCS)</span>)</span></span><br><span class="line">STATIC_LIB := /usr/local/lib/libpapi.a</span><br><span class="line">INCLUDE_DIR := -I/usr/local/<span class="keyword">include</span></span><br><span class="line">CC := gcc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="section">all: PAPI_flops</span></span><br><span class="line"></span><br><span class="line"><span class="section">PAPI_flops: <span class="variable">$(OBJECTS)</span></span></span><br><span class="line">     <span class="variable">$(CC)</span> -O0 <span class="variable">$&lt;</span> <span class="variable">$(STATIC_LIB)</span> -o <span class="variable">$@</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$(OBJECTS)</span>: <span class="variable">$(SRCS)</span></span><br><span class="line">     <span class="variable">$(CC)</span> <span class="variable">$(INCLUDE_DIR)</span> -O0 -c <span class="variable">$&lt;</span></span><br><span class="line"></span><br><span class="line"><span class="section">test:</span></span><br><span class="line">     echo <span class="string">&quot;----Running the PAPI_flops-----&quot;</span></span><br><span class="line">     @./PAPI_flops</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">     rm -rf PAPI_flops</span><br><span class="line">     rm -rf *.o</span><br></pre></td></tr></table></figure>
<h3 id="makefile中调用.a库的编写">makefile中调用.a库的编写</h3>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!Makefile</span></span><br><span class="line">CC = g++</span><br><span class="line"></span><br><span class="line">TINYCV_DIR = /home/cwl/TinyCV</span><br><span class="line">TINYCV_INCLUDE_DIR = <span class="variable">$(TINYCV_DIR)</span>/<span class="keyword">include</span></span><br><span class="line">LIB_DIR = <span class="variable">$(TINYCV_DIR)</span>/build</span><br><span class="line"></span><br><span class="line">CXX_FLAG = -O3 -std=c++11 -Wall -Werror -fPIC</span><br><span class="line"></span><br><span class="line"><span class="section">all: main</span></span><br><span class="line"></span><br><span class="line"><span class="section">main: main.o</span></span><br><span class="line">  <span class="variable">$(CC)</span> <span class="variable">$&lt;</span> <span class="variable">$(CXX_FLAG)</span> -I<span class="variable">$(TINYCV_INCLUDE_DIR)</span> -L<span class="variable">$(LIB_DIR)</span> -ltinycv -o <span class="variable">$@</span></span><br><span class="line"></span><br><span class="line"><span class="section">main.o: main.cpp</span></span><br><span class="line">  <span class="variable">$(CC)</span> <span class="variable">$(CXX_FLAG)</span> -I<span class="variable">$(TINYCV_INCLUDE_DIR)</span> -c <span class="variable">$&lt;</span></span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">  rm -f *.o main</span><br></pre></td></tr></table></figure>
<p>需要注意的是下面这句中<code>$&lt;</code>是指输入文件main.o，此处紧跟gcc
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">main: main.o</span><br><span class="line">  $(CC) $&lt; $(CXX_FLAG) -I$(TINYCV_INCLUDE_DIR) -L$(LIB_DIR) -ltinycv -o $@</span><br></pre></td></tr></table></figure> 但是如果变为如下情形，就会出现后面中的错误 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">main: main.o</span><br><span class="line">  $(CC) $(CXX_FLAG) -I$(TINYCV_INCLUDE_DIR) -L$(LIB_DIR) -ltinycv -o $@  $&lt;</span><br></pre></td></tr></table></figure>
错误： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">caowenlong@Server-NF5280M3:~/Test$ make</span><br><span class="line">g++ -O3 -std=c++11 -Wall -Werror -fPIC -I/home/cwl/TinyCV/include -c main.cpp</span><br><span class="line">g++ -O3 -std=c++11 -Wall -Werror -fPIC -I/home/cwl/TinyCV/include -L/home/cwl/TinyCV/build -ltinycv -o main main.o</span><br><span class="line">main.o：在函数‘main’中：</span><br><span class="line">main.cpp:(.text.startup+0x3b)：对‘tinycv::imread(std::string const&amp;, int)’未定义的引用</span><br><span class="line">main.cpp:(.text.startup+0x43)：对‘tinycv::Mat&lt;unsigned char&gt;::Mat()’未定义的引用</span><br><span class="line">main.cpp:(.text.startup+0x63)：对‘double tinycv::threshold&lt;unsigned char&gt;(tinycv::Mat&lt;unsigned char&gt; const&amp;, tinycv::Mat&lt;unsigned char&gt;&amp;, double, double, int)’未定义的引用</span><br><span class="line">collect2: error: ld returned 1 exit status</span><br><span class="line">make: *** [main] 错误 1</span><br></pre></td></tr></table></figure></p>
<h3 id="makefile中的全局自变量">makefile中的全局自变量</h3>
<p><code>$@</code>目标文件名 <code>@^</code>所有前提名，除副本
<code>@＋</code>所有前提名，含副本 <code>@＜</code>一个前提名
<code>@？</code>所有新于目标文件的前提名
<code>@*</code>目标文件的基名称</p>
<h3 id="是否输出执行过程">是否输出执行过程</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#! Makefile</span><br><span class="line">SAMPLE_ENABLE ?= 1</span><br><span class="line"></span><br><span class="line">ifeq ($(SAMPLE_ENABLE), 1)</span><br><span class="line">	EXEC ?= @echo &quot;[@]&quot;</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">target: target2</span><br><span class="line">	echo &quot;hehe, this is target&quot;</span><br><span class="line"></span><br><span class="line">target2:</span><br><span class="line">	echo &quot;this is target2&quot;</span><br><span class="line">clean:</span><br><span class="line">	rm -rf out.o</span><br></pre></td></tr></table></figure>
<ul>
<li><a
href="https://github.com/cwlseu/recipes/tree/master/makepractise">more
samples</a></li>
</ul>
<h2 id="cmake">CMake</h2>
<h3 id="cmake-入门案例">CMake 入门案例</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">PROJECT(sdk_common_samples)</span><br><span class="line">cmake_minimum_required(VERSION <span class="number">3.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找已经安装的包</span></span><br><span class="line">FIND_PACKAGE(OpenCV <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SET 指令的语法是:</span></span><br><span class="line"><span class="comment"># SET(VAR [VALUE] [CACHE TYPE DOCSTRING [FORCE]])</span></span><br><span class="line"></span><br><span class="line">SET(</span><br><span class="line">	SDK_COMMON_INCLUDE_DIR</span><br><span class="line">	$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/../../include</span><br><span class="line">	CACHE PATH</span><br><span class="line">	<span class="string">&quot;SDK_COMMON HEADER FILE PATH&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MESSAGE 指令的语法是:</span></span><br><span class="line"><span class="comment"># MESSAGE([SEND_ERROR | STATUS | FATAL_ERROR] &quot;message to display&quot; ...)</span></span><br><span class="line"><span class="comment"># 这个指令用于向终端输出用户定义的信息,包含了三种类型:</span></span><br><span class="line"><span class="comment"># SEND_ERROR,产生错误,生成过程被跳过。</span></span><br><span class="line"><span class="comment"># SATUS ,输出前缀为 — 的信息。</span></span><br><span class="line"><span class="comment"># FATAL_ERROR,立即终止所有 cmake 过程.</span></span><br><span class="line"></span><br><span class="line">MESSAGE(<span class="string">&quot;Find libs in $&#123;SDK_COMMON_LIB_DIR&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># INCLUDE_DIRECTORIES,其完整语法为:</span></span><br><span class="line"><span class="comment"># INCLUDE_DIRECTORIES([AFTER|BEFORE] [SYSTEM] dir1 dir2 ...)</span></span><br><span class="line"><span class="comment"># 这条指令可以用来向工程添加多个特定的头文件搜索路径,路径之间用空格分割,如果路径</span></span><br><span class="line"><span class="comment"># 中包含了空格,可以使用双引号将它括起来,默认的行为是追加到当前的头文件搜索路径的</span></span><br><span class="line"><span class="comment"># 后面,你可以通过两种方式来进行控制搜索路径添加的方式:</span></span><br><span class="line"><span class="comment"># 1,CMAKE_INCLUDE_DIRECTORIES_BEFORE,通过 SET 这个 cmake 变量为 on,可以</span></span><br><span class="line"><span class="comment"># 将添加的头文件搜索路径放在已有路径的前面。</span></span><br><span class="line"><span class="comment"># 2,通过 AFTER 或者 BEFORE 参数,也可以控制是追加还是置前。</span></span><br><span class="line">INCLUDE_DIRECTORIES(</span><br><span class="line">	$&#123;PROJECT_SOURCE_DIR&#125;</span><br><span class="line">	$&#123;SDK_COMMON_INCLUDE_DIR&#125;</span><br><span class="line">	$&#123;OpenCV_INCLUDE_DIRS&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加链接库的文件夹路径</span></span><br><span class="line">LINK_DIRECTORIES($&#123;SDK_COMMON_LIB_DIR&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set最长用的方法，就像shell中export一个变量一样</span></span><br><span class="line">SET(CMAKE_C_FLAGS <span class="string">&quot;$&#123;CMAKE_C_FLAGS&#125; -g -Wall -O2 -std=gnu++0x&quot;</span>)</span><br><span class="line">SET(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -g -Wall -O2 -std=gnu++0x&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找在相对路径下与*.cpp所匹配的模式的所有文件，保存到变量samples中</span></span><br><span class="line">FILE(GLOB samples $&#123;PROJECT_SOURCE_DIR&#125;/*.cpp)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 针对samples中的所有元素进行操作</span></span><br><span class="line">FOREACH (sample $&#123;samples&#125;)</span><br><span class="line">	STRING(REGEX MATCH <span class="string">&quot;[^/]+$&quot;</span> sample_file $&#123;sample&#125;)</span><br><span class="line">	STRING(REPLACE <span class="string">&quot;.cpp&quot;</span> <span class="string">&quot;&quot;</span> sample_basename $&#123;sample_file&#125;)</span><br><span class="line">	ADD_EXECUTABLE(test_$&#123;sample_basename&#125; $&#123;sample&#125;)</span><br><span class="line">	<span class="comment"># 添加执行时的需要链接的lib： common OpenCV_Libs</span></span><br><span class="line">	TARGET_LINK_LIBRARIES(test_$&#123;sample_basename&#125;</span><br><span class="line">	sdk_common $&#123;OpenCV_LIBS&#125;)</span><br><span class="line">	<span class="comment"># 另外，如果不是再window下的话需要添加线程库 -lpthread</span></span><br><span class="line">	<span class="keyword">if</span> (NOT WIN32)</span><br><span class="line">		TARGET_LINK_LIBRARIES(test_$&#123;sample_basename&#125; pthread)</span><br><span class="line">	endif()</span><br><span class="line">	</span><br><span class="line">	INSTALL(TARGETS test_$&#123;sample_basename&#125; DESTINATION $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/<span class="built_in">bin</span>)</span><br><span class="line">ENDFOREACH() <span class="comment"># foreach 结束</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="windows指定编译器">windows指定编译器</h2>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">cmake \</span><br><span class="line">-DCMAKE_MODULE_PATH:PATH=Y:\\cmake  -DCMAKE_CONFIGURATION_TYPES=release \</span><br><span class="line">-DCMAKE_INSTALL_PREFIX=C:\\cygwin\\data\\windows-x86_64\\<span class="keyword">test</span> \</span><br><span class="line">-G <span class="string">&quot;Visual Studio 12 Win64&quot;</span> -T <span class="string">&quot;v120_xp&quot;</span> ..</span><br><span class="line"></span><br><span class="line">cmake -G<span class="string">&quot;Visual Studio 12 2013&quot;</span> -A x64 -DCMAKE_BUILD_TYPE=RELEASE ..</span><br><span class="line">cmake -G<span class="string">&quot;Visual Studio 12 2013&quot;</span> -A Win32 -DCMAKE_BUILD_TYPE=RELEASE ..</span><br></pre></td></tr></table></figure>
<p>有的时候在windows下，buildtype为debug和release表现不同，而且概率还是比较高的。</p>
<h3 id="官网提供的入门教程中的案例">官网提供的入门教程中的案例</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required (VERSION <span class="number">2.6</span>)</span><br><span class="line">project (Tutorial)</span><br><span class="line"></span><br><span class="line"><span class="comment"># should we use our own math functions?</span></span><br><span class="line">option (USE_MYMATH </span><br><span class="line">  <span class="string">&quot;Use tutorial provided math implementation&quot;</span> ON) </span><br><span class="line"></span><br><span class="line"><span class="comment"># The version number.</span></span><br><span class="line"><span class="built_in">set</span> (Tutorial_VERSION_MAJOR <span class="number">1</span>)</span><br><span class="line"><span class="built_in">set</span> (Tutorial_VERSION_MINOR <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># configure a header file to pass some of the CMake settings</span></span><br><span class="line"><span class="comment"># to the source code</span></span><br><span class="line">configure_file (</span><br><span class="line">  <span class="string">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/TutorialConfig.h.in&quot;</span></span><br><span class="line">  <span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;/TutorialConfig.h&quot;</span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the binary tree to the search path for include files</span></span><br><span class="line"><span class="comment"># so that we will find TutorialConfig.h</span></span><br><span class="line">include_directories(<span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (USE_MYMATH)</span><br><span class="line">  include_directories (<span class="string">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/MathFunctions&quot;</span>)</span><br><span class="line">  add_subdirectory (MathFunctions)</span><br><span class="line">  <span class="built_in">set</span> (EXTRA_LIBS $&#123;EXTRA_LIBS&#125; MathFunctions)</span><br><span class="line">endif (USE_MYMATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the executable</span></span><br><span class="line">add_executable(Tutorial main.cpp)</span><br><span class="line">target_link_libraries (Tutorial $&#123;EXTRA_LIBS&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the install targets</span></span><br><span class="line">install (TARGETS Tutorial DESTINATION <span class="built_in">bin</span>)</span><br><span class="line">install (FILES <span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;/TutorialConfig.h&quot;</span>        </span><br><span class="line">  DESTINATION include)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">include(CTest)</span><br><span class="line"><span class="comment"># does it sqrt of 25</span></span><br><span class="line">add_test (TutorialComp25 Tutorial <span class="number">25</span>)</span><br><span class="line">set_tests_properties (TutorialComp25 PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;25 is 5&quot;</span>)</span><br><span class="line"><span class="comment"># does it handle negative numbers</span></span><br><span class="line"><span class="comment">#add_test (TutorialNegative Tutorial -25)</span></span><br><span class="line"><span class="comment">#set_tests_properties (TutorialNegative PROPERTIES PASS_REGULAR_EXPRESSION &quot;-25 is 0&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># does it handle small numbers</span></span><br><span class="line">add_test (TutorialSmall Tutorial <span class="number">0.0001</span>)</span><br><span class="line">set_tests_properties (TutorialSmall PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;0.0001 is 0.01&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># does the usage message work?</span></span><br><span class="line">add_test (TutorialUsage Tutorial)</span><br><span class="line">set_tests_properties (TutorialUsage PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;Usage:.*number&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#define a macro to simplify adding tests, then use it</span></span><br><span class="line">macro (do_test arg result)</span><br><span class="line">  add_test (TutorialComp$&#123;arg&#125; Tutorial $&#123;arg&#125;)</span><br><span class="line">  set_tests_properties (TutorialComp$&#123;arg&#125;</span><br><span class="line">  PROPERTIES PASS_REGULAR_EXPRESSION $&#123;result&#125;)</span><br><span class="line">endmacro (do_test)</span><br><span class="line"></span><br><span class="line">do_test (<span class="number">81</span> <span class="string">&quot;81 is 9&quot;</span>)</span><br><span class="line"><span class="comment"># do a bunch of result based tests</span></span><br><span class="line">do_test (<span class="number">25</span> <span class="string">&quot;25 is 5&quot;</span>)</span><br><span class="line">do_test (-<span class="number">25</span> <span class="string">&quot;-25 is 0&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="cmake-特点">CMake 特点</h3>
<ul>
<li>跨平台，并且可以生成响应的编译配置文件，如在linux平台下生成makefile,在苹果下生成xcode,在windows下可以生成MSVC的工程文件</li>
<li>开源，使用类BSD许可发布</li>
<li>简化管理大型项目</li>
<li>简化编译构建过程和编译过程cmake + make</li>
<li>可拓展，可以编写特定功能的模块</li>
</ul>
<h3 id="cmake问题">CMake问题</h3>
<ul>
<li>cmake编写的过程实际上是编程，每个目录一个CMakeLists.txt，使用cmake语言和语法</li>
<li>一些拓展可以使用，但是配合起来可能不是很理想</li>
<li>针对大型项目，如果项目比较小，还是直接编写makefile比较好</li>
</ul>
<h3 id="定义变量-1">定义变量</h3>
<ol type="1">
<li>命令行中 <code>cmake -DCUDA_USE_STATIC_CUDA_RUNTIME=1 ..</code></li>
<li><a
href="https://cmake.org/cmake/help/v3.10/command/set.html?highlight=set">cmake
中set的使用</a></li>
</ol>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 普通变量定义</span></span><br><span class="line"><span class="keyword">SET</span>(DIDBUILD_TARGET_OS LINUX)</span><br><span class="line"><span class="comment"># 强制覆盖</span></span><br><span class="line"><span class="keyword">SET</span>(CUDA_USE_STATIC_CUDA_RUNTIME <span class="keyword">OFF</span> CACHE BOOL <span class="string">&quot;fix cuda compiling error&quot;</span> FORCE)</span><br><span class="line"><span class="comment"># 有则忽略，否则定义变量</span></span><br><span class="line"><span class="keyword">SET</span>(DIDBUILD_TARGET_ARCH X86_64 CACHE <span class="keyword">STRING</span> <span class="string">&quot;default arch is x86_64&quot;</span>)</span><br><span class="line"><span class="comment"># 设置环境变量</span></span><br><span class="line"><span class="keyword">SET</span>(ENV&#123;LD_LIBRARY_PATH&#125; /usr/local/lib64)</span><br></pre></td></tr></table></figure>
<h3 id="字符串处理"><a
href="https://cmake.org/cmake/help/v3.10/command/string.html?highlight=string#command:string">字符串处理</a></h3>
<p><code>STRING(FIND $Origin_str $substr $target_str)</code></p>
<p>此外，<code>FIND</code>,<code>REPLACE</code>,<code>REGEX MATCH</code>，<code>APPEND</code>
<code>string(CONCAT &lt;output variable&gt; [&lt;input&gt;...])</code></p>
<p>Concatenate all the input arguments together and store the result in
the named output variable.</p>
<p><code>string(TOLOWER &lt;string1&gt; &lt;output variable&gt;)</code></p>
<p>Convert string to lower characters.</p>
<p><code>string(LENGTH &lt;string&gt; &lt;output variable&gt;)</code></p>
<p>Store in an output variable a given string’s length.</p>
<p><code>string(SUBSTRING &lt;string&gt; &lt;begin&gt; &lt;length&gt; &lt;output variable&gt;)</code></p>
<p>Store in an output variable a substring of a given string. If length
is -1 the remainder of the string starting at begin will be returned. If
string is shorter than length then end of string is used instead.</p>
<p><code>string(STRIP &lt;string&gt; &lt;output variable&gt;)</code></p>
<p>Store in an output variable a substring of a given string with
leading and trailing spaces removed. <figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">string</span>(COMPARE <span class="keyword">LESS</span> &lt;string1&gt; &lt;string2&gt; &lt;output variable&gt;)</span><br><span class="line"><span class="keyword">string</span>(COMPARE <span class="keyword">EQUAL</span> &lt;string1&gt; &lt;string2&gt; &lt;output variable&gt;)</span><br><span class="line"><span class="keyword">string</span>(&lt;HASH&gt; &lt;output variable&gt; &lt;input&gt;)</span><br></pre></td></tr></table></figure> Compute a
cryptographic hash of the input string. The supported
<code>&lt;HASH&gt;</code> algorithm names are: 很多</p>
<h3 id="strequal"><code>STREQUAL</code></h3>
<h3 id="make-verbose1"><code>make VERBOSE=1</code></h3>
<p>可以将cmake中定义的变量打印</p>
<h3 id="object-libraries">Object Libraries</h3>
<p>The OBJECT library type is also not linked to. It defines a
non-archival collection of object files resulting from compiling the
given source files. The object files collection can be used as source
inputs to other targets:</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">add_library</span>(archive OBJECT archive.cpp zip.cpp lzma.cpp)</span><br><span class="line"><span class="keyword">add_library</span>(archiveExtras STATIC $&lt;TARGET_OBJECTS:archive&gt; extras.cpp)</span><br><span class="line"><span class="keyword">add_executable</span>(test_exe $&lt;TARGET_OBJECTS:archive&gt; <span class="keyword">test</span>.cpp)</span><br></pre></td></tr></table></figure>
<p>OBJECT libraries may only be used locally as sources in a buildsystem
– they may not be installed, exported, or used in the right hand side of
<code>target_link_libraries()</code>. They also may not be used as the
<code>TARGET</code> in a use of the
<code>add_custom_command(TARGET)</code> command signature.</p>
<p>Although object libraries may not be named directly in calls to the
<code>target_link_libraries()</code> command, they can be “linked”
indirectly by using an Interface Library whose
<code>INTERFACE_SOURCES</code> target property is set to name
<code>$&lt;TARGET_OBJECTS:objlib&gt;</code>.</p>
<h3
id="externalproject通过url配置依赖第三方库">ExternalProject，通过url配置依赖第三方库</h3>
<blockquote>
<p>cmake/DownloadGoogleBenchmark.cmake</p>
</blockquote>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INCLUDE</span>(ExternalProject)</span><br><span class="line">ExternalProject_Add(googletest</span><br><span class="line">	URL https://github.com/google/googletest/archive/release-<span class="number">1.8</span>.<span class="number">0</span>.zip</span><br><span class="line">	URL_HASH SHA256=f3ed3b58511efd272eb074a3a6d6fb79d7c2e6a0e374323d1e6bcbcc1ef141bf</span><br><span class="line">	SOURCE_DIR <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_SOURCE_DIR&#125;/googletest&quot;</span></span><br><span class="line">	BINARY_DIR <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/googletest&quot;</span></span><br><span class="line">	CONFIGURE_COMMAND <span class="string">&quot;&quot;</span></span><br><span class="line">	<span class="keyword">BUILD_COMMAND</span> <span class="string">&quot;&quot;</span></span><br><span class="line">	INSTALL_COMMAND <span class="string">&quot;&quot;</span></span><br><span class="line">	TEST_COMMAND <span class="string">&quot;&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>主CMakeLists.txt中的使用</p>
</blockquote>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">IF</span>(PTHREADPOOL_BUILD_BENCHMARKS <span class="keyword">AND</span> <span class="keyword">NOT</span> <span class="keyword">DEFINED</span> GOOGLEBENCHMARK_SOURCE_DIR)</span><br><span class="line">     <span class="keyword">MESSAGE</span>(STATUS <span class="string">&quot;Downloading Google Benchmark to     $&#123;CONFU_DEPENDENCIES_SOURCE_DIR&#125;/googlebenchmark (define GOOGLEBENCHMARK_SOURCE_DIR to avoid it)&quot;</span>)</span><br><span class="line">     <span class="comment"># 添加其他依赖路径</span></span><br><span class="line">     <span class="keyword">CONFIGURE_FILE</span>(cmake/DownloadGoogleBenchmark.cmake <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/googlebenchmark-download/CMakeLists.txt&quot;</span>)</span><br><span class="line">     <span class="keyword">EXECUTE_PROCESS</span>(<span class="keyword">COMMAND</span> <span class="string">&quot;$&#123;CMAKE_COMMAND&#125;&quot;</span> -G <span class="string">&quot;$&#123;CMAKE_GENERATOR&#125;&quot;</span> .</span><br><span class="line">     WORKING_DIRECTORY <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/googlebenchmark-download&quot;</span>)</span><br><span class="line">     <span class="keyword">EXECUTE_PROCESS</span>(<span class="keyword">COMMAND</span> <span class="string">&quot;$&#123;CMAKE_COMMAND&#125;&quot;</span> --build .</span><br><span class="line">     WORKING_DIRECTORY <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/googlebenchmark-download&quot;</span>)</span><br><span class="line">     <span class="keyword">SET</span>(GOOGLEBENCHMARK_SOURCE_DIR <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_SOURCE_DIR&#125;/googlebenchmark&quot;</span> CACHE <span class="keyword">STRING</span> <span class="string">&quot;Google Benchmark source directory&quot;</span>)</span><br><span class="line"><span class="keyword">ENDIF</span>()</span><br></pre></td></tr></table></figure>
<h2 id="cmakelists中的高级用法">CMakeLists中的高级用法</h2>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSTALL</span>(TARGETS libdeepindeed</span><br><span class="line">  LIBRARY DESTINATION lib</span><br><span class="line">  RUNTIME DESTINATION bin</span><br><span class="line">  ARCHIVE DESTINATION lib)</span><br></pre></td></tr></table></figure>
<ul>
<li><p><a
href="https://cmake.org/cmake/help/v3.1/command/install.html#installing-targets">cmake
install target</a></p></li>
<li><p>库之间的符号继承等</p></li>
</ul>
<h2 id="参考资料">参考资料</h2>
<ul>
<li>[1] <a
href="https://cmake.org/cmake/help/v3.10/manual/cmake-buildsystem.7.html">cmake
buildsystem文档，主要关于target_property,
target_include_directories,target_link_libraries,set_target_properties</a></li>
<li>[2] <a
href="https://cmake.org/cmake/help/v3.0/module/ExternalProject.html">ExternalProject文档</a></li>
<li>[3] <a
href="https://app.yinxiang.com/shard/s40/res/ecb203bd-889b-4eb3-8ee6-d0b0e88765f6/CMake%20Practice.pdf?search=Cmake">CMake
Practice</a></li>
<li>[4] <a
href="https://app.yinxiang.com/shard/s40/res/67a665d8-3622-49d1-ac10-2b21c8f29277/Makefile%E4%B8%AD%E6%96%87%E6%95%99%E7%A8%8B.pdf?search=Cmake">Makefile中文简明教程(陈皓)</a></li>
<li>[5] <a
href="https://blog.csdn.net/u011092188/article/details/61425924">CMake如何查找链接库---find_package的使用方法</a></li>
<li>[6]. 练习CMake的项目: https://github.com/cwlseu/brick</li>
</ul>
<h2 id="cmake-manual">CMake manual</h2>
<ul>
<li><a
href="https://cmake.org/cmake/help/v3.12/manual/cmake-buildsystem.7.html">cmake
buildsystem</a></li>
<li>cmake packages
<ul>
<li><a
href="https://cmake.org/cmake/help/v3.12/manual/cmake-packages.7.html#creating-packages">creating-packages</a></li>
<li><a
href="https://github.com/cwlseu/codefeeling/tree/master/cmaketest/createpackage">cmaketest
sample</a></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux开发</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习: 一起来看数据增强</title>
    <url>/201902/20190225-Data-Argumentation/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>从AlexNet夺取ImageNet的冠军，到RCNN的出现，再到后来的SSD算法，数据增强仿佛像是一位功成名就的老者，虽然数据增强对于算法性能的提升起到重要的作用，但是他从来不居功，默默在背后付出"众里寻他千百度"，只为让你"蓦然回首，她在灯火阑珊处"。</p>
<h2 id="数据增强data-augmentation的目的与作用">数据增强(Data
Augmentation)的目的与作用</h2>
<p>卷积神经网络能够鲁棒地将物体分类，即便物体放置在不同的方向上，这也就是所说不变性的性质，即使卷积神经网络被放在不同方向上，它也能进行对象分类。更具体的说，卷积神经网络对平移、视角、尺寸或照度（或以上组合）保持不变性。
这就是数据增强的本质前提。在现实世界中，我们可能会有一组在有限的条件下拍摄的图像
。但是，我们的目标应用可能是在多变的环境中，例如，不同的方向、位置、比例、亮度等。我们通过使用经综合修改过的数据来训练神经网络，以应对这些情形。</p>
<blockquote>
<p>数据少的负面影响： 1.
模型训练的时候可能无法收敛，少量训练数据难以提供足够的信息给模型学习 2.
过拟合，模型容易将训练数据的完全不相关信息学习进去，如噪声 3.
容易陷入局部最优值 4.
难以衡量模型好坏，除了训练数据，测试数据也非常少，少量数据整的与否可能对结果产生较大影响。</p>
</blockquote>
<blockquote>
<p>数据不平衡的负面影响：
最常见的就是模型的权值更新被数据多的一个方向带跑偏了。</p>
</blockquote>
<blockquote>
<p>数据增强的作用 1. 补充数据样本不足 2.
减少网络的过拟合现象，通过对训练图片进行变换可以得到泛化能力更强的网络，更好的适应应用场景。</p>
</blockquote>
<h2 id="基本方法">基本方法</h2>
<p>现在最常用的数据方案是
数据增强的基本方法无非就是图像的基本操作进行排列组合，生成千万种数据增强的可能性：
* 旋转/反射变换(Rotation/reflection): 随机旋转图像一定角度;
改变图像内容的朝向; * 翻转变换(flip): 沿着水平或者垂直方向翻转图像; *
缩放变换(zoom): 按照一定的比例放大或者缩小图像; * 平移变换(shift):
在图像平面上对图像以一定方式进行平移; *
可以采用随机或人为定义的方式指定平移范围和平移步长,
沿水平或竖直方向进行平移. 改变图像内容的位置; * 尺度变换(scale):
对图像按照指定的尺度因子, 进行放大或缩小; 或者参照SIFT特征提取思想,
利用指定的尺度因子对图像滤波构造尺度空间. 改变图像内容的大小或模糊程度;
* 对比度变换(contrast):
在图像的HSV颜色空间，改变饱和度S和V亮度分量，保持色调H不变.
对每个像素的S和V分量进行指数运算(指数因子在0.25到4之间), 增加光照变化; *
噪声扰动(noise): 对图像的每个像素RGB进行随机扰动,
常用的噪声模式是椒盐噪声和高斯噪声; *
颜色变化：在图像通道上添加随机扰动。 * PCA Jittering 首先，按照 RGB
三个颜色通道计算均值和方差，规范网络输入数据；
然后，计算整个训练数据集的协方差矩阵，进行特征分解，得到特征向量和特征值，以作
PCA Jittering.</p>
<h2 id="caffe中的数据增强">caffe中的数据增强</h2>
<p><code>caffe/src/caffe/data_transformer.cpp</code>
只发现mirror、scale、crop三种。
其中Data_Transformer被调用的时候，会采用1/2的随机镜像，以及对应输入参数的scale和crop进行生成新的样本，输出到下一层网络中。因此，我们使用caffe训练的时候，只训练一个epoch就可以的情况是万万不能的。即使是同一个图片，同一套参数，也要进行多次采样才行。每个epoch进行shuffle一次，每次的batch中的分布就会发生变化，同样一张图片，虽然是同一套参数，也可能会出现不同的结果。在训练过程中的数据采样，随机性让样本不至于将噪声过度的学习。</p>
<h2 id="ssd中的数据增强">SSD中的数据增强</h2>
<p>SSD中的数据采样，在caffe中数据采样的基础上，进行了充分扩充，增强方式包括<code>resize</code>，<code>crop</code>，<code>distort</code>，...
更重要的是引入BatchSampler,
以Batch中的数据基础，达到真正的增加不同overlap的数据的目的，使得检测能力极大增强。因此，我一度认为，SSD的成功不是One-Stage在Detection的突破，而是数据增强方法的提升。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Sample a batch of bboxes with provided constraints.</span><br><span class="line">message BatchSampler &#123;</span><br><span class="line">  // 是否使用原来的图片</span><br><span class="line">  optional bool use_original_image = 1 [default = true];</span><br><span class="line">  // sampler的参数</span><br><span class="line">  optional Sampler sampler = 2;</span><br><span class="line">  // 对于采样box的限制条件，决定一个采样数据positive or negative</span><br><span class="line">  optional SampleConstraint sample_constraint = 3;</span><br><span class="line">  // 当采样总数满足条件时，直接结束</span><br><span class="line">  optional uint32 max_sample = 4;</span><br><span class="line">  // 为了避免死循环，采样最大try的次数.</span><br><span class="line">  optional uint32 max_trials = 5 [default = 100];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>更多内容，参考博客：http://deepindeed.cn/2017/04/05/SSD-Data-Augmentation/</p>
<h2
id="海康威视mscoco比赛中的数据增强">海康威视MSCOCO比赛中的数据增强</h2>
<ul>
<li>第一，对颜色的数据增强，包括色彩的饱和度、亮度和对比度等方面，主要从Facebook的代码里改过来的。</li>
<li>第二，PCA
Jittering，最早是由Alex在他2012年赢得ImageNet竞赛的那篇NIPS中提出来的.
我们首先按照RGB三个颜色通道计算了均值和标准差，对网络的输入数据进行规范化，随后我们在整个训练集上计算了协方差矩阵，进行特征分解，得到特征向量和特征值，用来做PCA
Jittering。</li>
<li>第三，在图像进行裁剪和缩放的时候，我们采用了随机的图像差值方式。</li>
<li>第四， Crop
Sampling，就是怎么从原始图像中进行缩放裁剪获得网络的输入。比较常用的有2种方法：
<ul>
<li>一是使用Scale Jittering，VGG和ResNet模型的训练都用了这种方法。</li>
<li>二是尺度和长宽比增强变换，最早是Google提出来训练他们的Inception网络的。我们对其进行了改进，提出Supervised
Data Augmentation方法。</li>
</ul></li>
</ul>
<h2 id="学习的数据增强策略">学习的数据增强策略</h2>
<p>在分类模型中，常见的数据增广策略有尺度、平移、旋转。在目标检测任务中，较多使用镜像和多尺度训练进行数据增广。除此以外，一些方法在图像上随机增加噪声、遮挡等，或者在训练图像上增加新物体。当前大多数图像分类器使用人工数据增广方法，目前有一些工作<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>不再使用人工数据增广方法，而是使用从数据中学习到的策略以提升图像分类模型的性能。学习到的数据增广策略对小数据有较大帮助，避免过拟合。对于一个增广策略，将其分解成K个子策略，在训练过程中随机选择每个子策略，将该策略应用到当前图像上。其中，每个子策略包括N个图像变换。将搜寻最佳数据增广策略的问题就转换成在搜索空间中的离散优化问题。当前存在许多解决离散优化问题的方法，包括强化学习，基于序列模型的优化等。<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>将离散优化问题构建为RNN的输出空间，并采用强化学习来更新模型的权重。<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></p>
<h2 id="启发点">启发点</h2>
<ul>
<li>并不是越多越好，要在多的基础上保持随机性，因为应用场景的不是固定的输入</li>
<li>结合新的方法，例如GAN进行生成图片等技术，进一步扩充训练集合</li>
<li>合理性采样降低样本不均衡的影响</li>
</ul>
<h2 id="小结">小结</h2>
<p>同样的算法，数据增强能够显著提升算法的性能。不仅仅是因为我们采集的数据不够全面，而是我们专注的这个CV领域就是一个受多种因素影响的领域，光照，人物姿势，拍照角度，旋转角度等等。想要我们的CNN算子将所有这些影响因素都考虑进去，这是几乎不可能的。只有可能让它多学一点，多看一点，少犯一点错罢了。而数据增强就是能够让它可以多学一点不一样的东西，少一点死板在里面。
https://github.com/mdbloice/Augmentor</p>
<h2 id="可参考链接">可参考链接</h2>
<ul>
<li><a href="https://arxiv.org/pdf/1406.6909.pdf">Discriminative
Unsupervised Feature Learning with Exemplar Convolutional Neural
Networks</a></li>
<li><a
href="https://arxiv.org/pdf/1511.05635.pdf">输入图像随机选择一块区域涂黑，《Random
Erasing Data Augmentation》</a></li>
<li><a href="https://arxiv.org/pdf/1902.04103.pdf">Bag of Freebies for
Training Object Detection Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1805.09501v1">AutoAugment: Learning
Augmentation Policies from Data</a></li>
<li><a
href="https://zhuanlan.zhihu.com/p/23249000">海康威视研究院ImageNet2016竞赛经验分享</a></li>
<li><a
href="https://github.com/kevinlin311tw/caffe-augmentation">https://github.com/kevinlin311tw/caffe-augmentation</a></li>
<li><a
href="https://github.com/codebox/image_augmentor">https://github.com/codebox/image_augmentor</a></li>
<li><a
href="https://github.com/aleju/imgaug.git">https://github.com/aleju/imgaug.git</a></li>
<li><a
href="http://lib.stat.cmu.edu/~brian/905-2009/all-papers/01-jcgs-art.pdf">The
art of Data Augmentation</a></li>
<li><a href="https://arxiv.org/abs/1902.07296">Augmentation for small
object detection</a></li>
<li><a
href="https://www.zhihu.com/question/35339639">使用深度学习(CNN)算法进行图像识别工作时，有哪些data
augmentation 的奇技淫巧？</a></li>
</ul>
<h2 id="案例-医学图像分割的数据增广">案例-医学图像分割的数据增广</h2>
<p><a href="http://arxiv.org/abs/1902.09383">Data augmentation using
learned transforms for one-shot medical image segmentation</a></p>
<p>github: https://github.com/xamyzhao/brainstorm</p>
<pre><code>Biomedical image segmentation is an important task in many medical applications. Segmentation methods based on convolutional neural networks attain state-of-the-art accuracy; however, they typically rely on supervised training with large labeled datasets. Labeling datasets of medical images requires significant expertise and time, and is infeasible at large scales. To tackle the lack of labeled data, researchers use techniques such as hand-engineered preprocessing steps, hand-tuned architectures, and data augmentation. However, these techniques involve costly engineering efforts, and are typically dataset-specific. We present an automated data augmentation method for medical images. We demonstrate our method on the task of segmenting magnetic resonance imaging (MRI) brain scans, focusing on the one-shot segmentation scenario -- a practical challenge in many medical applications. Our method requires only a single segmented scan, and leverages other unlabeled scans in a semi-supervised approach. We learn a model of transforms from the images, and use the model along with the labeled example to synthesize additional labeled training examples for supervised segmentation. Each transform is comprised of a spatial deformation field and an intensity change, enabling the synthesis of complex effects such as variations in anatomy and image acquisition procedures. Augmenting the training of a supervised segmenter with these new examples provides significant improvements over state-of-the-art methods for one-shot biomedical image segmentation.</code></pre>
<h3 id="医学图像segment中u-net">医学图像segment中U-Net</h3>
<ul>
<li>paper: <a
href="https://lmb.informatik.uni-freiburg.de/Publications/2019/FMBCAMBBR19/paper-U-Net.pdf">U-net:
Convolutional networks for biomedical image segmentation</a></li>
<li>作者： Olaf Ronneberger, Philipp Fischer, and Thomas Brox</li>
<li><a
href="https://lmb.informatik.uni-freiburg.de/resources/opensource/unet/">project</a>
其中使用的数据增强方案为论文 <a
href="https://arxiv.org/pdf/1406.6909.pdf">Discriminative Unsupervised
Feature Learning with Exemplar Convolutional Neural
Networks</a>中的方法：</li>
</ul>
<blockquote>
<p>we train the network to discriminate between a set of surrogate
classes. Each surrogate class is formed by applying a variety of
transformations to a randomly sampled ’seed’ image patch. In contrast to
supervised network training, the resulting feature representation is not
class specific. It rather provides robustness to the transformations
that have been applied during training. This generic feature
representation allows for classification results that outperform the
state of the art for unsupervised learning on several popular datasets
(STL-10, CIFAR-10, Caltech-101, Caltech-256). While such generic
features cannot compete with class specific features from supervised
training on a classification task, we show that they are advantageous on
geometric matching problems, where they also outperform the SIFT
descriptor.</p>
</blockquote>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>https://arxiv.org/pdf/1805.09501.pdf
"AutoAugment:Learning Augmentation Strategies from Data"<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>https://arxiv.org/pdf/1906.11172.pdf
"Learning Data Augmentation Strategies for Object Detection"<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>https://zhuanlan.zhihu.com/p/76446741
"目标检测之Data Augmentation"<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>detection</tag>
      </tags>
  </entry>
  <entry>
    <title>高通芯片笔记</title>
    <url>/201903/20190301-Hexagon-DSP/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>从2011年甚至更早开始，智能手机，智能终端，车载芯片等等智能终端中，高通芯片无处不在。相比较Intel，高通抓住了移动处理器中续航的问题，不断推出低功耗移动处理器，从而抓住移动处理器的市场。日常工作中接触到很多冠以高通之名的产品，记录以习之。</p>
<h2 id="性能排行榜">性能排行榜</h2>
<p>收集了一下<a
href="https://www.xianshua.net/top/5534.html">2018年高通骁龙CPU处理器排行榜</a>和<a
href="http://mobile.zol.com.cn/soc/">各种手机品牌的处理器性能对比</a>，从中可以看出，骁龙系列
处理器也是分为高中低端处理器的，其中去年最常见的845系列，占据较大的市场份额。与之争锋麒麟
980虽然在HUWEI Meta 20
Pro的跑分汇总获得更高名次，性能前10中高通独占8席。</p>
<h2 id="骁龙">骁龙</h2>
<p>为什么要选择骁龙处理器？
骁龙移动处理器是Qualcomm开发的完整片上系统解决方案系列产品，该系列适应用户需求而提供卓越的用户体验和更长的电池寿命。利用骁龙处理器先进的处理能力和并发性能，您可以同时运行多个高级应用，而对电池的消耗却可以降到最少。</p>
<p>骁龙处理器经过发展，早已不再仅仅支持先进的手机，还可在各种智能产品和互连设备上看到它的身影，包括可穿戴设备、智能家电、智能电话亭和数字标识系统等。我们的一系列软硬件解决方案专门提供您所需要的，以帮助您最大限度地利用采用骁龙处理器的设备。我们的SDK、Profiler分析器和调试器能帮助您分析和提升应用性能、打造创新特性和创造新的互连体验。我们甚至能帮助您开始按照您自身的设计打造设备（从原型设计到生产的全过程）。如果您要打造下一代设备，采用骁龙处理器的开发设备，您便已经可以将未来握在手中了。</p>
<p><a
href="https://developer.qualcomm.com/">高通公司官网开发文档</a></p>
<h3 id="cpu">CPU</h3>
<p>有了高品质的处理内核，骁龙处理器中经优化的CPU是专为让您的应用运行得更快、更流畅而设计。我们所有CPU的目标是将世界级的移动体验带进生活，同时智能地控制电池寿命。但是如果没有能完全发挥其特性的软件，即使是最高性能的CPU也不能开发出自身的全部潜力。采用骁龙LLVM编译器编译的代码在骁龙处理器上会执行的更好，因为它具有独特的优化处理和漏洞修复。</p>
<h3 id="gpu">GPU</h3>
<p>图形性能对于现代移动体验是一个重要部分，这就是为什么我们的Qualcomm骁龙处理器要内置开拓性的Adreno™图形处理器的原因。Adreno是目前最先进的移动图形处理背后的发电站，它能加速游戏、用户界面和网络浏览器中复杂几何体的渲染。快来下载Adreno
SDK，优化您针对Adreno
GPU的应用，该SDK含打造沉浸式手机游戏体验所需的工具、库、示例、文档和辅导资料。您还可利用Adreno
Profiler分析器来分析和优化您应用的图形性能。该分析器具有的特性包括：基于硬件的性能监视器、渲染调用指标、Shader原型设计等。</p>
<h3 id="dsp">DSP</h3>
<p>在最适合的处理引擎上运行适当的任务能为开发者带来性能优势。这就是为什么开发Hexagon
DSP的原因，该产品专为优化调制解调器和多媒体应用而设计，具有的特性包括<strong>硬件辅助多线程</strong>。Hexagon
SDK使您能最大化发挥DSP的性能，提供一个用于生成动态Hexagon
DSP代码模块的环境，并且使您能访问Hexagon
DSP上的内置计算资源。该SDK是专为帮助确保处理效率而设计，这意味着它具备更高的流动性、更低的延迟和卓越的应用性能。</p>
<h2 id="csdn中高通专栏"><a
href="https://qualcomm.csdn.net/">CSDN中高通专栏</a></h2>
<h2 id="中科创达-王庆民关于hexagon-dsp功能介绍"><a
href="https://blog.csdn.net/awangqm/article/details/49333385">【中科创达-王庆民】关于Hexagon
DSP功能介绍</a></h2>
<p>Qualcomm的晓龙芯片从创立之几乎一直内置Hexagon
DSP芯片，它是移动异构计算必需的处理引擎。Hexagon架构设计的核心在于如何在低功耗的情况下能够高性能的处理各种各样的应用，它具有的特性包括多线程，特权级，VLIW，SIMD以及专门适应于信号处理的指令。该CPU可以在单个时间周期中依序快速的将四个指令（已打包好）处理为执行单元。硬件多线程则由
TMT（TemporalMultiThreading，时间多线程）来实现，在这种模式下，频率600MHz的物理核心可以被抽象成三个频率200MHz的核心。许多体验如声音和图像增强功能以及高级摄像头和传感器功能都包括信号处理任务，而DSP尤其擅长在低功耗下处理这些任务。起初，Hexagon
DSP作为处理引擎，主要用于语音和简单的音频播放。现在，Hexagon
DSP的作用已经扩展至多种用途，如图像增强、计算机视觉、扩增实境、视频处理和传感器处理。随着智能手机使用需求的不断加大，现在包括摄像头和传感器功能都包括信号处理任务都需要借助DSP来完成，相比强大的CPU，DSP尤其擅长在低功耗下处理这些任务。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/dsp/820.png"
alt="@Qualcomm最新发布的Hexagon 680 DSP版本新特性" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="Qualcomm最新发布的Hexagon">@Qualcomm最新发布的Hexagon</span>
680 DSP版本新特性</figcaption>
</figure>
<h2 id="高清图像处理低功耗qualcomm-hexagon-vector-extensions-hvx"><a
href="https://www.csdn.net/article/a/2015-09-15/15828177">高清图像处理，低功耗——Qualcomm®
Hexagon™ Vector eXtensions (HVX)</a></h2>
<p>摘要：过去几年，开发人员一直在利用 Hexagon SDK，量身定制
DSP，处理音频、图像与计算 。在 HotChips
半导体会议上，我们揭开了即将上市的 Snapdragon 820 处理器中全新 Hexagon
DSP 的部分面纱。这款 Hexagon 680 DSP ，集成宽幅向量处理 Hexagon
向量扩展（HVX）核心，充分利用新的DSP 应用实例。 英文原版<a
href="https://developer.qualcomm.com/blog/high-res-image-processing-low-power-consumption-qualcomm-hexagon-vector-extensions-vx">High-Res
Image Processing, Low Power Consumption – Qualcomm® Hexagon™ Vector
eXtensions (VX)</a> 关于HVX技术，可以参考如下介绍
https://www.hotchips.org/wp-content/uploads/hc_archives/hc27/HC27.24-Monday-Epub/HC27.24.20-Multimedia-Epub/HC27.24.211-Hexagon680-Codrescu-Qualcomm.pdf</p>
<p>高通向量拓展技术的概括 与NEON编程模型相类似，在计算机视觉应用领域
<img data-src="https://cwlseu.github.io/images/dsp/DSP-HVX.png"
alt="Alt text" /></p>
<p>指令和CPU的NEON指令相比，指令简单，更低功耗 <img data-src="https://cwlseu.github.io/images/dsp/DSP-Difference.png"
alt="Alt text" /></p>
<p>性能方面,CPU使用NEON优化虽然能够提升1<sub>3的速度，但是单pixel功耗方面大约是DSP的4</sub>18倍。
<img data-src="https://cwlseu.github.io/images/dsp/DSP-Benchmark.png"
alt="@Benchmark" /></p>
<h2 id="snapdragon-neural-processing-engine-snpe">Snapdragon Neural
Processing Engine (SNPE)</h2>
<h3 id="capabilities">Capabilities</h3>
<p>The Snapdragon Neural Processing Engine (SNPE) is a Qualcomm
Snapdragon software accelerated runtime for the execution of deep neural
networks. With SNPE, users can:</p>
<ul>
<li>Execute an arbitrarily deep neural network</li>
<li>Execute the network on the SnapdragonTM CPU, the AdrenoTM GPU or the
HexagonTM DSP.</li>
<li>Debug the network execution on x86 Ubuntu Linux</li>
<li>Convert Caffe, Caffe2, ONNXTM and TensorFlowTM models to a SNPE Deep
Learning Container (DLC) file</li>
<li>Quantize DLC files to 8 bit fixed point for running on the Hexagon
DSP</li>
<li>Debug and analyze the performance of the network with SNPE
tools</li>
<li>Integrate a network into applications and other code via C++ or
Java</li>
</ul>
<h3 id="workflow">Workflow</h3>
<p>Model training is performed on a popular deep learning framework
(Caffe, Caffe2, ONNX and TensorFlow models are supported by SNPE.) After
training is complete the trained model is converted into a DLC file that
can be loaded into the SNPE runtime. This DLC file can then be used to
perform forward inference passes using one of the Snapdragon accelerated
compute cores. The basic SNPE workflow consists of only a few steps:</p>
<p><img data-src="https://cwlseu.github.io/images/dsp/snpe.png"
alt="@SNPE运行模型的工作流" /> * Convert the network model to a DLC file
that can be loaded by SNPE. * Optionally quantize the DLC file for
running on the Hexagon DSP. * Prepare input data for the model. * Load
and execute the model using SNPE runtime.</p>
<h3 id="测试模型">测试模型</h3>
<ol type="1">
<li>添加环境变量 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(__linux__) || defined(__ANDROID__)</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">SetAdspLibraryPath</span><span class="params">(std::string nativeLibPath)</span> </span>&#123;</span><br><span class="line">    std::stringstream path;</span><br><span class="line">    path &lt;&lt; nativeLibPath &lt;&lt; <span class="string">&quot;;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">setenv</span>(<span class="string">&quot;ADSP_LIBRARY_PATH&quot;</span>, path.<span class="built_in">str</span>().<span class="built_in">c_str</span>(), <span class="number">1</span> <span class="comment">/*override*/</span>) == <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">error</span> <span class="string">&quot;the platform not support dsp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure></li>
</ol>
<p><code>./snpe-net-run --container ./modelname.dlc --input_list list.one --use_dsp</code></p>
<ul>
<li><a
href="https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk">SNPE
sdk download</a></li>
<li><a
href="https://developer.qualcomm.com/docs/snpe/overview.html">SNPE
document</a></li>
<li><a
href="https://developer.qualcomm.com/docs/snpe/network_layers.html">SNPE支持的网络层</a></li>
<li><a
href="https://blog.csdn.net/guvcolie/article/details/77937786">SNPE用户自定义层JNI实现</a></li>
</ul>
<h2 id="参考链接">参考链接</h2>
<ul>
<li><a
href="http://mobile.zol.com.cn/soc/">手机处理器性能排行榜</a></li>
<li><a
href="http://www.mydrivers.com/zhuanti/tianti/01/">手机CPU性能天梯图</a></li>
<li><a
href="https://www.xianshua.net/top/5534.html">2018年高通骁龙CPU处理器排行榜</a></li>
<li><a
href="http://www.ti.com.cn/general/cn/docs/gencontent.tsp?contentId=61574">【德州仪器DSP技术应用工程师
冯华亮】影响高性能DSP功耗的因素及其优化方法</a></li>
<li><a
href="https://blog.csdn.net/yuanlulu/article/details/80857211">移动端深度学习框架小结</a></li>
</ul>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>HPC</tag>
        <tag>SNPE</tag>
      </tags>
  </entry>
  <entry>
    <title>Object Detection Metrics</title>
    <url>/201903/20190311-object-detection-metrics/</url>
    <content><![CDATA[<h2 id="物体检测效果评估相关的定义-1">物体检测效果评估相关的定义 <a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h2>
<h3 id="intersection-over-union-iou">Intersection Over Union (IOU)</h3>
<p>Intersection Over Union (IOU) is measure based on Jaccard Index that
evaluates the overlap between two bounding boxes. It requires a ground
truth bounding box <span class="math inline">\(B_{gt}\)</span>and a
predicted bounding box <span class="math inline">\(B_p\)</span> By
applying the IOU we can tell if a detection is valid (True Positive) or
not (False Positive).<br />
IOU is given by the overlapping area between the predicted bounding box
and the ground truth bounding box divided by the area of union between
them:</p>
<p><span class="math display">\[IOU = \frac{\text{area of
overlap}}{\text{area of union}} = \frac{area(B_p \cap B_{gt})}{area(B_p
\cup B_{gt})}\]</span></p>
<p>The image below illustrates the IOU between a ground truth bounding
box (in green) and a detected bounding box (in red).</p>
<p align="center">
<img data-src="https://cwlseu.github.io/images/detection/iou.png" align="center"/>
</p>
<h3
id="true-positive-false-positive-false-negative-and-true-negative4">True
Positive, False Positive, False Negative and True Negative<a href="#fn2"
class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></h3>
<p>Some basic concepts used by the metrics:</p>
<ul>
<li><strong>True Positive (TP)</strong>: A correct detection. Detection
with <code>IOU ≥ _threshold_</code></li>
<li><strong>False Positive (FP)</strong>: A wrong detection. Detection
with <code>IOU &lt; _threshold_</code></li>
<li><strong>False Negative (FN)</strong>: A ground truth not
detected</li>
<li><strong>True Negative (TN)</strong>: Does not apply. It would
represent a corrected misdetection. In the object detection task there
are many possible bounding boxes that should not be detected within an
image. Thus, TN would be all possible bounding boxes that were
corrrectly not detected (so many possible boxes within an image). That's
why it is not used by the metrics.</li>
</ul>
<p><code>_threshold_</code>: depending on the metric, it is usually set
to 50%, 75% or 95%.</p>
<h3 id="precision">Precision</h3>
<p>Precision is the ability of a model to identify <strong>only</strong>
the relevant objects. It is the percentage of correct positive
predictions and is given by: <span class="math display">\[Precision =
\frac{TP}{TP + FP} = \frac{TP}{all-detections}\]</span></p>
<h3 id="recall">Recall</h3>
<p>Recall is the ability of a model to find all the relevant cases (all
ground truth bounding boxes). It is the percentage of true positive
detected among all relevant ground truths and is given by: <span
class="math display">\[Recall = \frac{TP}{TP + FN} =
\frac{TP}{all-groundtruths}\]</span> <img data-src="http://cwlseu.github.io/images/detection/confusion-metrics.png"
alt="@混淆矩阵" /></p>
<h2 id="评估方法metrics235">评估方法Metrics<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a><a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a><a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a></h2>
<ul>
<li>Receiver operating characteristics (ROC) curve</li>
<li>Precision x Recall curve</li>
<li>Average Precision
<ul>
<li>11-point interpolation</li>
<li>Interpolating all points</li>
</ul></li>
</ul>
<h2 id="物体检测中的损失函数">物体检测中的损失函数</h2>
<p><a
href="https://yq.aliyun.com/articles/602858?utm_content=m_1000002415">【机器学习者都应该知道的五种损失函数！】</a>
我们假设有<span class="math inline">\(n\)</span>个样本, 其中<span
class="math inline">\(x_i\)</span>的gt值为<span
class="math inline">\(y_i\)</span>, 算法<span
class="math inline">\(f(x)\)</span>的预测结果为<span
class="math inline">\(y_i^p\)</span></p>
<h4 id="均方误差-l2损失">均方误差 —— L2损失</h4>
<p>均方误差（MSE）是回归损失函数中最常用的误差，它是预测值与目标值之间差值的平方和，公式如下</p>
<p><span class="math display">\[MSE = \frac{\sum_{i=1}^{n}(y_i -
y_i^p)^2}{n}\]</span></p>
<h4 id="平均绝对误差l1损失函数">平均绝对误差——L1损失函数</h4>
<p>平均绝对误差（MAE）是另一种常用的回归损失函数，它是目标值与预测值之差绝对值的和，表示了预测值的平均误差幅度，而不需要考虑误差的方向（注：平均偏差误差MBE则是考虑的方向的误差，是残差的和），范围是0到<span
class="math inline">\(\infin\)</span></p>
<p><span class="math display">\[MAE = \frac{\sum_{i=1}^{n}|y_i -
y_i^p|}{n}\]</span></p>
<h4 id="l1-v.s-l2损失函数7">L1 v.s L2损失函数<a href="#fn6"
class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a></h4>
<p>通常，利用均方差更容易求解，但平方绝对误差则对于异常值更稳健。</p>
<p>下面让我们对这两种损失函数进行具体的分析。无论哪一种机器学习模型，目标都是找到能使目标函数最小的点。在最小值处每一种损失函数都会得到最小值。</p>
<p><a
href="http://nbviewer.ipython.org/github/rishy/rishy.github.io/blob/master/ipy_notebooks/L1%20vs.%20L2%20Loss.ipynb">可以运行相关代码进行分析</a><a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p>
<p>由于均方误差（MSE）在误差较大点时的损失远大于平均绝对误差（MAE），它会给异常值赋予更大的权重，模型会全力减小异常值造成的误差，从而使得模型的整体表现下降。所以当训练数据中含有较多的异常值时，平均绝对误差（MAE）更为有效。当我们对所有观测值进行处理时，如果利用MSE进行优化则我们会得到所有观测的均值，而使用MAE则能得到所有观测的中值。与均值相比，中值对于异常值的鲁棒性更好，这就意味着平均绝对误差对于异常值有着比均方误差更好的鲁棒性。</p>
<p>但MAE也存在一个问题，特别是对于神经网络来说，它的<strong>梯度在极值点处会有很大的跃变</strong>，及时很小的损失值也会长生很大的误差，这很不利于学习过程。<strong>为了解决这个问题，需要在解决极值点的过程中动态减小学习率</strong>。MSE在极值点却有着良好的特性，及时在固定学习率下也能收敛。MSE的梯度随着损失函数的减小而减小，这一特性使得它在最后的训练过程中能得到更精确的结果。</p>
<p>在实际训练过程中，如果异常值对于实际业务十分重要需要进行检测，MSE是更好的选择，而如果在异常值极有可能是坏点的情况下MAE则会带来更好的结果。</p>
<p>总结：L1损失对于异常值更鲁棒，但它的导数不连续使得寻找最优解的过程低效；L2损失对于异常值敏感，但在优化过程中更为稳定和准确。更详细的L1和L2不同比较可以参考这篇文章。</p>
<blockquote>
<p>但现实中还存在两种损失都很难处理的问题。例如某个任务中90%的数据都符合目标值——150，而其余的10%数据取值则在0-30之间。那么利用MAE优化的模型将会得到150的预测值而忽略的剩下的10%（倾向于中值）；而对于MSE来说由于异常值会带来很大的损失，将使得模型倾向于在0-30的方向取值。这两种结果在实际的业务场景中都是我们不希望看到的。</p>
</blockquote>
<h4 id="huber损失平滑平均绝对误差">Huber损失——平滑平均绝对误差</h4>
<p>Huber损失相比于平方损失来说对于异常值不敏感，但它同样保持了可微的特性。它基于绝对误差但在误差很小的时候变成了平方误差。我们可以使用超参数<span
class="math inline">\(\delta\)</span>来调节这一误差的阈值。当<span
class="math inline">\(\delta\)</span>趋向于0时它就退化成了MAE，而当<span
class="math inline">\(\delta\)</span>趋向于无穷时则退化为了MSE，其表达式如下，是一个连续可微的分段函数：</p>
<p><span class="math display">\[ L_\delta(y, f(x)) =
   \begin{cases}
    \frac{1}{2}(y - f(x))^2       &amp; \quad \text{if } |y - f(x)| \le
\delta\\
    \delta{|y - f(x)|} - \frac{1}{2}\delta^2  &amp; \quad
\text{otherwise }\\
  \end{cases} \]</span></p>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/HuberLoss.png"
alt="@HuberLoss with delta change" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="HuberLoss">@HuberLoss</span> with delta change</figcaption>
</figure>
<p>对于Huber损失来说，<span
class="math inline">\(\delta\)</span>的选择十分重要，它决定了模型处理异常值的行为。当残差大于<span
class="math inline">\(\delta\)</span>时使用L1损失，很小时则使用更为合适的L2损失来进行优化。</p>
<p>Huber损失函数克服了MAE和MSE的缺点，不仅可以保持损失函数具有连续的导数，同时可以利用MSE梯度随误差减小的特性来得到更精确的最小值，也对异常值具有更好的鲁棒性。</p>
<p>而Huber损失函数的良好表现得益于精心训练的超参数<span
class="math inline">\(\delta\)</span>.</p>
<h2 id="参考文献">参考文献</h2>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://github.com/cwlseu/Object-Detection-Metrics
"评估标准"<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"
role="doc-endnote"><p>https://acutecaretesting.org/en/articles/precision-recall-curves-what-are-they-and-how-are-they-used
"Precision-recall curves – what are they and how are they used"<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>https://www.jianshu.com/p/c61ae11cc5f6
"机器学习之分类性能度量指标 : ROC曲线、AUC值、正确率、召回率"<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/
"How and When to Use ROC Curves and Precision-Recall Curves for
Classification in Python"<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>https://www.zhihu.com/question/30643044
"精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？"<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://yq.aliyun.com/articles/602858?utm_content=m_1000002415
"机器学习者都应该知道的五种损失函数！"<a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"
role="doc-endnote"><p>http://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/?spm=a2c4e.10696291.0.0.170b19a44a9JnP<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>detection</tag>
      </tags>
  </entry>
  <entry>
    <title>笔记：混合精度训练技术报告</title>
    <url>/201904/20190407-cuda9-mixed-precision/</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<p>CUDA在推出7.5的时候提出了
可以计算16位浮点数据的新特性。定义了两种新的数据类型<code>half</code>和<code>half2</code>.
NVIDIA GPUs implement the IEEE 754 floating point standard (2008), which
defines half-precision numbers as follows (see Figure 1).</p>
<ul>
<li>Sign: 1 bit</li>
<li>Exponent width: 5 bits</li>
<li>Significand precision: 11 bits (10 explicitly stored) The range of
half-precision numbers is approximately <span class="math inline">\(5.96
\times 10^{-8} \ldots 6.55 \times 10^4\)</span>. <code>half2</code>
structures store two half values in the space of a single 32-bit word,
as the bottom of Figure 1 shows.</li>
</ul>
<figure>
<img data-src="https://devblogs.nvidia.com/wp-content/uploads/2015/07/fp16_format-624x146.png"
alt="@Figure 1:16-bit half-precision data formats. Top: single half value. Bottom: half2 vector representation." />
<figcaption aria-hidden="true"><span class="citation"
data-cites="Figure">@Figure</span> 1:16-bit half-precision data formats.
Top: single <code>half</code> value. Bottom: <code>half2</code> vector
representation.</figcaption>
</figure>
<p>CUDA-9中已经开始支持混合精度训练<a href="#fn1" class="footnote-ref"
id="fnref1"
role="doc-noteref"><sup>1</sup></a>，TensorRT作为NVIDIA的inference引擎，同样支持混合精度的神经网络inference计算.
之前在网上看到半精度memory
copy与计算，发现copy的代价会减少一半，而计算的提升并不是很理想。后来看到了《<a
href="https://devtalk.nvidia.com/default/topic/972337/gpu-accelerated-libraries/why-cublashgemm-is-slower-more-than-cublassgemm-when-i-use-/"><code>why cublasHgemm is slower more than cublasSgemm when I use?</code></a>》这个帖子，终于发现其中的一点规律。</p>
<p>问题的提出者问，为什么在GTX1070上运行<code>cublasHgemm</code>（半精度计算）
比
<code>cublasSgemm</code>（单精度计算）计算的慢呢？NVIDIA官方的回答说，当前Pascal架构的GPU只有的P100的FP16计算快于FP32。并且给出了编程手册的吞吐量的表<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>。</p>
<h1 id="alibaba-pai-auto-mixed-precision-training-techniques">Alibaba
PAI: Auto-Mixed Precision Training Techniques</h1>
<p>随着NVIDIA release的APEX<a href="#fn3" class="footnote-ref"
id="fnref3"
role="doc-noteref"><sup>3</sup></a>，利用Volta架构和混合精度在Pytorch上进行拓展，实现了训练的精度混合。腾讯<a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>和百度<a href="#fn5"
class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>分别发表关于混合精度训练的文章.PAI-TAO是alibaba内部一个关于混合精度训练的一个研究项目。
在整个AI模型的生命周期中的位置如下：</p>
<figure>
<img data-src="http://cwlseu.github.io/images/mixed-precision/PAI-TAO.png"
alt="@PAI-TAO" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="PAI-TAO">@PAI-TAO</span></figcaption>
</figure>
<p>从中可以看出，自动混合精度主要是在训练过程中，为了加快计算节点之间的数据交换和层之间的数据交换与计算，采用FP16来替换FP32，这样在计算结果精度几乎不损失的情况下，带了数据交换和计算速度方面的性能提升，从而加快模型训练速度。</p>
<p>而这项任务的成功，与CUDA9中支持TensorCore的特性是息息相关的。下面对TensorCode进行简单介绍。</p>
<figure>
<img data-src="http://cwlseu.github.io/images/mixed-precision/tensorcore.png"
alt="@tensor core" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="tensor">@tensor</span> core</figcaption>
</figure>
<p>TensorCore是NVIDIA在Volta
architecture下引入的，专门针对计算4x4矩阵的计算模块。
以前NVIDIA的GPU中只有FP32和FP64计算单元，在TensorCore中，特别针对FP16做了相应的补充，
来补充在半精度浮点方面的不足。TensorCore相比较直接进行FP32的计算，速度有了很大的提升。</p>
<h3 id="为什么采用ampauto-mixed-precision">为什么采用AMP（Auto
mixed-precision）</h3>
<h4 id="mixed-precision的优势">Mixed-precision的优势</h4>
<ul>
<li>充分发挥Volta架构引入的TensorCore计算性能
(<code>15</code>-&gt;<code>120TFLOPs</code>, 8X)</li>
<li>减少了访存带宽</li>
</ul>
<h4 id="no-free-lunch">No free-lunch</h4>
<ul>
<li>用户模型改写的人力负担</li>
<li>精度调优问题</li>
<li>充分利用TensorCore的技术tricks
<ul>
<li>数据尺寸对齐问题</li>
<li>Layout问题</li>
</ul></li>
<li>TensorCore将计算密集部分比例降低以后的进一步优化空间挖掘</li>
</ul>
<h3 id="如何ampdesign-philosophy">如何AMP：Design Philosophy</h3>
<ul>
<li>精度问题
<ul>
<li>模型以FP32进行保存</li>
<li>不同算子的区别处理
<ul>
<li>计算密集型算子（MatMul/Conv）
输入为FP16，FP32累加中间结果，输出为FP32，计算基于TensorCore</li>
<li>访存密集型算法（Add/Reduce/…) 输入输出均为FP16，计算为FP16/FP32,
不使用TensorCore，访存量减少</li>
</ul></li>
<li>Loss scaling策略解决gradient underflow问题</li>
<li>表达精度问题： FP32-&gt;FP16
<ul>
<li>尾数位减少: precision gap in sum (Solution: 模型以FP32进行保存)</li>
<li>指数位减少: gradient underflow</li>
</ul></li>
</ul></li>
</ul>
<figure>
<img data-src="http://cwlseu.github.io/images/mixed-precision/scaling.png"
alt="@scale在训练过程中的作用" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="scale在训练过程中的作用">@scale在训练过程中的作用</span></figcaption>
</figure>
<ul>
<li>速度及易用性问题
<ul>
<li>通过图优化pass自动完成混合精度所需的图转换工作</li>
</ul></li>
</ul>
<h3 id="结果">结果</h3>
<ul>
<li>No laborious FP32/FP16 casting work anymore</li>
<li>Already supporting diversified internal workloads:
NLP/CNN/Bert/Graph Embedding</li>
<li><code>1.3~3x</code> time-to-accuracy speed-up 与PAI-TAO
Compiler联合使用可以达到1+1&gt;2的加速收益</li>
</ul>
<h1 id="题外思考">题外思考</h1>
<p>现在我们的训练应该是没有引入混合精度训练的，而且inference框架中没有混合精度的苗头。
我们的inference应该可以先支持起混合精度的，然后后面慢慢地在训练框架中添加相关功能。
然后重构节点之间的数据交换代码，加大对混合精度训练的时候并行度，进一步降低训练模型的成本。
尤其是弱计算能力的芯片上，通过添加混合计算功能，能够在加速的同时，追求更高的精度。
现在很多AI推理芯片如华为himix200中，支持int8和int16的计算，而且同一个模型可以混合int8和int16的精度类型。</p>
<h1 id="参考文献">参考文献</h1>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://docs.nvidia.com/deeplearning/sdk/pdf/Training-Mixed-Precision-User-Guide.pdf
"Training-Mixed-Precision-User-Guide"
<!-- [^7]: http://m.elecfans.com/article/640489.html "英伟达发布全新AI芯片Jetson Xavier" --><a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"
role="doc-endnote"><p>https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#arithmetic-instructions
"throughputs of the arithmetic instructions"<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>https://cloud.tencent.com/developer/news/254121
"混合精度训练之APEX"<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>http://m.elecfans.com/article/721085.html
"一种具有混合精度的高度可扩展的深度学习训练系统"<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>https://arxiv.org/pdf/1710.03740.pdf
"百度和NVIDIA联合出品：MIXED PRECISION TRAINING"<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>HPC</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>开发中常见的编译器技巧</title>
    <url>/201904/20190411-cpp-compiler/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>编译器是我们开发人员与机器指令之间的翻译,现在编译器越来越优化,而且基于一些开源的编译器项目(gcc,clang)等,相继出现不同platform下的编译器。
此外，各种芯片、开发板层出不穷，各个商业公司都针对自己出产的开发板定制特定的编译链条。例如华为hisi系列的himix100中提供的编译链中，包括编译器，链接器，打包器之外，还提供了nm，gdb，gcov，gprof等等开发工具。
这篇文章将主要将开发工作中与编译器（这篇文章中不作特殊说明，指的是gnu
gcc编译器）相关的一些options和配置参数进行总结,方便在后面的项目遇到相似的问题进行查阅与借鉴。</p>
<h2 id="编译常见问题">编译常见问题</h2>
<h3
id="包含静态库中所有符号的option">1、包含静态库中所有符号的option</h3>
<p><span class="math display">\[A -&gt; B -&gt; C\]</span></p>
<p>编译shared target
B库的时候，gcc编译器默认是用什么区什么的原则，也就是说，依赖了库A中哪个.o文件中的东西，就会把相应的.o文件
打包到最终的库中。但是，有的时候在这个库中我们并没有引用全部的符号，但是当其他库C依赖我们这个B库的时候，如果引用了B中未引用的A中的符号，这个时候会出现"undefined
reference"的编译错误。<code>-Wl,--whole-archive</code>可以实现将所有库中的符号打包进去。</p>
<p>编译器编译动态库或者运行程序的时候，会对依赖的静态库中进行基于<code>.o</code>的选择，但是有的时候我们希望我们编译的动态库能够包含所有的函数实现给用户使用。gcc中的链接控制选项<code>-Wl,--whole-archive xxxxx_lib -Wl,--no-whole-archive</code>就可以实现类似功能。</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">target_link_libraries</span>(xxxx_export </span><br><span class="line">            PRIVATE <span class="string">&quot;-Wl,--whole-archive&quot;</span> $&lt;TARGET_FILE:xxxxx_lib&gt;</span><br><span class="line">                    <span class="string">&quot;-Wl,--no-whole-archive -Wl,--exclude-libs,ALL&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="其他可能问题">2、其他可能问题</h3>
<p><code>--exclude-libs</code> does not work for static libraries
affected by the <code>--whole-archive</code> option.</p>
<ul>
<li><code>--exclude-libs</code> creates a list of static library paths
and does library lookups in this list.</li>
<li><code>--whole-archive</code> splits the static libraries that follow
it into separate objects. As a result, lld no longer sees static
libraries among linked files and does no <code>--exclude-libs</code>
lookups.</li>
</ul>
<h4 id="solution">Solution</h4>
<p>The proposed solution is to make <code>--exclude-libs</code> consider
object files too. When lld finds an object file it checks whether this
file originates from an archive and, if so, looks the archive up in the
<code>--exclude-libs</code> list.</p>
<p><strong>Reference</strong>: https://reviews.llvm.org/D39353</p>
<h3
id="编译运行查找头文件和库的顺序">3、编译运行查找头文件和库的顺序</h3>
<blockquote>
<p>gcc 在编译时如何去寻找所需要的头文件:</p>
</blockquote>
<ul>
<li>所以header file的搜寻会从-I开始</li>
<li>然后找gcc的环境变量
<code>C_INCLUDE_PATH</code>，<code>CPLUS_INCLUDE_PATH</code>，<code>OBJC_INCLUDE_PATH</code></li>
<li>再找内定目录
<ul>
<li><code>/usr/include</code></li>
<li><code>/usr/local/include</code></li>
</ul></li>
</ul>
<p>gcc的一系列自带目录
<code>CPLUS_INCLUDE_PATH=/usr/lib/gcc/x86_64-linux-gnu/4.9.4/include:/usr/include/c++/4.9.4</code></p>
<blockquote>
<p>库文件</p>
</blockquote>
<p>编译的时候： * gcc会去找-L * 再找gcc的环境变量LIBRARY_PATH *
再找内定目录 * <code>/lib</code>和<code>/lib64</code> *
<code>/usr/lib</code> 和<code>/usr/lib64</code> *
<code>/usr/local/lib</code>和<code>/usr/local/lib64</code></p>
<p>这是当初compile gcc时写在程序内的</p>
<h3 id="运行时动态库的搜索路径">4、运行时动态库的搜索路径</h3>
<p>动态库的搜索路径搜索的先后顺序是： 1.
编译目标代码时指定的动态库搜索路径； 2.
环境变量<code>LD_LIBRARY_PATH</code>指定的动态库搜索路径； 3.
配置文件<code>/etc/ld.so.conf</code>中指定的动态库搜索路径； 4.
默认的动态库搜索路径<code>/lib</code>； 5.
默认的动态库搜索路径<code>/usr/lib</code>。</p>
<h3 id="动态库中的static变量">5、动态库中的static变量</h3>
<blockquote>
<p>In all cases, static global variables (or functions) are never
visible from outside a module (dll/so or executable). The C++ standard
requires that these have internal linkage, meaning that they are not
visible outside the translation unit (which becomes an object file) in
which they are defined.</p>
</blockquote>
<h2 id="windows编译">windows编译</h2>
<p>在windows常用的编译器是VS里面的cl编译器。我们要实现上述
cmake使用<code>cmake -DCMAKE_WINDOWS_EXPORT_ALL_SYMBOLS=TRUE -DBUILD_SHARED_LIBS=TRUE</code></p>
<pre><code>Enable this boolean property to automatically create a module definition (.def) file with all global symbols found in the input .obj files for a SHARED library on Windows. The module definition file will be passed to the linker causing all symbols to be exported from the .dll. For global data symbols, __declspec(dllimport) must still be used when compiling against the code in the .dll. All other function symbols will be automatically exported and imported by callers. This simplifies porting projects to Windows by reducing the need for explicit dllexport markup, even in C++ classes.

This property is initialized by the value of the CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS variable if it is set when a target is created.</code></pre>
<p><strong>Reference</strong>: <a
href="https://cmake.org/cmake/help/v3.4/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html"><code>WINDOWS_EXPORT_ALL_SYMBOLS</code></a></p>
<h3 id="windows下路径长度不能太长">windows下路径长度不能太长</h3>
<p><strong>error MSB3491: Could n ot write lines to file</strong>
https://stackoverflow.com/questions/31765909/node-socket-io-client-windows-path-too-long-to-install</p>
<h3 id="msvc中预定义宏5">MSVC中预定义宏<a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h3>
<ul>
<li><p><code>_M_IX86</code> Defined as the integer literal value 600 for
compilations that target x86 processors. This macro isn't defined for
x64 or ARM compilation targets.</p></li>
<li><p><code>_M_IX86_FP</code> Defined as an integer literal value that
indicates the <code>/arch</code> compiler option that was set, or the
default. This macro is always defined when the compilation target is an
x86 processor. Otherwise, undefined. When defined, the value is:</p>
<ul>
<li>0 if the <code>/arch:IA32</code> compiler option was set.</li>
<li>1 if the <code>/arch:SSE</code> compiler option was set.</li>
<li>2 if the <code>/arch:SSE2</code>, <code>/arch:AVX</code>,
<code>/arch:AVX2</code>, or <code>/arch:AVX512</code> compiler option
was set. This value is the default if an /arch compiler option wasn't
specified. When <code>/arch:AVX</code> is specified, the macro
<code>__AVX__</code> is also defined. When <code>/arch:AVX2</code> is
specified, both <code>__AVX__</code> and <code>__AVX2__</code> are also
defined. When /arch:AVX512 is specified, <code>__AVX__</code>,
<code>__AVX2__</code>, <code>__AVX512BW__</code>,
<code>__AVX512CD__</code>, <code>__AVX512DQ__</code>,
<code>__AVX512F__</code> and <code>__AVX512VL__</code> are also
defined.</li>
</ul>
<p>For more information, see /arch (x86).</p></li>
<li><p><code>_M_X64</code> Defined as the integer literal value 100 for
compilations that target x64 processors. Otherwise, undefined.</p></li>
<li><p><code>_MSC_VER</code> Defined as an integer literal that encodes
the major and minor number elements of the compiler's version number.
The major number is the first element of the period-delimited version
number and the minor number is the second element. For example, if the
version number of the Microsoft C/C++ compiler is 17.00.51106.1, the
<code>_MSC_VER</code> macro evaluates to 1700. Enter <code>cl /?</code>
at the command line to view the compiler's version number. This macro is
always defined.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Visual Studio version</th>
<th style="text-align: center;"><code>_MSC_VER</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Visual Studio 6.0</td>
<td style="text-align: center;">1200</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio .NET 2002 (7.0)</td>
<td style="text-align: center;">1300</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio .NET 2003 (7.1)</td>
<td style="text-align: center;">1310</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2005 (8.0)</td>
<td style="text-align: center;">1400</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2008 (9.0)</td>
<td style="text-align: center;">1500</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2010 (10.0)</td>
<td style="text-align: center;">1600</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2012 (11.0)</td>
<td style="text-align: center;">1700</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2013 (12.0)</td>
<td style="text-align: center;">1800</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2015 (14.0)</td>
<td style="text-align: center;">1900</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2017 RTW (15.0)</td>
<td style="text-align: center;">1910</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2017 version 15.3</td>
<td style="text-align: center;">1911</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2017 version 15.5</td>
<td style="text-align: center;">1912</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2017 version 15.6</td>
<td style="text-align: center;">1913</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2017 version 15.7</td>
<td style="text-align: center;">1914</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2017 version 15.8</td>
<td style="text-align: center;">1915</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2017 version 15.9</td>
<td style="text-align: center;">1916</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2019 RTW (16.0)</td>
<td style="text-align: center;">1920</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2019 version 16.1</td>
<td style="text-align: center;">1921</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2019 version 16.2</td>
<td style="text-align: center;">1922</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2019 version 16.3</td>
<td style="text-align: center;">1923</td>
</tr>
</tbody>
</table></li>
<li><p><code>_MSVC_LANG</code> Defined as an integer literal that
specifies the C++ language standard targeted by the compiler. It's set
only in code compiled as C++. The macro is the integer literal value
201402L by default, or when the <code>/std:c++14</code> compiler option
is specified. The macro is set to 201703L if the <code>/std:c++17</code>
compiler option is specified. It's set to a higher, unspecified value
when the <code>/std:c++latest</code> option is specified. Otherwise, the
macro is undefined. The <code>_MSVC_LANG</code> macro and
<code>/std (Specify Language Standard Version)</code> compiler options
are available beginning in Visual Studio 2015 Update 3.</p></li>
<li><p><code>_MT</code> Defined as 1 when /MD or /MDd (Multithreaded
DLL) or /MT or /MTd (Multithreaded) is specified. Otherwise,
undefined.</p></li>
<li><p><code>_WIN32</code> Defined as 1 when the compilation target is
32-bit ARM, 64-bit ARM, x86, or x64. Otherwise, undefined.</p></li>
<li><p><code>_WIN64</code> Defined as 1 when the compilation target is
64-bit ARM or x64. Otherwise, undefined.</p></li>
</ul>
<h2 id="gnu-编译器">GNU 编译器</h2>
<h3 id="gccg的--as-needed">1、gcc/g++的<code>--as-needed</code></h3>
<p>gcc/g++提供了<code>-Wl,--as-needed</code>和
<code>-Wl,--no-as-needed</code>两个选项，这两个选项一个是开启特性，一个是取消该特性。</p>
<p>在生成可执行文件的时候，通过 -lxxx
选项指定需要链接的库文件。以动态库为例，如果我们指定了一个需要链接的库，则连接器会在可执行文件的文件头中会记录下该库的信息。而后，在可执行文件运行的时候，动态加载器会读取文件头信息，并加载所有的链接库。在这个过程中，如果用户指定链接了一个毫不相关的库，则这个库在最终的可执行程序运行时也会被加载，如果类似这样的不相关库很多，会明显拖慢程序启动过程。</p>
<p>这时，通过指定<code>-Wl,--as-needed</code>选项，链接过程中，链接器会检查所有的依赖库，没有实际被引用的库，不再写入可执行文件头。最终生成的可执行文件头中包含的都是必要的链接库信息。<code>-Wl,--no-as-needed</code>选项不会做这样的检查，会把用户指定的链接库完全写入可执行文件中。</p>
<p><strong>Reference</strong>: <a
href="https://my.oschina.net/yepanl/blog/2222870">GCC/G++选项
-Wl,--as-needed</a></p>
<h3 id="rdynamic">2、-rdynamic</h3>
<pre><code>Pass the flag `-export-dynamic` to the ELF linker, on targets that support
it. This instructs the linker to add all symbols, not only used ones, to the dynamic symbol table. This option is needed for some uses of `dlopen` or to allow obtaining backtraces from within a program.</code></pre>
<p>关键的不同是：<code>-Wl,--export-dynamic -pthread</code>
<code>-Wl</code>:指示后面的选项是给链接器的 <code>-pthread</code>:
链接程序的时包含libpthread.so
<code>--export-dynamic</code>：就是这个选项让主程序内定义的全局函数对库函数可见。</p>
<p><strong>Reference</strong>: <a
href="https://blog.csdn.net/u011644231/article/details/88880362">gcc链接选项--export-dynamic的一次问题记录</a></p>
<h3
id="glibcxx_use_cxx11_abi">3、<code>_GLIBCXX_USE_CXX11_ABI</code></h3>
<p>在GCC
5.1版本中，libstdc++引入了一个新的ABI，其中包括std::string和std::list的新实现。为了符合2011年c++标准，这些更改是必要的，该标准禁止复制即写字符串，并要求列表跟踪字符串的大小。
为了保持与libstdc++链接的现有代码的向后兼容性，库的soname没有更改，并且仍然支持与新实现并行的旧实现。这是通过在内联命名空间中定义新的实现来实现的，因此它们具有不同的用于链接目的的名称，例如，<code>std::list</code>的新版本实际上定义为<code>std:: _cxx11::list</code>。因为新实现的符号有不同的名称，所以两个版本的定义可以出现在同一个库中。
<code>_GLIBCXX_USE_CXX11_ABI</code>宏控制库头中的声明是使用旧ABI还是新ABI。因此，可以为正在编译的每个源文件分别决定使用哪个ABI。使用GCC的默认配置选项，宏的默认值为1，这将导致新的ABI处于活动状态，因此要使用旧的ABI，必须在包含任何库头之前显式地将宏定义为0。(<strong>注意，一些GNU/Linux发行版对GCC
5的配置不同，因此宏的默认值是0，用户必须将它定义为1才能启用新的ABI</strong>)。</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">IF</span>(CMAKE_CXX_COMPILER_VERSION <span class="keyword">VERSION_LESS</span> <span class="string">&quot;5.1&quot;</span>)</span><br><span class="line">	<span class="keyword">ADD_DEFINITIONS</span>(-D_GLIBCXX_USE_CXX11_ABI=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">ENDIF</span>()</span><br></pre></td></tr></table></figure>
<h3 id="wl--allow-shlib-undefined">4、-Wl,--allow-shlib-undefined</h3>
<p>在交叉编译程序过程中，往往会有这样的情况，依赖的target系统上的动态库（例如android上的OpenCL.so）又依赖其他的许多动态库，这个时候，我们希望链接target系统上的这个动态库的时候，我们可以不要去找OpenCL相关的依赖符号。</p>
<p><code>SET(CMAKE_CXX_FLAGS "$&#123;CMAKE_CXX_FLAGS&#125; -Wl,--allow-shlib-undefined")</code></p>
<blockquote>
<p>Linking errors with “-Wl,--no-undefined
-Wl,--no-allow-shlib-undefined”</p>
</blockquote>
<p>第二个参数的默认值是<code>--allow-shlib-undefined</code>。如果您选择该选项，代码可能会生成。
第二个参数处理构建时检查，启用它意味着检查您所链接的库是否在构建时连接了其依赖项。</p>
<p>第一个参数确保您没有忘记声明对运行时库的依赖项(也可能是运行时库对另一个运行时库的依赖项)。
例如，如果您调用的函数的实现位于示例运行时库“libfunc”中。然后这个库会调用另一个运行时库中的函数libext。然后通过声明对libfunc的“func”和“ext”的依赖关系。因此，将在内部生成一个对libext的依赖引用。
如果您省略<code>--no undefined</code>并忘记添加依赖项声明，那么构建仍然会成功，因为您相信运行时链接器将在运行时解析依赖项。
由于构建成功了，您可能会相信一切都会好起来，而不知道构建已经将责任推迟到运行时链接器。
但大多数情况下，运行时链接器的设计目的不是搜索未解析的引用，而是希望找到运行时库中声明的此类依赖项。如果没有这样的引用，您将得到一个运行时错误。
运行时错误通常比解决编译时错误要昂贵得多。</p>
<h3
id="target_link_library-link_library">5、<code>TARGET_LINK_LIBRARY</code>
&amp; <code>LINK_LIBRARY</code></h3>
<p>target_link_libraries 会将需要链接的库作为属性挂在目标库上，
后面用户用到这个库的时候可以通过<code>get_target_property(interface_link_libs $&#123;&#125; TARGET_LINK_LIBRARIES)</code>进行获取相应的值。</p>
<h2 id="gcc不同版本中一些东西">GCC不同版本中一些东西</h2>
<h3 id="gcc4.9.4">1、GCC4.9.4</h3>
<blockquote>
<p>The <code>-Wdate-time</code> option has been added for the C, C++ and
Fortran compilers, which warns when the <code>__DATE__</code>,
<code>__TIME__</code> or <code>__TIMESTAMP__</code> macros are used.
Those macros might prevent bit-wise-identical reproducible
compilations.</p>
</blockquote>
<blockquote>
<p>With the new <code>#pragma GCC ivdep</code>, the user can assert that
there are no loop-carried dependencies which would prevent concurrent
execution of consecutive iterations using SIMD (single instruction
multiple data) instructions.</p>
</blockquote>
<h4 id="inter-procedural-optimization-improvements">Inter-procedural
optimization improvements:</h4>
<ul>
<li>New type inheritance analysis module improving devirtualization.
Devirtualization now takes into account anonymous name-spaces and the
C++11 final keyword.</li>
<li>New speculative devirtualization pass (controlled by
<code>-fdevirtualize-speculatively</code>.</li>
<li>Calls that were speculatively made direct are turned back to
indirect where direct call is not cheaper.</li>
<li>Local aliases are introduced for symbols that are known to be
semantically equivalent across shared libraries improving dynamic
linking times.</li>
</ul>
<h4 id="feedback-directed-optimization-improvements">Feedback directed
optimization improvements:</h4>
<ul>
<li>Profiling of programs using C++ inline functions is now more
reliable.</li>
<li>New time profiling determines typical order in which functions are
executed.</li>
<li>A new function reordering pass (controlled by -freorder-functions)
significantly reduces startup time of large applications. Until binutils
support is completed, it is effective only with link-time
optimization.</li>
<li>Feedback driven indirect call removal and devirtualization now
handle cross-module calls when link-time optimization is enabled.</li>
</ul>
<p>https://gcc.gnu.org/gcc-4.9/porting_to.html</p>
<h3 id="gcc-5.4">2、GCC 5.4</h3>
<ul>
<li><p>The default mode for C is now -std=gnu11 instead of
-std=gnu89.</p></li>
<li><p>The C++ runtime library (libstdc++) uses a new ABI by default
(see below).</p></li>
<li><p>The non-standard C++0x type traits
<code>has_trivial_default_constructor</code>,
<code>has_trivial_copy_constructor</code> and
<code>has_trivial_copy_assign</code> have been deprecated and will be
removed in a future version. The standard C++11 traits
<code>is_trivially_default_constructible</code>,
<code>is_trivially_copy_constructible</code> and
<code>is_trivially_copy_assignable</code> should be used
instead.</p></li>
<li><p>添加<code>-fipa-icf</code>的配置项目 &gt; An Identical Code
Folding (ICF) pass (controlled via -fipa-icf) has been added. Compared
to the identical code folding performed by the Gold linker this pass
does not require function sections. It also performs merging before
inlining, so inter-procedural optimizations are aware of the code
re-use. On the other hand not all unifications performed by a linker are
doable by GCC which must honor aliasing information.</p></li>
<li><p>The devirtualization pass was significantly improved by adding
better support for speculative devirtualization and dynamic type
detection.</p></li>
<li><p>虚表进行了优化以减少动态链接时间 Virtual tables are now
optimized. Local aliases are used to reduce dynamic linking time of C++
virtual tables on ELF targets and data alignment has been reduced to
limit data segment bloat.</p></li>
<li><p>添加针对不允许插入导出符号的shared库，添加了控制项目以提高代码质量
&gt; A new -fno-semantic-interposition option can be used to improve
code quality of shared libraries where interposition of exported symbols
is not allowed.</p></li>
<li><p>内联可以控制 &gt; With profile feedback the function inliner can
now bypass --param inline-insns-auto and --param inline-insns-single
limits for hot calls.</p></li>
<li><p>常量的过程间传播现在也传播指针参数的对齐。 &gt; The
interprocedural propagation of constants now also propagates alignments
of pointer parameters. This for example means that the vectorizer often
does not need to generate loop prologues and epilogues to make up for
potential misalignments.</p></li>
<li><p>内存使用上一些优化 &gt; Memory usage and link times were
improved. Tree merging was sped up, memory usage of GIMPLE declarations
and types was reduced, and, support for on-demand streaming of variable
constructors was added.</p></li>
</ul>
<h4 id="libstd上的优化">libstd++上的优化</h4>
<ul>
<li>Dual ABI</li>
<li>A new implementation of std::string is enabled by default, using the
small string optimization(SSO) instead of copy-on-write(COW) reference
counting.</li>
<li>A new implementation of std::list is enabled by default, with an
O(1) size() function;</li>
</ul>
<h3 id="gcc-dump-preprocessor-defines">3、GCC dump preprocessor
defines</h3>
<ul>
<li>最常用的输出编译器预定义的宏</li>
</ul>
<p><code>gcc -dM -E - &lt; /dev/null</code></p>
<p><code>g++ -dM -E -x c++ - &lt; /dev/null</code></p>
<ul>
<li>How do I dump preprocessor macros coming from a particular header
file?</li>
</ul>
<p><code>echo "#include &lt;sys/socket.h&gt;" | gcc -E -dM -</code></p>
<ul>
<li>添加某些options之后的</li>
</ul>
<p><code>gcc -dM -E -msse4 - &lt; /dev/null | grep SSE[34]</code> &gt;
#define <strong>SSE3</strong> 1<br />
&gt; #define <strong>SSE4_1</strong> 1<br />
&gt; #define <strong>SSE4_2</strong> 1<br />
&gt; #define <strong>SSSE3</strong> 1</p>
<h3 id="todo">4、TODO</h3>
<ul>
<li>常用的交叉编译的选项</li>
<li>-O3和-O2之间的差别</li>
<li>不同平台之间之间的差别</li>
<li>如何给不同版本的gcc打补丁</li>
</ul>
<p>在文章[Algorithm-Optimization]<a href="#fn2" class="footnote-ref"
id="fnref2"
role="doc-noteref"><sup>2</sup></a>中介绍了一些有利于优化性能的函数，感兴趣可以结合不同平台的优化指令一起学习使用。</p>
<h2 id="gcc-different-platform的配置项">GCC different
platform的配置项</h2>
<p>[Using static and shared libraries across platforms]<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p><img data-src="https://cwlseu.github.io/images/gcc/compilerflag_1.png"
alt="@" /> <img data-src="https://cwlseu.github.io/images/gcc/compilerflag_2.png"
alt="@" /></p>
<h2 id="更多c内容">更多C++内容</h2>
<ul>
<li>http://deepindeed.cn/2018/11/28/gnu-cpp-Relearn/</li>
<li>http://deepindeed.cn/2019/03/18/cpp-program-trick/</li>
<li>libstdc++关于dual ABI文档:
https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html</li>
</ul>
<h2 id="其他">其他</h2>
<ul>
<li>[gcc与g++的区别]<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></li>
<li>[ARM？华为？]<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></li>
<li>himix100的交叉编译链 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">➜  arm-himix100-linux tree -L 2 ./host_bin </span><br><span class="line">./host_bin</span><br><span class="line">├── arm-linux-androideabi-addr2line</span><br><span class="line">├── arm-linux-androideabi-ar</span><br><span class="line">├── arm-linux-androideabi-as</span><br><span class="line">├── arm-linux-androideabi-c++</span><br><span class="line">├── arm-linux-androideabi-c++filt</span><br><span class="line">├── arm-linux-androideabi-cpp</span><br><span class="line">├── arm-linux-androideabi-elfedit</span><br><span class="line">├── arm-linux-androideabi-g++</span><br><span class="line">├── arm-linux-androideabi-gcc</span><br><span class="line">├── arm-linux-androideabi-gcc-6.3.0</span><br><span class="line">├── arm-linux-androideabi-gcc-ar</span><br><span class="line">├── arm-linux-androideabi-gcc-nm</span><br><span class="line">├── arm-linux-androideabi-gcc-ranlib</span><br><span class="line">├── arm-linux-androideabi-gcov</span><br><span class="line">├── arm-linux-androideabi-gcov-tool</span><br><span class="line">├── arm-linux-androideabi-gdb</span><br><span class="line">├── arm-linux-androideabi-gprof</span><br><span class="line">├── arm-linux-androideabi-ld</span><br><span class="line">├── arm-linux-androideabi-ld.bfd</span><br><span class="line">├── arm-linux-androideabi-nm</span><br><span class="line">├── arm-linux-androideabi-objcopy</span><br><span class="line">├── arm-linux-androideabi-objdump</span><br><span class="line">├── arm-linux-androideabi-ranlib</span><br><span class="line">├── arm-linux-androideabi-readelf</span><br><span class="line">├── arm-linux-androideabi-run</span><br><span class="line">├── arm-linux-androideabi-size</span><br><span class="line">├── arm-linux-androideabi-strings</span><br><span class="line">├── arm-linux-androideabi-strip</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="参考文献">参考文献</h2>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://docs.microsoft.com/en-us/cpp/preprocessor/predefined-macros?view=vs-2017
"Predefined macros"<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"
role="doc-endnote"><p>http://deepindeed.cn/2017/03/17/Algorithm-Optimization/<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>http://www.fortran-2000.com/ArnaudRecipes/sharedlib.html
"Using static and shared libraries across platforms"<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://www.cnblogs.com/liushui-sky/p/7729838.html
"gcc和g++的区别"<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>https://news.mydrivers.com/1/628/628308.htm<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Complier</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ Programming Tricks</title>
    <url>/201811/20181128-gnu-cpp-programming-tricks/</url>
    <content><![CDATA[<h2 id="pragma-warning"><code>pragma warning</code></h2>
<p><a
href="https://stackoverflow.com/questions/3350852/how-to-correctly-fix-zero-sized-array-in-struct-union-warning-c4200-without">关于warning的一个问题：
warning C4200: nonstandard extension used : zero-sized array in
struct/union Cannot generate copy-ctor or copy-assignment operator when
UDT contains a zero-sized array</a></p>
<h4 id="常用去警告">常用去警告：</h4>
<ul>
<li><code>#pragma warning(disable:4035)</code> //no return value</li>
<li><code>#pragma warning(disable:4068)</code> //unknown pragma</li>
<li><code>#pragma warning(disable:4201)</code> //nonstandard extension
used : nameless struct/union</li>
<li><code>#pragma warning(disable:4267)</code></li>
<li><code>#pragma warning(disable:4018)</code> //signed/unsigned
mismatch</li>
<li><code>#pragma warning(disable:4127)</code> //conditional expression
is constant</li>
<li><code>#pragma warning(disable:4146)</code></li>
<li><code>#pragma warning(disable:4244)</code> //conversion from
'LONG_PTR' to 'LONG', possible loss of data</li>
<li><code>#pragma warning(disable:4311)</code> //'type cast' : pointer
truncation from 'BYTE *' to 'ULONG'</li>
<li><code>#pragma warning(disable:4312)</code> //'type cast' :
conversion from 'LONG' to 'WNDPROC' of greater size</li>
<li><code>#pragma warning(disable:4346)</code> //_It::iterator_category'
: dependent name is not a type</li>
<li><code>#pragma warning(disable:4786)</code></li>
<li><code>#pragma warning(disable:4541)</code> //'dynamic_cast' used on
polymorphic type</li>
<li><code>#pragma warning(disable:4996)</code> //declared deprecated
?</li>
<li><code>#pragma warning(disable:4200)</code> //zero-sized array in
struct/union</li>
<li><code>#pragma warning(disable:4800)</code> //forcing value to bool
'true' or 'false' (performance warning)</li>
</ul>
<h4 id="常用用法">常用用法:</h4>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(push) </span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(disable:XXXX)    <span class="comment">// 需要消除警告的代码</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(pop)</span></span><br></pre></td></tr></table></figure>
<p>or: <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(disable:XXXX) <span class="comment">// 需要消除警告的代码</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(enable:XXXX)  <span class="comment">// 如果出现：&#x27;enable&#x27;not valid specifier 用 </span></span></span><br><span class="line">                                <span class="comment">// #pragma   warning(default:XXXX)  代替试试</span></span><br></pre></td></tr></table></figure></p>
<h4 id="pragma-支持"><code>#pragma</code> 支持</h4>
<p>开发人员可以使用 <code>#pragma</code>
指令将警告作为错误处理；还可以启用或禁用警告，如下面的示例所示：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span> (<span class="keyword">error</span>: 6260) </span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span> (disable: 6011) </span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span> (enable: 6056)</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><code>Q: #pragma warning (disable : 4996)和#pragma warning (default : 4996) 是干啥用的呢？</code></p>
</blockquote>
<ol type="1">
<li><code>#pragma warning(disable: n)</code> 将某个警报置为失效</li>
<li><code>#pragma warning(default: n)</code> 将报警置为默认
使用VS2005,编译提示"xxxxxx被声明为否决的
这是MS新的C库提供的带有检查的函数,有内存溢出检测。可以防止一部分程序bug,
抵制缓冲区溢出攻击(buffer overflow attack). 但是应该速度上有牺牲。</li>
</ol>
<blockquote>
<p>解决办法 - 所以在你确信安全的情况下,可以用#pragma warning(disable:
4996)消除这个警告 -
建议使用_s的缓冲区安全的版本，而不是简单的屏蔽警告。</p>
</blockquote>
<h3 id="关于pragma-warning">关于#pragma warning</h3>
<ol type="1">
<li><p><code>#pragma warning</code>只对当前文件有效（对于.h，对包含它的cpp也是有效的），
而不是是对整个工程的所有文件有效。当该文件编译结束，设置也就失去作用。</p></li>
<li><p><code>#pragma warning(push)</code> 存储当前报警设置。
<code>#pragma warning(push, n)</code>
存储当前报警设置，并设置报警级别为n。n为从1到4的自然数。</p></li>
<li><p><code>#pragma warning(pop)</code>
恢复之前压入堆栈的报警设置。在一对push和pop之间作的任何报警相关设置都将失效。</p></li>
<li><p><code>#pragma warning(disable: n)</code>
将某个警报置为失效</p></li>
<li><p><code>#pragma warning(default: n)</code> 将报警置为默认</p></li>
<li><p>某些警告如C4309是从上到下生效的。即文件内<code>#pragma warning</code>从上到下遍历，依次生效。</p>
<p>例如： <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(disable: 4189)</span></span><br><span class="line">      <span class="type">char</span> s;</span><br><span class="line">      s = <span class="number">128</span>;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(default: 4189)</span></span><br><span class="line">      <span class="type">char</span> c;</span><br><span class="line">      c = <span class="number">128</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 则s =
128不会产生C4309报警，而C4309会产生报警。</p></li>
<li><p>某些警告例如C4189是以函数中最后出现的#pragma
warning设置为准的，其余针对该报警的设置都是无效的。 例如：</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(disable: 4189)</span></span><br><span class="line">      <span class="type">int</span> x = <span class="number">1</span>;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(default: 4189)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
则C4189仍然会出现，因为default指令是函数的最后一条。在该文件内的其他函数中，如果没有重新设置，C4189也是以<code>#pragma warning(default: 4189)</code>为准。如果重新设置，同样是按照其函数中的最后一个<code>#pragma warning</code>为准。</p></li>
<li><p>某些警告（MSDN认为是大于等于C4700的警告）是在函数结束后才能生效。
例如：</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(disable:4700)</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="type">int</span> x;</span><br><span class="line">      <span class="type">int</span> y = x;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(default:4700)</span></span><br><span class="line">      <span class="type">int</span> z= x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>则y = x和z =
x都不会产生C4700报警。只有在函数结束后的后的另外一个函数中，<code>#pragma warning(default:4700)</code>才能生效。</p></li>
</ol>
<h2 id="cc-宏定义define中-的含义">C++/C 宏定义（define）中# ##
的含义</h2>
<p>define 中的# ##
一般是用来拼接字符串的，但是实际使用过程中，有哪些细微的差别呢，我们通过几个例子来看看。</p>
<p>#是字符串化的意思，出现在宏定义中的#是把跟在后面的参数转成一个字符串；</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A simple registry for caffe commands.</span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">int</span> <span class="params">(*BrewFunction)</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">typedef</span> std::map&lt;caffe::string, BrewFunction&gt; BrewMap;</span><br><span class="line">BrewMap g_brew_map;</span><br><span class="line"></span><br><span class="line">\<span class="meta">#<span class="keyword">define</span> RegisterBrewFunction(func) \</span></span><br><span class="line"><span class="meta">namespace &#123; \</span></span><br><span class="line"><span class="meta">class __Registerer_##func &#123; \</span></span><br><span class="line"><span class="meta"> public: <span class="comment">/* NOLINT */</span> \</span></span><br><span class="line"><span class="meta">  __Registerer_##func() &#123; \</span></span><br><span class="line"><span class="meta">  g_brew_map[#func] = &amp;func; \</span></span><br><span class="line"><span class="meta">  &#125; \</span></span><br><span class="line"><span class="meta">&#125;; \</span></span><br><span class="line"><span class="meta">__Registerer_##func g_registerer_##func; \</span></span><br><span class="line"><span class="meta">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> BrewFunction <span class="title">GetBrewFunction</span><span class="params">(<span class="type">const</span> caffe::string&amp; name)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (g_brew_map.<span class="built_in">count</span>(name)) &#123;</span><br><span class="line">  <span class="keyword">return</span> g_brew_map[name];</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;Available caffe actions:&quot;</span>;</span><br><span class="line">  <span class="keyword">for</span> (BrewMap::iterator it = g_brew_map.<span class="built_in">begin</span>();</span><br><span class="line">  it != g_brew_map.<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">  <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;\t&quot;</span> &lt;&lt; it-&gt;first;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown action: &quot;</span> &lt;&lt; name;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">NULL</span>; <span class="comment">// not reachable, just to suppress old compiler warnings.</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面这段代码是Caffe源码tools/caffe.cpp中的一段程序，主要完成了caffe不同工作阶段的注册工作。如caffe可以在
<code>train, test</code>
等不同环境下工作。每个环境对应着响应的处理函数。这些函数是如何通过main函数统一管理的。就是通过这个<code>GetBrewFunction</code>函数统一调用的。那么这个函数如何获取具体的调用函数，就得知道函数指针和宏替换的相关知识了。具体参考<a
href="https://github.com/BVLC/caffe/blob/master/tools/caffe.cpp">caffe.cpp</a></p>
<h2 id="gnu-c中不为人知的特色__attribute__机制">GNU
C中不为人知的特色：<code>__attribute__</code>机制</h2>
<p>偶然碰到了<code>__attribute__</code>，虽然之前在看Linux内核代码时见过很多次，但还是对它熟视无睹，罪过啊，下面的文章是从源码网上转载的，原文在这里:http://www.yuanma.org/data/2006/0625/article_948.htm，此处只是做简单阐述，共同进步。</p>
<ol type="1">
<li><p>GNU
C的一大特色（却不被初学者所知）就是<code>__attribute__</code>机制。<code>__attribute__</code>可以设置函数属性（Function
Attribute）、变量属性（Variable Attribute）和类型属性（Type
Attribute）。它的书写特征是：<code>__attribute__</code>前后都有两个下划线，并切后面会紧跟一对原括弧，括弧里面是相应的<code>__attribute__</code>参数，语法格式如下：
<code>__attribute__ ((attribute-list))</code></p></li>
<li><p>另外，它必须放于声明的尾部“；”之前。</p></li>
</ol>
<p>函数属性可以帮助开发者把一些特性添加到函数声明中，从而可以使编译器在错误检查方面的功能更强大。<code>__attribute__</code>机制也很容易同非GNU应用程序做到兼容之功效。</p>
<p><strong>GNU CC需要使用
–Wall编译器来击活该功能</strong>，这是控制警告信息的一个很好的方式。下面介绍几个常见的属性参数。</p>
<p><code>__attribute__ format</code>。该<code>__attribute__</code>属性可以给被声明的函数加上类似<code>printf</code>或者<code>scanf</code>的特征，它可以使编译器检查函数声明和函数实际调用参数之间的格式化字符串是否匹配。该功能十分有用，尤其是处理一些很难发现的bug。<code>format</code>的语法格式为：</p>
<p><code>format (archetype, string-index, first-to-check)</code></p>
<p>format属性告诉编译器，按照printf, scanf,
strftime或strfmon的参数表格式规则对该函数的参数进行检查。“archetype”指定是哪种风格；“string-index”指定传入函数的第几个参数是格式化字符串；“first-to-check”指定从函数的第几个参数开始按上述规则进行检查。</p>
<ol start="3" type="1">
<li>具体使用格式如下： <code>__attribute__((format(printf,m,n)))</code>
<code>__attribute__((format(scanf,m,n)))</code></li>
</ol>
<p>其中参数m与n的含义为： * m：第几个参数为格式化字符串（format
string）； *
n：参数集合中的第一个，即参数“…”里的第一个参数在函数参数总数排在第几，注意，有时函数参数里还有“隐身”的呢，后面会提到；</p>
<p>在使用上，<code>__attribute__((format(printf,m,n)))</code>是常用的，而另一种却很少见到。下面举例说明，其中myprint为自己定义的一个带有可变参数的函数，其功能类似于printf：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//m=1；n=2</span></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myprint</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *format,...)</span> __<span class="title">attribute__</span><span class="params">((format(printf,<span class="number">1</span>,<span class="number">2</span>)))</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//m=2；n=3</span></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myprint</span><span class="params">(<span class="type">int</span> l，<span class="type">const</span> <span class="type">char</span> *format,...)</span> __<span class="title">attribute__</span><span class="params">((format(printf,<span class="number">2</span>,<span class="number">3</span>)))</span></span>;</span><br></pre></td></tr></table></figure>
<p>需要特别注意的是，如果myprint是一个函数的成员函数，那么m和n的值可有点“悬乎”了，例如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//m=3；n=4</span></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myprint</span><span class="params">(<span class="type">int</span> l，<span class="type">const</span> <span class="type">char</span> *format,...)</span> __<span class="title">attribute__</span><span class="params">((format(printf,<span class="number">3</span>,<span class="number">4</span>)))</span></span>;</span><br></pre></td></tr></table></figure>
<p>其原因是，类成员函数的第一个参数实际上一个“隐身”的“this”指针。（有点C++基础的都知道点this指针，不知道你在这里还知道吗？）</p>
<p>这里给出测试用例：attribute.c，代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">extern</span> <span class="title">myprint</span><span class="params">(<span class="type">const</span> *format,...)</span> <span class="title">attribute__</span><span class="params">((format(printf,<span class="number">1</span>,<span class="number">2</span>)))</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">test</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%d\n&quot;</span>, <span class="number">1</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%s\n&quot;</span>, <span class="number">2</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%s\n&quot;</span>,<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;%s,%d,%d\n&quot;</span>,<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myprint</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *format,...)</span> __<span class="title">attribute__</span><span class="params">((format(printf,<span class="number">1</span>,<span class="number">2</span>)))</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">test</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%d\n&quot;</span>,<span class="number">6</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%s\n&quot;</span>,<span class="number">6</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%s\n&quot;</span>,<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;%s,%d,%d\n&quot;</span>,<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>gcc编译后会提示<code>format argument is not a pointer</code>的警告。若去掉<code>__attribute__((format(printf,1,2)))</code>，则会正常编译。需要注意的是，编译器只能识别类似printf的标准输出库函数。</p>
<p>还有一个<code>__attribute__ noreturn</code>，该属性通知编译器函数从不返回值，当遇到类似函数需要返回值而却不可能运行到返回值处就已经退出来的情况，该属性可以避免出现错误信息。C库函数中的<code>abort()</code>和<code>exit()</code>的声明格式就采用了这种格式，如下所示：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">exit</span><span class="params">(<span class="type">int</span>)</span> __<span class="title">attribute__</span><span class="params">((noreturn))</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">abort</span><span class="params">(<span class="type">void</span>)</span> __<span class="title">attribute__</span><span class="params">((noreturn))</span></span>;</span><br></pre></td></tr></table></figure>
<p>为了方便理解，大家可以参考如下的例子：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//name: noreturn.c ；测试__attribute__((noreturn))</span></span><br><span class="line">  <span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myexit</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">test</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ( n &gt; <span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">myexit</span>();</span><br><span class="line">      <span class="comment">/* 程序不可能到达这里*/</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>//name: noreturn.c ；测试__attribute__((noreturn))</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myexit</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">test</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> ( n &gt; <span class="number">0</span> )</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">myexit</span>();</span><br><span class="line">    <span class="comment">/* 程序不可能到达这里*/</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译后的输出结果如下：</p>
<p><code>$gcc –Wall –c noreturn.c</code></p>
<p>noreturn.c: In function `test':</p>
<p>noreturn.c:12: warning: control reaches end of non-void function</p>
<p>很显然，这是因为一个被定义为有返回值的函数却没有返回值。加上_<em>attribute_</em>((noreturn))则可以解决此问题的出现。</p>
<p>后面还有<code>__attribute__const</code>、<code>-finstrument-functions</code>、<code>no_instrument_function</code>等的属性描述，就不多转了，感兴趣的可以看原文。</p>
<h2 id="变量属性variable-attribute">变量属性(Variable Attribute)</h2>
<p>关键字<code>__attribute__</code>也可以对变量或结构体成员进行属性设置。这里给出几个常用的参数的解释，更多的参数可参考原文给出的连接。</p>
<p>在使用<code>__attribute__</code>参数时，你也可以在参数的前后都加上“__”（两个下划线），例如，使用<code>__attribute__</code>而不是aligned，这样，你就可以在相应的头文件里使用它而不用关心头文件里是否有重名的宏定义。</p>
<h3 id="aligned-alignment">aligned (alignment)</h3>
<p>该属性规定变量或结构体成员的最小的对齐格式，以字节为单位。例如：</p>
<p><code>int x __attribute__ ((aligned (16))) = 0;</code></p>
<p>编译器将以16字节（注意是字节byte不是位bit）对齐的方式分配一个变量。也可以对结构体成员变量设置该属性，例如，创建一个双字对齐的int对，可以这么写：</p>
<p><code>struct foo &#123; int x[2] __attribute__ ((aligned (8))); &#125;;</code></p>
<p>如上所述，你可以手动指定对齐的格式，同样，你也可以使用默认的对齐方式。如果aligned后面不紧跟一个指定的数字值，那么编译器将依据你的目标机器情况使用最大最有益的对齐方式。例如：</p>
<p><code>short array[3] __attribute__ ((aligned));</code></p>
<ol type="1">
<li><p>选择针对目标机器最大的对齐方式，可以提高拷贝操作的效率。aligned属性使被设置的对象占用更多的空间，相反的，使用packed可以减小对象占用的空间。</p></li>
<li><p>需要注意的是，attribute属性的效力与你的连接器也有关，如果你的连接器最大只支持16字节对齐，那么你此时定义32字节对齐也是无济于事的。</p></li>
<li><p>使用该属性可以使得变量或者结构体成员使用最小的对齐方式，即对变量是一字节对齐，对域（field）是位对齐。</p></li>
</ol>
<p>下面的例子中，x成员变量使用了该属性，则其值将紧放置在a的后面：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">test</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">char</span> a;</span><br><span class="line">    <span class="type">int</span> x[<span class="number">2</span>] __attribute__ ((packed));</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其它可选的属性值还可以是：<code>cleanup，common，nocommon，deprecated，mode，section，shared，tls_model，transparent_union，unused，vector_size，weak，dllimport，dlexport</code>等。</p>
<h2 id="类型属性type-attribute">类型属性（Type Attribute）</h2>
<p>关键字<code>__attribute__</code>也可以对结构体（struct）或共用体（union）进行属性设置。大致有六个参数值可以被设定，即：<code>aligned, packed, transparent_union, unused, deprecated</code>和
<code>may_alias</code>。</p>
<p>在使用<code>__attribute__</code>参数时，你也可以在参数的前后都加上“__”（两个下划线），例如，使用<code>__aligned__</code>而不是<code>aligned</code>，这样，你就可以在相应的头文件里使用它而不用关心头文件里是否有重名的宏定义。</p>
<h3 id="aligned-alignment-1">aligned (alignment)</h3>
<p>该属性设定一个指定大小的对齐格式（以字节为单位），例如：</p>
<p><code>struct S &#123; short f[3]; &#125; __attribute__ ((aligned (8)));</code></p>
<p><code>typedef int more_aligned_int __attribute__ ((aligned (8)));</code></p>
<pre><code>该声明将强制编译器确保（尽它所能）变量类型为struct S或者more-aligned-int的变量在分配空间时采用8字节对齐方式。</code></pre>
<p>如上所述，你可以手动指定对齐的格式，同样，你也可以使用默认的对齐方式。如果aligned后面不紧跟一个指定的数字值，那么编译器将依据你的目标机器情况使用最大最有益的对齐方式。例如：</p>
<p><code>struct S &#123; short f[3]; &#125; __attribute__ ((aligned));</code></p>
<p>这里，如果sizeof（short）的大小为2（byte），那么，S的大小就为6。取一个2的次方值，使得该值大于等于6，则该值为8，所以编译器将设置S类型的对齐方式为8字节。</p>
<ol type="1">
<li><p>aligned属性使被设置的对象占用更多的空间，相反的，使用packed可以减小对象占用的空间。</p></li>
<li><p>需要注意的是，attribute属性的效力与你的连接器也有关，如果你的连接器最大只支持16字节对齐，那么你此时定义32字节对齐也是无济于事的。</p></li>
<li><p>使用该属性对struct或者union类型进行定义，设定其类型的每一个变量的内存约束。当用在enum类型定义时，暗示了应该使用最小完整的类型（it
indicates that the smallest integral type should be used）。</p></li>
</ol>
<p>下面的例子中，my-packed-struct类型的变量数组中的值将会紧紧的靠在一起，但内部的成员变量s不会被“pack”，如果希望内部的成员变量也被packed的话，my-unpacked-struct也需要使用packed进行相应的约束。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">my_unpacked_struct</span>&#123;</span><br><span class="line"><span class="type">char</span> c;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">my_packed_struct</span>&#123;</span><br><span class="line">  <span class="type">char</span> c;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">my_unpacked_struct</span> s;</span><br><span class="line">&#125;__attribute__ ((__packed__));</span><br></pre></td></tr></table></figure>
<h2 id="变量属性与类型属性举例">变量属性与类型属性举例</h2>
<p>下面的例子中使用<code>__attribute__</code>属性定义了一些结构体及其变量，并给出了输出结果和对结果的分析。</p>
<p>程序代码为：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  程序代码为：</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">p</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">char</span> b;</span><br><span class="line">    <span class="type">char</span> c;</span><br><span class="line">  &#125;__attribute__((<span class="built_in">aligned</span>(<span class="number">4</span>))) pp;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">q</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">char</span> b;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">n</span> qn;</span><br><span class="line">    <span class="type">char</span> c;</span><br><span class="line">  &#125;__attribute__((<span class="built_in">aligned</span>(<span class="number">8</span>))) qq;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;sizeof(int)=%d,sizeof(short)=%d.sizeof(char)=%d\n&quot;</span>,<span class="built_in">sizeof</span>(<span class="type">int</span>),<span class="built_in">sizeof</span>(<span class="type">short</span>),<span class="built_in">sizeof</span>(<span class="type">char</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;pp=%d,qq=%d \n&quot;</span>, <span class="built_in">sizeof</span>(pp),<span class="built_in">sizeof</span>(qq));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><p>输出结果： sizeof(int)=4,sizeof(short)=2.sizeof(char)=1
pp=8,qq=24</p></li>
<li><p>结果分析： sizeof(int)=4,sizeof(short)=2.sizeof(char)=1
pp=8,qq=24 sizeof(pp): sizeof(a)+ sizeof(b)+ sizeof(c)=4+1+1=6&lt;23=8=
sizeof(pp) sizeof(qq): sizeof(a)+ sizeof(b)=4+1=5
sizeof(qn)=8;即qn是采用8字节对齐的，所以要在a，b后面添3个空余字节，然后才能存储qn，
4+1+（3）+8+1=17
因为qq采用的对齐是8字节对齐，所以qq的大小必定是8的整数倍，即qq的大小是一个比17大又是8的倍数的一个最小值，由此得到
17&lt;24+8=24= sizeof(qq)</p></li>
</ul>
<h2 id="declspec"><code>__declspec</code></h2>
<table>
<colgroup>
<col style="width: 18%" />
<col style="width: 35%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Compiler</th>
<th style="text-align: left;">Simple deprecation</th>
<th style="text-align: left;">Deprecation with message</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">gcc and clang</td>
<td
style="text-align: left;"><code>__attribute__((deprecated)) int a;</code></td>
<td
style="text-align: left;"><code>__attribute__((deprecated("message"))) int a;</code></td>
</tr>
<tr class="even">
<td style="text-align: left;">Visual Studio</td>
<td
style="text-align: left;"><code>__declspec(deprecated) int a;</code></td>
<td
style="text-align: left;"><code>__declspec(deprecated("message")) int a;</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Embarcadero(1)</td>
<td style="text-align: left;"><code>int a [[deprecated]];</code></td>
<td
style="text-align: left;"><code>int a [[deprecated("message")]];</code></td>
</tr>
</tbody>
</table>
<p><a
href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3760.html">table
from</a> <a
href="http://www.cnblogs.com/ylhome/archive/2010/07/10/1774770.html"><code>__declspec</code>
blog</a></p>
<h2 id="gcc-__attribute__关键字举例之visibility">gcc
<code>__attribute__</code>关键字举例之<code>visibility</code></h2>
<p>看opencv的源代码的时候，发现<code>CV_EXPORT</code>的宏定义是</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">if</span> (defined WIN32 || defined _WIN32 || defined WINCE || defined __CYGWIN__) &amp;&amp; defined CVAPI_EXPORTS</span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> CV_EXPORTS __declspec(dllexport)</span></span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined __GNUC__ &amp;&amp; __GNUC__ &gt;= 4</span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> CV_EXPORTS __attribute__ ((visibility (<span class="string">&quot;default&quot;</span>)))</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> CV_EXPORTS</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<p>我就发现了新大陆似的开始找这个属性的特点。这个在工程中尤其重要，我们实现的函数要想被其他用户调用，就必须使用<code>visibility</code>让
用户可见，否则我们的实现的功能函数对用户隐藏，出现"undefined
reference".</p>
<blockquote>
<p>visibility用于设置动态链接库中函数的可见性，将变量或函数设置为hidden，则该符号仅在本so中可见，在其他库中则不可见。</p>
</blockquote>
<p>g++在编译时，可用参数<code>-fvisibility</code>指定所有符号的可见性(不加此参数时默认外部可见，参考man
g++中<code>-fvisibility</code>部分)；若需要对特定函数的可见性进行设置，需在代码中使用<code>__attribute__</code>设置visibility属性。</p>
<p>编写大型程序时，可用<code>-fvisibility=hidden</code>设置符号默认隐藏，针对特定变量和函数，在代码中使用<code>__attribute__ ((visibility("default")))</code>另该符号外部可见，这种方法可用有效避免so之间的符号冲突。</p>
<p>下面是visibility的实例，这里extern “C”可以省略（另外两篇文章 gcc
<code>__attribute__</code>关键字举例之alias 和 C++覆盖系统函数的方法
中extern "C"不可用省略）。</p>
<p>值得注意的是，visibility2.cc中可以调用fun1，原因是visibility1.o和visibility2.o同属于一个so文件。</p>
<blockquote>
<p>visibility1.cc：</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun1</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in %s\n&quot;</span>,__FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__attribute__ ((<span class="built_in">visibility</span>(<span class="string">&quot;hidden&quot;</span>))) <span class="function"><span class="type">void</span> <span class="title">fun1</span><span class="params">()</span></span>;<span class="comment">//</span></span><br></pre></td></tr></table></figure>
<p>若编译此文件时使用了参数<code>-fvisibility=hidden</code>，则此行可以省略</p>
<blockquote>
<p>visibility2.cc：</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun1</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">fun1</span>();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in %s\n&quot;</span>,__FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line">__attribute__ ((<span class="built_in">visibility</span>(<span class="string">&quot;default&quot;</span>))) <span class="function"><span class="type">void</span> <span class="title">fun2</span><span class="params">()</span></span>;<span class="comment">//若编译此文件时没有使用参数-fvisibility或设置参数-fvisibility=default，则此行可以省略</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>main.cpp</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun1</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun2</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">fun1</span>();</span><br><span class="line">  <span class="built_in">fun2</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Makefile：</p>
</blockquote>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">all:test</span></span><br><span class="line"><span class="section">test:main.o libvisibility.so</span></span><br><span class="line">        g++ -o test main.o -lvisibility -L .</span><br><span class="line"><span class="section">main.o::main.cc</span></span><br><span class="line">        g++ -c main.cc</span><br><span class="line"><span class="section">libvisibility.so:visibility1.o visibility2.o</span></span><br><span class="line">        g++ -shared -o libvisibility.so visibility1.o visibility2.o</span><br><span class="line"><span class="section">visibility1.o:visibility1.cc</span></span><br><span class="line">        g++ -fvisibility=hidden -fPIC -c visibility1.cc</span><br><span class="line"><span class="section">visibility2.o:visibility2.cc</span></span><br><span class="line">        g++ -fvisibility=hidden -fPIC -c visibility2.cc</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">        rm -f *.o *.so test</span><br></pre></td></tr></table></figure>
<blockquote>
<p>编译和输出： <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ make</span><br><span class="line">g++ -c main.cc</span><br><span class="line">g++ -fvisibility=hidden -fPIC -c visibility1.cc</span><br><span class="line">g++ -fvisibility=hidden -fPIC -c visibility2.cc</span><br><span class="line">g++ -shared -o libvisibility.so visibility1.o visibility2.o</span><br><span class="line">g++ -o <span class="built_in">test</span> main.o -lvisibility -L .</span><br><span class="line">main.o: In <span class="keyword">function</span> `main<span class="string">&#x27;:</span></span><br><span class="line"><span class="string">main.cc:(.text+0x5): undefined reference to `fun1&#x27;</span></span><br><span class="line">collect2: ld returned 1 <span class="built_in">exit</span> status</span><br><span class="line">make: *** [<span class="built_in">test</span>] Error 1</span><br></pre></td></tr></table></figure>
可以看到，<code>main()</code>中可以不可用调用<code>fun1</code>,可以调用<code>fun2</code>，因为<code>fun1</code>已经设置为外部不可见，<code>fun2</code>设置为外部可见。</p>
</blockquote>
<p>使用readelf对各个.o文件分析可以看到，fun1的Vis属性为HIDDEN，fun2的Vis属性为DEFAULT：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ readelf -s visibility1.o|grep fun</span><br><span class="line">6: 0000000000000007    5 OBJECT  LOCAL  DEFAULT    6 _ZZ4fun1E12__FUNCTION__</span><br><span class="line">12: 0000000000000000    30 FUNC    GLOBAL HIDDEN    2 fun1</span><br><span class="line"></span><br><span class="line">$ readelf -s visibility2.o|grep fun</span><br><span class="line">6: 0000000000000007    5 OBJECT  LOCAL  DEFAULT    6 _ZZ4fun2E12__FUNCTION__</span><br><span class="line">12: 0000000000000000    35 FUNC    GLOBAL DEFAULT    2 fun2</span><br><span class="line">15: 0000000000000000    0 NOTYPE  GLOBAL DEFAULT  UND fun1</span><br><span class="line"></span><br><span class="line">$ readelf -s libvisibility.so|grep fun</span><br><span class="line">9: 00000000000006ac    35 FUNC    GLOBAL DEFAULT  12 fun2</span><br><span class="line">41: 000000000000071d    5 OBJECT  LOCAL  DEFAULT  14 _ZZ4fun1E12__FUNCTION__</span><br><span class="line">43: 0000000000000729    5 OBJECT  LOCAL  DEFAULT  14 _ZZ4fun2E12__FUNCTION__</span><br><span class="line">48: 000000000000068c    30 FUNC    LOCAL  HIDDEN  12 fun1</span><br><span class="line">54: 00000000000006ac    35 FUNC    GLOBAL DEFAULT  12 fun2</span><br></pre></td></tr></table></figure>
<h1 id="linux-内核中的-gcc-特性">Linux 内核中的 GCC 特性</h1>
<ul>
<li>功能性 扩展提供新功能。</li>
<li>优化 扩展帮助生成更高效的代码。</li>
</ul>
<h2 id="功能性扩展">功能性扩展</h2>
<h3 id="类型发现">类型发现</h3>
<p>GCC 允许通过变量的引用识别类型。这种操作支持泛型编程。在 C++、Ada 和
Java™ 语言等许多现代编程语言中都可以找到相似的功能。Linux 使用 typeof
构建 min 和 max 等依赖于类型的操作。清单 1 演示如何使用 typeof
构建一个泛型宏（见 ./linux/include/linux/kernel.h）。</p>
<p>清单 1. 使用 typeof 构建一个泛型宏 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define min(x, y) (&#123;                \</span><br><span class="line">    typeof(x) _min1 = (x);          \</span><br><span class="line">    typeof(y) _min2 = (y);          \</span><br><span class="line">    (void) (&amp;_min1 == &amp;_min2);      \</span><br><span class="line">    _min1 &lt; _min2 ? _min1 : _min2; &#125;)</span><br></pre></td></tr></table></figure></p>
<h3 id="范围扩展">范围扩展</h3>
<p>GCC 支持范围，在 C 语言的许多方面都可以使用范围。其中之一是
switch/case 块中的 case 语句。在复杂的条件结构中，通常依靠嵌套的 if
语句实现与清单 2（见 ./linux/drivers/scsi/sd.c）相同的结果，但是清单 2
更简洁。使用 switch/case 也可以通过使用跳转表实现进行编译器优化。</p>
<p>清单 2. 在 case 语句中使用范围 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">sd_major</span><span class="params">(<span class="type">int</span> major_idx)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">switch</span> (major_idx) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> SCSI_DISK0_MAJOR;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">1</span> ... <span class="number">7</span>:</span><br><span class="line">        <span class="keyword">return</span> SCSI_DISK1_MAJOR + major_idx - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">8</span> ... <span class="number">15</span>:</span><br><span class="line">        <span class="keyword">return</span> SCSI_DISK8_MAJOR + major_idx - <span class="number">8</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        BUG();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;   <span class="comment">/* shut up gcc */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
还可以使用范围进行初始化，如下所示（见<code>./linux/arch/cris/arch-v32/kernel/smp.c</code>）。在这个示例中，<code>spinlock_t</code>
创建一个大小为<code>LOCK_COUNT</code>
的数组。数组的每个元素初始化为<code>SPIN_LOCK_UNLOCKED</code> 值。
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Vector of locks used for various atomic operations */</span></span><br><span class="line"><span class="type">spinlock_t</span> cris_atomic_locks[] = &#123; [<span class="number">0</span> ... LOCK_COUNT - <span class="number">1</span>] = SPIN_LOCK_UNLOCKED&#125;;</span><br></pre></td></tr></table></figure>
范围还支持更复杂的初始化。例如，以下代码指定数组中几个子范围的初始值。
<code>int widths[] = &#123; [0 ... 9] = 1, [10 ... 99] = 2, [100] = 3 &#125;;</code></p>
<h3 id="零长度的数组">零长度的数组</h3>
<p>在 C
标准中，必须定义至少一个数组元素。这个需求往往会使代码设计复杂化。但是，GCC
支持零长度数组的概念，这对于结构定义尤其有用。这个概念与 ISO C99
中灵活的数组成员相似，但是使用不同的语法。</p>
<p>下面的示例在结构的末尾声明一个没有成员的数组（见
<code>./linux/drivers/ieee1394/raw1394-private.h</code>）。这允许结构中的元素引用结构实例后面紧接着的内存。在需要数量可变的数组成员时，这个特性很有用。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct iso_block_store &#123;</span><br><span class="line">        atomic_t refcount;</span><br><span class="line">        size_t data_size;</span><br><span class="line">        quadlet_t data[0];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<h3 id="判断调用地址">判断调用地址</h3>
<p>在许多情况下，需要判断给定函数的调用者。GCC 提供用于此用途的内置函数
<code>__builtin_return_address</code>。这个函数通常用于调试，但是它在内核中还有许多其他用途。</p>
<p>如下面的代码所示，<code>__builtin_return_address</code> 接收一个称为
level 的参数。这个参数定义希望获取返回地址的调用堆栈级别。例如，如果指定
level 为 0，那么就是请求当前函数的返回地址。如果指定 level 为
1，那么就是请求进行调用的函数的返回地址，依此类推。
<code>void * __builtin_return_address( unsigned int level );</code>
在下面的示例中（见
./linux/kernel/softirq.c），<code>local_bh_disable</code>
函数在本地处理器上禁用软中断，从而禁止在当前处理器上运行
<code>softirqs</code>、<code>tasklets</code>和
<code>bottom halves</code>。使用<code>__builtin_return_address</code>
捕捉返回地址，以便在以后进行跟踪时使用这个地址。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void local_bh_disable(void)&#123;</span><br><span class="line">        __local_bh_disable((unsigned long)__builtin_return_address(0));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="常量检测">常量检测</h3>
<p>在编译时，可以使用 GCC
提供的一个内置函数判断一个值是否是常量。这种信息非常有价值，因为可以构造出能够通过常量叠算（constant
folding）优化的表达式。<code>__builtin_constant_p</code>
函数用来检测常量。</p>
<p><code>__builtin_constant_p</code>
的原型如下所示。注意，<code>__builtin_constant_p</code>
并不能检测出所有常量，因为 GCC 不容易证明某些值是否是常量。
<code>int __builtin_constant_p( exp )</code> Linux
相当频繁地使用常量检测。在清单 3 所示的示例中（见
./linux/include/linux/log2.h），使用常量检测优化
<code>roundup_pow_of_two</code>
宏。如果发现表达式是常量，那么就使用可以优化的常量表达式。如果表达式不是常量，就调用另一个宏函数把值向上取整到
2 的幂。</p>
<p>清单 3. 使用常量检测优化宏函数 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define roundup_pow_of_two(n)           \</span><br><span class="line">(                       \</span><br><span class="line">    __builtin_constant_p(n) ? (     \</span><br><span class="line">        (n == 1) ? 1 :          \</span><br><span class="line">        (1UL &lt;&lt; (ilog2((n) - 1) + 1)) \</span><br><span class="line">                   ) :      \</span><br><span class="line">    __roundup_pow_of_two(n)         \</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<h3 id="函数属性">函数属性</h3>
<p>GCC
提供许多函数级属性，可以通过它们向编译器提供更多数据，帮助编译器执行优化。本节描述与功能相关联的一些属性。下一节描述
影响优化的属性。</p>
<p>如清单 4
所示，属性通过其他符号定义指定了别名。可以以此帮助阅读源代码参考，了解属性的使用方法（见
./linux/include/linux/compiler-gcc3.h）。</p>
<p>清单 4. 函数属性定义 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># define __inline__  __inline__  __attribute__((always_inline))</span><br><span class="line"># define __deprecated           __attribute__((deprecated))</span><br><span class="line"># define __attribute_used__     __attribute__((__used__))</span><br><span class="line"># define __attribute_const__     __attribute__((__const__))</span><br><span class="line"># define __must_check            __attribute__((warn_unused_result))</span><br></pre></td></tr></table></figure> 清单 4 所示的定义是 GCC
中可用的一些函数属性。它们也是在 Linux
内核中最有用的函数属性。下面解释如何使用这些属性： -
<code>always_inline</code> 让 GCC
以内联方式处理指定的函数，无论是否启用了优化。 - <code>deprecated</code>
指出函数已经被废弃，不应该再使用。如果试图使用已经废弃的函数，就会收到警告。还可以对类型和变量应用这个属性，促使开发人员尽可能少使用它们。
- <code>__used__</code> 告诉编译器无论 GCC
是否发现这个函数的调用实例，都要使用这个函数。这对于从汇编代码中调用 C
函数有帮助。 - <code>__const__</code>
告诉编译器某个函数是无状态的（也就是说，它使用传递给它的参数生成要返回的结果）。
- <code>warn_unused_result</code>
让编译器检查所有调用者是否都检查函数的结果。这确保调用者适当地检验函数结果，从而能够适当地处理错误。</p>
<p>下面是在 Linux 内核中使用这些属性的示例。deprecated
示例来自与体系结构无关的内核（./linux/kernel/resource.c），const
示例来自 IA64 内核源代码（./linux/arch/ia64/kernel/unwind.c）。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> __deprecated __check_region(<span class="keyword">struct</span> resource </span><br><span class="line">    *parent, <span class="type">unsigned</span> <span class="type">long</span> start, <span class="type">unsigned</span> <span class="type">long</span> n)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">enum</span> unw_register_index __attribute_const__ </span></span><br><span class="line"><span class="function">    <span class="title">decode_abreg</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> abreg, <span class="type">int</span> memory)</span></span></span><br></pre></td></tr></table></figure>
<h2 id="优化扩展">优化扩展</h2>
<p>现在，讨论有助于生成更好的机器码的一些 GCC 特性。</p>
<h3 id="分支预测提示">分支预测提示</h3>
<p>在 Linux
内核中最常用的优化技术之一是<code>__builtin_expect</code>。在开发人员使用有条件代码时，常常知道最可能执行哪个分支，而哪个分支很少执行。如果编译器知道这种预测信息，就可以围绕最可能执行的分支生成最优的代码。</p>
<p>如下所示，<code>__builtin_expect</code> 的使用方法基于两个宏 likely
和 unlikely（见 ./linux/include/linux/compiler.h）。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define likely(x)   __builtin_expect(!!(x), 1)</span><br><span class="line">#define unlikely(x) __builtin_expect(!!(x), 0)</span><br></pre></td></tr></table></figure>
通过使用
<code>__builtin_expect</code>，编译器可以做出符合提供的预测信息的指令选择决策。这使执行的代码尽可能接近实际情况。它还可以改进缓存和指令流水线。</p>
<p>例如，如果一个条件标上了 “likely”，那么编译器可以把代码的 True
部分直接放在分支指令后面（这样就不需要执行分支指令）。通过分支指令访问条件结构的
False
部分，这不是最优的方式，但是访问它的可能性不大。按照这种方式，代码对于最可能出现的情况是最优的。</p>
<p>清单 5 给出一个使用 likely 和 unlikely 宏的函数（见
./linux/net/core/datagram.c）。这个函数预测 sum 变量将是零（数据包的
checksum 是有效的），而且 ip_summed 变量不等于 CHECKSUM_HW。</p>
<p>清单 5. likely 和 unlikely 宏的使用示例 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> __skb_checksum_complete(<span class="keyword">struct</span> sk_buff *skb)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">int</span> sum;</span><br><span class="line"> </span><br><span class="line">        sum = (u16)<span class="built_in">csum_fold</span>(<span class="built_in">skb_checksum</span>(skb, <span class="number">0</span>, skb-&gt;len, skb-&gt;csum));</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">likely</span>(!sum)) &#123;</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">unlikely</span>(skb-&gt;ip_summed == CHECKSUM_HW))</span><br><span class="line">                        <span class="built_in">netdev_rx_csum_fault</span>(skb-&gt;dev);</span><br><span class="line">                skb-&gt;ip_summed = CHECKSUM_UNNECESSARY;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="预抓取">预抓取</h3>
<p>另一种重要的性能改进方法是把必需的数据缓存在接近处理器的地方。缓存可以显著减少访问数据花费的时间。大多数现代处理器都有三类内存：
* 一级缓存通常支持单周期访问 * 二级缓存支持两周期访问 *
系统内存支持更长的访问时间</p>
<p>为了尽可能减少访问延时并由此提高性能，最好把数据放在最近的内存中。手工执行这个任务称为预抓取。GCC
通过内置函数 <code>__builtin_prefetch</code>
支持数据的手工预抓取。在需要数据之前，使用这个函数把数据放到缓存中。如下所示，<code>__builtin_prefetch</code>
函数接收三个参数：</p>
<ul>
<li>数据的地址</li>
<li>rw 参数，使用它指明预抓取数据是为了执行读操作，还是执行写操作</li>
<li>locality
参数，使用它指定在使用数据之后数据应该留在缓存中，还是应该清除
<code>void __builtin_prefetch( const void *addr, int rw, int locality );</code></li>
</ul>
<p>Linux 内核经常使用预抓取。通常是通过宏和包装器函数使用预抓取。清单 6
是一个辅助函数示例，它使用内置函数的包装器（见
./linux/include/linux/prefetch.h）。这个函数为流操作实现预抓取机制。使用这个函数通常可以减少缓存缺失和停顿，从而提高性能。</p>
<p>清单 6. 范围预抓取的包装器函数 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> ARCH_HAS_PREFETCH</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> prefetch(x) __builtin_prefetch(x)</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title">prefetch_range</span><span class="params">(<span class="type">void</span> *addr, <span class="type">size_t</span> len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> ARCH_HAS_PREFETCH</span></span><br><span class="line">    <span class="type">char</span> *cp;</span><br><span class="line">    <span class="type">char</span> *end = addr + len;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> (cp = addr; cp &lt; end; cp += PREFETCH_STRIDE)</span><br><span class="line">        <span class="built_in">prefetch</span>(cp);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="变量属性">变量属性</h3>
<p>除了本文前面讨论的函数属性之外，GCC
还为变量和类型定义提供了属性。最重要的属性之一是 <code>aligned</code>
属性，它用于在内存中实现对象对齐。除了对于性能很重要之外，某些设备或硬件配置也需要对象对齐。<code>aligned</code>
属性有一个参数，它指定所需的对齐类型。</p>
<p>下面的示例用于软件暂停（见
./linux/arch/i386/mm/init.c）。在需要页面对齐时，定义
<code>PAGE_SIZE</code> 对象。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">char __nosavedata swsusp_pg_dir[PAGE_SIZE]</span><br><span class="line">    __attribute__ ((aligned (PAGE_SIZE)));</span><br></pre></td></tr></table></figure> 清单 7
中的示例说明关于优化的两点：</p>
<p><code>packed</code>
属性打包一个结构的元素，从而尽可能减少它们占用的空间。这意味着，如果定义一个
char 变量，它占用的空间不会超过一字节（8
位）。位字段压缩为一位，而不会占用更多存储空间。
这段源代码使用一个<code>__attribute__</code>
声明进行优化，它用逗号分隔的列表定义多个属性。 清单 7.
结构打包和设置多个属性 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">swsusp_header</span> &#123;</span><br><span class="line">        <span class="type">char</span> reserved[PAGE_SIZE - <span class="number">20</span> - <span class="built_in">sizeof</span>(<span class="type">swp_entry_t</span>)];</span><br><span class="line">        <span class="type">swp_entry_t</span> image;</span><br><span class="line">        <span class="type">char</span>    orig_sig[<span class="number">10</span>];</span><br><span class="line">        <span class="type">char</span>    sig[<span class="number">10</span>];</span><br><span class="line">&#125; __attribute__((packed, <span class="built_in">aligned</span>(PAGE_SIZE))) swsusp_header;</span><br></pre></td></tr></table></figure></p>
<h2 id="参考链接">参考链接</h2>
<ol type="1">
<li><p><a
href="https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html#Function-Attributes">Function
Attributes</a></p></li>
<li><p><a
href="https://gcc.gnu.org/onlinedocs/gcc/Visibility-Pragmas.html#Visibility-Pragmas">Visibility
Pragmas</a></p></li>
<li><p><a
href="http://liulixiaoyao.blog.51cto.com/1361095/814329">GCC扩展
<strong>attribute</strong> ((visibility("hidden")))</a></p></li>
<li><p><a
href="https://www.ibm.com/developerworks/cn/linux/l-gcc-hacks/">【IBM】Linux
内核中的 GCC 特性</a></p></li>
</ol>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>开发</tag>
      </tags>
  </entry>
  <entry>
    <title>Detection算法Overview</title>
    <url>/201907/20190714-detection/</url>
    <content><![CDATA[<h1 id="物体检测算法概述">物体检测算法概述</h1>
<p>深度学习让物体检测从实验室走到生活。基于深度学习的物体检测算法分类两大类。一类是像RCNN类似的两stage方法，将ROI的选择和对ROI的分类score过程。
另外一类是类似YOLO将ROI的选择和最终打分实现端到端一步完成。前者是先由算法生成一系列作为样本的候选框，再通过卷积神经网络进行样本分类；后者则不用产生候选框，直接将目标边框定位的问题转化为回归问题处理。正是由于两种方法的差异，在性能上也有不同，前者在检测准确率和定位精度上占优，后者在算法速度上占优。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/Detection-All.png"
alt="@物体检测算法概览图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="物体检测算法概览图">@物体检测算法概览图</span></figcaption>
</figure>
<p><a
href="https://www.jianshu.com/p/0586fdb412bf?utm_source=oschina-app">各种检测算法之间的性能对比，准确率，速度，以及一些可能加速的tips</a></p>
<h2 id="r-cnn的前世">R-CNN的前世</h2>
<ul>
<li>HOG</li>
<li>DPM</li>
<li>Selective Search</li>
<li><a
href="https://zhuanlan.zhihu.com/p/32564990">深度学习应用到物体检测以前</a></li>
</ul>
<h1 id="基于region-proposals的方法two-stage方法">基于region
proposals的方法（Two-Stage方法）</h1>
<ul>
<li>RCNN =&gt; Fast RCNN =&gt; Faster RCNN =&gt; FPN <img data-src="https://cwlseu.github.io/images/detection/RCNN-types2.png"
alt="@R-CNN、Fast R-CNN、Faster R-CNN三者关系" /></li>
</ul>
<h2 id="rcnn">RCNN</h2>
<p>在早期深度学习技术发展进程中，主要都是围绕分类问题展开研究，这是因为神经网络特有的结构输出将概率统计和分类问题结合，提供一种直观易行的思路。国内外研究人员虽然也在致力于将其他如目标检测领域和深度学习结合，但都没有取得成效，这种情况直到R-CNN算法出现才得以解决。</p>
<ul>
<li>论文链接：https://arxiv.org/pdf/1311.2524.pdf</li>
<li>作者：Ross Girshick Jeff Donahue Trevor Darrell Jitendra Malik
之前的视觉任务大多数考虑使用SIFT和HOG特征，而近年来CNN和ImageNet的出现使得图像分类问题取得重大突破，那么这方面的成功能否迁移到PASCAL
VOC的目标检测任务上呢？基于这个问题，论文提出了R-CNN。 R-CNN
(Region-based CNN features) 性能：RCNN在VOC2007上的mAP是58%左右。</li>
</ul>
<h3 id="主要工作流程">主要工作流程</h3>
<p><img data-src="https://cwlseu.github.io/images/detection/RCNN.png"
alt="@R-CNN要完成目标定位，其流程主要分为四步" />
R-CNN要完成目标定位，其流程主要分为四步： * 输入图像 *
利用选择性搜索(Selective Search)这样的区域生成算法提取Region Proposal
提案区域(2000个左右) * 将每个Region
Proposal分别resize(因为训练好的CNN输入是固定的)后(也即下图中的warped
region，文章中是归一化为227×227)作为CNN网络的输入。 *
CNN网络提取到经过resize的region
proposal的特征送入每一类的SVM分类器，判断是否属于该类</p>
<h3 id="rcnn的缺点">RCNN的缺点</h3>
<ul>
<li>对于提取的每个Region
Proposal，多数都是互相重叠，重叠部分会被多次重复提取feature)，都要分别进行CNN前向传播一次(相当于进行了2000吃提特征和SVM分类的过程)，计算量较大。</li>
<li>CNN的模型确定的情况下只能接受固定大小的输入(也即wraped
region的大小固定)</li>
</ul>
<h3 id="优化思路">优化思路</h3>
<p>既然所有的Region
Proposal都在输入图像中，与其提取后分别作为CNN的输入，为什么不考虑将带有Region
Proposal的原图像直接作为CNN的输入呢？原图像在经过CNN的卷积层得到feature
map，原图像中的Region
Proposal经过特征映射(也即CNN的卷积下采样等操作)也与feature
map中的一块儿区域相对应。</p>
<h2 id="spp-net">SPP net</h2>
<ul>
<li>论文链接：]https://arxiv.org/abs/1406.4729</li>
<li>作者：Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun 简述：SPP
net中Region
Proposal仍然是在原始输入图像中选取的，不过是通过CNN映射到了feature
map中的一片区域。</li>
</ul>
<h3 id="spp-net的主要思想">SPP-NET的主要思想</h3>
<p><img data-src="https://cwlseu.github.io/images/detection/SPPNet-arch.png"
alt="@SPPNet架构图" /> * 对卷积层的feature map上的Region
Proposal映射区域分别划分成1×1，2×2，4×4的窗口(window)， *
在每个窗口内做max pooling，这样对于一个卷积核产生的feature
map，就可以由SPP得到一个(1×1+2×2+4×4)维的特征向量。 *
论文中采用的网络结构最后一层卷积层共有256个卷积核，所以最后会得到一个固定维度的特征向量(1×1+2×2+4×4)×256维)，并用此特征向量作为全连接层的输入后做分类。</p>
<h3 id="相对于r-cnnspp-net的优势">相对于R-CNN，SPP-net的优势</h3>
<ul>
<li>使用原始图像作为CNN网络的输入来计算feature map(R-CNN中是每个Region
Proposal都要经历一次CNN计算)，大大减少了计算量。</li>
<li>RCNN要resize，易于失真，而SPP-net不需要，原因是，SPP net中Region
Proposal仍然是通过选择性搜索等算法在输入图像中生成的，通过映射的方式得到feature
map中对应的区域，并对Region Proposal在feature
map中对应区域做空间金字塔池化。通过空间金字塔池化操作，对于任意尺寸的候选区域，经过SPP后都会得到固定长度的特征向量。</li>
</ul>
<!-- ### SPP-net缺点
* 训练分多个阶段，步骤繁琐(微调网络+训练SVM+训练边框回归器)
* SPP net在微调网络的时候固定了卷积层，只对全连接层进行微调 -->
<h2 id="fast-rcnn">Fast RCNN</h2>
<ul>
<li><a
href="https://arxiv.org/abs/1504.08083"><code>Fast R-CNN</code></a></li>
<li>作者：Ross Girshick 性能：在VOC2007上的mAP也提高到了68%</li>
</ul>
<h3 id="算法框架图">算法框架图</h3>
<p><img data-src="https://cwlseu.github.io/images/detection/FastRCNN-1.png" /> <img data-src="https://cwlseu.github.io/images/detection/FastRCNN.png" /></p>
<h3 id="优点贡献">优点&amp;贡献</h3>
<ul>
<li>Fast R-CNN引入了RoI 池化层(相当于是一层SPP)，对于图像中的Region
Poposal(也即RoI)，通过映射关系(图中的RoI projection)可以得到feature
map中Region Proposal对应的区域。</li>
<li>RoI Pooling层的操作是将feature
map上的RoI区域划分为7×7的窗口，在每个窗口内进行max
pooling，然后得到(7×7)×256的输出，最后连接到全连接层得到固定长度的RoI特征向量。</li>
<li>前面得到的RoI特征向量再通过全连接层作为Softmax和Regressor的输入,训练过程可以更新所有的网络层</li>
<li>训练过程是端到端的(Sigle-stage),并使用了一个多任务的损失函数(也即将边框回归直接加入到CNN网络中后,Fast
R-CNN网络的损失函数包含了Softmax的损失和Regressor的损失)</li>
</ul>
<h3 id="小结">小结</h3>
<p>在前面三种目标检测框架中(R-CNN，SPP net，Fast R-CNN)，Region
Proposal都是通过区域生成的算法(选择性搜索等)在原始输入图像中产生的，不过在SPP
net及Fast R-CNN中都是输入图像中的Region
Proposal通过映射关系映射到CNN中feature map上再操作的。Fast
R-CNN中RoI池化的对象是输入图像中产生的proposal在feature
map上的映射区域</p>
<h2 id="faster-rcnn">Faster RCNN</h2>
<ul>
<li>论文链接：https://arxiv.org/pdf/1506.01497.pdf</li>
<li>作者：Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun</li>
</ul>
<h3 id="faster-rcnn算法框架">Faster RCNN算法框架</h3>
<p><img data-src="https://cwlseu.github.io/images/detection/FasterRCNN.png"
alt="@faster RCNN的算法框架" />
我们先整体的介绍下上图中各层主要的功能</p>
<ul>
<li><strong>卷积网络提取特征图</strong>：</li>
</ul>
<p>作为一种CNN网络目标检测方法，Faster
RCNN首先使用一组基础的conv+relu+pooling层提取input image的feature
maps,该feature maps会用于后续的RPN层和全连接层。</p>
<ul>
<li><strong>RPN(Region Proposal Networks,区域提议网络)</strong>:</li>
</ul>
<p>RPN网络主要用于生成region proposals， - 首先生成一堆Anchor
box，对其进行裁剪过滤后通过softmax判断anchors属于前景(foreground)或者后景(background)，即是物体or不是物体，所以这是一个二分类；
- 另一分支bounding box regression修正anchor
box，形成较精确的proposal（注：这里的较精确是相对于后面全连接层的再一次box
regression而言）</p>
<p>Feature Map进入RPN后，先经过一次<span
class="math inline">\(3*3\)</span>的卷积，同样，特征图大小依然是<span
class="math inline">\(60*40\)</span>,数量512，这样做的目的应该是进一步集中特征信息，接着看到两个全卷积,即kernel_size=1*1,p=0,stride=1;
- cls layer 逐像素对其9个Anchor box进行二分类 - reg layer
逐像素得到其9个Anchor box四个坐标信息</p>
<p>特征图大小为60<em>40，所以会一共生成60</em>40*9=21600个Anchor box</p>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/FasterCNN-RPN.png"
alt="@FasterRCNN-RPN" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FasterRCNN-RPN">@FasterRCNN-RPN</span></figcaption>
</figure>
<ul>
<li><strong>Roi Pooling</strong>：</li>
</ul>
<p>该层利用RPN生成的proposals和VGG16最后一层得到的feature
map，得到固定大小的proposal feature
map,进入到后面可利用全连接操作来进行目标识别和定位</p>
<ul>
<li><strong>Classifier</strong>：</li>
</ul>
<p>会将ROI Pooling层形成固定大小的feature
map进行全连接操作，利用Softmax进行具体类别的分类，同时，利用SmoothL1Loss完成bounding
box regression回归操作获得物体的精确位置。</p>
<p><img data-src="https://cwlseu.github.io/images/detection/FasterRCNN-Arch.png"
alt="@FasterRCNN算法详细过程图" /> <img data-src="https://cwlseu.github.io/images/detection/FasterRCNNNetwork.png"
alt="@FasterRCNN proposal&amp;RPN Netscope" /></p>
<h3 id="参考链接">参考链接</h3>
<ul>
<li>[1]. https://www.cnblogs.com/wangyong/p/8513563.html</li>
<li>[2]. https://www.jianshu.com/p/00a6a6efd83d</li>
<li>[3]. https://www.cnblogs.com/liaohuiqiang/p/9740382.html</li>
<li>[4]. https://blog.csdn.net/u011436429/article/details/80414615</li>
<li>[5]. https://blog.csdn.net/xiaoye5606/article/details/71191429</li>
</ul>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/RCNN-types.png"
alt="@RCNN系列对比总结表" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="RCNN系列对比总结表">@RCNN系列对比总结表</span></figcaption>
</figure>
<p>向<a href="http://www.rossgirshick.info/">RGB大神</a>,<a
href="http://kaiminghe.com/">He Kaiming</a>致敬！</p>
<h2 id="fpnfeature-pyramid-networks-for-object-detection">FPN(feature
pyramid networks for object detection)</h2>
<ul>
<li>论文链接：https://arxiv.org/abs/1612.03144</li>
<li>poster链接：
https://vision.cornell.edu/se3/wp-content/uploads/2017/07/fpn-poster.pdf</li>
<li>caffe实现: https://github.com/unsky/FPN</li>
<li>作者：Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath
Hariharan, Serge Belongie</li>
</ul>
<h3 id="图像金字塔">图像金字塔</h3>
<p>图像金字塔,在很多的经典算法里面都有它的身影，比如SIFT、HOG等算法。
我们常用的是高斯金字塔，所谓的高斯金字塔是通过高斯平滑和亚采样获得
一些下采样图像，也就是说第K层高斯金字塔通过平滑、亚采样操作就可以
获得K+1层高斯图像，高斯金字塔包含了一系列低通滤波器，其截止频率从
上一层到下一层是以因子2逐渐增加，所以高斯金字塔可以跨越很大的频率范围。
总之，我们输入一张图片，我们可以获得多张不同尺度的图像，我们将这些
不同尺度的图像的4个顶点连接起来，就可以构造出一个类似真实金字塔的一
个图像金字塔。通过这个操作，我们可以为2维图像增加一个尺度维度（或者说是深度），
这样我们可以从中获得更多的有用信息。整个过程类似于人眼看一个目标由远及近的
过程（近大远小原理）。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/pyramidImage.jpg"
alt="@图像金字塔" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="图像金字塔">@图像金字塔</span></figcaption>
</figure>
<h3 id="论文概述">论文概述：</h3>
<p>作者提出的多尺度的object detection算法：FPN（feature pyramid
networks）。原来多数的object
detection算法都是只采用顶层特征做预测，但我们知道低层的特征语义信息比较少，但是目标位置准确；高层的特征语义信息比较丰富，但是目标位置比较粗略。另外虽然也有些算法采用多尺度特征融合的方式，但是一般是采用融合后的特征做预测，而本文不一样的地方在于预测是在不同特征层独立进行的。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/FPN.png"
alt="@FPN架构图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FPN架构图">@FPN架构图</span></figcaption>
</figure>
<p>前面已经提到了高斯金字塔，由于它可以在一定程度上面提高算法的性能，
因此很多经典的算法中都包含它。但是这些都是在传统的算法中使用，当然也可以将
这种方法直应用在深度神经网络上面，但是由于它需要大量的运算和大量的内存。
但是我们的特征金字塔可以在速度和准确率之间进行权衡，可以通过它获得更加鲁棒
的语义信息，这是其中的一个原因。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/FPN-multiScale.png"
alt="@FPN不同层识别的目标不同" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FPN不同层识别的目标不同">@FPN不同层识别的目标不同</span></figcaption>
</figure>
<p>如上图所示，我们可以看到我们的图像中存在不同尺寸的目标，而不同的目标具有不同的特征，
利用浅层的特征就可以将简单的目标的区分开来；
利用深层的特征可以将复杂的目标区分开来；这样我们就需要这样的一个特征金字塔来完成这件事。
图中我们在第1层（请看绿色标注）输出较大目标的实例分割结果，
在第2层输出次大目标的实例检测结果，在第3层输出较小目标的实例分割结果。
检测也是一样，我们会在第1层输出简单的目标，第2层输出较复杂的目标，第3层输出复杂的目标。</p>
<h3 id="小结-1">小结</h3>
<p>作者提出的FPN（Feature Pyramid
Network）算法同时利用低层特征高分辨率和高层特征的高语义信息，通过融合这些不同层的特征达到预测的效果。并且预测是在每个融合后的特征层上单独进行的，这和常规的特征融合方式不同。</p>
<h2 id="mask-rcnn">Mask-RCNN</h2>
<ul>
<li>论文地址：https://arxiv.org/abs/1703.06870</li>
<li>作者：Kaiming He，Georgia Gkioxari，Piotr Dollar，Ross Girshick</li>
<li>FAIR Detectron：https://github.com/facebookresearch/Detectron</li>
<li>tensorflow: https://github.com/matterport/Mask_RCNN</li>
</ul>
<h2 id="mask-scoring-r-cnn">Mask Scoring R-CNN</h2>
<ul>
<li>论文地址：https://arxiv.org/abs/1903.00241</li>
<li>github: https://github.com/zjhuang22/maskscoring_rcnn</li>
</ul>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/MSRCNN.png"
alt="@Mask Scoring RCNN的架构图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="Mask">@Mask</span> Scoring RCNN的架构图</figcaption>
</figure>
<h1 id="one-stage方法">One-stage方法</h1>
<p>以R-CNN算法为代表的two
stage的方法由于RPN结构的存在，虽然检测精度越来越高，但是其速度却遇到瓶颈，比较难于满足部分场景实时性的需求。
因此出现一种基于回归方法的one stage的目标检测算法，不同于two
stage的方法的分步训练共享检测结果，one stage的方法能实现完整单次
训练共享特征，且在保证一定准确率的前提下，速度得到极大提升。</p>
<h3 id="ssd原理与实现">SSD原理与实现</h3>
<p>https://blog.csdn.net/u010712012/article/details/86555814
https://github.com/amdegroot/ssd.pytorch
http://www.cs.unc.edu/~wliu/papers/ssd_eccv2016_slide.pdf</p>
<h2 id="cornernet-人体姿态检测">CornerNet 人体姿态检测</h2>
<ul>
<li>paper出处：https://arxiv.org/abs/1808.01244</li>
<li>https://zhuanlan.zhihu.com/p/46505759</li>
</ul>
<h2 id="rpn中的anchor">RPN中的Anchor</h2>
<p>Anchor是RPN网络的核心。需要确定每个滑窗中心对应感受野内存在目标与否。由于目标大小和长宽比例不一，需要多个尺度的窗。Anchor即给出一个基准窗大小，按照倍数和长宽比例得到不同大小的窗。有了Anchor之后，才能通过Select
Search的方法Windows方法进行选取ROI的。</p>
<p>首先我们需要知道anchor的本质是什么，本质是SPP(spatial pyramid
pooling)思想的逆向。而SPP本身是做什么的呢，就是将不同尺寸的输入resize成为相同尺寸的输出。所以SPP的逆向就是，将相同尺寸的输出，倒推得到不同尺寸的输入。</p>
<p>接下来是anchor的窗口尺寸，这个不难理解，三个面积尺寸（128<sup>2，256</sup>2，512^2），然后在每个面积尺寸下，取三种不同的长宽比例（1:1,1:2,2:1）.这样一来，我们得到了一共9种面积尺寸各异的anchor。示意图如下：
<img data-src="https://cwlseu.github.io/images/detection/Anchor.png"
alt="@9个Anchor示意图" />
至于这个anchor到底是怎么用的，这个是理解整个问题的关键。</p>
<ul>
<li>Faster RCNN</li>
<li>SSD</li>
<li>YOLO</li>
<li>Guided Anchor: https://arxiv.org/abs/1901.03278</li>
</ul>
<h2 id="目标检测算法研究问题小结">目标检测算法研究问题小结</h2>
<p>目标检测领域的深度学习算法，需要进行目标定位和物体识别，算法相对来说还是很复杂的。当前各种新算法也是层不出穷，但模型之间有很强的延续性，大部分模型算法都是借鉴了前人的思想，站在巨人的肩膀上。我们需要知道经典模型的特点，这些tricks是为了解决什么问题，以及为什么解决了这些问题。这样才能举一反三，万变不离其宗。综合下来，目标检测领域主要的难点如下:</p>
<ul>
<li>检测速度：实时性要求高，故网络结构不能太复杂，参数不能太多，卷积层次也不能太多。</li>
<li><strong>位置准确率</strong>：<code>(x y w h)</code>参数必须准确，也就是检测框大小尺寸要匹配，且重合度IOU要高。SSD和faster
RCNN通过多个bounding box来优化这个问题</li>
<li><strong>漏检率</strong>：必须尽量检测出所有目标物体，特别是靠的近的物体和尺寸小的物体。SSD和faster
RCNN通过多个bounding box来优化这个问题</li>
<li><strong>物体宽高比例不常见</strong>：SSD通过不同尺寸feature
map，yoloV2通过不同尺寸输入图片，来优化这个问题。</li>
<li>靠的近的物体准确率低</li>
<li>小尺寸物体准确率低：SSD取消全连接层，yoloV2增加pass through
layer，采用高分辨率输入图片，来优化这个问题</li>
</ul>
<h1 id="目标检测特殊层">目标检测特殊层</h1>
<h2 id="roipooling">ROIpooling</h2>
<p>ROIs
Pooling顾名思义，是Pooling层的一种，而且是针对RoIs的Pooling，他的特点是输入特征图尺寸不固定，但是输出特征图尺寸固定；</p>
<blockquote>
<p>ROI是Region of Interest的简写，指的是在“特征图上的框”; * 在Fast
RCNN中， RoI是指Selective
Search完成后得到的“候选框”在特征图上的映射，如下图中的红色框所示； *
在Faster
RCNN中，候选框是经过RPN产生的，然后再把各个“候选框”映射到特征图上，得到RoIs。</p>
</blockquote>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/ROIPooling.png"
alt="@" />
<figcaption aria-hidden="true">@</figcaption>
</figure>
<p>参考faster rcnn中的ROI
Pool层，功能是将不同size的ROI区域映射到固定大小的feature map上。</p>
<h3 id="缺点由于两次量化带来的误差">缺点：由于两次量化带来的误差；</h3>
<ul>
<li>将候选框边界量化为整数点坐标值。</li>
<li>将量化后的边界区域平均分割成<span class="math inline">\(k\times
k\)</span>个单元(bin),对每一个单元的边界进行量化。</li>
</ul>
<h3 id="案例说明">案例说明</h3>
<p>下面我们用直观的例子具体分析一下上述区域不匹配问题。如 图1
所示，这是一个Faster-RCNN检测框架。输入一张<span
class="math inline">\(800\times 800\)</span>的图片，图片上有一个<span
class="math inline">\(665\times
665\)</span>的包围框(框着一只狗)。图片经过主干网络提取特征后，特征图缩放步长（stride）为32。因此，图像和包围框的边长都是输入时的1/32。800正好可以被32整除变为25。但665除以32以后得到20.78，带有小数，于是ROI
Pooling 直接将它量化成20。接下来需要把框内的特征池化<span
class="math inline">\(7\times7\)</span>的大小，因此将上述包围框平均分割成<span
class="math inline">\(7\times7\)</span>个矩形区域。显然，每个矩形区域的边长为2.86，又含有小数。于是ROI
Pooling
再次把它量化到2。经过这两次量化，候选区域已经出现了较明显的偏差（如图中绿色部分所示）。更重要的是，该层特征图上0.1个像素的偏差，缩放到原图就是3.2个像素。那么0.8的偏差，在原图上就是接近30个像素点的差别，这一差别不容小觑。</p>
<p><a
href="https://github.com/ShaoqingRen/caffe/blob/062f2431162165c658a42d717baf8b74918aa18e/src/caffe/layers/roi_pooling_layer.cpp"><code>caffe中实现roi_pooling_layer.cpp</code></a></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="type">void</span> ROIPoolingLayer&lt;Dtype&gt;::<span class="built_in">Forward_cpu</span>(<span class="type">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">      <span class="type">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  <span class="comment">//输入有两部分组成，data和rois</span></span><br><span class="line">  <span class="type">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;<span class="built_in">cpu_data</span>();</span><br><span class="line">  <span class="type">const</span> Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;<span class="built_in">cpu_data</span>();</span><br><span class="line">  <span class="comment">// ROIs的个数</span></span><br><span class="line">  <span class="type">int</span> num_rois = bottom[<span class="number">1</span>]-&gt;<span class="built_in">num</span>();</span><br><span class="line">  <span class="type">int</span> batch_size = bottom[<span class="number">0</span>]-&gt;<span class="built_in">num</span>();</span><br><span class="line">  <span class="type">int</span> top_count = top[<span class="number">0</span>]-&gt;<span class="built_in">count</span>();</span><br><span class="line">  Dtype* top_data = top[<span class="number">0</span>]-&gt;<span class="built_in">mutable_cpu_data</span>();</span><br><span class="line">  <span class="built_in">caffe_set</span>(top_count, <span class="built_in">Dtype</span>(-FLT_MAX), top_data);</span><br><span class="line">  <span class="type">int</span>* argmax_data = max_idx_.<span class="built_in">mutable_cpu_data</span>();</span><br><span class="line">  <span class="built_in">caffe_set</span>(top_count, <span class="number">-1</span>, argmax_data);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For each ROI R = [batch_index x1 y1 x2 y2]: max pool over R</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; num_rois; ++n) &#123;</span><br><span class="line">    <span class="type">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// 把原图的坐标映射到feature map上面</span></span><br><span class="line">    <span class="type">int</span> roi_start_w = <span class="built_in">round</span>(bottom_rois[<span class="number">1</span>] * spatial_scale_);</span><br><span class="line">    <span class="type">int</span> roi_start_h = <span class="built_in">round</span>(bottom_rois[<span class="number">2</span>] * spatial_scale_);</span><br><span class="line">    <span class="type">int</span> roi_end_w = <span class="built_in">round</span>(bottom_rois[<span class="number">3</span>] * spatial_scale_);</span><br><span class="line">    <span class="type">int</span> roi_end_h = <span class="built_in">round</span>(bottom_rois[<span class="number">4</span>] * spatial_scale_);</span><br><span class="line">    <span class="comment">// 计算每个roi在feature map上面的大小</span></span><br><span class="line">    <span class="type">int</span> roi_height = <span class="built_in">max</span>(roi_end_h - roi_start_h + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> roi_width = <span class="built_in">max</span>(roi_end_w - roi_start_w + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="comment">//pooling之后的feature map的一个值对应于pooling之前的feature map上的大小</span></span><br><span class="line">    <span class="comment">//注：由于roi的大小不一致，所以每次都需要计算一次</span></span><br><span class="line">    <span class="type">const</span> Dtype bin_size_h = <span class="built_in">static_cast</span>&lt;Dtype&gt;(roi_height)</span><br><span class="line">                             / <span class="built_in">static_cast</span>&lt;Dtype&gt;(pooled_height_);</span><br><span class="line">    <span class="type">const</span> Dtype bin_size_w = <span class="built_in">static_cast</span>&lt;Dtype&gt;(roi_width)</span><br><span class="line">                             / <span class="built_in">static_cast</span>&lt;Dtype&gt;(pooled_width_);</span><br><span class="line">    <span class="comment">//找到对应的roi的feature map，如果input data的batch size为1</span></span><br><span class="line">    <span class="comment">//那么roi_batch_ind=0</span></span><br><span class="line">    <span class="type">const</span> Dtype* batch_data = bottom_data + bottom[<span class="number">0</span>]-&gt;<span class="built_in">offset</span>(roi_batch_ind);</span><br><span class="line">    <span class="comment">//pooling的过程是针对每一个channel的，所以需要循环遍历</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; channels_; ++c) &#123;</span><br><span class="line">      <span class="comment">//计算output的每一个值，所以需要遍历一遍output，然后求出所有值</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> ph = <span class="number">0</span>; ph &lt; pooled_height_; ++ph) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> pw = <span class="number">0</span>; pw &lt; pooled_width_; ++pw) &#123;</span><br><span class="line">          <span class="comment">// Compute pooling region for this output unit:</span></span><br><span class="line">          <span class="comment">//  start (included) = floor(ph * roi_height / pooled_height_)</span></span><br><span class="line">          <span class="comment">//  end (excluded) = ceil((ph + 1) * roi_height / pooled_height_)</span></span><br><span class="line">          <span class="comment">// 计算output上的一点对应于input上面区域的大小[hstart, wstart, hend, wend]</span></span><br><span class="line">          <span class="type">int</span> hstart = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>(<span class="built_in">static_cast</span>&lt;Dtype&gt;(ph)</span><br><span class="line">                                              * bin_size_h));</span><br><span class="line">          <span class="type">int</span> hend = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">ceil</span>(<span class="built_in">static_cast</span>&lt;Dtype&gt;(ph + <span class="number">1</span>)</span><br><span class="line">                                           * bin_size_h));</span><br><span class="line">          <span class="type">int</span> wstart = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>(<span class="built_in">static_cast</span>&lt;Dtype&gt;(pw)</span><br><span class="line">                                              * bin_size_w));</span><br><span class="line">          <span class="type">int</span> wend = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">ceil</span>(<span class="built_in">static_cast</span>&lt;Dtype&gt;(pw + <span class="number">1</span>)</span><br><span class="line">                                           * bin_size_w));</span><br><span class="line">          <span class="comment">//将映射后的区域平动到对应的位置[hstart, wstart, hend, wend]</span></span><br><span class="line">          hstart = <span class="built_in">min</span>(<span class="built_in">max</span>(hstart + roi_start_h, <span class="number">0</span>), height_);</span><br><span class="line">          hend = <span class="built_in">min</span>(<span class="built_in">max</span>(hend + roi_start_h, <span class="number">0</span>), height_);</span><br><span class="line">          wstart = <span class="built_in">min</span>(<span class="built_in">max</span>(wstart + roi_start_w, <span class="number">0</span>), width_);</span><br><span class="line">          wend = <span class="built_in">min</span>(<span class="built_in">max</span>(wend + roi_start_w, <span class="number">0</span>), width_);</span><br><span class="line">          <span class="comment">//如果映射后的矩形框不符合</span></span><br><span class="line">          <span class="type">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line">          <span class="comment">//pool_index指的是此时计算的output的值对应于output的位置</span></span><br><span class="line">          <span class="type">const</span> <span class="type">int</span> pool_index = ph * pooled_width_ + pw;</span><br><span class="line">          <span class="comment">//如果矩形不符合，此处output的值设为0，此处的对应于输入区域的最大值为-1</span></span><br><span class="line">          <span class="keyword">if</span> (is_empty) &#123;</span><br><span class="line">            top_data[pool_index] = <span class="number">0</span>;</span><br><span class="line">            argmax_data[pool_index] = <span class="number">-1</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//遍历output的值对应于input的区域块</span></span><br><span class="line">          <span class="keyword">for</span> (<span class="type">int</span> h = hstart; h &lt; hend; ++h) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> w = wstart; w &lt; wend; ++w) &#123;</span><br><span class="line">             <span class="comment">// 对应于input上的位置</span></span><br><span class="line">              <span class="type">const</span> <span class="type">int</span> index = h * width_ + w;</span><br><span class="line">              <span class="comment">//计算区域块的最大值，保存在output对应的位置上</span></span><br><span class="line">              <span class="comment">//同时记录最大值的索引</span></span><br><span class="line">              <span class="keyword">if</span> (batch_data[index] &gt; top_data[pool_index]) &#123;</span><br><span class="line">                top_data[pool_index] = batch_data[index];</span><br><span class="line">                argmax_data[pool_index] = index;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Increment all data pointers by one channel</span></span><br><span class="line">      batch_data += bottom[<span class="number">0</span>]-&gt;<span class="built_in">offset</span>(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">      top_data += top[<span class="number">0</span>]-&gt;<span class="built_in">offset</span>(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">      argmax_data += max_idx_.<span class="built_in">offset</span>(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Increment ROI data pointer</span></span><br><span class="line">    bottom_rois += bottom[<span class="number">1</span>]-&gt;<span class="built_in">offset</span>(<span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="roi-align">ROI Align</h2>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/ROIAlign-1.png"
alt="@ROIAlign模块使用示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="ROIAlign模块使用示意图">@ROIAlign模块使用示意图</span></figcaption>
</figure>
<p>为了解决ROI Pooling的上述缺点，作者提出了ROI Align这一改进的方法。ROI
Align的思路很简单：取消量化操作，使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值,从而将整个特征聚集过程转化为一个连续的操作。值得注意的是，在具体的算法操作上，ROI
Align并不是简单地补充出候选区域边界上的坐标点，然后将这些坐标点进行池化，而是重新设计了一套比较优雅的流程，如下图所示：
<img data-src="https://cwlseu.github.io/images/detection/ROIAlign-2.png"
alt="@浮点坐标计算过程" /> *
遍历每一个候选区域，保持浮点数边界不做量化。 * 将候选区域分割成<span
class="math inline">\(k\times
k\)</span>个单元，每个单元的边界也不做量化。 *
在每个单元中计算固定四个坐标位置，用双线性内插的方法计算出这四个位置的值，然后进行最大池化操作。</p>
<p>这里对上述步骤的第三点作一些说明：这个固定位置是指在每一个矩形单元（bin）中按照固定规则确定的位置。比如，如果采样点数是1，那么就是这个单元的中心点。如果采样点数是4，那么就是把这个单元平均分割成四个小方块以后它们分别的中心点。显然这些采样点的坐标通常是浮点数，所以需要使用插值的方法得到它的像素值。在相关实验中，作者发现将采样点设为4会获得最佳性能，甚至直接设为1在性能上也相差无几。
事实上，ROIAlign在遍历取样点的数量上没有ROIPooling那么多，但却可以获得更好的性能，这主要归功于解决了<strong>misalignment</strong>的问题。值得一提的是，我在实验时发现，ROIAlign在<code>VOC2007</code>数据集上的提升效果并不如在<code>COCO</code>上明显。经过分析，造成这种区别的原因是<code>COCO</code>上小目标的数量更多，而小目标受<strong>misalignment</strong>问题的影响更大（比如，同样是0.5个像素点的偏差，对于较大的目标而言显得微不足道，但是对于小目标，误差的影响就要高很多）。ROIAlign层要将feature
map固定为2*2大小，那些蓝色的点即为采样点，然后每个bin中有4个采样点，则这四个采样点经过MAX得到ROI
output；</p>
<blockquote>
<p>通过双线性插值避免了量化操作，保存了原始ROI的空间分布，有效避免了误差的产生；小目标效果比较好</p>
</blockquote>
<h2 id="nms算法优化的必要性">NMS算法优化的必要性</h2>
<h3 id="nms算法的功能">NMS算法的功能</h3>
<p>非极大值抑制（NMS）非极大值抑制顾名思义就是抑制不是极大值的元素，搜索局部的极大值。例如在对象检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分类及分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是某类对象的概率最大），并且抑制那些分数低的窗口。印象最为深刻的就是Overfeat算法中的狗熊抓鱼图了。</p>
<h3 id="从r-cnn到sppnet">从R-CNN到SPPNet</h3>
<p><span
class="math inline">\(RCNN\)</span>主要作用就是用于物体检测，就是首先通过<span
class="math inline">\(selective search\)</span>选择<span
class="math inline">\(2000\)</span>个候选区域，这些区域中有我们需要的所对应的物体的bounding-box，然后对于每一个region
proposal都wrap到固定的大小的scale, <span
class="math inline">\(227\times227\)</span>(AlexNet
Input),对于每一个处理之后的图片，把他都放到CNN上去进行特征提取，得到每个region
proposal的feature map,这些特征用固定长度的特征集合feature vector来表示。
最后对于每一个类别，我们都会得到很多的feature
vector，然后把这些特征向量直接放到SVM现行分类器去判断，当前region所对应的实物是background还是所对应的物体类别，每个region都会给出所对应的score，因为有些时候并不是说这些region中所包含的实物就一点都不存在，有些包含的多有些包含的少，包含的多少还需要合适的bounding
box，所以我们才会对于每一region给出包含实物类别多少的分数，选出前几个对大数值，然后再用非极大值抑制canny来进行边缘检测，最后就会得到所对应的bounding
box.</p>
<p><img data-src="https://cwlseu.github.io/images/detection/SPPNet.png"
alt="Alt text" /> 同样，SPPNet作者观察得，对selective
search(ss)提供的2000多个候选区域都逐一进行卷积处理，势必会耗费大量的时间，
所以SPPNet中先对一整张图进行卷积得到特征图，然后再将ss算法提供的2000多个候选区域的位置记录下来，通过比例映射到整张图的feature
map上提取出候选区域的特征图B,然后将B送入到金字塔池化层中，进行权重计算.
然后经过尝试，这种方法是可行的，于是在RCNN基础上，进行了这两个优化得到了这个新的网络SPPNet.</p>
<h4 id="faster-rcnn-1">Faster RCNN</h4>
<p>NMS算法，非极大值抑制算法，引入NMS算法的目的在于：根据事先提供的score向量，以及regions(由不同的bounding
boxes，矩形窗口左上和右下点的坐标构成)
的坐标信息，从中筛选出置信度较高的bounding boxes。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/FasterRCNN_NMS.jpeg"
alt="@FasterRCNN中的NMS的作用" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FasterRCNN中的NMS的作用">@FasterRCNN中的NMS的作用</span></figcaption>
</figure>
<p><img data-src="https://cwlseu.github.io/images/detection/FasterRCNN_anchor.jpeg"
alt="@FasterRCNN中anchor推荐框的个数" /> Faster
RCNN中输入s=600时，采用了三个尺度的anchor进行推荐，分别时128,256和512，其中推荐的框的个数为<span
class="math inline">\(1106786\)</span>，需要将这<span
class="math inline">\(1100k\)</span>的推荐框合并为<span
class="math inline">\(2k\)</span>个。这个过程其实正是<span
class="math inline">\(RPN\)</span>神经网络模型。</p>
<h3 id="ssd">SSD</h3>
<p>https://blog.csdn.net/wfei101/article/details/78176322
SSD算法中是分为default box(下图中(b)中为default box示意图)和prior
box(实际推荐的框) <img data-src="https://cwlseu.github.io/images/detection/SSD-1.png"
alt="@SSD算法中的anchor box和default box示意图" /></p>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/SSD-2.png"
alt="@SSD算法架构图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="SSD算法架构图">@SSD算法架构图</span></figcaption>
</figure>
<figure>
<img data-src="https://cwlseu.github.io/images/detection/SSD-3.png"
alt="SSD算法推荐框的个数" />
<figcaption aria-hidden="true">SSD算法推荐框的个数</figcaption>
</figure>
<h3 id="注意">注意</h3>
<p>在图像处理领域，几点经验： 1.
输入的图像越大，结果越准确，但是计算量也更多 2.
推荐的框越多，定位准确的概率更高，但是计算量也是会增多 3.
推荐的框往往远大于最终的定位的个数</p>
<p>那么NMS存在什么问题呢，其中最主要的问题有这么几个： -
物体重叠：如下面第一张图，会有一个最高分数的框，如果使用nms的话就会把其他置信度稍低，但是表示另一个物体的预测框删掉（由于和最高置信度的框overlap过大）
-
某些情况下，所有的bbox都预测不准，对于下面第二张图我们看到，不是所有的框都那么精准，有时甚至会出现某个物体周围的所有框都标出来了，但是都不准的情况
-
传统的NMS方法是基于分类分数的，只有最高分数的预测框能留下来，但是大多数情况下IoU和分类分数不是强相关，很多分类标签置信度高的框都位置都不是很准</p>
<h3 id="参考文献">参考文献</h3>
<ol type="1">
<li><a
href="https://www.cnblogs.com/makefile/p/nms.html">NMS的解释</a></li>
<li><a
href="http://www.cnblogs.com/rocbomb/p/4428946.html">附录中ROI的解释</a></li>
<li><a
href="https://blog.csdn.net/u013989576/article/details/73439202/">SSD算法</a></li>
<li><a
href="https://towardsdatascience.com/review-retinanet-focal-loss-object-detection-38fba6afabe4">One-Stage
Detector, With Focal Loss and RetinaNet Using ResNet+FPN, Surpass the
Accuracy of Two-Stage Detectors, Faster R-CNN</a></li>
<li><a
href="https://blog.csdn.net/lcczzu/article/details/86518615">非极大值抑制算法的两个改进算法
&amp; 传统NMS的问题</a></li>
<li><a
href="http://blog.prince2015.club/2018/07/23/NMS/">非极大值抑制算法（NMS）与源码分析</a></li>
</ol>
<h2
id="one-stage和two-stage的anchor-base-detection">one-stage和two-stage的anchor-base
detection</h2>
<p>它们的主要区别 * one-stage网络速度要快很多 *
one-stage网络的准确性要比two-stage网络要低</p>
<h3
id="为什么one-stage网络速度要快很多">为什么one-stage网络速度要快很多？</h3>
<p>首先来看第一点这个好理解，one-stage网络生成的anchor框只是一个逻辑结构，或者只是一个数据块，只需要对这个数据块进行分类和回归就可以，不会像two-stage网络那样，生成的
anchor框会映射到feature
map的区域（rcnn除外），然后将该区域重新输入到全连接层进行分类和回归，每个anchor映射的区域都要进行这样的分类和回归，所以它非常耗时</p>
<h3
id="为什么one-stage网络的准确性要比two-stage网络要低">为什么one-stage网络的准确性要比two-stage网络要低？</h3>
<p>我们来看RCNN，它是首先在原图上生成若干个候选区域，这个候选区域表示可能会是目标的候选区域，注意，这样的候选区域肯定不会特别多，假如我一张图像是<span
class="math inline">\(100\times100\)</span>的，它可能会生成<code>2000</code>个候选框，然后再把这些候选框送到分类和回归网络中进行分类和回归，Fast
R-CNN其实差不多，只不过它不是最开始将原图的这些候选区域送到网络中，而是在最后一个feature
map将这个候选区域提出来，进行分类和回归，它可能最终进行分类和回归的候选区域也只有<code>2000</code>多个并不多。再来看Faster
R-CNN，虽然Faster R-CNN它最终一个feature
map它是每个像素点产生9个anchor，那么<span
class="math inline">\(100\times100\)</span>假如到最终的feature
map变成了<span
class="math inline">\(26\times26\)</span>了，那么生成的anchor就是<span
class="math display">\[26\times 26 \times 9 =
6084\]</span>个，虽然看似很多，但是其实它在RPN网络结束后，它会不断的筛选留下<code>2000</code>多个，然后再从<code>2000</code>多个中筛选留下<code>300</code>多个，然后再将这<code>300</code>多个候选区域送到最终的分类和回归网络中进行训练，所以不管是R-CNN还是Fast-RCNN还是Faster-RCNN，它们最终进行训练的anchor其实并不多，几百到几千，不会存在特别严重的正负样本不均衡问题.
但是我们再来看yolo系列网络，就拿yolo3来说吧，它有三种尺度，<span
class="math inline">\(13\times 13\)</span>，<span
class="math inline">\(26\times 26\)</span>，<span
class="math inline">\(52\times
52\)</span>，每种尺度的每个像素点生成三种anchor，那么它最终生成的anchor数目就是
<span class="math display">\[(13\times 13+26\times 26+52\times52)\times
3 =
10647\]</span>个anchor，而真正负责预测的可能每种尺度的就那么几个，假如一张图片有3个目标，那么每种尺度有三个anchor负责预测，那么10647个anchor中总共也只有9个anchor负责预测，也就是正样本，其余的10638个anchor都是背景anchor，这存在一个严重的正负样本失衡问题，虽然位置损失，类别损失，这10638个anchor不需要参与，但是目标置信度损失，背景anchor参与了，因为</p>
<p><span class="math display">\[总的损失 = 位置损失 + 目标置信度损失 +
类别损失\]</span></p>
<p>所以背景anchor对总的损失有了很大的贡献，但是我们其实不希望这样的，我们更希望的是非背景的anchor对总的损失贡献大一些，这样不利于正常负责预测anchor的学习，而two-stage网络就不存在这样的问题，two-stage网络最终参与训练的或者计算损失的也只有<code>2000</code>个或者<code>300</code>个，它不会有多大的样本不均衡问题，不管是正样本还是负样本对损失的贡献几乎都差不多，所以网络会更有利于负责预测anchor的学习，所以它最终的准确性肯定要高些</p>
<blockquote>
<p>总结</p>
</blockquote>
<p>one-stage网络最终学习的anchor有很多，但是只有少数anchor对最终网络的学习是有利的，而大部分anchor对最终网络的学习都是不利的，这部分的anchor很大程度上影响了整个网络的学习，拉低了整体的准确率；而two-stage网络最终学习的anchor虽然不多，但是背景anchor也就是对网络学习不利的anchor也不会特别多，它虽然也能影响整体的准确率，但是肯定没有one-stage影响得那么严重，所以它的准确率比one-stage肯定要高。</p>
<h3
id="那么什么情况下背景anchor不会拉低这个准确率呢">那么什么情况下背景anchor不会拉低这个准确率呢？</h3>
<p>设置阀值，与真实GrundTruth
IOU阀值设得小一点，只要大于这个阀值，就认为你是非背景anchor（注意这部分anchor只负责计算目标置信度损失，而位置、类别损失仍然还是那几个负责预测的anchor来负责）或者假如一个图片上有非常多的位置都是目标，这样很多anchor都不是背景anchor；总之保证背景anchor和非背景anchor比例差不多，那样可能就不会拉低这个准确率，但是只要它们比例相差比较大，那么就会拉低这个准确率，只是不同的比例，拉低的程度不同而已</p>
<h3
id="解决one-stage网络背景anchor过多导致的不均衡问题方案">解决one-stage网络背景anchor过多导致的不均衡问题方案</h3>
<ul>
<li>采用focal loss，将目标置信度这部分的损失换成focal loss</li>
<li>增大非背景anchor的数量</li>
</ul>
<p>某个像素点生成的三个anchor，与真实GrundTruth重合最大那个负责预测，它负责计算位置损失、目标置信度损失、类别损失，这些不管，它还有另外两个anchor，虽然另外两个anchor不是与真实GrundTruth重合最大，但是只要重合大于某个阀值比如大于<code>0.7</code>，我就认为它是非背景anchor，但注意它只计算目标置信度损失，位置和类别损失不参与计算，而小于<code>0.3</code>的我直接不让它参与目标置信度损失的计算，实现也就是将它的权重置0，这个思想就类似two-stage网络那个筛选机制，从<code>2000</code>多个anchor中筛选<code>300</code>个参与训练或者计算目标置信度损失，相当于我把小于<code>0.3</code>的anchor我都筛选掉了，让它不参与损失计算</p>
<ul>
<li>设置权重
在目标置信度损失计算时，将背景anchor的权重设置得很小，非背景anchor的权重设置得很大。</li>
</ul>
<h3 id="四步交替训练faster-rcnn">四步交替训练Faster RCNN</h3>
<p><a href="https://zhuanlan.zhihu.com/p/34327246">训练RPN网络</a></p>
<p>Faster
RCNN有两种训练方式，一种是四步交替训练法，一种是end-to-end训练法。主文件位于/tools/train_fast_rcnn_alt_opt.py。</p>
<p>第一步，训练RPN，该网络用ImageNet预训练的模型初始化，并端到端微调，用于生成region
proposal;</p>
<p>第二步，由imageNet model初始化，利用第一步的RPN生成的region
proposals作为输入数据，训练Fast
R-CNN一个单独的检测网络，这时候两个网络还没有共享卷积层;</p>
<p>第三步，用第二步的fast-rcnn
model初始化RPN再次进行训练，但固定共享的卷积层，并且只微调RPN独有的层，现在两个网络共享卷积层了;</p>
<p>第四步，由第三步的RPN
model初始化fast-RCNN网络，输入数据为第三步生成的proposals。保持共享的卷积层固定，微调Fast
R-CNN的fc层。这样，两个网络共享相同的卷积层，构成一个统一的网络。</p>
<h2
id="faster-rcnn和yolo的anchor有什么区别">Faster-RCNN和YOLO的anchor有什么区别</h2>
<figure>
<img data-src="https://img-blog.csdnimg.cn/20190116235428577.jpg"
alt="@FasterRCNN generator anchor" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FasterRCNN">@FasterRCNN</span> generator anchor</figcaption>
</figure>
<p>可以看到yolov3是直接对你的训练样本进行k-means聚类，由训练样本得来的先验框（anchor），也就是对样本聚类的结果。Kmeans因为初始点敏感，所以每次运行得到的anchor值不一样，但是对应的avg
iou稳定。用于训练的话就需要统计多组anchor，针对固定的测试集比较了。</p>
<ul>
<li><p>https://blog.csdn.net/xiqi4145/article/details/86516511</p></li>
<li><p>https://blog.csdn.net/cgt19910923/article/details/82154401</p></li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>detection</tag>
      </tags>
  </entry>
  <entry>
    <title>自然场景文本检测与识别</title>
    <url>/201908/20190809-scene-text-detection-component/</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<p>基于深度学习算法的的自然场景文本检测，经过几年的研究，针对解决实际问题中的某些问题，涌现出CTC,
LSTM等大量的单元。在深度学习之前，已经有大量的优秀工作如SWT，MSER等算法被提出，这里我将先对一些OCR领域的经典作品进行介绍，然后再引入OCR中的深度学习算法。</p>
<h1 id="经典算法在ocr应用中的问题9">经典算法在OCR应用中的问题<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h1>
<ul>
<li>文本定位，尤其是非水平的文本定位问题，例如SWT算子是比较常用的文本定位算法，但针对非水平文本定位存在一定的局限性。</li>
<li>无法处理序列不定长的问题</li>
<li>文字大小不一的问题</li>
</ul>
<h1 id="开源数据集合">开源数据集合</h1>
<figure>
<img data-src="https://cwlseu.github.io/images/ocr/ocr-opendataset.png"
alt="@数据集合用途统计" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="数据集合用途统计">@数据集合用途统计</span></figcaption>
</figure>
<figure>
<img data-src="https://cwlseu.github.io/images/ocr/ocr-opendataset2.png"
alt="@数据集合标注属性统计" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="数据集合标注属性统计">@数据集合标注属性统计</span></figcaption>
</figure>
<h1 id="swt算子1">SWT算子<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></h1>
<ul>
<li><a
href="http://cmp.felk.cvut.cz/~cernyad2/TextCaptchaPdf/Detecting%20Text%20in%20Natural%20Scenes%20with%20Stroke%20Width%20Transform.pdf"><code>Paper: Detecting Text in Natural Scenes with Stroke Width Transform</code></a></li>
<li><a
href="https://github.com/aperrau/DetectText"><code>github: https://github.com/aperrau/DetectText</code></a></li>
</ul>
<p>下面根据原文的结构和上述提供的代码详细的解读一下该算法。总的来说该算法分为四步：
* 利用<code>canny</code>算子检测图片的边界 * 笔画宽度变换-Stroke Width
Transform（这一步输出的图像我们称为SWT图像） *
通过<code>SWT</code>图像得到多个连通域 *
通过自定义的规则过滤一些连通域，得到候选连通域 *
将连通域合并得到文本行</p>
<h3 id="step-1利用canny算子检测图片的边界">Step
1：利用canny算子检测图片的边界</h3>
<p>这步不用多说，基础的图像处理知识，利用OpenCV
的Canny函数可以得到图片边缘检测的结果。</p>
<h3 id="step-2笔画宽度变换stroke-width-transform">Step
2：笔画宽度变换（Stroke Width Transform）</h3>
<p>这一步输出图像和输入图像大小一样，只是输出图像像素为笔画的宽度，具体如下。
<img data-src="http://cwlseu.github.io/images/ocr/SWT_01.png" /></p>
<p>如上图所示，通过边缘检测得到上图a，假设现在从边缘上的点p开始，根据p点梯度的反方向找到边缘另一边的点q，如果p点的梯度与q点梯度的反方向夹角在<span
class="math inline">\(\pm\pi/6\)</span>之间，那么这两点间的距离为一个笔画宽度，那么p点和q点以及它们之间的像素在SWT输出图像中对应位置的值为p和q点的距离大小。</p>
<p>按照上述的计算方法会有两种情况需要考虑。如下图所示，</p>
<p><img data-src="http://cwlseu.github.io/images/ocr/SWT_02.png" /></p>
<p>下图a表示一个笔画中的像素可能得到两个笔画宽度，这种情况下将红点出的笔画宽度设置为最小的那个值，下图b表示当一个笔画出现更为复杂情况，b图中的红点计算出的两个笔画宽度用两个红线表示，这两红线都无法真正表示笔画的宽度，这时候笔画宽度取这里面所有像素计算得到的笔画宽度的中值作为红点出的笔画宽度。</p>
<p>因为有文字比背景更亮和背景比文字更亮两种情况，这样会导致边缘的梯度方向相反，所以这一个步骤要执行两遍。这个步骤结束后得到一张SWT图像。</p>
<h3 id="step-3通过swt图像得到多个连通域">Step
3：通过SWT图像得到多个连通域</h3>
<p>在通过上述步骤得到SWT输出图像后，该图像大小与原图像大小一致，图像中的像素值为对应像素所在笔画的宽度（下面称为SWT值）。现将相邻像素SWT值比不超过3.0的归为一个连通域。这样就能得到多个连通域。</p>
<h3 id="step-4过滤连通域">Step 4：过滤连通域</h3>
<p>上述步骤输出的多个连通域中，并不是所有的连通域都被认为是笔画候选区域，需要过滤一些噪声的影响，过滤的规则有：
*
如果某连通域的方差过大（方差大于连通域的一半为方差过大为过大），则认为该连通域不是有效的
*
如果某连通域过大（宽大于300）或者过小（宽小于10），则认为该连通域不是有效的（代码中只过滤了过大的连通域，连通域的长宽为连通域外接矩形的长宽）
*
如果某连通域的长宽比不在0.1-10的范围内，则认为该连通域不是有效的（连通域的长宽为连通域外接矩形的长宽）
*
如果某连通域的外接矩形包含其他两个连通域，则认为该连通域不是有效的（代码中判定，如果某个连通域的外接矩形包含两个或两个以上连通域外接矩形的中心时，认为其包含了两个连通域）
上述条件都满足的连通域，认为是笔画候选区域，用于输入给下一步操作。</p>
<h3 id="step-5将连通域合并得到文本行">Step
5：将连通域合并得到文本行</h3>
<p>文中认为，在自然场景中，一般不会只有单个字母出现，所有将连通域合并为文本有利于进一步将噪声排除。</p>
<p>当两个连通域满足下面条件时，认为这两个连通域是一对： *
两个连通域中值的比小于2.0（连通域中值，指的是连通域中所有像素值的中值）
* 两个连通域高的比小于2.0（连通域的高，指其外界矩形的高） *
两个连通域之间的距离小于较宽的连通域宽度的3倍（连通域之间的距离为连通域外界矩形中心点之间的距离）
*
两个连通域的颜色相似（代码用两个连通域对应于原图区域的像素均值代表该连通域的颜色）</p>
<p>得到两两连通域组成的多对连通域后，如果有两对连通域有共享的连通域，共享的连通域都在连通域对的一端（即连通域的首端或者尾端），且方向相同（方向用一个连通域中心到另一个连通域中心的方向），就将这两对连通域合并为一个新的连通域组，依次进行，知道没有连通域对需要合并则合并结束。</p>
<p>最后将合并完的结果中滤除小于3的连通域的连通域组得到的最终结果，认为是一行文字。</p>
<h1 id="最大极值稳定区域mser分析2">最大极值稳定区域MSER分析<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></h1>
<p>最大稳定极值区域MSER是一种类似分水岭图像的分割与匹配算法，它具有仿射不变性。极值区域反映的就是集合中的像素灰度值总大于或小于其邻域区域像素的灰度值。对于最大稳定区域，通过局部阈值集操作，区域内的像素数量变化是最小的。</p>
<p>MSER的基本原理是对一幅灰度图像（灰度值为0～255）取阈值进行二值化处理，阈值从0到255依次递增。阈值的递增类似于分水岭算法中的水面的上升，随着水面的上升，有一些较矮的丘陵会被淹没，如果从天空往下看，则大地分为陆地和水域两个部分，这类似于二值图像。在得到的所有二值图像中，图像中的某些连通区域变化很小，甚至没有变化，则该区域就被称为最大稳定极值区域。这类似于当水面持续上升的时候，有些被水淹没的地方的面积没有变化。</p>
<p>上述做法只能检测出灰度图像的黑色区域，不能检测出白色区域，因此还需要对原图进行反转，然后再进行阈值从0～255的二值化处理过程。这两种操作又分别称为MSER+和MSER-。</p>
<p>MSER是当前认为性能最好的仿射不变性区域的检测方法，其使用不同灰度阈值对图像进行二值化来得到最稳定区域，表现特征有以下三点：
* 对图像灰度仿射变化具有不变性， * 对区域支持相对灰度变化具有稳定性， *
对区域不同精细程度的大小区域都能进行检测。</p>
<p>MSER最大极值稳定区域的提取步骤： * 像素点排序 * 极值区域生成 *
稳定区域判定 * 区域拟合 * 区域归一化</p>
<h1 id="hmm-ctc">HMM &amp; CTC</h1>
<h3 id="问题">问题</h3>
<p>序列学习任务需要从未分割的输入数据中预测序列的结果。HMM模型与CRF模型是序列标签任务中主要使用的框架，这些方法对于许多问题已经获得了较好的效果，但是它们也有缺点：</p>
<ul>
<li>需要大量任务相关的知识，例如，HMM中的状态模型，CRF中的输入特征选择</li>
<li>需要有独立性假设作为支撑；</li>
<li>对于标准的HMM模型，它是生成式的，但是序列标签时判别式的。</li>
</ul>
<p>RNN网络除了输入与输出的表达方式需要选择之外不需要任何数据的先验。
它可以进行判别训练，它的内部状态为构建时间序列提供了强大的通用机制。
此外，其对时间和空间噪声具有很强的鲁棒性。</p>
<p>但是对于RNN呢，它是不能拿来做序列预测的，这是<strong>因为RNN只能去预测一些独立标签的分类，因而就需要进行序列预分割</strong>。要解决该问题，那么将RNN与HMM结合起来被称之为hybrid
approach。在该方法中使用HMM为长序列结构数据建立模型，神经网络就提供局部分类。加入HMM之后可以使得在训练中自动分割序列，并且将原本的网络分类转换到标签序列。然而，它并没有避免上述内容中HMM使用缺点。</p>
<h3 id="引入ctc">引入CTC</h3>
<p>CTC( Connectionist Temporal
Classification)，可以解决前面提到的两点局限，直接使用序列进行训练。CTC引入了一个<strong>新的损失函数</strong>，可以使得RNN网络可以直接使用未切分的序列记性训练。为了使用这个损失函数，
为RNN引入其可以输出的"BLANK"标签, RNN的输出是所有标签的概率。
这里将Temporal Classification定义为<span
class="math inline">\(h\)</span>，训练数据集合<span
class="math inline">\(S\)</span>中数据是成对存在的<span
class="math inline">\((\mathbf{x},z)\)</span>，其中<span
class="math inline">\(\mathbf{x}\)</span>是训练的时序数据，<span
class="math inline">\(z\)</span>是标签数据。目标就是找到一个时序分类器<span
class="math inline">\(h\)</span>使得<span
class="math inline">\(S\)</span>中的<span
class="math inline">\(x\)</span>被分类到<span
class="math inline">\(z\)</span>。训练这个分类器，就需要一个错误度量，这里就借鉴了编辑（ED）距离度量，而引入了label
error rate（LER）。在这里还对其进行了归一化，从而得到了如下的形式：</p>
<p><span class="math display">\[LER(h, S) =
\frac{1}{Z}\sum_{(\mathbf{x},z)\in S} ED(h(\mathbf{x}))\]</span></p>
<p>将网络输出转换成为基于标签序列的条件概率，从而可以使用分类器对输入按照概率大小进行分类。</p>
<h3 id="从网络输出到连续标签">从网络输出到连续标签</h3>
<p>在CTC网络中拥有一个<span
class="math inline">\(softmax\)</span>输出层，其输出的个数为<span
class="math inline">\(∣L∣+1\)</span>，<span
class="math inline">\(L\)</span>是标签元素的集合，额外的一个那当然就是"BLANK"标签了。这些输出定义了将所有可能的标签序列与输入序列对齐的所有可能路径的概率。任何一个标签序列的总概率可以通过对其不同排列的概率求和得到。
首先对于一条可行的路径<span
class="math inline">\(p(\pi|x)\)</span>被定义为对应路径上的各个时刻输出预测概率的乘积。其定义如下：</p>
<p><span class="math display">\[p(\pi|x) = \prod^T_{t=1}y_{\pi_t}^t,
\quad \forall \pi \in L&#39;^T\]</span></p>
<p>对于预测结果中的一条路径的标签，论文中假设这些不同时刻网络的输出是相互独立的，而这种独立性是通过输出层与自身或网络之间不存在反馈连接来确保实现的。</p>
<p>在此基础上还定义了映射函数<span
class="math inline">\(B\)</span>，它的职责就是去除"BLANK"与重复的标签。因而给定的一个标签其输出概率就可以描述为几个可行路径相加和的形式:</p>
<p><span class="math display">\[ p(l|\mathbf{x}) = \sum_{\pi \in
B^{-1}(l)} p(\pi|\mathbf{x}) \]</span></p>
<h3 id="构建分类器">构建分类器</h3>
<p>从上面的内容中已经得到了一个序列标签的输出条件概率，那么怎么才能找到输入数据最匹配的标签呢？最为直观的便是求解</p>
<p><span class="math display">\[h(X) = \arg\max_{l\in L \le T}
p(l|\mathbf{x})\]</span></p>
<p>在给定输入情况下找到其最可能的标签序列，这样的过程使用HMM中的术语叫做解码。目前，还没有一种通过易理解的解码算法，但下面的两种方法在实践过程中也取得了不错的效果。</p>
<h4 id="最佳路径解码">最佳路径解码</h4>
<p>该方法是建立在概率最大的路径与最可能的标签时对应的，因而分类器就被描述为如下形式：</p>
<p><span class="math display">\[h(\mathbf{x}) \approx
B(\pi^*)\]</span></p>
<p><span class="math display">\[where\quad \pi^* = \arg\max_{\pi \in
N^t}p(\pi|\mathbf{x})\]</span></p>
<p>从上面的形式中就可以看出，最佳路径解码的计算式很容易的，因为最佳路径中的元素是各个时刻输出的级联。但是呢，这是不能保证找到最可能的标签的。</p>
<h4 id="前缀解码">前缀解码</h4>
<p>前缀解码在足够时间的情况下会找到最可能的标签，但是随着输入序列长度的增强时间也会指数增加。如果输入的概率分布是尖状的，那么可以在合理的时间内找到最可能的路径。</p>
<p>实践中，前缀搜索在这个启发式下工作得很好，通常超过了最佳路径解码，但是在有些情况下，效果不佳。</p>
<h1 id="ctc网络训练">CTC网络训练</h1>
<p>目标函数是由极大似然原理导出的。也就是说，最小化它可以最大化目标标签的对数可能性。有了损失函数之后就可以使用依靠梯度进行优化的算法进行最优化。</p>
<p>CTC在网络中放置在双向递归网络的后面作为序列预测的损失来源。CTC会在RNN网络中传播梯度，进而使得其学习一条好路径。</p>
<h3 id="ctc前向传播算法">CTC前向传播算法</h3>
<p>需要一种有效的方法来计算单个标签的条件概率<span
class="math inline">\(p(l|\mathbf{x})\)</span>。对于这样的问题，其实就是对应于给定标签的所有路径的综合。通常有很多这样的路径。这里我们采用动态规划的算法计算所有可能路径的概率和，其思想是，与标签对应的路径和可以分解为与标签前缀对应的路径的迭代和。
然后，可以使用递归向前和向后变量有效地计算迭代。
以下是本文设计到的一些符号定义：</p>
<ul>
<li><span class="math inline">\(y_{k}^{t}\)</span>, 时刻t的输出字符<span
class="math inline">\(k\)</span></li>
<li><span class="math inline">\(l\)</span>, 标签序列对应的损失。</li>
<li><span
class="math inline">\(l^{\prime}\)</span>，相同的标签序列，但是在字符之间添加了"BLANK"标签</li>
</ul>
<p><span class="math display">\[\alpha_t(s) \overset{def}{=} \sum_{\pi
\in N^T: \atop B(\pi_{1:t}) = l_{1:s}} \prod^t_{t^{\prime} = 1}
y_{\pi_{t^{\prime}}}^{t^{\prime}}.\]</span></p>
<p>其中B是溢出所有"BLANK"与重复字符的变换；<span
class="math inline">\({\pi \in N^T:B(\pi_{1:t}) = l_{1:s}}\)</span>
是时刻1到t的预测矩阵中，给出经过变换<span
class="math inline">\(B\)</span>之后与标签有前s个一致的所有可行路径；<span
class="math inline">\(y^{t^{\prime}}\)</span> 是指时刻<span
class="math inline">\(t^{\prime}\)</span>时RNN的输出。而且<span
class="math inline">\(\alpha_{t}(s)\)</span>可以通过<span
class="math inline">\(\alpha_{t-1}(s)\)</span>与<span
class="math inline">\(\alpha_{t-1}(s-1)\)</span>迭代计算出来。</p>
<p>图3中描述的状态转移图与上面公式的含义是相同的。为了能够在输出路径中出现"BLANK"标签，将标签修改成了<span
class="math inline">\(l^{\prime}\)</span>，也就是在标签的前后与字符之前插入空白标签，因而生成的标签长度就变成了<span
class="math inline">\(2|l|+1\)</span>的长度，使其可以再空白标签与非空白标签之间转换，也可以使非空白标签之间发生转换。
上面的公式1中已经给出了其计算的内容，但其计算并不具有可行性。但是可以根据图3中<span
class="math inline">\(\alpha_{t}(s)\)</span>的递归定义使用动态规划算法去解决该问题，仔细看这幅图，是不是有点像HMM的前向计算过程。</p>
<p>对于解决该问题使用动态规划的算法进行解决，首先来分析时刻1时候的情况：</p>
<p><span class="math display">\[\alpha_1(1) = y_b^1\]</span></p>
<p><span class="math display">\[\alpha_1(2) =
y_{l^{\prime}}^1\]</span></p>
<p><span class="math display">\[\alpha_1(s) = 0, \forall s &gt;
2\]</span></p>
<p><span class="math display">\[\alpha_t(s) = \begin{cases}
a_t(s)y_{l_{s}^{\prime}}^t, \quad if\quad l_s^{\prime} = b\quad
or\quad  l_{s-2}^{\prime} = l_s^{\prime}\\
(\bar{\alpha_t}(s) +\alpha_{t-1}(s -2))y_{l_{s}^{\prime}}^t, \quad
otherwise
\end{cases}\]</span></p>
<p>where <span class="math inline">\(\alpha_t(s) \overset{def}{=}
\alpha_{t-1}(s) + \alpha_{t-1}(s-1)\)</span>
最后就可以得到一个序列的输出概率</p>
<p><span class="math display">\[p(l|\mathbf{x}) = \alpha_T(|l^{\prime}|)
+ \alpha_T(|l^{\prime}| -1)\]</span></p>
<h3 id="反向传播算法">反向传播算法</h3>
<p>反向传播的变量<span
class="math inline">\(\beta_{t}(s)\)</span>被定义为<span
class="math inline">\(t\)</span>时刻<span
class="math inline">\(l_{s:|l|}\)</span>的总概率 <span
class="math display">\[
\beta_{t}(s) \stackrel{\mathrm{def}}{=} \sum_{\pi \in N^{T} \atop
\mathcal{B}(\pi_{t : T}) = l_{s:|l|}} \prod_{t^{\prime}=t}^{T}
y_{\pi_{t^{\prime}}^{\prime}}^{t^{\prime}}
\]</span></p>
<p><span class="math display">\[
\beta_{T}\left(\left|\mathbf{l}^{\prime}\right|\right)=y_{b}^{T}            \\
\beta_{T}\left(\left|\mathbf{l}^{\prime}\right|-1\right)=y_{l_{|l|}}^{T}    \\
\beta_{T}(s)=0, \quad \forall
s&lt;\left|\mathbf{l}^{\prime}\right|-1          \\
\beta_{t}(s)=\left\{
    \begin{array}{ll}{
        \overline{\beta}_{t}(s) y_{1 s}^{t}} &amp; {\text { if }
1_{s}^{\prime}=b \text { or } 1_{s+2}^{\prime}=1_{s}^{\prime}} \\
        {\left(\overline{\beta}_{t}(s)+\beta_{t+1}(s+2)\right)
y_{1_{s}^{t}}} &amp; {\text { otherwise }}
    \end{array}
\right.
\]</span></p>
<p><span class="math display">\[
\begin{array}{l}{
\text {where}}
{\quad\overline{\beta}_{t}(s) \stackrel{\mathrm{def}}{=}
\beta_{t+1}(s)+\beta_{t+1}(s+1)}
\end{array}
\]</span></p>
<h3 id="最大似然训练">最大似然训练</h3>
<p>最大似然训练的目的是同时最大化训练集中所有正确分类的对数概率。因而这里可以将损失函数定义为：</p>
<p><span class="math display">\[
O^{M L}\left(S, \mathcal{N}_{w}\right)=-\sum_{(\mathbf{x}, \mathbf{z})
\in S} \ln (p(\mathbf{z} | \mathbf{x}))
\]</span></p>
<p>为了使用梯度进行网络训练，因而就需要对网络的输出进行微分，且训练样本是相互独立的，也就是说可以单独考虑了，因而可以将微分写为：</p>
<p><span class="math display">\[
\frac{\partial O^{M L}\left(\{(\mathbf{x}, \mathbf{z})\},
\mathcal{N}_{w}\right)}{\partial y_{k}^{t}}=-\frac{\partial \ln
(p(\mathbf{z} | \mathbf{x}))}{\partial y_{k}^{t}}
\]</span></p>
<p>这里可以用前向后向算法计算上式。主要思想是：对于一个标记l，在给定s和t的情况下，前向和后向变量的内积是对应l所有可能路径的概率。表达式为：</p>
<p><span class="math display">\[
\alpha_{t}(s) \beta_{t}(s)=\sum_{\pi \in \mathcal{B}^{-1}(1) : \atop
{\pi_t = l_s^{\prime}}} y_{1_{s}}^{t} \prod_{t=1}^{T} y_{\pi_{t}}^{t}
\]</span></p>
<p>且根据上面的公式（2）联合可以得到：</p>
<p><span class="math display">\[
\frac{\alpha_{t}(s) \beta_{t}(s)}{y_{1_{s}^{t}}^{t}}=\sum_{\pi \in
\mathcal{B}^{-1}(1): \atop {\pi_t = l_s^{\prime}}} p(\pi | \mathbf{x})
\]</span></p>
<p>再与前面的公式（3）联合可以得到</p>
<p><span class="math display">\[
p(\mathbf{l} | \mathbf{x})=\sum_{s=1}^{\left|\mathbf{l}^{\prime}\right|}
\frac{\alpha_{t}(s) \beta_{t}(s)}{y_{1_{s}^{\prime}}^{t}}
\]</span></p>
<h1 id="rlstmreverse-lstm">RLSTM(Reverse LSTM)</h1>
<ul>
<li>RNN<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></li>
<li>LSTM<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a><a href="#fn6" class="footnote-ref"
id="fnref6" role="doc-noteref"><sup>6</sup></a></li>
</ul>
<h3 id="reverse-lstm">Reverse LSTM</h3>
<p>整体架构如下，其中需要用到Reverse这种Layer</p>
<p><img data-src="http://cwlseu.github.io/images/ocr/rlstm.png" /></p>
<h1 id="channelshuffle">ChannelShuffle</h1>
<p><img data-src="http://cwlseu.github.io/images/ocr/shuffle_2.png" /></p>
<p>一般的分组卷积(如ResNeXt的)仅对<span
class="math inline">\(3\times3\)</span>的层进行了分组操作，然而<span
class="math inline">\(1\times1\)</span>的pointwise卷积占据了绝大多数的乘加操作，在小模型中为了减少运算量只能减少通道数，然而减少通道数会大幅损害模型精度。作者提出了对<span
class="math inline">\(1\times1\)</span>也进行分组操作，但是如图１(a)所示，输出只由部分输入通道决定。为了解决这个问题，作者提出了图(c)中的通道混淆(channel
shuffle)操作来分享组间的信息，假设一个卷基层有g
groups，每个group有n个channel，因此shuffle后会有<span
class="math inline">\(g\times
n\)</span>个通道，首先将输出的通道维度变形为(g,
n)，然后转置(transpose)、展平(flatten)，shuffle操作也是可导的。</p>
<p><img data-src="http://cwlseu.github.io/images/ocr/shuffle_3.png" /></p>
<p>图2 (a)是一个将卷积替换为depthwise卷积<a href="#fn7"
class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a>的residual block，(b)中将两个<span
class="math inline">\(1\times1\)</span>卷积都换为pointwise group
convolution，然后添加了channel shuffle，为了简便，没有在第二个pointwise
group convolution后面加channel
shuffle。根据Xception的论文，depthwise卷积后面没有使用ReLU。(c)为stride
&gt; 1的情况，此时在shotcut path上使用<span
class="math inline">\(3\times3\)</span>的平均池化，并将加法换做通道concatenation来增加输出通道数(一般的设计中，stride=2的同时输出通道数乘2)。</p>
<p>对于<span class="math inline">\(c \times h \times
w\)</span>的输入大小，bottleneck channels为m，则ResNet unit需要<span
class="math inline">\(hw(2cm + 9m^2)FLOPs\)</span>，ResNeXt需要<span
class="math inline">\(hw(2cm + 9m^2/g)FLOPs\)</span>，ShuffleNet
unit只需要<span class="math inline">\(hw(2cm/g +
9m)FLOPs\)</span>，g表示卷积分组数。换句话说，在有限计算资源有限的情况下，ShuffleNet可以使用更宽的特征图，作者发现对于小型网络这很重要。</p>
<p>即使depthwise卷积理论上只有很少的运算量，但是在移动设备上的实际实现不够高效，和其他密集操作(dense
operation)相比，depthwise卷积的computation/memory access
ratio很糟糕。因此作者只在bottleneck里实现了depthwise卷积。</p>
<h1 id="ctpn4">CTPN<a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a></h1>
<p><img data-src="http://cwlseu.github.io/images/ocr/CTPN.png"
alt="@The-Arch-of-CTPN" /> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_planes, out_planes,</span></span><br><span class="line"><span class="params">                 kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 dilation=<span class="number">1</span>, groups=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 relu=<span class="literal">True</span>, bn=<span class="literal">True</span>, bias=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicConv, self).__init__()</span><br><span class="line">        self.out_channels = out_planes</span><br><span class="line">        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)</span><br><span class="line">        self.bn = nn.BatchNorm2d(out_planes, eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>) <span class="keyword">if</span> bn <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>) <span class="keyword">if</span> relu <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="keyword">if</span> self.bn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.bn(x)</span><br><span class="line">        <span class="keyword">if</span> self.relu <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">Commom_C = <span class="number">512</span></span><br><span class="line">anchor_k = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CTPN_Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        base_model = models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">        layers = <span class="built_in">list</span>(base_model.features)[:-<span class="number">1</span>]</span><br><span class="line">        self.base_layers = nn.Sequential(*layers)  <span class="comment"># block5_conv3 output</span></span><br><span class="line">        self.prelstm = BasicConv(Commom_C, Commom_C, <span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>,bn=<span class="literal">False</span>)</span><br><span class="line">        self.bilstm = nn.GRU(Commom_C, Commom_C/<span class="number">2</span>, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.lstm_fc = BasicConv(Commom_C, Commom_C, <span class="number">1</span>, <span class="number">1</span>, relu=<span class="literal">True</span>, bn=<span class="literal">False</span>)</span><br><span class="line">        self.rpn_class = BasicConv(Commom_C, anchor_k*<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, relu=<span class="literal">False</span>,bn=<span class="literal">False</span>)</span><br><span class="line">        self.rpn_regress = BasicConv(Commom_C, anchor_k*<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, relu=<span class="literal">False</span>, bn=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># basebone network run</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        x = self.base_layers(x)</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># Convert feature map to lstm input</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        x = self.prelstm(x)</span><br><span class="line">        x1 = x.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous()  <span class="comment"># channels last</span></span><br><span class="line">        b = x1.size()  <span class="comment"># batch_size, h, w, c</span></span><br><span class="line">        x1 = x1.view(b[<span class="number">0</span>]*b[<span class="number">1</span>], b[<span class="number">2</span>], b[<span class="number">3</span>])</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># BiLSTM</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        x2, _ = self.bilstm(x1)</span><br><span class="line"></span><br><span class="line">        xsz = x.size()</span><br><span class="line">        x3 = x2.view(xsz[<span class="number">0</span>], xsz[<span class="number">2</span>], xsz[<span class="number">3</span>], <span class="number">256</span>)  <span class="comment"># torch.Size([4, 20, 20, 256])</span></span><br><span class="line"></span><br><span class="line">        x3 = x3.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous()  <span class="comment"># channels first</span></span><br><span class="line">        x3 = self.lstm_fc(x3)</span><br><span class="line">        x = x3</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># RPN</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        rpn_cls = self.rpn_class(x)</span><br><span class="line">        rpn_regr = self.rpn_regress(x)</span><br><span class="line"></span><br><span class="line">        rpn_cls = rpn_cls.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous()</span><br><span class="line">        rpn_regr = rpn_regr.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous()</span><br><span class="line"></span><br><span class="line">        rpn_cls = rpn_cls.view(rpn_cls.size(<span class="number">0</span>), rpn_cls.size(<span class="number">1</span>)*rpn_cls.size(<span class="number">2</span>)*anchor_k, <span class="number">2</span>)</span><br><span class="line">        rpn_regr = rpn_regr.view(rpn_regr.size(<span class="number">0</span>), rpn_regr.size(<span class="number">1</span>)*rpn_regr.size(<span class="number">2</span>)*anchor_k, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> rpn_cls, rpn_regr</span><br></pre></td></tr></table></figure></p>
<p>解释一下conv5 feature map如何从<span class="math inline">\(N\times C
\times H \times W\)</span>变为<span class="math inline">\(N \times 9C
\times H \times W\)</span> <img data-src="http://cwlseu.github.io/images/ocr/covertCNN5.jpg" /></p>
<p>在原版caffe代码中是用im2col提取每个点附近的9点临近点，然后每行都如此处理：</p>
<p><span class="math inline">\(H\times W \rightarrow 9 \times H \times
W\)</span></p>
<p>接着每个通道都如此处理： <span class="math inline">\(C\times H\times
W \rightarrow 9C\times H \times W\)</span></p>
<p>而im2col是用于卷积加速的操作，即将卷积变为矩阵乘法，从而使用Blas库快速计算。到了tf，没有这种操作，所以一般是用conv2d代替im2col，即强行卷积<span
class="math inline">\(C\rightarrow 9C\)</span> 。</p>
<p>再将这个feature map进行Reshape</p>
<p><span class="math display">\[N \times 9C \times H \times W
\xrightarrow{\text{reshape}} (NH)\times W\times 9C\]</span></p>
<p>然后以Batch = NH 且最大时间长度<span class="math inline">\(T_{max} =
W\)</span>的数据流输入双向LSTM,学习每一行的序列特征。双向LSTM输出为<span
class="math inline">\((NH)\times W\times
256\)</span>,再经Reshape恢复形状 <span class="math inline">\((NH)\times
W \times 256 \xrightarrow{reshape} N \times 256 \times H \times
W\)</span></p>
<p>该特征即包含空间特性，也包含LSTM学到的序列特征。</p>
<p>然后经过"FC"卷积层，变为<span class="math inline">\(N\times512\times
H \times W\)</span>的特征 最后经过类似Faster R-CNN的RPN网络，获得text
proposals.</p>
<h2 id="文本线构造算法">文本线构造算法</h2>
<p><img data-src="https://pic1.zhimg.com/80/v2-822f0709d3e30df470a8e17f09a25de0_hd.jpg" /></p>
<p>为了说明问题，假设某张图有图9所示的2个text
proposal，即蓝色和红色2组Anchor，CTPN采用如下算法构造文本线：</p>
<p>按照水平<span class="math inline">\(x\)</span>坐标排序anchor
按照规则依次计算每个anchor <span
class="math inline">\(box_i\)</span>的<span
class="math inline">\(pair(box_j)\)</span>，组成<span
class="math inline">\(pair(box_i, box_j)\)</span> 通过<span
class="math inline">\(pair(box_i, box_j)\)</span>建立一个Connect
graph，最终获得文本检测框</p>
<p>下面详细解释。假设每个anchor index如绿色数字，同时每个anchor Softmax
score如黑色数字。</p>
<p>文本线构造算法通过如下方式建立每个anchor <span
class="math inline">\(box_i\)</span>的<span
class="math inline">\(pair(box_i, box_j)\)</span>:</p>
<blockquote>
<p>正向寻找:</p>
</blockquote>
<ul>
<li>沿水平正方向，寻找和<span
class="math inline">\(box_i\)</span>水平距离小于50的候选anchor</li>
<li>从候选anchor中，挑出与<span
class="math inline">\(box_i\)</span><strong>竖直方向</strong><span
class="math inline">\(overlap_v \gt 0.7\)</span>的anchor</li>
<li>挑出符合条件2中Softmax score最大的<span
class="math inline">\(box_j\)</span></li>
</ul>
<blockquote>
<p>反向寻找:</p>
</blockquote>
<ul>
<li>沿水平负方向，寻找和<span
class="math inline">\(box_j\)</span>水平距离小于50的候选Anchor</li>
<li>从候选Anchor中，挑出与<span
class="math inline">\(box_j\)</span>竖直方向<span
class="math inline">\(overlap_v \gt 0.7\)</span>的anchor</li>
<li>挑出符合条件2中Softmax score最大的<span
class="math inline">\(box_k\)</span></li>
</ul>
<blockquote>
<p>对比<span class="math inline">\(score_i\)</span>和<span
class="math inline">\(score_k\)</span>:</p>
</blockquote>
<p>如果<span class="math inline">\(score_i \ge
score_k\)</span>，则这是一个最长连接，那么设置<span
class="math inline">\(Graph(i, j) = True\)</span> 如果<span
class="math inline">\(score_i \lt
score_k\)</span>，说明这不是一个最长的连接（即该连接肯定包含在另外一个更长的连接中）。</p>
<h1 id="text-recognition">Text Recognition</h1>
<ul>
<li><a
href="https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7">Beam
Search Decoding in CTC-trained Neural Networks</a></li>
</ul>
<h1 id="其他相关算法">其他相关算法</h1>
<p><code>Levenshtein distances</code><a href="#fn9" class="footnote-ref"
id="fnref9" role="doc-noteref"><sup>9</sup></a>是俄罗斯科学家Vladimir
Levenshtein在1965年发明的，也叫做编辑距离（实际上编辑距离代表一大类算法），距离代表着从s到t需要删、插、代替单个字符的最小步骤数。主要应用：
* <code>Spell checking</code> 检查拼写 * <code>Speech recognition</code>
语音识别 * <code>DNA analysis</code> DNA分析 *
<code>Plagiarism detection</code> 检测抄袭</p>
<h1 id="参考文献">参考文献</h1>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://www.jianshu.com/p/56f8c714f372
"自然场景文本检测识别技术综述"<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"
role="doc-endnote"><p>https://blog.csdn.net/liuxiaoheng1992/article/details/85305871
"SWT博客"<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>https://www.cnblogs.com/shangd/p/6164916.html
"MSER 博客"<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://zybuluo.com/hanbingtao/note/541458
"循环神经网络"<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>http://colah.github.io/posts/2015-08-Understanding-LSTMs/
"理解LSTM"<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://www.jianshu.com/p/4b4701beba92
"理解LSTM中文"<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>https://arxiv.org/pdf/1610.02357.pdf
"Xception"<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>https://zhuanlan.zhihu.com/p/34757009
"场景文字检测—CTPN原理与实现" - tf code:
https://github.com/eragonruan/text-detection-ctpn<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>http://www.levenshtein.net/index.html
"编辑距离"<a href="#fnref9" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>OCR</tag>
      </tags>
  </entry>
  <entry>
    <title>认识神经网络：卷积，归一化，优化和语料</title>
    <url>/201907/20190722-deeplearning-note/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>一个基于神经网络模型的视觉模型中，<em>卷积</em>和<em>归一化层</em>是最为耗时的两种layer。卷积数据计算密集类型，今年来大量的优化主要集中在各种设备上的卷积加速。
归一化层通过计算一个批量中的均值与方差来进行特征归一化。众多实践证明，它利于优化且使得深度网络易于收敛。批统计的随机不确定性也作为一个有利于泛化的正则化项。BN
已经成为了许多顶级计算机视觉算法的基础。添加归一化层作为提高算法性能的很好的一种策略，但由于像BN遭受数据同步延时的问题，现在逐渐被一些新的normalization方式所替代。</p>
<h2 id="卷积">卷积</h2>
<h3 id="认识卷积">认识卷积</h3>
<blockquote>
<p>卷积定义</p>
</blockquote>
<p><span class="math display">\[h(x) = f(x)*g(x) = \int_{ - \infty }^{ +
\infty } {f(t)g(x - t)dt}\]</span></p>
<p><span class="math inline">\(f(t)\)</span>先不动， <span
class="math inline">\(g(-t)\)</span>相当于<span
class="math inline">\(g(t)\)</span>函数的图像沿y轴（t=0）做了一次翻转。<span
class="math inline">\(g(x-t)\)</span>相当于<span
class="math inline">\(g(-t)\)</span>的整个图像沿着t轴进行了平移，向右平移了x个单位。他们相乘之后围起来的面积就是<span
class="math inline">\(h(x)\)</span>。</p>
<blockquote>
<p>离散卷积的定义</p>
</blockquote>
<p><span class="math display">\[h(x) = f(x)*g(x) = \sum_{\tau =
-\infty}^{+\infty}f(\tau)g(x-\tau)\]</span></p>
<p>其实，深度学习中的卷积对应于数学中的cross correlation.
从卷积的定义来看，我们当前在深度学习中训练的卷积核是<strong>翻转之后的卷积核</strong>。</p>
<p>下面是一些介绍卷积的文章和常见卷积类型统计表： * <a
href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215">A
Comprehensive Introduction to Different Types of Convolutions in Deep
Learning</a> * <a href="https://blog.yani.io/filter-group-tutorial/">A
Tutorial on Filter Groups (Grouped Convolution)</a> * AlexNet *
MobileNet * <a
href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">An
Introduction to different Types of Convolutions in Deep Learning</a> *
<a href="https://github.com/vdumoulin/conv_arithmetic">Convolution
arithmetic</a> * <a
href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and
Checkerboard Artifacts</a></p>
<table>
<colgroup>
<col style="width: 34%" />
<col style="width: 20%" />
<col style="width: 22%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Convolution Name</th>
<th style="text-align: left;">参考文献</th>
<th style="text-align: left;">典型代表</th>
<th style="text-align: left;">附录</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Convolution</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">AlexNet, VGG</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">1x1</td>
<td style="text-align: left;"><a
href="https://arxiv.org/abs/1312.4400">Network in Network</a></td>
<td style="text-align: left;">GoogLeNet, Inception</td>
<td style="text-align: left;">(1). Dimensionality reduction for
efficient computations;<br>(2).Efficient low dimensional embedding, or
feature pooling; <br>(3). Applying nonlinearity again after
convolution</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Dilated convolution</td>
<td style="text-align: left;"><a
href="https://arxiv.org/abs/1511.07122">Multi-Scale Context Aggregation
by Dilated Convolutions</a></td>
<td style="text-align: left;">语义分割</td>
<td style="text-align: left;">support exponentially expanding receptive
fields without losing resolution or coverage.
Upsampling/poolinglayer(e.g. bilinear interpolation) is deterministic.
(a.k.a. not learnable); <br> 内部数据结构丢失, 空间层级化信息丢失;
<br>小物体信息无法重建 (假设有四个pooling layer则任何小于<span
class="math inline">\(2^4=16\)</span>pixel的物体信息将理论上无法重建。)<br><a
href="https://www.jianshu.com/p/aa1027f95b90">如何理解空洞卷积</a></td>
</tr>
<tr class="even">
<td style="text-align: left;">Group Convolution</td>
<td style="text-align: left;"><a
href="https://arxiv.org/pdf/1605.06489.pdf">Deep Roots:Improving CNN
Efficiency with Hierarchical Filter Groups</a></td>
<td style="text-align: left;">MobileNet, <a
href="https://arxiv.org/abs/1611.05431">ResNeXt</a></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pointwise grouped convolution</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">ShuffleNet</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Depthwise separable convolution</td>
<td style="text-align: left;"><a
href="https://arxiv.org/abs/1610.02357">Xception: Deep Learning with
Depthwise Separable Convolutions</a></td>
<td style="text-align: left;">Xception</td>
<td
style="text-align: left;">MobileNet是典型的代表，通过该卷积，大大降低了计算复杂度和模型大小。也是现在落地产品中移动端常用的操作。</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Deconvolutions</td>
<td style="text-align: left;"><a
href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and
Checkerboard Artifacts</a></td>
<td style="text-align: left;">DSSD</td>
<td
style="text-align: left;">Deconvolution也是一种常用的上采样方式，在物体分割和多尺度检测都可用到</td>
</tr>
<tr class="even">
<td style="text-align: left;">Flattened convolutions</td>
<td style="text-align: left;"><a
href="https://arxiv.org/abs/1412.5474">Flattened convolutional neural
networks for feedforward acceleration</a></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">computation costs due to the significant
reduction of learning parameters.</td>
</tr>
</tbody>
</table>
<h3 id="卷积的实现">卷积的实现</h3>
<p>计算卷积的方法有很多种，常见的有以下几种方法: *
滑窗：这种方法是最直观最简单的方法。但是，该方法不容易实现大规模加速，因此，通常情况下不采用这种方法
(但是也不是绝对不会用，在一些特定的条件下该方法反而是最高效的.) *
im2col: 目前几乎所有的主流计算框架包括[Caffe]<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>,
MXNet等都实现了该方法。该方法把整个卷积过程转化成了GEMM过程，而GEMM在各种BLAS库中都是被极致优化的，一般来说，速度较快.
* FFT:
傅里叶变换和快速傅里叶变化是在经典图像处理里面经常使用的计算方法，但是，在
ConvNet 中通常不采用，主要是因为在 ConvNet
中的卷积模板通常都比较小，例如3×3 等，这种情况下，FFT
的时间开销反而更大. * [Winograd]<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a>: Winograd
是存在已久最近被重新发现的方法，在大部分场景中，Winograd
方法都显示和较大的优势，目前cudnn中计算卷积就使用了该方法.</p>
<h3 id="计算复杂度分析">计算复杂度分析</h3>
<ul>
<li>假设输入<span class="math inline">\(I = R^{C_0H_0W_0}\)</span>,
卷积核大小为<span class="math inline">\(k\)</span>, 输出<span
class="math inline">\(O = R^{C_1H_1W_1}\)</span>，
则卷积过程的计算量为：</li>
</ul>
<p><span class="math display">\[(k^2C_0*H_1W_1)*C_1\]</span></p>
<p>使用Depthwise separable convolution卷积的计算量为:</p>
<p><span class="math display">\[(k^2*H_1W_1*C_0 +
C_0C_1*H_1W_1)\]</span></p>
<p>那么计算量之比为</p>
<p><span class="math display">\[
\frac{(k^2*H_1W_1*C_0 + C_0C_1*H_1W_1)}{(k^2C_0*H_1W_1)*C_1}
=\frac{1}{C_1} + \frac{1}{k^2} \approx \frac{1}{k^2}
\]</span></p>
<p>一般情况下，<span class="math inline">\(k^2 &lt;&lt; C_1\)</span>,
所以当<span
class="math inline">\(k=3\)</span>的时候，计算量之比约为原来的<span
class="math inline">\(\frac{1}{9}\)</span>.</p>
<ul>
<li>假设input的<span class="math inline">\(H_0 = W_0\)</span>，用<span
class="math inline">\(w\)</span>表示，<span
class="math inline">\(k\)</span>是卷积核的大小，<span
class="math inline">\(p\)</span>表示填充的大小，<span
class="math inline">\(s\)</span>表示stride步长</li>
</ul>
<p><span class="math display">\[o = \frac{w - k + 2p}{s} +
1\]</span></p>
<h2 id="normalization">Normalization</h2>
<p><img data-src="https://cwlseu.github.io/images/detection/normalization-methods.jpg"
alt="@归一化方法" /> 每个子图表示一个feature map张量，以<span
class="math inline">\(N\)</span>为批处理轴，<span
class="math inline">\(C\)</span>为通道轴，<span
class="math inline">\((H,W)\)</span>作为空间轴。其中蓝色区域内的像素使用相同的均值和方差进行归一化，并通过聚合计算获得这些像素的值。从示意图中可以看出，GN没有在N维度方向上进行拓展，因此batch
size之间是独立的，GPU并行化容易得多。</p>
<ul>
<li>batchNorm是在batch上，对NHW做归一化，对小batchsize效果不好；</li>
<li>layerNorm在通道方向上，对CHW归一化，主要对RNN作用明显；</li>
<li>instanceNorm在图像像素上，对HW做归一化，用在风格化迁移；</li>
<li>GroupNorm将channel分组，然后再做归一化；</li>
<li>SwitchableNorm是将BN、LN、IN结合，赋予权重，让网络自己去学习归一化层应该使用什么方法。</li>
</ul>
<h3 id="batch-normalization">Batch Normalization</h3>
<p>需要比较大的Batch Size，需要更强的计算硬件的支持。</p>
<blockquote>
<p>A small batch leads to inaccurate estimation of the batch statistics,
and reducing BN’s batch size increases the model error dramatically</p>
</blockquote>
<p>尤其是在某些需要高精度输入的任务中，BN有很大局限性。同时，BN的实现是在Batch
size之间进行的，需要大量的数据交换。</p>
<blockquote>
<p>batch normalization存在以下缺点：</p>
</blockquote>
<ul>
<li>对batchsize的大小比较敏感，由于每次计算均值和方差是在一个batch上，所以如果batchsize太小，则计算的均值、方差不足以代表整个数据分布；</li>
<li>BN实际使用时需要计算并且保存某一层神经网络batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其他sequence长很多，这样training时，计算很麻烦。（参考于https://blog.csdn.net/lqfarmer/article/details/71439314）</li>
</ul>
<h3 id="layer-normalizaiton">Layer Normalizaiton</h3>
<p>LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；
BN中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。</p>
<p>所以，LN不依赖于batch的大小和输入sequence的深度，因此可以用于batchsize为1和RNN中对边长的输入sequence的normalize操作。</p>
<h3 id="instance-normalization">Instance Normalization</h3>
<p>BN注重对每个batch进行归一化，保证数据分布一致，因为判别模型中结果取决于数据整体分布。</p>
<p>但是图像风格化中，生成结果主要依赖于某个图像实例，所以对整个batch归一化不适合图像风格化中，因而对HW做归一化。可以加速模型收敛，并且保持每个图像实例之间的独立。</p>
<h3 id="group-normalization">Group Normalization</h3>
<blockquote>
<p>GN does not exploit the batch dimension, and its computation is
independent of batch sizes.</p>
</blockquote>
<p><img data-src="https://cwlseu.github.io/images/detection/GN-Results.png"
alt="@BN,LN,IN,GN result comparison" />
从实验结果中可以看出在训练集合上GN的valid
error低于BN，但是测试结果上逊色一些。这个
可能是因为BN的均值和方差计算的时候，通过<em>随机批量抽样（stochastic
batch sampling）</em>引入了不确定性因素，这有助于模型参数正则化。
<strong>而这种不确定性在GN方法中是缺失的，这个将来可能通过使用不同的正则化算法进行改进。</strong></p>
<h3 id="lrnlocal-response-normalization">LRN（Local Response
Normalization）</h3>
<blockquote>
<p>动机</p>
</blockquote>
<p>在神经深武学有一个概念叫做侧抑制(lateral
inhibitio)，指的是被激活的神经元抑制相邻的神经元。
归一化的目的就是“抑制”，局部响应归一化就是借鉴侧抑制的思想来实现局部抑制，尤其是当我们使用ReLU
的时候，这种侧抑制很管用。</p>
<blockquote>
<p>好处</p>
</blockquote>
<p>有利于增加泛化能力，做了平滑处理，识别率提高1~2%</p>
<h3 id="参考文献">参考文献</h3>
<ul>
<li><a href="https://arxiv.org/abs/1502.03167v2">Batch Normalization:
Accelerating Deep Network Training by Reducing Internal Covariate
Shift</a></li>
<li><a href="https://arxiv.org/abs/1607.06450">Jimmy Lei Ba, Jamie Ryan
Kiros, Geoffrey E. Hinton. Layer normalization.</a></li>
<li><a href="https://arxiv.org/pdf/1803.08494.pdf">Group
Normalization</a></li>
<li><a
href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">AlexNet中提出的LRN</a></li>
<li><a href="https://arxiv.org/abs/1409.1556">VGG：Very Deep
Convolutional Networks for Large-Scale Image Recognition</a></li>
<li><a
href="https://blog.csdn.net/liuxiao214/article/details/81037416">BatchNormalization、LayerNormalization、InstanceNorm、GroupNorm、SwitchableNorm总结</a></li>
<li><a href="https://arxiv.org/abs/1509.09308v2">Fast Algorithms for
Convolutional Neural Networks</a></li>
</ul>
<h2 id="优化">优化</h2>
<h3 id="梯度下降法gradient-descent">梯度下降法（Gradient Descent）</h3>
<p>梯度下降法是最早最简单，也是最为常用的最优化方法。梯度下降法实现简单，当目标函数是凸函数时，梯度下降法的解是全局解。
一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，
因为该方向为当前位置的最快下降方向，所以也被称为是"最速下降法"。最速下降法越接近目标值，步长越小，前进越慢。
梯度下降法的搜索迭代示意图如下图所示：</p>
<figure>
<img data-src="http://cwlseu.github.io/images/optmethods/gd1.png"
alt="@梯度下降法的搜索迭代示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="梯度下降法的搜索迭代示意图">@梯度下降法的搜索迭代示意图</span></figcaption>
</figure>
<p>梯度下降法的缺点： * 靠近极小值时收敛速度减慢，如下图所示； *
直线搜索时可能会产生一些问题； * 可能会“之字形”地下降。</p>
<figure>
<img data-src="http://cwlseu.github.io/images/optmethods/gd2.png"
alt="@梯度下降法的之字形示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="梯度下降法的之字形示意图">@梯度下降法的之字形示意图</span></figcaption>
</figure>
<h3 id="参考文献-1">参考文献</h3>
<ul>
<li><a
href="https://www.quora.com/What-is-the-purpose-for-the-use-of-gradient-descent-in-machine-learning?__filter__=&amp;__nsrc__=2&amp;__snid3__=2889908801&amp;redirected_qid=31223828">梯度下降(gradient
descent)</a></li>
<li><a
href="http://ruder.io/optimizing-gradient-descent/">梯度下降优化算法</a></li>
<li><a
href="http://www.cnblogs.com/shixiangwan/p/7532830.html">常见的几种最优化方法</a></li>
</ul>
<h2 id="其他参考文献">其他参考文献</h2>
<h3 id="深度学习教程">深度学习教程</h3>
<p><a href="https://cs231n.github.io/">CS231n: Convolutional Neural
Networks for Visual Recognition.</a></p>
<h3 id="计算平台">计算平台</h3>
<ol type="1">
<li><a
href="https://en.wikipedia.org/wiki/ARM_architecture">arm平台</a></li>
<li><a
href="https://www.acmesystems.it/arm9_toolchain">linux上编译arm交叉编译链</a></li>
<li><a
href="http://preshing.com/20141119/how-to-build-a-gcc-cross-compiler/">How
to Build a GCC Cross-Compiler</a></li>
</ol>
<h2 id="常用数据集合">常用数据集合</h2>
<p>https://www.analyticsvidhya.com/blog/2018/03/comprehensive-collection-deep-learning-datasets/
这里我们列出了一组高质量的数据集，研究这些数据集将使你成为一个更好的数据科学家。
我们可以使用这些数据集来学习各种深度学习技术，也可以使用它们来磨练您的技能，理解如何识别和构造每个问题，考虑独特的应用场景!</p>
<h3 id="图像类">图像类</h3>
<table>
<colgroup>
<col style="width: 22%" />
<col style="width: 13%" />
<col style="width: 42%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: center;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
<td style="text-align: left;">50MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1710.09829.pdf">Dynamic Routing Between
Capsules</a></td>
<td
style="text-align: center;">手写数字识别，包含60000个训练数据及10000个测试数据，可分为10类</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://cocodataset.org/#home">MSCOCO</a></td>
<td style="text-align: left;">~25G</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1703.06870.pdf">Mask RCNN</a></td>
<td style="text-align: center;">COCO is a large-scale and rich for
object detection, segmentation and captioning dataset. 330K images, 1.5
million object instances, 80 object categories, 5 captions per image,
250,000 people with key points</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://www.image-net.org/">ImageNet</a></td>
<td style="text-align: left;">150GB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1611.05431.pdf">ResNeXt</a></td>
<td style="text-align: center;">ImageNet is a dataset of images that are
organized according to the WordNet hierarchy. WordNet contains
approximately 100,000 phrases and ImageNet has provided around 1000
images on average to illustrate each phrase. Number of Records: Total
number of images: ~1,500,000; each with multiple bounding boxes and
respective class labels</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://github.com/openimages/dataset#download-the-data">Open
Image Dataset</a></td>
<td style="text-align: left;">500GB</td>
<td style="text-align: center;"><a href="">ResNet</a></td>
<td style="text-align: center;">一个包含近900万个图像URL的数据集。
这些图像拥有数千个类别及边框进行了注释。
该数据集包含9,011219张图像的训练集，41,260张图像的验证集以及125,436张图像的测试集。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://www.visualqa.org/">VisualQA</a></td>
<td style="text-align: left;">25GB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1708.02711">Tips and Tricks for Visual
Question Answering: Learnings from the 2017 Challenge</a></td>
<td style="text-align: center;">图像的问答系统数据集 265,016 images, at
least 3 questions per image, 10 ground truth answers per question</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://ufldl.stanford.edu/housenumbers/">The Street View House
Numbers(SVHN)</a></td>
<td style="text-align: left;">2.5GB</td>
<td style="text-align: center;"><a href="">Distributional Smoothing With
Virtual Adversarial Training</a></td>
<td
style="text-align: center;">门牌号数据集，可用来做物体检测与识别</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
<td style="text-align: left;">170MB</td>
<td style="text-align: center;"><a
href="https://openreview.net/pdf?id=S1NHaMW0b">ShakeDrop
regularization</a></td>
<td style="text-align: center;">图像识别数据集，包含
50000张训练数据，10000张测试数据，可分为10类</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a></td>
<td style="text-align: left;">30MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1708.04896">Random Erasing Data
Augmentation</a></td>
<td
style="text-align: center;">包含60000训练样本和10000测试样本的用于服饰识别的数据集，可分为10类。</td>
</tr>
</tbody>
</table>
<h3 id="自然语言处理类">自然语言处理类</h3>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 13%" />
<col style="width: 43%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: left;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
href="http://ai.stanford.edu/~amaas/data/sentiment/">IMDB
影评数据</a></td>
<td style="text-align: left;">80MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1705.09207">Learning Structured Text
Representations</a></td>
<td
style="text-align: left;">可以实现对情感的分类，除了训练集和测试集示例之外，还有更多未标记的数据。原始文本和预处理的数据也包括在内。25,000
highly polar movie reviews for training, and 25,000 for testing</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups">Twenty
Newsgroups</a></td>
<td style="text-align: left;">20MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1606.01781">Very Deep Convolutional Networks
for Text Classification</a></td>
<td
style="text-align: left;">包含20类新闻的文章信息，内类包含1000条数据</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://help.sentiment140.com/for-students/">Sentiment140</a></td>
<td style="text-align: left;">80MB</td>
<td style="text-align: center;"><a
href="http://www.aclweb.org/anthology/W17-5202">Assessing
State-of-the-Art Sentiment Models on State-of-the-Art Sentiment
Datasets</a></td>
<td style="text-align: left;">1,60,000 tweets,用于情感分析的数据集</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://wordnet.princeton.edu/">WordNet</a></td>
<td style="text-align: left;">10MB</td>
<td style="text-align: center;"><a
href="https://aclanthology.info/pdf/R/R11/R11-1097.pdf">Wordnets: State
of the Art and Perspectives</a></td>
<td style="text-align: left;">117,000 synsets is linked to other synsets
by means of a small number of “conceptual relations.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="https://www.yelp.com/dataset">Yelp点评数据集</a></td>
<td style="text-align: left;">2.66GB JSON文件,2.9GB
SQL文件,7.5GB图片数据</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1710.00519.pdf">Attentive
Convolution</a></td>
<td
style="text-align: left;">包括470万条用户评价，15多万条商户信息，20万张图片，12个大都市。此外，还涵盖110万用户的100万条tips，超过120万条商家属性（如营业时间、是否有停车场、是否可预订和环境等信息），随着时间推移在每家商户签到的总用户数。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://nlp.cs.nyu.edu/wikipedia-data/">维基百科语料库（英语）</a></td>
<td style="text-align: left;">20MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1711.03953.pdf">Breaking The Softmax
Bottelneck: A High-Rank RNN language Model</a></td>
<td style="text-align: left;">包含4400000篇文章
及19亿单词，可用来做语言建模</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm">博客作者身份语料库</a></td>
<td style="text-align: left;">300MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1609.06686.pdf">Character-level and
Multi-channel Convolutional Neural Networks for Large-scale Authorship
Attribution</a></td>
<td
style="text-align: left;">从blogger.com收集到的19,320名博主的博客，其中博主的信息包括博主的ID、性别、年龄、行业及星座</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://statmt.org/wmt18/index.html">各种语言的机器翻译数据集</a></td>
<td style="text-align: left;">15GB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1706.03762">Attention Is All You
Need</a></td>
<td style="text-align: left;">包含英-汉、英-法、英-捷克、英语-
爱沙尼亚、英 - 芬兰、英-德、英 - 哈萨克、英 - 俄、英 -
土耳其之间互译的数据集</td>
</tr>
</tbody>
</table>
<h3 id="语音类">语音类</h3>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 13%" />
<col style="width: 43%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: left;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
href="https://github.com/Jakobovski/free-spoken-digit-dataset">Free
Spoken Digit Dataset</a></td>
<td style="text-align: left;">10MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1712.00866">Raw Waveform-based Audio
Classification Using Sample-level CNN Architectures</a></td>
<td
style="text-align: left;">数字语音识别数据集，包含3个人的声音，每个数字说50遍，共1500条数据</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://github.com/mdeff/fma">Free Music Archive (FMA)</a></td>
<td style="text-align: left;">1000GB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1803.05337.pdf">Learning to Recognize
Musical Genre from Audio</a></td>
<td
style="text-align: left;">可以用于对音乐进行分析的数据集，数据集中包含歌曲名称、音乐类型、曲目计数等信息。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://mtg.upf.edu/ismir2004/contest/tempoContest/node5.html">Ballroom</a></td>
<td style="text-align: left;">14GB</td>
<td style="text-align: center;"><a href="">A Multi-Model Approach To
Beat Tracking Considering Heterogeneous Music Styles</a></td>
<td
style="text-align: left;">舞厅舞曲数据集，可对舞曲风格进行识别。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://labrosa.ee.columbia.edu/millionsong/">Million Song
Dataset</a></td>
<td style="text-align: left;">280GB</td>
<td style="text-align: center;"><a href="">Preliminary Study on a
Recommender System for the Million Songs Dataset Challenge</a></td>
<td style="text-align: left;">Echo
Nest提供的一百万首歌曲的特征数据.该数据集不包含任何音频，但是可以使用他们提供的代码下载音频</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="ttp://www.openslr.org/12/">LibriSpeech</a></td>
<td style="text-align: left;">60GB</td>
<td style="text-align: center;"><a href="">Letter-Based Speech
Recognition with Gated ConvNets</a></td>
<td
style="text-align: left;">包含1000小时采样频率为16Hz的英语语音数据及所对应的文本，可用作语音识别</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/">VoxCeleb</a></td>
<td style="text-align: left;">150MB</td>
<td style="text-align: center;">VoxCeleb: a large-scale speaker
identification dataset]()</td>
<td style="text-align: left;">大型的说话人识别数据集。
它包含约1,200名来自YouTube视频的约10万个话语。
数据在性别是平衡的（男性占55％）。说话人跨越不同的口音，职业和年龄。
可用来对说话者的身份进行识别。</td>
</tr>
</tbody>
</table>
<h3 id="analytics-vidhya实践问题">Analytics Vidhya实践问题</h3>
<ul>
<li><a
href="https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/register">Twitter情绪分析</a>
<ul>
<li>描述：识别是否包含种族歧视及性别歧视的推文。</li>
<li>大小：3MB</li>
<li>31,962 tweets</li>
</ul></li>
<li><a
href="https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/">印度演员的年龄识别数据集</a>
<ul>
<li>描述：根据人的面部属性，识别人的年龄的数据集。</li>
<li>大小：48MB</li>
<li>19,906 images in the training set and 6636 in the test set</li>
</ul></li>
<li><a
href="https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/">城市声音分类数据集</a>
<ul>
<li>描述：该数据集包含来自10个类的城市声音的8732个标记的声音片段，每个片段时间小于4秒。</li>
<li>大小：训练数据集3GB，训练数据集2GB。</li>
<li>8732 labeled sound excerpts (&lt;=4s) of urban sounds from 10
classes</li>
</ul></li>
</ul>
<h3 id="more-dataset">more dataset</h3>
<ul>
<li><a
href="https://www.jiqizhixin.com/articles/2018-09-05-2">机器之心整理的数据集合</a></li>
<li><a
href="https://github.com/Prasanna1991/DHCD_Dataset">DHCD_Dataset</a></li>
</ul>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://github.com/BVLC/caffe/blob/master/src/caffe/util/im2col.cpp<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>https://arxiv.org/abs/1509.09308v2<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ Object Model</title>
    <url>/202208/20200407-cpp-object-model/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>面向对象的三大特征是抽象、继承、多态。《深度探索C++对象模型》一书中从数据的排布，C++对象函数的调用设计等等。
我尝试以一个编译器的设计者的角度去理解C++对象，该书中也提到了多种编译器，有的时候也会涉及一些不同编译器厂商在设计过程中的不同，虽然没有深入探究不同的原因以及优劣对比，
但对于我这个新手来说已经开了很大的窗户。</p>
<p>整个书籍通过横向切割方式，分别从构造、数据成员、成员函数、运行时C++对象的特点来介绍，从缔造者的视角来理解C++对象的设计，有利于我们写出更加高效、简洁的程序。</p>
<h2 id="关于对象">关于对象</h2>
<h3 id="c对象比c-struct对象在空间与时间的有额外负担吗">C++对象比C
struct对象在空间与时间的有额外负担吗？</h3>
<p>封装的后布局成本与C struct是一样的。member
functions虽然旱灾class的声明之内，却不出现在的object中。每一个non-inline
memberfunction 只会诞生一个函数实例。
C++在布局以及存取时间上的主要的额外负担是由virtual引起的，包括： *
virtual function机制，引入vptr以及vtbl，支持一个有效率的"执行期绑定" *
virtual base class，用以实现"多次出现在继承体系中的base
class，有一个单一而被共享的实例" *
多重继承下，派生类跟第二个以及后续基类之间的转换</p>
<h3 id="c对象模型">C++对象模型</h3>
<p>在C++中，有两种数据成员（class data members）：static
和nonstatic,以及三种类成员函数（class member
functions）:static、nonstatic和virtual: <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Base</span>(<span class="type">int</span> i) :<span class="built_in">baseI</span>(i)&#123;&#125;;    </span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">getI</span><span class="params">()</span></span>&#123; <span class="keyword">return</span> baseI; &#125; </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">countI</span><span class="params">()</span></span>&#123;&#125;;   <span class="comment">//static</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">print</span><span class="params">(<span class="type">void</span>)</span></span>&#123; cout &lt;&lt; <span class="string">&quot;Base::print()&quot;</span>; &#125; <span class="comment">// virtual</span></span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">Base</span>()&#123;&#125;         <span class="comment">// virtual</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> baseI;  <span class="comment">// no static </span></span><br><span class="line">    <span class="type">static</span> <span class="type">int</span> baseS;  <span class="comment">// static</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>在此模型下，nonstatic
数据成员被置于每一个类对象中，而static数据成员被置于类对象之外。static与nonstatic函数也都放在类对象之外，而对于virtual
函数，则通过虚函数表+虚指针来支持，具体如下： -
每个类生成一个表格，称为虚表（virtual
table，简称vtbl）。虚表中存放着一堆指针，这些指针指向该类每一个虚函数。虚表中的函数地址将按声明时的顺序排列，不过当子类有多个重载函数时例外，后面会讨论。
-
每个类对象都拥有一个虚表指针(vptr)，由编译器为其生成。虚表指针的设定与重置皆由类的复制控制（也即是构造函数、析构函数、赋值操作符）来完成。vptr的位置为编译器决定，传统上它被放在所有显示声明的成员之后，不过现在许多编译器把vptr放在一个类对象的最前端。关于数据成员布局的内容，在后面会详细分析。
- 另外，虚函数表的前面设置了一个指向type_info的指针，用以支持RTTI（Run
Time Type
Identification，运行时类型识别）。RTTI是为多态而生成的信息，包括对象继承关系，对象本身的描述等，只有具有虚函数的对象在会生成。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/gcc/cppobjmodel_1.png"
alt="@vs2015下对象的内存结构" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="vs2015下对象的内存结构">@vs2015下对象的内存结构</span></figcaption>
</figure>
<p>这个模型的优点在于它的空间和存取时间的效率；缺点如下：如果应用程序本身未改变，但当所使用的类的non
static数据成员添加删除或修改时，需要重新编译。</p>
<blockquote>
<p>Note:
针对析构函数，g++中的实现有一些令人疑惑的地方，~Base在虚表中出现了两次，我表示不能理解，网上也没有找到相关说明。</p>
<p>Vtable for Base Base::_ZTV4Base: 6u entries 0 (int (<em>)(...))0 4
(int (</em>)(...))(&amp; _ZTI4Base) 8 (int (<em>)(...))Base::print 12
(int (</em>)(...))Base::~Base 16 (int (*)(...))Base::~Base</p>
</blockquote>
<p>我猜测可能是我们使用g++编译中合成根据我添加的~Base()合成了一个用于动态内存分配释放的析构函数和静态释放的析构函数。当然如果有大佬知道这个是为什么，请务必指导一番，不胜感激。</p>
<h3 id="多重继承">多重继承</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base1</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">virtual</span> ~<span class="built_in">Base1</span>() &#123;&#125;;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">speakClearly</span><span class="params">()</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Base1::speakClearly()&quot;</span>&lt;&lt;endl;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> Base1 *<span class="title">clone</span><span class="params">()</span> <span class="type">const</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Base1::clone()&quot;</span>&lt;&lt;endl; <span class="keyword">return</span> <span class="keyword">new</span> Base1;&#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">	<span class="type">float</span> data_Base1;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base2</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">virtual</span> ~<span class="built_in">Base2</span>() &#123;&#125;;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">mumble</span><span class="params">()</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Base2::mumble()&quot;</span>&lt;&lt;endl;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> Base2 *<span class="title">clone</span><span class="params">()</span> <span class="type">const</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Base2::clone()&quot;</span>&lt;&lt;endl; <span class="keyword">return</span> <span class="keyword">new</span> Base2;&#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">	<span class="type">float</span> data_Base2;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="keyword">public</span> Base1,<span class="keyword">public</span> Base2</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">virtual</span> ~<span class="built_in">Derived</span>()  &#123;cout&lt;&lt;<span class="string">&quot;Derived::~Derived()&quot;</span>&lt;&lt;endl;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> Derived *<span class="title">clone</span><span class="params">()</span> <span class="type">const</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Derived::clone()&quot;</span>&lt;&lt;endl; <span class="keyword">return</span> <span class="keyword">new</span> Derived;&#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">	<span class="type">float</span> data_Derived;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img data-src="https://cwlseu.github.io/images/gcc/multi-inherited.png"
alt="@逻辑上的图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="逻辑上的图">@逻辑上的图</span></figcaption>
</figure>
<p>类似问题在vs2010中也有，<a
href="https://blog.csdn.net/Microsues/article/details/6452249?depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-1&amp;utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-1">主要是多重继承的时，将派生类赋值给第二个基类时</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1&gt;  Derived::$vftable@Base1@:</span><br><span class="line">1&gt;   | &amp;Derived_meta</span><br><span class="line">1&gt;   |  0</span><br><span class="line">1&gt;   0 | &amp;Derived::&#123;dtor&#125;</span><br><span class="line">1&gt;   1 | &amp;Base1::speakClearly</span><br><span class="line">1&gt;   2 | &amp;Derived::clone</span><br><span class="line">1&gt;  </span><br><span class="line">1&gt;  Derived::$vftable@Base2@:</span><br><span class="line">1&gt;   | -8</span><br><span class="line">1&gt;   0 | &amp;thunk: this-=8; goto Derived::&#123;dtor&#125;</span><br><span class="line">1&gt;   1 | &amp;Base2::mumble</span><br><span class="line">1&gt;   2 | &amp;thunk: this-=8; goto Base2* Derived::clone</span><br><span class="line">1&gt;   3 | &amp;thunk: this-=8; goto Derived* Derived::clone</span><br></pre></td></tr></table></figure>
<ul>
<li><p>派生类的虚函数表数目是它所有基类的虚函数数目之和，基类的虚函数表被复制到派生类的对应的虚函数表中。</p></li>
<li><p>派生类中重写基类的虚拟函数时，该被重写的函数在派生类的虚函数列表中得到更新，派生类的虚析构函数覆盖基类的虚析构函数。</p></li>
<li><p>派生类中新增加的虚函数被添加到与第一个基类相对应的虚函数表中。</p></li>
<li><p>virtual
table[1]中的clone分别为：<code>Base2* Derived::clone</code> 和 Derived*
Derived::clone
。这里为什么会比table[0]多一个<code>Base2* Derived::clone</code>呢？
因为：如果将一个Derived对象地址指定给一个Base1指针或者Derived指针是，虚拟机制使用的是virtual
table[0]
；如果将一个Derived对象地址指定给一个Base2指针时，虚拟机制使用的是virtual
table[1]。 （&lt;&lt;C++对象模型&gt;&gt; P164)</p></li>
</ul>
<!-- 1. "指针的类型"会教导编译器如何解释某个特定地址中的内存内容以及其大小（void*指针只能够持有一个地址，而不能通过它操作所指向的object）
2. C++通过class的pointers和references来支持多态，付出的代价就是额外的间接性。它们之所以支持多态是因为它们并不引发内存中任何"与类型有关的内存委托操作(type-dependent commitment)"，会受到改变的，只有他们所指向的内存的"大小和内容的解释方式"而已。
 -->
<h2 id="构造函数">构造函数</h2>
<p><img data-src="https://cwlseu.github.io/images/gcc/ctor.png" /></p>
<h2 id="参考链接">参考链接</h2>
<p><a
href="https://docs.microsoft.com/zh-cn/archive/blogs/zhanli/c-tips-adjustor-thunk-what-is-it-why-and-how-it-works">MSVC应对多重继承中的thunk技术</a>
<a
href="https://www.cnblogs.com/tgycoder/p/5426628.html">C++对象模型详解</a>
<a
href="https://www.cnblogs.com/QG-whz/p/4909359.html">图说C++对象模型：对象内存布局详解</a>
<a
href="https://blog.csdn.net/heyuhang112/article/details/41982929">RTTI实现详解</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Inference Framework based TensorRT</title>
    <url>/201911/20191120-TensorRT/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>视觉算法经过几年高速发展，大量的算法被提出。为了能真正将算法在实际应用场景中更好地应用，高性能的
inference框架层出不穷。从手机端上的ncnn到tf-lite，NVIDIA在cudnn之后，推出专用于神经网络推理的TensorRT.
经过几轮迭代，支持的操作逐渐丰富，补充的插件已经基本满足落地的需求。笔者觉得，尤其是tensorrt
5.0之后，无论是接口还是使用samples都变得非常方便集成。</p>
<h2 id="版本选型与基本概念">版本选型与基本概念</h2>
<h3 id="fp16-int8">FP16 INT8</h3>
<p>The easiest way to benefit from mixed precision in your application
is to take advantage of the support for FP16 and INT8 computation in
NVIDIA GPU libraries. Key libraries from the NVIDIA SDK now support a
variety of precisions for both computation and storage.</p>
<p>Table shows the current support for FP16 and INT8 in key CUDA
libraries as well as in PTX assembly and CUDA C/C++ intrinsics.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Feature</th>
<th style="text-align: center;">FP16x2</th>
<th style="text-align: center;">INT8/16 DP4A/DP2A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PTX instructions</td>
<td style="text-align: center;">CUDA 7.5</td>
<td style="text-align: center;">CUDA 8</td>
</tr>
<tr class="even">
<td style="text-align: center;">CUDA C/C++ intrinsics</td>
<td style="text-align: center;">CUDA 7.5</td>
<td style="text-align: center;">CUDA 8</td>
</tr>
<tr class="odd">
<td style="text-align: center;">cuBLAS GEMM</td>
<td style="text-align: center;">CUDA 7.5</td>
<td style="text-align: center;">CUDA 8</td>
</tr>
<tr class="even">
<td style="text-align: center;">cuFFT</td>
<td style="text-align: center;">CUDA 7.5</td>
<td style="text-align: center;">I/O via cuFFT callbacks</td>
</tr>
<tr class="odd">
<td style="text-align: center;">cuDNN</td>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">TensorRT</td>
<td style="text-align: center;">v1</td>
<td style="text-align: center;">v2 Tech Preview</td>
</tr>
</tbody>
</table>
<h3 id="ptx">PTX</h3>
<p>PTX(parallel-thread-execution，并行线程执行)
预编译后GPU代码的一种形式，开发者可以通过编译选项
“-keep”选择输出PTX代码，当然开发人员也可以直接编写PTX级代码。另外，PTX是独立于GPU架构的，因此可以重用相同的代码适用于不同的GPU架构。
具体可参考CUDA-PDF之<a
href="https://docs.nvidia.com/cuda/parallel-thread-execution/">《PTX ISA
reference document》</a></p>
<p>建议我们的CUDA 版本为CUDA 8.0以上,
显卡至少为<code>GeForce 1060</code>,
如果想支持Int8/DP4A等feature，还是需要<code>RTX 1080</code>或者<code>P40</code>。</p>
<h2 id="tensorrt特性助力高性能算法">TensorRT特性助力高性能算法</h2>
<h3 id="优化原理">优化原理</h3>
<figure>
<img data-src="https://img-blog.csdnimg.cn/20190907135522420.png"
alt="@优化原理" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="优化原理">@优化原理</span></figcaption>
</figure>
<h3 id="网络模型的裁剪与重构">网络模型的裁剪与重构</h3>
<figure>
<img data-src="https://miro.medium.com/max/965/1*PyNcjHKZ8rQ48QCPsdQ9wA.png"
alt="@原始网络" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="原始网络">@原始网络</span></figcaption>
</figure>
<p><img data-src="https://miro.medium.com/max/951/1*bJts223Qo55toZ9AY60Ruw.png" alt="@vertical fusion｜" style="zoom:67%;" /></p>
<p>The above figures explain the vertical fusion optimization that TRT
does. The Convolution (C), Bias(B) and Activation(R, ReLU in this case)
are all collapsed into one single node (implementation wise this would
mean a single CUDA kernel launch for C, B and R).</p>
<p><img data-src="https://miro.medium.com/max/2000/0*UKwCx_lq-oHcLYkI.png" alt="@horizontal fusion｜" style="zoom:67%;" /></p>
<p>There is also a horizontal fusion where if multiple nodes with same
operation are feeding to multiple nodes then it is converted to one
single node feeding multiple nodes. The three 1x1 CBRs are fused to one
and their output is directed to appropriate nodes. Other optimizations
Apart from the graph optimizations, TRT, through experiments and based
on parameters like batch size, convolution kernel(filter) sizes, chooses
efficient algorithms and kernels(CUDA kernels) for operations in
network.</p>
<h3 id="低精度计算的支持">低精度计算的支持</h3>
<ul>
<li>FP16 &amp; Int8指令的支持</li>
<li>DP4A(Dot Product of 4 8-bits Accumulated to a 32-bit)</li>
</ul>
<p>TensorRT 进行优化的方式是 DP4A (Dot Product of 4 8-bits Accumulated
to a 32-bit)，如下图：</p>
<p><img data-src="https://arleyzhang.github.io/images/TensorRT-5-int8-calibration.assets/DP4A.png"
alt="@DP4A原理过程" /> 这是PASCAL
系列GPU的硬件指令，INT8卷积就是使用这种方式进行的卷积计算。更多关于DP4A的信息可以参考<a
href="https://devblogs.nvidia.com/mixed-precision-programming-cuda-8/">Mixed-Precision
Programming with CUDA 8</a></p>
<p>INT8 vector dot products (DP4A) improve the efficiency of radio
astronomy cross-correlation by a large factor compared to FP32
computation.</p>
<figure>
<img data-src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/10/cross-correlation-efficiency-p40-624x453.png"
alt="@INT8 vector dot products (DP4A) improve the efficiency of radio astronomy cross-correlation by a large factor compared to FP32 computation" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="INT8">@INT8</span> vector dot products (DP4A) improve the
efficiency of radio astronomy cross-correlation by a large factor
compared to FP32 computation</figcaption>
</figure>
<h3 id="硬件方面tensor-core的支持优化卷积运算">硬件方面Tensor
Core的支持，优化卷积运算</h3>
<p>这个需要硬件的支持，如果没有类似Volta架构的GPU就不要强求。</p>
<h2 id="framework-todo-schedule">Framework TODO SCHEDULE</h2>
<ul>
<li><strong>model load sample</strong>
模型初始化当前包括通过parser初始化和通过模型流初始化的方式。通过parser初始化过程相比较来说比较慢，因为包含parser过程
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
caffe model</li>
<li><input type="checkbox" disabled="" checked="" />
gie model</li>
</ul></li>
<li>plugin &amp; extend layers
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
设计plugin的管理机制,更新初始化流程</li>
<li><input type="checkbox" disabled="" />
<a href="https://github.com/hszhao/PSPNet">interp</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a
href="https://github.com/rbgirshick/caffe-fast-rcnn/tree/0dcd397b29507b8314e252e850518c5695efbb83">ROIPooling</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="">RPNProposal</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="">PriorBox</a></li>
<li><input type="checkbox" disabled="" />
<a href="">ChannelShuffle</a></li>
<li><input type="checkbox" disabled="" />
<a href="">CTC</a></li>
<li><input type="checkbox" disabled="" />
<a href="">SLLSTM</a></li>
</ul></li>
<li>int8 quantity inference
<ul class="task-list">
<li><input type="checkbox" disabled="" />
矫正算法的设计</li>
<li><input type="checkbox" disabled="" />
量化数据集合的管理，这个可以和NNIE的量化数据统一起来管理</li>
<li><input type="checkbox" disabled="" />
与研究侧共同确定各个层量化的范围</li>
<li><input type="checkbox" disabled="" />
最后更新inference模式</li>
</ul></li>
</ul>
<h2 id="document-for-reference">Document for Reference</h2>
<ul>
<li><a href="http://nvdla.org/">NVDLA官网</a></li>
<li><a
href="https://devblogs.nvidia.com/production-deep-learning-nvidia-gpu-inference-engine/">NVIDIA
blog: Production Deep Learning with NVIDIA GPU Inference Engine</a></li>
<li><a
href="https://developer.download.nvidia.cn/compute/machine-learning/tensorrt/docs/5.1/rc/TensorRT-Support-Matrix-Guide.pdf">TensorRT
5.1的技术参数文档</a></li>
<li><a
href="http://nvdla.org/sw/runtime_environment.html">nvdla-sw-Runtime
environment</a></li>
<li><a
href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">Szymon
Migacz, NVIDIA: 8-bit Inference with TensorRT</a></li>
<li><a
href="https://arleyzhang.github.io/articles/923e2c40/">INT8量化校准原理</a></li>
<li><a
href="https://devblogs.nvidia.com/mixed-precision-programming-cuda-8/">Mixed-Precision
Programming with CUDA 8</a></li>
<li><a
href="https://medium.com/tensorflow/high-performance-inference-with-tensorrt-integration-c4d78795fbfe">Tensorflow使用TensorRT高速推理</a></li>
<li><a
href="https://on-demand.gputechconf.com/gtc/2019/video/_/S9431/">Tensorflow使用TensorRT高速推理视频</a></li>
</ul>
<h2 id="附录">附录</h2>
<h3 id="init.caffemodel">Init.CaffeModel</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[I] Output &quot;prob&quot;: 1000x1x1</span><br><span class="line">[I] [TRT] Applying generic optimizations to the graph for inference.</span><br><span class="line">[I] [TRT] Original: 141 layers</span><br><span class="line">[I] [TRT] After dead-layer removal: 141 layers</span><br><span class="line">[I] [TRT] After scale fusion: 141 layers</span><br><span class="line">[I] [TRT] Fusing conv1/7x7_s2 with conv1/relu_7x7</span><br><span class="line">[I] [TRT] Fusing conv2/3x3_reduce with conv2/relu_3x3_reduce</span><br><span class="line">。。。</span><br><span class="line">[I] [TRT] Fusing inception_5b/pool_proj with inception_5b/relu_pool_proj</span><br><span class="line">[I] [TRT] After vertical fusions: 84 layers</span><br><span class="line">[I] [TRT] After swap: 84 layers</span><br><span class="line">[I] [TRT] After final dead-layer removal: 84 layers</span><br><span class="line">[I] [TRT] Merging layers: inception_3a/1x1 + inception_3a/relu_1x1 || inception_3a/3x3_reduce + inception_3a/relu_3x3_reduce || inception_3a/5x5_reduce + inception_3a/relu_5x5_reduce</span><br><span class="line">[I] [TRT] Merging layers: inception_3b/1x1 + inception_3b/relu_1x1 || inception_3b/3x3_reduce + inception_3b/relu_3x3_reduce || inception_3b/5x5_reduce + inception_3b/relu_5x5_reduce</span><br><span class="line">。。。</span><br><span class="line">[I] [TRT] Merging layers: inception_5b/1x1 + inception_5b/relu_1x1 || inception_5b/3x3_reduce + inception_5b/relu_3x3_reduce || inception_5b/5x5_reduce + inception_5b/relu_5x5_reduce</span><br><span class="line">[I] [TRT] After tensor merging: 66 layers</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_3a/output</span><br><span class="line">[I] [TRT] Generating copy for inception_3a/1x1 + inception_3a/relu_1x1 || inception_3a/3x3_reduce + inception_3a/relu_3x3_reduce || inception_3a/5x5_reduce + inception_3a/relu_5x5_reduce to inception_3a/output</span><br><span class="line">[I] [TRT] Retargeting inception_3a/3x3 to inception_3a/output</span><br><span class="line">[I] [TRT] Retargeting inception_3a/5x5 to inception_3a/output</span><br><span class="line">[I] [TRT] Retargeting inception_3a/pool_proj to inception_3a/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_3b/output</span><br><span class="line">[I] [TRT] Generating copy for inception_3b/1x1 + inception_3b/relu_1x1 || inception_3b/3x3_reduce + inception_3b/relu_3x3_reduce || inception_3b/5x5_reduce + inception_3b/relu_5x5_reduce to inception_3b/output</span><br><span class="line">[I] [TRT] Retargeting inception_3b/3x3 to inception_3b/output</span><br><span class="line">[I] [TRT] Retargeting inception_3b/5x5 to inception_3b/output</span><br><span class="line">[I] [TRT] Retargeting inception_3b/pool_proj to inception_3b/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4a/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4a/1x1 + inception_4a/relu_1x1 || inception_4a/3x3_reduce + inception_4a/relu_3x3_reduce || inception_4a/5x5_reduce + inception_4a/relu_5x5_reduce to inception_4a/output</span><br><span class="line">[I] [TRT] Retargeting inception_4a/3x3 to inception_4a/output</span><br><span class="line">[I] [TRT] Retargeting inception_4a/5x5 to inception_4a/output</span><br><span class="line">[I] [TRT] Retargeting inception_4a/pool_proj to inception_4a/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4b/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4b/1x1 + inception_4b/relu_1x1 || inception_4b/3x3_reduce + inception_4b/relu_3x3_reduce || inception_4b/5x5_reduce + inception_4b/relu_5x5_reduce to inception_4b/output</span><br><span class="line">[I] [TRT] Retargeting inception_4b/3x3 to inception_4b/output</span><br><span class="line">[I] [TRT] Retargeting inception_4b/5x5 to inception_4b/output</span><br><span class="line">[I] [TRT] Retargeting inception_4b/pool_proj to inception_4b/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4c/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4c/1x1 + inception_4c/relu_1x1 || inception_4c/3x3_reduce + inception_4c/relu_3x3_reduce || inception_4c/5x5_reduce + inception_4c/relu_5x5_reduce to inception_4c/output</span><br><span class="line">[I] [TRT] Retargeting inception_4c/3x3 to inception_4c/output</span><br><span class="line">[I] [TRT] Retargeting inception_4c/5x5 to inception_4c/output</span><br><span class="line">[I] [TRT] Retargeting inception_4c/pool_proj to inception_4c/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4d/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4d/1x1 + inception_4d/relu_1x1 || inception_4d/3x3_reduce + inception_4d/relu_3x3_reduce || inception_4d/5x5_reduce + inception_4d/relu_5x5_reduce to inception_4d/output</span><br><span class="line">[I] [TRT] Retargeting inception_4d/3x3 to inception_4d/output</span><br><span class="line">[I] [TRT] Retargeting inception_4d/5x5 to inception_4d/output</span><br><span class="line">[I] [TRT] Retargeting inception_4d/pool_proj to inception_4d/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4e/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4e/1x1 + inception_4e/relu_1x1 || inception_4e/3x3_reduce + inception_4e/relu_3x3_reduce || inception_4e/5x5_reduce + inception_4e/relu_5x5_reduce to inception_4e/output</span><br><span class="line">[I] [TRT] Retargeting inception_4e/3x3 to inception_4e/output</span><br><span class="line">[I] [TRT] Retargeting inception_4e/5x5 to inception_4e/output</span><br><span class="line">[I] [TRT] Retargeting inception_4e/pool_proj to inception_4e/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_5a/output</span><br><span class="line">[I] [TRT] Generating copy for inception_5a/1x1 + inception_5a/relu_1x1 || inception_5a/3x3_reduce + inception_5a/relu_3x3_reduce || inception_5a/5x5_reduce + inception_5a/relu_5x5_reduce to inception_5a/output</span><br><span class="line">[I] [TRT] Retargeting inception_5a/3x3 to inception_5a/output</span><br><span class="line">[I] [TRT] Retargeting inception_5a/5x5 to inception_5a/output</span><br><span class="line">[I] [TRT] Retargeting inception_5a/pool_proj to inception_5a/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_5b/output</span><br><span class="line">[I] [TRT] Generating copy for inception_5b/1x1 + inception_5b/relu_1x1 || inception_5b/3x3_reduce + inception_5b/relu_3x3_reduce || inception_5b/5x5_reduce + inception_5b/relu_5x5_reduce to inception_5b/output</span><br><span class="line">[I] [TRT] Retargeting inception_5b/3x3 to inception_5b/output</span><br><span class="line">[I] [TRT] Retargeting inception_5b/5x5 to inception_5b/output</span><br><span class="line">[I] [TRT] Retargeting inception_5b/pool_proj to inception_5b/output</span><br><span class="line">[I] [TRT] After concat removal: 66 layers</span><br><span class="line">[I] [TRT] Graph construction and optimization completed in 0.00874238 seconds.</span><br><span class="line">[I] [TRT] </span><br><span class="line">[I] [TRT] --------------- Timing conv1/7x7_s2 + conv1/relu_7x7(3)</span><br><span class="line">[I] [TRT] Tactic 0 time 0.370688</span><br><span class="line">[I] [TRT] </span><br><span class="line">[I] [TRT] --------------- Timing conv1/7x7_s2 + conv1/relu_7x7(14)</span><br><span class="line">[I] [TRT] Tactic 3146172331490511787 time 0.694752</span><br><span class="line">[I] [TRT] Tactic 3528302785056538033 time 0.429056</span><br><span class="line">[I] [TRT] Tactic -6618588952828687390 time 0.419296</span><br><span class="line">[I] [TRT] Tactic -6362554771847758902 time 0.371168</span><br><span class="line">[I] [TRT] Tactic -2701242286872672544 time 0.685056</span><br><span class="line">[I] [TRT] Tactic -675401754313066228 time 0.365568</span><br><span class="line">[I] [TRT] </span><br><span class="line">。。。</span><br><span class="line">[I] [TRT] Tactic 5 time 0.032192</span><br><span class="line">[I] [TRT] </span><br><span class="line">[I] [TRT] --------------- Timing loss3/classifier(15)</span><br><span class="line">[I] [TRT] Tactic 2624962759642542471 time 0.07424</span><br><span class="line">[I] [TRT] Tactic 6241535668063793554 time 0.094688</span><br><span class="line">[I] [TRT] Tactic 8292480392881939394 time 0.074752</span><br><span class="line">[I] [TRT] Tactic 8436800165353340181 time 0.059936</span><br><span class="line">[I] [TRT] Tactic -7597689592892725774 time 0.09216</span><br><span class="line">[I] [TRT] --------------- Chose 6 (5)</span><br><span class="line">[I] [TRT] </span><br><span class="line">[I] [TRT] --------------- Timing prob(11)</span><br><span class="line">[I] [TRT] Tactic 0 is the only option, timing skipped</span><br><span class="line">[I] [TRT] Formats and tactics selection completed in 10.0197 seconds.</span><br><span class="line">[I] [TRT] After reformat layers: 66 layers</span><br><span class="line">[I] [TRT] Block size 1073741824</span><br><span class="line">[I] [TRT] Block size 12845056</span><br><span class="line">[I] [TRT] Block size 9633792</span><br><span class="line">[I] [TRT] Block size 3211264</span><br><span class="line">[I] [TRT] Block size 3211264</span><br><span class="line">[I] [TRT] Total Activation Memory: 1102643200</span><br><span class="line">[I] [TRT] Detected 1 input and 1 output network tensors.</span><br><span class="line">[I] [TRT] Data initialization and engine generation completed in 0.0458818 seconds.</span><br><span class="line">loadmodel time: 10322 ms</span><br><span class="line">infer time: 8.20 ms</span><br></pre></td></tr></table></figure>
<h3 id="init.giemodel">Init.GIEModel</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[I] [TRT] Glob Size is 40869280 bytes.</span><br><span class="line">[I] [TRT] Added linear block of size 3211264</span><br><span class="line">[I] [TRT] Added linear block of size 2408448</span><br><span class="line">[I] [TRT] Added linear block of size 802816</span><br><span class="line">[I] [TRT] Added linear block of size 802816</span><br><span class="line">[I] [TRT] Deserialize required 13227 microseconds.</span><br><span class="line">[I] googlenet_gie.bin has been successfully loaded.</span><br><span class="line">loadmodel time: 36 ms</span><br><span class="line">infer time: 2.80 ms</span><br></pre></td></tr></table></figure>
<h3
id="iplugin接口中需要被重载的函数">IPlugin接口中需要被重载的函数</h3>
<ol type="1">
<li><p>确定输出：一个是通过<code>int getNbOutput()</code>得到output输出的数目，即用户所定义的一层有几个输出。另一个是通过<code>Dims getOutputDimensions (int index, const Dims* inputs, int nbInputDims)</code>
得到整个输出的维度信息，大家可能不一定遇到有多个输出，一般来讲只有一个输出，但是大家在做检测网络的时候可能会遇到多个输出，一个输出是实际的检测目标是什么，另一个输出是目标的数目，可能的过个输出需要设定Dimension的大小。</p></li>
<li><p>层配置：通过<code>void configure()</code>
实现构建推断（Inference）
engine时模型中相应的参数大小等配置，configure()只是在构建的时候调用，这个阶段确定的东西是在运行时作为插件参数来存储、序列化/反序列化的。</p></li>
<li><p>资源管理：通过<code>void Initialize()</code>来进行资源的初始化，<code>void terminate()</code>来销毁资源，甚至中间可能会有一些临时变量，也可以使用这两个函数进行初始化或销毁。需要注意的是，void
Initialize()和void
terminate()是在整个运行时都被调用的，并不是做完一次推断（Inference）就去调用terminate。相当于在线的一个服务，服务起的时候会调用void
Initialize()，而服务止的时候调用void
terminate()，但是服务会进进出出很多sample去做推断（Inference）。</p></li>
<li><p>执行(Execution)：<code>void enqueue()</code>来定义用户层的操作</p></li>
<li><p>序列化和反序列化：这个过程是将层的参数写入到二进制文件中，需要定义一些序列化的方法。通过<code>size_t getSerializationSize()</code>获得序列大小，通过void
serialize()将层的参数序列化到缓存中，通过PluginSample()从缓存中将层参数反序列化。需要注意的是，TensorRT没有单独的反序列化的API，因为不需要，在实习构造函数的时候就完成了反序列化的过程</p></li>
<li><p>从Caffe
Parser添加Plugin：首先通过<code>Parsernvinfer1::IPlugin* createPlugin()</code>实现nvcaffeparser1::IPlugin
接口，然后传递工厂实例到<code>ICaffeParser::parse()</code>，Caffe的Parser才能识别</p></li>
<li><p>运行时创建插件：通过<code>IPlugin* createPlugin()</code>实现nvinfer1::IPlugin接口，传递工厂实例到<code>IInferRuntime::deserializeCudaEngine()</code></p></li>
</ol>
<h3 id="tensorrt-中已经实现的plugin">TensorRT 中已经实现的Plugin</h3>
<p>打开verbose logger之后可以看到如下输出，相关的调用接口如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[V] [TRT] Plugin Creator registration succeeded - GridAnchor_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - NMS_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - Reorg_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - Region_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - Clip_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - LReLU_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - PriorBox_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - Normalize_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - RPROI_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - BatchedNMS_TRT</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief Create a plugin layer that fuses the RPN and ROI pooling using user-defined parameters.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;RPROI_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param featureStride Feature stride.</span></span><br><span class="line"><span class="comment">//! \param preNmsTop Number of proposals to keep before applying NMS.</span></span><br><span class="line"><span class="comment">//! \param nmsMaxOut Number of remaining proposals after applying NMS.</span></span><br><span class="line"><span class="comment">//! \param iouThreshold IoU threshold.</span></span><br><span class="line"><span class="comment">//! \param minBoxSize Minimum allowed bounding box size before scaling.</span></span><br><span class="line"><span class="comment">//! \param spatialScale Spatial scale between the input image and the last feature map.</span></span><br><span class="line"><span class="comment">//! \param pooling Spatial dimensions of pooled ROIs.</span></span><br><span class="line"><span class="comment">//! \param anchorRatios Aspect ratios for generating anchor windows.</span></span><br><span class="line"><span class="comment">//! \param anchorScales Scales for generating anchor windows.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \return Returns a FasterRCNN fused RPN+ROI pooling plugin. Returns nullptr on invalid inputs.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createRPNROIPlugin</span><span class="params">(<span class="type">int</span> featureStride, <span class="type">int</span> preNmsTop,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                                <span class="type">int</span> nmsMaxOut, <span class="type">float</span> iouThreshold, <span class="type">float</span> minBoxSize,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                                <span class="type">float</span> spatialScale, nvinfer1::DimsHW pooling,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                                nvinfer1::Weights anchorRatios, nvinfer1::Weights anchorScales)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Normalize plugin layer normalizes the input to have L2 norm of 1 with scale learnable.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;Normalize_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param scales Scale weights that are applied to the output tensor.</span></span><br><span class="line"><span class="comment">//! \param acrossSpatial Whether to compute the norm over adjacent channels (acrossSpatial is true) or nearby spatial locations (within channel in which case acrossSpatial is false).</span></span><br><span class="line"><span class="comment">//! \param channelShared Whether the scale weight(s) is shared across channels.</span></span><br><span class="line"><span class="comment">//! \param eps Epsilon for not diviiding by zero.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createNormalizePlugin</span><span class="params">(<span class="type">const</span> nvinfer1::Weights* scales, <span class="type">bool</span> acrossSpatial, <span class="type">bool</span> channelShared, <span class="type">float</span> eps)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The PriorBox plugin layer generates the prior boxes of designated sizes and aspect ratios across all dimensions (H x W).</span></span><br><span class="line"><span class="comment">//! PriorBoxParameters defines a set of parameters for creating the PriorBox plugin layer.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;PriorBox_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createPriorBoxPlugin</span><span class="params">(nvinfer1::plugin::PriorBoxParameters param)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Grid Anchor Generator plugin layer generates the prior boxes of</span></span><br><span class="line"><span class="comment">//! designated sizes and aspect ratios across all dimensions (H x W) for all feature maps.</span></span><br><span class="line"><span class="comment">//! GridAnchorParameters defines a set of parameters for creating the GridAnchorGenerator plugin layer.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;GridAnchor_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createAnchorGeneratorPlugin</span><span class="params">(nvinfer1::plugin::GridAnchorParameters* param, <span class="type">int</span> numLayers)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The DetectionOutput plugin layer generates the detection output based on location and confidence predictions by doing non maximum suppression.</span></span><br><span class="line"><span class="comment">//! DetectionOutputParameters defines a set of parameters for creating the DetectionOutput plugin layer.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;NMS_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createNMSPlugin</span><span class="params">(nvinfer1::plugin::DetectionOutputParameters param)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The LReLu plugin layer performs leaky ReLU for 4D tensors. Give an input value x, the PReLU layer computes the output as x if x &gt; 0 and negative_slope //! x if x &lt;= 0.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;LReLU_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param negSlope Negative_slope value.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createLReLUPlugin</span><span class="params">(<span class="type">float</span> negSlope)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Reorg plugin reshapes input of shape CxHxW into a (C*stride*stride)x(H/stride)x(W/stride) shape, used in YOLOv2.</span></span><br><span class="line"><span class="comment">//! It does that by taking 1 x stride x stride slices from tensor and flattening them into (stridexstride) x 1 x 1 shape.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;Reorg_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param stride Strides in H and W, it should divide both H and W. Also stride * stride should be less than or equal to C.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createReorgPlugin</span><span class="params">(<span class="type">int</span> stride)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Region plugin layer performs region proposal calculation: generate 5 bounding boxes per cell (for yolo9000, generate 3 bounding boxes per cell).</span></span><br><span class="line"><span class="comment">//! For each box, calculating its probablities of objects detections from 80 pre-defined classifications (yolo9000 has 9416 pre-defined classifications,</span></span><br><span class="line"><span class="comment">//! and these 9416 items are organized as work-tree structure).</span></span><br><span class="line"><span class="comment">//! RegionParameters defines a set of parameters for creating the Region plugin layer.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;Region_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createRegionPlugin</span><span class="params">(nvinfer1::plugin::RegionParameters params)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Clip Plugin performs a clip operation on the input tensor. It</span></span><br><span class="line"><span class="comment">//! clips the tensor values to a specified min and max. Any value less than clipMin are set to clipMin.</span></span><br><span class="line"><span class="comment">//! Any values greater than clipMax are set to clipMax. For example, this plugin can be used</span></span><br><span class="line"><span class="comment">//! to perform a Relu6 operation by specifying clipMin=0.0 and clipMax=6.0</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;Clip_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param layerName The name of the TensorRT layer.</span></span><br><span class="line"><span class="comment">//! \param clipMin The minimum value to clip to.</span></span><br><span class="line"><span class="comment">//! \param clipMax The maximum value to clip to.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createClipPlugin</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* layerName, <span class="type">float</span> clipMin, <span class="type">float</span> clipMax)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The BatchedNMS Plugin performs non_max_suppression on the input boxes, per batch, across all classes.</span></span><br><span class="line"><span class="comment">//! It greedily selects a subset of bounding boxes in descending order of</span></span><br><span class="line"><span class="comment">//! score. Prunes away boxes that have a high intersection-over-union (IOU)</span></span><br><span class="line"><span class="comment">//! overlap with previously selected boxes. Bounding boxes are supplied as [y1, x1, y2, x2],</span></span><br><span class="line"><span class="comment">//! where (y1, x1) and (y2, x2) are the coordinates of any</span></span><br><span class="line"><span class="comment">//! diagonal pair of box corners and the coordinates can be provided as normalized</span></span><br><span class="line"><span class="comment">//! (i.e., lying in the interval [0, 1]) or absolute.</span></span><br><span class="line"><span class="comment">//! The plugin expects two inputs.</span></span><br><span class="line"><span class="comment">//! Input0 is expected to be 4-D float boxes tensor of shape [batch_size, num_boxes,</span></span><br><span class="line"><span class="comment">//! q, 4], where q can be either 1 (if shareLocation is true) or num_classes.</span></span><br><span class="line"><span class="comment">//! Input1 is expected to be a 3-D float scores tensor of shape [batch_size, num_boxes, num_classes]</span></span><br><span class="line"><span class="comment">//! representing a single score corresponding to each box.</span></span><br><span class="line"><span class="comment">//! The plugin returns four outputs.</span></span><br><span class="line"><span class="comment">//! num_detections : A [batch_size] int32 tensor indicating the number of valid</span></span><br><span class="line"><span class="comment">//! detections per batch item. Can be less than keepTopK. Only the top num_detections[i] entries in</span></span><br><span class="line"><span class="comment">//! nmsed_boxes[i], nmsed_scores[i] and nmsed_classes[i] are valid.</span></span><br><span class="line"><span class="comment">//! nmsed_boxes : A [batch_size, max_detections, 4] float32 tensor containing</span></span><br><span class="line"><span class="comment">//! the co-ordinates of non-max suppressed boxes.</span></span><br><span class="line"><span class="comment">//! nmsed_scores : A [batch_size, max_detections] float32 tensor containing the</span></span><br><span class="line"><span class="comment">//! scores for the boxes.</span></span><br><span class="line"><span class="comment">//! nmsed_classes :  A [batch_size, max_detections] float32 tensor containing the</span></span><br><span class="line"><span class="comment">//! classes for the boxes.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;BatchedNMS_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createBatchedNMSPlugin</span><span class="params">(nvinfer1::plugin::NMSParameters param)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief Initialize and register all the existing TensorRT plugins to the Plugin Registry with an optional namespace.</span></span><br><span class="line"><span class="comment">//! The plugin library author should ensure that this function name is unique to the library.</span></span><br><span class="line"><span class="comment">//! This function should be called once before accessing the Plugin Registry.</span></span><br><span class="line"><span class="comment">//! \param logger Logger object to print plugin registration information</span></span><br><span class="line"><span class="comment">//! \param libNamespace Namespace used to register all the plugins in this library</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI <span class="type">bool</span> <span class="title">initLibNvInferPlugins</span><span class="params">(<span class="type">void</span>* logger, <span class="type">const</span> <span class="type">char</span>* libNamespace)</span></span>;</span><br></pre></td></tr></table></figure>
<p>https://medium.com/<span class="citation"
data-cites="r7vme/converting-neural-network-to-tensorrt-part-1-using-existing-plugins-edd9c2b9e42a">@r7vme/converting-neural-network-to-tensorrt-part-1-using-existing-plugins-edd9c2b9e42a</span></p>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>inference</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title>The history of C++</title>
    <url>/202004/20200401-cplusplus-history/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>在阅读C++相关的技术书籍或博客时，常常会提到一些日常开发中不常接触的名词，如cfront
2.0或者TR1等，这些名词在C++的历史发展中属于里程碑式的的名词。从C++不同时期的发展中可以看出对于程序员的开发需求逐渐满足，伴随着C++的标准的变化，编译器对语言的支持也逐渐完善。</p>
<h2 id="c-历史大事件">C++ 历史大事件</h2>
<figure>
<img data-src="https://isocpp.org/files/img/wg21-timeline-2019-07.png"
alt="@" />
<figcaption aria-hidden="true">@</figcaption>
</figure>
<h2 id="关键事件总结">关键事件总结</h2>
<table>
<colgroup>
<col style="width: 31%" />
<col style="width: 18%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">date</th>
<th>feature</th>
<th>details</th>
<th>sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1979</td>
<td>首次实现引入类的C</td>
<td>C with Classes first implemented<br>1.
新特性：<strong>类、成员函数、继承类</strong>、独立编译、<strong>公共和私有访问控制、友元、函数参数类型检查、默认参数、内联函数、赋值符号重载、构造函数、析构函数</strong>、f()相当于f(void)、调用函数和返回函数（同步机制，不是在C++中）</br>
2. 库：并发任务程序库（不是在C++中）</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">1985</td>
<td>编译器cfront 1.0</td>
<td>1.
新特性：<strong>虚函数、函数和操作符重载</strong>、<strong>引用</strong>、<strong>new和delete操作符</strong>、<strong>const关键词</strong>、范围解析运算符::<br>2.
新加入的库：复数（complex）、字符串（string）、输入输出流（iostream）</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">1985</td>
<td>《C++编程语言第一版》</td>
<td>The C++ Programming Language, 1st edition</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">1989</td>
<td>编译器cfront 2.0</td>
<td>1.新特性：多重继承、成员指针、保护访问控制、类型安全联接、抽象类、静态和常量成员函数、特定类的new和delete
<br> 2. 新库：I/O 操作器 <br></td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">1990</td>
<td>ANSI C++委员会成立（ANSI C++ Committee founded）</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">1990</td>
<td>《C++参考手册注解》</td>
<td>The Annotated C++ Reference Manual was released.</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">1991</td>
<td>ISO C++委员会成立（ISO C++ Committee founded）</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">1998</td>
<td>C++98</td>
<td>1. 新特性：<strong>运行时类型信息［RTTI（dynamic_cast,
typeid）］</strong>、协变返回类型（covariant return types）、cast
操作符、可变型、布尔型、声明情况、模板例示、成员模板、导出 <br> 2.
新库：容器、算法、迭代器、函数对象（STL中）、区域设置、位集合、值向量、自动指针（auto_ptr）、模块化字符串、输入输出流和复数<br>
the C++ standards committee published the first international standard
for C++ ISO/IEC 14882:1998, which would be informally known as C++98.
The Annotated C++ Reference Manual was said to be a large influence in
the development of the standard. <strong>The Standard Template
Library</strong>, which began its conceptual development in 1979, was
also included.</td>
<td>*****</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1999</td>
<td>Boost由委员会成员成立，旨在开发新的高质量库以作为标准库的候选库</td>
<td>Boost founded by the committee members to produce new high-quality
candidate libraries for the standard</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2003</td>
<td>C++03 (ISO/IEC 14882:2003)</td>
<td>The committee responded to multiple problems that were reported with
their 1998 standard, and revised it accordingly. The changed language
was dubbed <strong>C++03</strong>.
这是一个次要修订版本，修正了一些错误。</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">2006</td>
<td>Performance TR (ISO/IEC TR 18015:2006) (ISO Store ) (2006 draft
)</td>
<td>性能技术报告</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2007</td>
<td>2007 Library extension TR1 (ISO/IEC TR 19768:2007) (ISO store )
(2005 draft )</td>
<td>1. 源自Boost：<strong>引用包装器（Reference
wrapper）</strong>、<strong>智能指针（Smart
pointers）</strong>、成员函数（Member function）、Result of
、绑定（Binding）、函数（Function）、类型特征（type
traits）、随机（Random）、数学特殊函数（Mathematical Special
Functions）、元组（Tuple）、数组（Array）、无序容器［Unordered
Containers包括哈希（Hash）］还有<strong>正则表达式（Regular
Expressions）</strong> <br> 2.
源自C99：math.h中同时也是新加入C99的数学函数、空白字符类、浮点环境（Floating-point
environment）、十六进制浮点I/O操作符（hexfloat I/O
Manipulator）、固定大小整数类型（fixed-size integral
types）、长整型（the long long type）、va_copy、snprintf()
和vscanf()函数族，还有C99 的printf()与scanf()函数族的指定转换。
TR1除了一些特殊函数，大部分都被囊括进C++11。</td>
<td>*****</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2010</td>
<td>数学特殊函数技术报告［2010 Mathematical special functions TR
(ISO/IEC 29124:2010)(ISO Store)］</td>
<td>此TR是一个C++标准库扩展，加入了TR1中的部分特殊函数，但那些函数之前没有被包括进C++11：椭圆积分、指数积分、拉盖尔多项式（Laguerre
polynomials）、勒让徳多项式（Legendre
polynomials）、艾尔米特多项式（Hermite
polynomials）、贝塞尔（Bessel）函数、纽曼（Newmann）函数、<span
class="math inline">\(\beta\)</span>函数和黎曼（Riemann）<span
class="math inline">\(\zeta\)</span>函数</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2011</td>
<td>C++11 (ISO/IEC 14882:2011) (ISO Store) (ANSI Store )</td>
<td>1.
新语言特性：<strong>自动（auto）和类型获取（decltype）</strong>、默认和已删除函数（defaulted
and deleted
functions）、<strong>不可更改（final）和重载（override）</strong>、<strong>拖尾返回类型（trailing
return type）</strong>、<strong>右值引用（rvalue
references）</strong>、<strong>移动构造函数（move
constructors）/移动赋值（move assignment）</strong>、作用域枚举（scoped
enums）、常量表达式（constexpr）和文字类型（literal
types）、<strong>列表初始化（list
initialization）</strong>、授权（delegating）和<strong>继承构造器（inherited
constructors）</strong>、大括号或等号（brace-or-equal）初始化器、<strong>空指针（nullptr）</strong>、长整型（long
long）、char16_t和char32_t、类型别名（type
aliases）、<strong>可变参数模板（variadic
templates）</strong>、广义联合体（generalized
unions）、广义POD、Unicode字符串文字（Unicode string
literals）、自定义文字（user-defined
literals）、属性（attributes）、<strong><span
class="math inline">\(\lambda\)</span>表达式（lambda
expressions）</strong>、无异常（noexcept）、对齐查询（alignof）和对齐指定（alignas）、<strong>多线程内存模型（multithreaded
memory model）、线程本地存储（thread-local
storage）</strong>、<strong>GC接口（GC interface）</strong>、range
for(based on a Boost library)、静态断言［static assertions（based on a
Boost library）］<br> 2.新库特性：原子操作库（atomic operations
library）、<strong>emplace()</strong>和贯穿整个现有库的右值引用的使用、std::initializer_list、状态性的和作用域内的分配器（stateful
and scoped
allocators）、前向列表（forward_list）、<strong>计时库（chrono
library）</strong>、分数库（ratio library）、新算法（new
algorithms）、Unicode conversion facets
<br>3.源自TR1：除了特殊的函数，TR1中全部都被囊括进来
<br>4.源自Boost：线程库（The thread
library）、异常指针（exception_ptr）、错误码（error_code）和错误情况（error_condition）、迭代器改进［iterator
improvements（std::begin, std::end, std::next,
std::prev）］<br>5.源自C：C风格的Unicode转换函数<br>6.搜集错误报告修复：363个错误在2008草案中被解决，另外有322个错误接着被修复。其中的错误包括530号，它使得std::basic_string对象相连。</td>
<td>*****</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2011</td>
<td>十进制浮点技术报告［Decimal floating-point TR (ISO/IEC TR
24733:2011) (ISO Store ) (2009 draft )］</td>
<td>这个TR根据IEEE 754-2008浮点算数标准（Floating Point
Arithmetic）：std::decimal::decimal32、std::decimal::decimal64、std::decimal::decimal128</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2012</td>
<td>标准C++基金会成立</td>
<td>The Standard C++ Foundation founded</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">2013</td>
<td>《C++编程语言第四版》</td>
<td>The C++ Programming Language, 4th edition</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2014</td>
<td>C++14 (2014 final draft )</td>
<td>1. 新语言特性：变量模板（variable
templates）、多态lambda（polymorphic lambdas）、λ动捕获（move capture
for lambdas）、<strong>new/delete
elision</strong>、常量表达式函数放宽限制（relax restrictions on
constexpr functions）、二值文本（binary literals）、数字分隔符（digit
separators）、函数返回类型推演（return type deduction for
functions）、用大括号或等号初始符集合初始化类<br> 2.
新库特性：std::make_unique、std::shared_mutex和std::shared_lock、std::index_sequence、std::exchange、std::quoted，还有许多针对现有库的小改进，比如一些算法的双距离重载（two-range
overloads for some algorithms）、类型特征的类型别名版本（type alias
versions of type traits）、用户定义字符串（user-defined
string）、持续期（duration）和复杂数字文本（complex number
literals）等等<br> 3.搜集错误报告修复：149号库（149 library issues）
基础库技术规范（Library fundamentals TS）, 文件系统技术规范（Filesystem
TS）和其他专业技术规范（ experimental technical specifications）</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="不同编译器对c标准的支持">不同编译器对c++标准的支持</h2>
<p>cfront x.x就是Bjarne
Stroustrup的第一个C++编译器，将C++转换成C语言。在1993年，cfront
4.0因为尝试支持异常机制失败而被取消。我们开发者最长打交道的工具就是编译器了。我们只要通过编写程序语言，编译器会翻译成具体的更底层命令来控制计算机去实现我们的需要的功能。但C++语言标准是一个庞大的特性集合，而不同编译器厂商在根据这个统一标准做编译器的过程中，由于各种原因，不可能支持全部的标准中列举出来的特性。
例如，C++11已经流行多年，很多特性是随着编译器版本release才逐渐支持的，如下图：</p>
<figure>
<img data-src="https://cwlseu.github.io/images/gcc/compiler_support.jpg"
alt="@" />
<figcaption aria-hidden="true">@</figcaption>
</figure>
<ul>
<li><p><a
href="https://en.cppreference.com/w/cpp/compiler_support">关于不同编译器对C++不同时期的语言特性的支持程度</a></p></li>
<li><p><a href="https://gcc.gnu.org/projects/cxx-status.html">gnu
gcc对C++语言特定的支持情况以及最低支持版本等信息</a></p></li>
</ul>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="https://gcc.gnu.org/onlinedocs/libstdc++/faq.html">gnu
gcc常见问题</a></li>
<li><a
href="http://www.cplusplus.com/info/history/">C++官方的history页面</a></li>
<li><a
href="https://www.cnblogs.com/fickleness/p/3154937.html">中文博客C++的历史与现状</a></li>
<li><a
href="https://isocpp.org/std/standing-documents/sd-6-sg10-feature-test-recommendations">Feature-Test
Macros and Policies</a></li>
<li><a
href="https://isocpp.org/get-started">各编译器下载地址，包括vs2017社区版</a></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>中文文本纠错</title>
    <url>/202107/20210723-csc-survey/</url>
    <content><![CDATA[<h2 id="常见错误类型">常见错误类型</h2>
<p>在中文中，常见的错误类型大概有如下几类：</p>
<p>由于字音字形相似导致的错字形式：体脂称—&gt;体脂秤 多字错误：iphonee
—&gt; iphone 少字错误：爱有天意 --&gt; 假如爱有天意 顺序错误: 表达难以
--&gt; 难以表达 ## 纠错组成模块 纠错一般分两大模块：</p>
<p>错误检测：识别错误发生的位置
错误纠正：对疑似的错误词，根据字音字形等对错词进行候选词召回，并且根据语言模型等对纠错后的结果进行排序，选择最优结果。
<img data-src="https://cwlseu.github.io/images/nlp/csc/1625834835557.png"
alt="Alt text" /></p>
<h2 id="赛事">赛事</h2>
<p>几届中文纠错评测，例如CGED与NLPCC - Chinese Spelling Check Evaluation
at SIGHAN Bake-off 2013 [Wu et al., 2013]<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> -
CLP-2014 Chinese Spelling Check Evaluation (Yu et al., 2014) <img data-src="https://cwlseu.github.io/images/nlp/csc/1625588548317.png"
alt="Alt text" /></p>
<h2 id="数据集">数据集</h2>
<p>1、Academia Sinica Balanced Corpus (ASBC for short hereafter, cf.
Chen et al., 1996). 2、混淆词数据集[^A Hybrid Approach to Automatic
Corpus Generation for Chinese Spelling Check]</p>
<p>[^A Hybrid Approach to Automatic Corpus Generation for Chinese
Spelling Check]: Wang, D. , Song, Y. , Li, J. , Han, J. , &amp; Zhang,
H. . (2018). A Hybrid Approach to Automatic Corpus Generation for
Chinese Spelling Check. Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing.
https://aclanthology.org/D18-1273.pdf</p>
<p>3、Chinese Grammatical Error Diagnosis NLPTEA 2016 Shared Task:
http://ir.itc.ntnu.edu.tw/lre/nlptea16cged.htm NLPTEA 2015 Shared Task:
http://ir.itc.ntnu.edu.tw/lre/nlptea15cged.htm NLPTEA 2014 Shared Task:
http://ir.itc.ntnu.edu.tw/lre/nlptea14cfl.htm</p>
<p>4、Chinese Spelling Check SIGHAN 2015 Bake-off:
http://ir.itc.ntnu.edu.tw/lre/sighan8csc.html CLP 2014 Bake-off:
http://ir.itc.ntnu.edu.tw/lre/clp14csc.html SIGHAN 2013 Bake-off:
http://ir.itc.ntnu.edu.tw/lre/sighan7csc.html</p>
<p>http://nlp.ee.ncu.edu.tw/resource/csc.html</p>
<h4 id="构造方法">构造方法</h4>
<p>1、对字进行增删、交换位置、混淆词替换 2、常见混淆集整理 &gt;
视觉上和语音上的相似字是造成汉语文本错误的主要因素。通过定义适当的相似性度量，考虑扩展仓颉代码，我们可以在几分之一秒内识别视觉上相似的字符。根据汉语词汇中单个汉字的发音信息，我们可以计算出一个与给定汉字在语音上相似的汉字列表。我们收集了网络上出现的621个错误的中文词汇，并分析了这些错误的原因。其中83%的错误与语音相似性有关，48%的错误与所涉及的字符之间的视觉相似性有关。生成语音和视觉上相似的字符列表，我们的程序能够包含报告错误中超过90%的错误字符。<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></p>
<p>3、基于说文解字、四角码计算[^Using Confusion Sets and N-gram
Statistics]</p>
<p>[^Using Confusion Sets and N-gram Statistics]: Lin C J, Chu W C. A
Study on Chinese Spelling Check Using Confusion Sets and N-gram
Statistics[J]. International Journal of Computational Linguistics &amp;
Chinese Language Processing, Volume 20, Number 1, June 2015-Special
Issue on Chinese as a Foreign Language, 2015, 20(1).</p>
<h3 id="编辑距离">编辑距离</h3>
<p>编辑距离的经典应用就是用于拼写检错，如果用户输入的词语不在词典中，自动从词典中找出编辑距离小于某个数<span
class="math inline">\(n\)</span>的单词，让用户选择正确的那一个，<span
class="math inline">\(n\)</span>通常取到2或者3。</p>
<p>这个问题的难点在于，怎样才能快速在字典里找出最相近的单词？可以像
使用贝叶斯做英文拼写检查里是那样，通过单词自动修改一个单词，检查是否在词典里，这样有暴力破解的嫌疑，是否有更优雅的方案呢？</p>
<p>1973年，Burkhard和Keller提出的BK树有效地解决了这个问题。BK树<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a><a href="#fn4" class="footnote-ref"
id="fnref4" role="doc-noteref"><sup>4</sup></a>的核心思想是： &gt;
令<span
class="math inline">\(d(x,y)\)</span>表示字符串x到y的Levenshtein距离，那么显然：
&gt; <span class="math inline">\(d(x,y) = 0\)</span> 当且仅当 <span
class="math inline">\(x=y\)</span> （Levenshtein距离为0 &lt;==&gt;
字符串相等） &gt; <span class="math inline">\(d(x,y) = d(y,x)\)</span>
（从x变到y的最少步数就是从y变到x的最少步数） &gt; <span
class="math inline">\(d(x,y) + d(y,z) &gt;= d(x,z)\)</span>
（从x变到z所需的步数不会超过x先变成y再变成z的步数）</p>
<p>最后这一个性质叫做三角形不等式。就好像一个三角形一样，两边之和必然大于第三边。</p>
<h2 id="发展历史概述">发展历史概述</h2>
<h4 id="依赖条件">依赖条件</h4>
<p>纠错技术相对于词法分析，句法分析等受到的关注一直较小，一方面是因为<strong>文本出错的比例比较小</strong>，在一些重要场合，也有专门人员进行校验；另一方面<strong>本身问题也相对较难</strong>，其要求计算机对语言规则以及文本语义有深刻的理解。</p>
<p>我们把中文常见错误总结分为三类： -
用词错误，由于输入法等原因导致的选词错误，其主要表现为音近，形近等； -
文法/句法错误，该类错误主要是由于对语言不熟悉导致的如多字、少字、乱序等错误，其错误片段相对较大；
-
知识类错误，该类错误可能由于对某些知识不熟悉导致的错误，要解决该类问题，通常得引入外部知识、常识等。</p>
<h4 id="发展历程">发展历程</h4>
<ul>
<li>2000年以前，业界主要依靠长期积累的纠错规则和纠错词典来进行纠错，比如微软的文档编辑产品WORD即采用这种方法</li>
<li>随着机器学习技术的发展，纠错问题受到了学术界和工业界越来越多的关注，其中有两大主流方法：
<ul>
<li>一种解决思路是将语言错误归类，然后采用Maxent（最大熵模型）、SVM等分类方法对这些类别进行重点识别；</li>
<li>另外一种思路是借鉴统计机器翻译（SMT）的思想，将语言纠错等价为机器翻译的过程，即错误文本翻译为正确文本，并随之出现了一系列的优化方法。</li>
</ul></li>
</ul>
<h4 id="调研的必要性">调研的必要性</h4>
<p>近年来，随着新媒体行业的快速发展，中国自媒体从业人数逐年增长，至2017年有近260万。但是相对于传统媒体，其缺少人工校稿环节，编辑好的文章即刻发表，导致文章的错误比例较高。比如一些新媒体平台的正文错误率在2%以上，标题错误率在1%左右。同时，语音智能硬件产品的兴起，也暴露出语音识别技术的错误率高企问题，在某些场景语音识别中，错误率可能达到8%-10%，影响了后续的query理解及对话效果。因此研发优质的中文纠错技术，便成为了必须。</p>
<h2 id="技术调研">技术调研</h2>
<p>整体上，将纠错流程，分解为错误检测、候选召回、纠错排序三个关键步骤。通过引入语言知识、上下文理解和知识计算的核心技术，提升不同类型错误的解决能力。最后，支持SMT
based和NMT based两套Framework，形成完整的系统架构。 ###
关键步骤（错误检测-&gt;候选召回-&gt;纠错排序） <img data-src="https://cwlseu.github.io/images/nlp/csc/1625573756452.png"
alt="Alt text" /></p>
<p><strong>错误检测</strong>的目标是识别输入句子可能存在的问题，采用序列表示（Transformer/LSTM）+CRF的序列预测模型，这个模型的创新点主要包括：
- 词法/句法分析等语言先验知识的充分应用； -
特征设计方面，除了DNN相关这种泛化能力比较强的特征，还结合了大量hard统计特征，既充分利用DNN模型的泛化能力，又对低频与OOV（Out
of Vocabulary）有一定的区分； -
最后，根据字粒度和词粒度各自的特点，在模型中对其进行融合，解决词对齐的问题。
<img data-src="https://cwlseu.github.io/images/nlp/csc/1625573965653.png"
alt="Alt text" /></p>
<p><strong>候选召回</strong>指的是，识别出具体的错误点之后，需要进行错误纠正，为了达到更好的效果以及性能，需要结合历史错误行为，以及音形等特征召回纠错候选。主要可分为两部分工作：离线的候选挖掘，在线的候选预排序。离线候选挖掘利用大规模多来源的错误对齐语料，通过对齐模型，得到不同粒度的错误混淆矩阵。在线候选预排序主要是针对当前的错误点，对离线召回的大量纠错候选，结合语言模型以及错误混淆矩阵的特征，控制进入纠错排序阶段的候选集数量与质量。</p>
<h3
id="核心技术语言知识-上下文理解-知识计算">核心技术（语言知识-&gt;上下文理解-&gt;知识计算）</h3>
<h4 id="采用翻译技术纠错">采用翻译技术纠错</h4>
<blockquote>
<p>优点</p>
</blockquote>
<p>将纠错当做翻译任务去做，可以对不同类型的错误形式：错词，少词，多词等进行纠错</p>
<blockquote>
<p>缺点</p>
</blockquote>
<p>模型没有对字音字形相似关系的学习，纠错后的结果不受约束，很容易出现过纠错和误纠问题</p>
<h3 id="soft-masked-bert">Soft-Masked BERT</h3>
<p>Soft-Masked BERT：文本纠错与BERT的最新结合 - 头条 - ACL 2020</p>
<blockquote>
<p>给定<span class="math inline">\(n\)</span>个字或词构成的序列<span
class="math inline">\(X=(x_1, x_2,...,
x_n)\)</span>，目标是把它转化为另一个相同长度的字序列<span
class="math inline">\(Y=(y_1,y_2,...,y_n)\)</span>， <span
class="math inline">\(X\)</span>中的错字用正确的字替换得到<span
class="math inline">\(Y\)</span>
。该任务可看作序列标注问题，模型是映射函数<span
class="math inline">\(f:X\rightarrow Y\)</span>。</p>
</blockquote>
<p>这篇文章中的纠错模型是由基于Bi-GRU序列二进制标注检测模型和基于BERT的序列多类标注纠正模型组成，
其中soft-masked embedding: <span class="math inline">\(e_i’ = p_i \cdot
e_{mask} + (1-p_i) \cdot e_i\)</span>
可以实现将错字概率传递给后续纠正网络，使得纠正网络专注在预测正确字上。
<img data-src="https://cwlseu.github.io/images/nlp/csc/1625632229795.png"
alt="Soft-Masked BERT纠错算法框架" /></p>
<p>https://zhuanlan.zhihu.com/p/144995580 ### SpellGCN[^SpellGCN:
Incorporating Phonological and Visual Similarities into Language Models
for Chinese Spelling Check]</p>
<p>3、https://zhuanlan.zhihu.com/p/145825024?from_voters_page=true
[^SpellGCN: Incorporating Phonological and Visual Similarities into
Language Models for Chinese Spelling Check]:
https://aclanthology.org/2020.acl-main.81.pdf</p>
<h3
id="confusionset-ptrnet---cscconfusionset-guided-pointer-networks-for-chinese-spelling-check">ConfusionSet
+PtrNet -&gt; CSC[^Confusionset-guided Pointer Networks for Chinese
Spelling Check]</h3>
<p>[^Confusionset-guided Pointer Networks for Chinese Spelling Check]:
https://www.aclweb.org/anthology/P19-1578.pdf</p>
<p>4、基于统计语言模型的文本纠错方法研究
https://www.cnblogs.com/baobaotql/p/13358035.html</p>
<p>规则类：哪些更适合规则类？ 语言模型 混淆集</p>
<h2 id="todo">TODO</h2>
<p>ACL2021 Global Attention Decoder for Chinese Spelling Error
Correction Correcting Chinese Spelling Errors with Phonetic Pre-training
Dynamic Connected Networks for Chinese Spelling Check
https://github.com/gitabtion/SoftMaskedBert-PyTorch</p>
<p>https://github.com/gitabtion/BertBasedCorrectionModels</p>
<h2 id="gec">GEC</h2>
<p>Encoder-Decoder Models Can Benefit from Pre-trained Masked Language
Models in Grammatical Error Correction
https://aclanthology.org/2020.acl-main.391.pdf</p>
<p>Do Grammatical Error Correction Models Realize Grammatical
Generalization? https://arxiv.org/abs/2106.03031</p>
<h2 id="互联网企业papers">互联网企业Papers</h2>
<p>1、腾讯云:基于语言模型的拼写纠错：https://cloud.tencent.com/developer/article/1156792</p>
<p>2、平安寿险AI https://zhuanlan.zhihu.com/p/159101860</p>
<p>3、爱奇艺:
https://blog.csdn.net/BGoodHabit/article/details/114589007#21_FASPell_20</p>
<table>
<colgroup>
<col style="width: 18%" />
<col style="width: 27%" />
<col style="width: 27%" />
<col style="width: 27%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">模型</th>
<th style="text-align: left;">发表位置</th>
<th style="text-align: left;">创新点</th>
<th style="text-align: center;">总结</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">FASPell(爱奇艺)</td>
<td style="text-align: left;">ACL2020</td>
<td
style="text-align: left;">融合字音字形相似度分数，拟合最佳分割曲线</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">SpellGCN(阿里)</td>
<td style="text-align: left;"></td>
<td
style="text-align: left;">用GCN学习字音字形关系结构向量，让错词更倾向于纠错为混淆集中的字</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Soft-Mask BERT(字节)</td>
<td style="text-align: left;"></td>
<td
style="text-align: left;">增加纠错检测模块，用错误检测概率控制纠错模块，减少过纠问题</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">SCFL(ebay)</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">seq2seq</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">HeadFit(加利福尼亚)</td>
<td style="text-align: left;"></td>
<td
style="text-align: left;">treeLSTM模型学习字形向量，取代固定的混淆集</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<h3 id="业务中主要存在的问题">业务中主要存在的问题</h3>
<p>1、多数方案通过将字音字形信息融入到模型学习中，解决纠错问题主要因为字音字形相似等带来的错误
2、在输入连续出错等纠错问题上，还面临着很多的挑战</p>
<h2 id="参考文献">参考文献</h2>
<p>[1]Lee L H, Yu L C, Chang L P. Guest Editoral: Special Issue on
Chinese as a Foreign Language[J]. International Journal of Computational
Linguistics &amp; Chinese Language Processing, Volume 20, Number 1, June
2015-Special Issue on Chinese as a Foreign Language, 2015, 20(1).</p>
<p>[2]Yu J, Li Z. Chinese spelling error detection and correction based
on language model, pronunciation, and shape[C]//Proceedings of The Third
CIPS-SIGHAN Joint Conference on Chinese Language Processing. 2014:
220-223.</p>
<p>[3] Lv, Y.Y.; Deng, Y.I.; Liu, M.L.; Lu, Q.Y. Automatic error
checking and correction of electronic medical records. Front. Artif.
Intell. Appl. 2016, 281, 32–40. 无法下载，需要钱</p>
<p>[4] Liu X, Cheng K, Luo Y, et al. A hybrid Chinese spelling
correction using language model and statistical machine translation with
reranking[C]//Proceedings of the Seventh SIGHAN Workshop on Chinese
Language Processing. 2013: 54-58.</p>
<p>[5]Chen K Y, Lee H S, Lee C H, et al. A study of language modeling
for Chinese spelling check[C]//Proceedings of the Seventh SIGHAN
Workshop on Chinese Language Processing. 2013: 79-83.</p>
<p>[6]Xie W, Huang P, Zhang X, et al. Chinese spelling check system
based on n-gram model[C]//Proceedings of the Eighth SIGHAN Workshop on
Chinese Language Processing. 2015: 128-136.</p>
<p>[7] Zhao J, Liu H, Bao Z, et al. N-gram Model for Chinese Grammatical
Error Diagnosis[C]//Proceedings of the 4th Workshop on Natural Language
Processing Techniques for Educational Applications (NLPTEA 2017). 2017:
39-44.</p>
<p>[8] Jui-Feng Yeh, Sheng-Feng Li, Mei-Rong Wu, Wen-Yi Chen, and
Mao-Chuan Su. 2013. Chinese word spelling correction based on N-gram
ranked inverted index list. In Proceedings of the 7th SIGHAN Workshop on
Chinese Language Processing. 43–48.</p>
<p>[9] Zheng B, Che W, Guo J, et al. Chinese Grammatical Error Diagnosis
with Long Short-Term Memory Networks[C]//Proceedings of the 3rd Workshop
on Natural Language Processing Techniques for Educational Applications
(NLPTEA2016). 2016: 49-56.</p>
<p>[10] Xie P. Alibaba at IJCNLP-2017 Task 1: Embedding Grammatical
Features into LSTMs for Chinese Grammatical Error Diagnosis Task[J].
Proceedings of the IJCNLP 2017, Shared Tasks, 2017: 41-46.</p>
<p>[11] Wang, D. , Song, Y. , Li, J. , Han, J. , &amp; Zhang, H. .
(2018). A Hybrid Approach to Automatic Corpus Generation for Chinese
Spelling Check. Proceedings of the 2018 Conference on Empirical Methods
in Natural Language Processing.</p>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Wu, S. , Liu, C. , &amp; Lee, L. .
(2014). Chinese Spelling Check Evaluation at SIGHAN Bake-off 2013.
Sighan Workshop on Chinese Language Processing.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Liu, C. L. , Lai, M. H. , Tien, K. W.
, Chuang, Y. H. , S.-H., W. U. , &amp; Lee, C. Y. . (2011). Visually and
phonologically similar characters in incorrect chinese words: analyses,
identification, and applications. Acm Transactions on Asian Language
Information Processing, 10(2), 1-39.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>https://www.cnblogs.com/xiaoqi/p/BK-Tree.html<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>ttps://en.wikipedia.org/wiki/BK-tree<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Label Noise Learning</title>
    <url>/202203/20220304-label-noise-learning/</url>
    <content><![CDATA[<h2 id="序言">序言</h2>
<p>过参数化在深度学习时代常常被提到，它的神经网络参数个数甚至超过了
training sample
的个数，在实验中也体现出了非常好的效果。但是，一旦training
samples中带有一些噪声，整个模型就趋向于过拟合，没有办法很好地泛化到测试集。一般而言，training
samples带噪声的方式有两种，一是在 data points上加 Gaussian noise，二是
label noise. 我们这里主要探究第二种。</p>
<h2 id="存在噪声标注数据">存在噪声标注数据</h2>
<p>诸如数据增强、权重衰减、dropout和批量归一化等流行的正则化技术已经被广泛应用，但是它们本身并不能完全克服在噪声数据上过拟合问题。
### 1、噪声的类别</p>
<ol type="1">
<li><code>instance-independent label noise</code>:
现有大部分算算法都是针对这种类型的带噪数据进行的研究建模的，因为instance-dependent
建模比较复杂。</li>
</ol>
<ul>
<li>symmetric noise: 一个标签标错为其他类别的标签概率一样</li>
<li>asymmetric noise: 一个标签标错为其他类别的标签概率不一样</li>
<li>pair noise: 一个标签只会错标为对应的另外一种标签,
标错的是在这些标签对形式存在(a, b) <img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646207730120.png"
alt="Alt text" /></li>
</ul>
<ol start="2" type="1">
<li><code>instance-dependent label noise</code> ### 2、困难
（1）深度学习模型因为其高阶的表达方式，更容易受到label
noise的影响。</li>
</ol>
<h3
id="要获得一个鲁棒性的模型方法可以大致分为三类">3、要获得一个鲁棒性的模型，方法可以大致分为三类：</h3>
<p>（1）设计使用好的损失函数 （2）训练方式: Training architectures
methods （3）减少错误标注: Label correction methods.
噪声数据比重占比在8.0% ~38.5%范围内。</p>
<h3 id="常用概念">4、常用概念</h3>
<h4 id="label-transition"><strong>Label Transition</strong></h4>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646132202285.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646132138068.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<h4 id="memorization-effect"><strong>Memorization Effect</strong></h4>
<p><img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646132315328.png"
alt="Alt text" />
结果表明，DNN的权值在训练开始时仍保持在初始权值附近，在对noise
label过度拟合时开始偏离初始权值很远，这一现象也被称为DNN的记忆效应，即DNN倾向于首先学习简单和概括的模式，然后逐渐过度适应所有的噪声模式。因此，为了实现更好的泛化，通常采用提前停止和偏爱小损失训练实例来设计健壮的训练方法
<strong>Risk Minimization</strong> <img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646383784880.png"
alt="Alt text" />
一般采用经验风险最小化的迭代优化如下，而在非clean的dataset上直接使用该优化方法，将在泛化数据集上测试结果退化。
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646385418270.png"
alt="Alt text" />
一般情况下通过优化过程中降低或者屏蔽噪音sample影响以实现缓解退化的问题。
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646385503435.png"
alt="Alt text" /> <img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646385546244.png"
alt="Alt text" /></p>
<hr />
<h2 id="文献调研">文献调研</h2>
<h3 id="naf">1、NAF</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646228063756.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li>paper: Named Entity Recognition via Noise Aware Training Mechanism
with Data Filter（ACL-IJCNLP 2021 Findings）</li>
<li>论文链接：https://aclanthology.org/2021.findings-acl.423.pdf</li>
</ul>
<h4 id="问题定义">问题定义</h4>
<p>区分难样本和噪声样本仍然是一个挑战，特别是在过拟合的情况下变得更具挑战性。
存在歧义的hard sample与noise sample是比较难以分开的，因为hard
sample在训练初期也是具有较大loss的。 <img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646017261211.png"
alt="Alt text|400x400" /> #### Logit-Maximum-Difference (LMD) mechanism
（0）一般我们是NN之后的logist矩阵加softmax和损失，由于softmax是归一化的指数函数，这就使得logist矩阵中的值的变化不是通过线性变化反映出来，这给我们识别noise
sample带来了不公平。</p>
<p><img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1645781321621.png"
alt="Alt text" /> （1）上图中需要注意的是，noise
sample的情况下，相对差距比较其他两类：hard/easy sample 较小。</p>
<p><span class="math display">\[LMD(x, y) =
\frac{1}{T}\sum^T_{t=1}(min(Z_y^{(t)} -
max_{i!=y}Z_i^{(t)}))\]</span></p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646035706110.png"
alt="Alt text|center|400x300" />
<figcaption aria-hidden="true">Alt text|center|400x300</figcaption>
</figure>
<p>（2）训练过程中，刚开始几个epoch，模型总是倾向于学习正确的样品。这意味着即使有些样本即使贴上了错误的标签，模型仍然可以预测正确的结果。随着训练epoch过长，会出现overfitting的问题。如上图所示，在hard和noise
sample 中训练发现损失趋于一致。这就是在noise
sample中overfitting的一种现象。</p>
<h4 id="noise-tolerant-term-named-distrust-cross-entropydce">noise
tolerant term named Distrust-Cross-Entropy(DCE)</h4>
<p>（0）主要想法 - 在CRF的损失函数中添加DCE
项，用来平衡是否接受模型输出还是标注 - 超参数<span
class="math inline">\(\delta\)</span>越大，则越相信预测结果</p>
<p>（1）预测结果的分布 <span class="math display">\[
\begin{align*}
p &amp;= p(k\mid x)     \\
\end{align*}
\]</span> （2）标注结果分布是one-hot的分布，分布如下 <span
class="math display">\[
\begin{align*}
q &amp;= q(k\mid x)      \\
\end{align*}
\]</span> （3）则应用KL散度可以衡量预测与实际输出的分布差异。 <span
class="math display">\[
\begin{align*}
KL(q\mid\mid p)&amp;= H(q, p) - H(q) \\
\end{align*}
\]</span> （4）通过在基本损失函数基础上，引入DCE项，来 <span
class="math display">\[
\begin{align*}
L_{DCE} &amp;= - plog(\delta p+(1- \delta)q) \\
L_{In\_trust} &amp;= \alpha L_{CRF}+\beta L_{DCE}
\end{align*}
\]</span></p>
<blockquote>
<p>结论</p>
</blockquote>
<p>通过分析发现，<span
class="math inline">\(\delta\)</span>越大，那么就通过输出结果<span
class="math inline">\(p\)</span>学习，<span
class="math inline">\(\delta\)</span>越小，就通过<span
class="math inline">\(q\)</span>学些。 &gt; We observe that when is
larger, the model tends to learn from the p of the model output, and
when is smaller, the model tends to learn from the label q</p>
<blockquote>
<p>小结:
该方法通过分析难例与噪声标注之间的差异，添加额外项优化损失函数，减少noise
label对模型优化的影响。</p>
</blockquote>
<hr />
<h3 id="aum">2、AUM</h3>
<p><img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646209203901.png"
alt="Alt text" /> - paper: Identifying mislabeled data using the area
under the margin ranking</p>
<p>首先通过经验角度分析提出的noise label与hard
label之间的差异，得出经验判别条件。 <img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1645780487021.png"
alt="Alt text" /></p>
<p>Margin的定义如下所示，其中t代表是第t个epoch，x代表是输入的数据，y代表annotation
labe，z代表的是最终prediction的logits。由式子定义可知其可能会去到负数，当为负数的时候，代表模型预测的结果可能和真值结果存在不同，因此当前样本可能是噪声。
<span class="math display">\[M^{t}(x,y) = z^{t}_{y}(x) - max_{i !=
y}z^{t}_{i}(x)\]</span> 考虑到不同epoch
margin值可能是不一样的，因此作者定义了如下所示的AUM值，它相当于对前T个epoch的Margin值计算了平均。
<span class="math display">\[AUM(x, y) =
\frac{1}{T}\sum_{t=1}^T{M^t(x,y)}\]</span></p>
<p>AUM值越小代表这个样本越有可能是噪声数据，但是只根据ranking是没有办法得到一个绝对的划分。因此需要一个绝对的划分。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1645781193479.png"
alt="Alt text|center|500x400" />
<figcaption aria-hidden="true">Alt text|center|500x400</figcaption>
</figure>
<p>作者提出使用threshold
samples，作者从训练集合中抽样一部分数据出来作为threshold
samples，这部分数据会人为的指定噪声标签，并且加入训练。最终这部分数据的AUM前从高到底排序的90分位值即可以作为AUM的阈值，用于划分噪声数据和非噪声数据。</p>
<blockquote>
<p>该方法通过最大化margin的角度，减少噪声的影响。</p>
</blockquote>
<hr />
<h3 id="早停">早停</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646209122905.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li>paper: Hwanjun Song, Minseok Kim, Dongmin Park, &amp; Jae-Gil Lee
(2019). How does Early Stopping Help Generalization against Label Noise
arXiv: Learning.</li>
<li>链接地址:
https://ui.adsabs.harvard.edu/link_gateway/2019arXiv191108059S/arxiv:1911.08059</li>
</ul>
<p><img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646098782428.png"
alt="Alt text" />
探究了<code>Best point to early stop</code>与<code>Criterion of a maximal safe set</code></p>
<p>1、Best point to early stop</p>
<ul>
<li>Validation Heuristic: 准备一个干净的验证集<span
class="math inline">\(\mathcal{V}\)</span> <img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646099293021.png"
alt="Alt text" /></li>
<li>Noise-Rate Heuristic: 需要知道数据集的噪声率<span
class="math inline">\(\tau\)</span>， 但是在真实业务场景不容易获得。
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646099402925.png"
alt="Alt text" /></li>
</ul>
<p>2、Criterion of a maximal safe set</p>
<blockquote>
<p>该方法挖掘cleandata进行训练，规避noise label数据对模型的影响</p>
</blockquote>
<hr />
<h3 id="sop">4、SOP</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646206068555.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li>github: https://github.com/shengliu66/SOP</li>
<li>paper: Robust Training under Label Noise by
Over-parameterization</li>
</ul>
<p>这篇文章的思路其实并不复杂，我们需要在原有模型的基础上，对于每一个数据点增加一个
variable <span class="math inline">\(s_i\)</span>，它代表该数据点的
label noise，最后的目标函数就是 <img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646205879003.png"
alt="Alt text|center" />
其中，由于这个noise是具有sparse性质的，因此作者们沿用了先前若干文章中的技巧，采用了一种特殊的参数化方式：
<span class="math inline">\(s_i = u_i \odot u_i - v_i \odot v_i\)</span>
，当然其中还需要规定一下 <span class="math inline">\(u_i,
v_i\)</span>的取值范围，最终的优化问题是： <img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646206339359.png"
alt="Alt text" /></p>
<hr />
<h3 id="小结">5、小结</h3>
<ul>
<li>hard sample与noise label
sample是我们这块更关注的，但是这对难兄难弟又杂糅在一起，本文中多篇文章中对二者差异进行了经验结果分析，这个对于我们在实际业务数据上实验的时候可以提供一些思路。例如难例挖掘是不是就可以考虑利用这个特点？</li>
<li>如果业务数据中有噪声，可以考虑清理一个干净的validate
dataset。训练过程中的一些测评结果，对于评估模型设计是否合理，数据是否干净还是比较有用的。但是可能因为交付时间等外部原因，我们往往忽略这些中间结果。</li>
<li>这一块除了早停或者清洗验证集之外，还有就是训练时候能够将损失函数将noise
label的数据权重降低，而标样本的权重高一些。</li>
</ul>
<hr />
<h2 id="关于noise-label更多文献">关于noise label更多文献</h2>
<h3 id="矫正noise样本">矫正noise样本</h3>
<blockquote>
<p>Hwanjun Song, Minseok Kim, &amp; Jae-Gil Lee (2019). SELFIE:
Refurbishing Unclean Samples for Robust Deep Learning International
Conference on Machine Learning.</p>
</blockquote>
<p>我们的核心思想是有选择地更新和利用可高精度校正的不干净样本，从而逐步增加可用训练样本的数量</p>
<h3 id="关于noisy-labels-learning的综述">关于Noisy labels
learning的综述</h3>
<blockquote>
<p>Hwanjun Song, Minseok Kim, Dongmin Park, &amp; Jae-Gil Lee (2020).
Learning from Noisy Labels with Deep Neural Networks: A Survey arXiv:
Learning.</p>
</blockquote>
<p>通过有监督的学习使得模型对于有噪声的标签具有更好的鲁棒性。鲁棒损失函数和损失调整是为了修改损失函数或其损失值；鲁棒结构是为了更改体系结构以对噪声数据集的噪声转换矩阵进行建模；鲁棒正则化是为了使DNN减少对错误标记样本的过度拟合；样本选择是为了从带有噪声的训练数据中识别出带有真实标签的样本。除了监督学习之外，研究人员最近还尝试通过采用元学习和半监督学习来进一步提高噪声鲁棒性。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/Label-Noise-Learning/1646122219977.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<h3 id="其他资料">其他资料</h3>
<ul>
<li>https://github.com/songhwanjun/Awesome-Noisy-Labels</li>
<li>https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise</li>
<li>Open-set Label Noise Can Improve Robustness Against Inherent Label
Noise</li>
<li>Song, H., Kim, M., and Lee, J.-G. SELFIE: Refurbishing unclean
samples for robust deep learning. In ICML, pp.5907–5915, 2019.</li>
<li>Han, B. , Yao, Q. , Liu, T. , Niu, G. , Tsang, I. W. , &amp; Kwok,
J. T. , et al. (2020). A survey of label-noise representation learning:
past, present and future. https://arxiv.org/pdf/2011.04406v1.pdf</li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP 文本场景的数据优化</title>
    <url>/202203/20220310-nlp-text-data-augmentation/</url>
    <content><![CDATA[<h2 id="序言">序言</h2>
<p>数据增强（Data
Augmentation，简称DA），是指根据现有数据，合成新数据的一类方法。毕竟数据才是真正的效果天花板，有了更多数据后可以提升效果、增强模型泛化能力、提高鲁棒性等。数据增强主要在CV应用中比较常见，然而由于NLP任务天生的难度，类似CV的裁剪方法可能会改变语义，既要保证数据质量又要保证多样性，所以大家在做数据增强时要十分谨慎。</p>
<h3 id="数据增强的目的">数据增强的目的</h3>
<ul>
<li>在很多机器学习场景下，没有足够的数据（数据稀缺场景）来训练高质量的模型。</li>
<li>提高训练数据的多样性，从而得到在真实场景下（很多没有见过的数据）更好的泛化效果。</li>
<li>样本不均衡</li>
<li>为了模型安全，应对模型的对抗攻击。</li>
</ul>
<h3 id="nlp数据增强研究基本现状1">NLP数据增强研究基本现状<a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h3>
<ul>
<li>在CV上很成功，逐渐在NLP任务上发现有效</li>
<li>在文本分类<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>领域数据增强方法也比较多，其他任务例如NER，多标签分类等就相对少一些;</li>
<li>语言输入是离散，而且一定的文本改变容易引起文本分布的巨大改变，无法做到像图片那样不可见的抖动;</li>
<li>一般算法都可以从输入文本空间和文本编码空间进行数据增强。</li>
<li>对抗攻击:
相比较CV的对抗，文本的对抗存在很大差异。文本输入为离散的</li>
</ul>
<p>问题： -
数据增广在当前迁移学习大背景下的大规模预训练模型上有用吗？</p>
<hr />
<h2 id="data-augmentation-in-nlp">Data Augmentation in NLP</h2>
<p>Paraphrasing：对句子中的词、短语、句子结构做一些更改，保留原始的语义
Noising：在保证label不变的同时，增加一些离散或连续的噪声，对语义的影响不大
Sampling：旨在根据目前的数据分布选取新的样本，会生成更多样的数据</p>
<blockquote>
<p>Data Augmentation Approaches in Natural LanguageProcessing: A
Survey<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></p>
</blockquote>
<h3 id="paraphrasing">Paraphrasing</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646188514617.png"
alt="Alt text|center|600x350" />
<figcaption aria-hidden="true">Alt text|center|600x350</figcaption>
</figure>
<p>小结:
在尽可能保留句子整体语义的情况下，增加文本丰富度，包括让每个词拥有更加丰富的上下文context，让相似的语义表达有更多样的语法构成，词汇构成等等</p>
<h3 id="noiseing">Noiseing</h3>
<p>作者给出了以下5种增加噪声的方法： <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646188965975.png"
alt="Alt text|center|600x600" /></p>
<ul>
<li><strong>Swapping</strong>：除了交换词之外，在分类任务中也可以交换instance或者sentence</li>
<li><strong>Deletion</strong>：可以根据tf-idf等词的重要程度进行删除</li>
<li><strong>Insertion</strong>：可以把同义词随机插入句子中</li>
<li><strong>Substitution</strong>：把一些词随机替换成其他词（非同义），模拟misspelling的场景。为了避免改变label，可以使用label-independent的词，或者利用训练数据中的其他句子</li>
<li><strong>Mixup</strong>：这个方法最近两年比较火，把句子表示和标签分别以一定权重融合，引入连续噪声，可以生成不同label之间的数据，但可解释性较差
总的来说，引入噪声的DA方法使用简单，但会对句子结构和语义造成影响，多样性有限，主要还是提升鲁棒性。
ConSERT时用到的方法：</li>
<li>对抗样本</li>
<li><strong>Dropout</strong>：也是SimCSE用到的，还有R-drop，都是通过dropout来加入连续噪声</li>
<li><strong>Feature
Cut-off</strong>：比如BERT的向量都是768维，可以随机把一些维度置为0，这个效果也不错</li>
</ul>
<p>小结： 增加模型稳健性，在不过多影响training
error的前提下，降低模型的复杂度从而降低generalization error,
类比dropout，l2，random noise injection</p>
<h3 id="sampling">Sampling</h3>
<p><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646189105516.png"
alt="Alt text|center|750x500" />
Sampling是指从数据分布中采样出新的样本，不同于较通用的paraphrasing，<strong>采样更依赖任务，需要在保证数据可靠性的同时增加更多多样性</strong>，比前两个数据增强方法更难。作者整理了4种方法：
- Rules：用规则定义新的样本和label，比如把句子中的主谓进行变换 - Seq2Seq
Models：根据输入和label生成新的句子，比如在NLI任务中，有研究者先为每个label（entailment，contradiction，neutral）训一个生成模型，再给定新的句子，生成对应label的。对比之下，paraphrasing主要是根据当前训练样本进行复述
- Language
Models：给定label，利用语言模型生成样本，有点像前阵子看的谷歌UDG。有些研究会加个判别模型过滤
-
Self-training：先有监督训练一个模型，再给无监督数据打一些标签，有点蒸馏的感觉</p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646189330930.png"
alt="Alt text|center|600x250" />
<figcaption aria-hidden="true">Alt text|center|600x250</figcaption>
</figure>
<h3 id="增强方法选择依据">增强方法选择依据</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646136022521.png"
alt="三种类别的数据增强方法特点总结" />
<figcaption
aria-hidden="true">三种类别的数据增强方法特点总结</figcaption>
</figure>
<p>Method Stacking
实际应用时可以应用多种方法、或者一种方法的不同粒度。</p>
<p>作者推荐了两款工具eda<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>和uda<a href="#fn5"
class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>,
eda_chinese<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a>, nlpaug<a href="#fn7"
class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>第一，在使用增强的数据时，如果数据质量不高，可以先让模型在增强后的数据上pre-train，之后再用有标注数据训练。如果要一起训练，在增强数据量过大的情况下，可以对原始训练数据过采样</p>
<p>第二，在进行数据增强时注意这些超参数的调整： <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646188644628.png"
alt="各种方法的超参数" />
第三，其实增强很多简单数据的提升有限，可以注重困难样本的生成。比如有研究加入对抗训练、强化学习、在loss上下文章等。如果用生成方法做数据增强，也可以在生成模型上做功夫，提升数据多样性。</p>
<p>第四，如果生成错数据可能引入更多噪声，可以增加其他模型对准确性进行过滤。</p>
<hr />
<h2 id="分类任务">分类任务</h2>
<p>1、Mixup: Mixup-Transformer: Dynamic Data Augmentation for NLP
Tasks</p>
<p><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646137192219.png"
alt="Alt text" /> <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646137248012.png"
alt="Alt text|center|500x60" /></p>
<p>在数据不足的情况下，只用40%的数据就可以比不应用增强方案的全量数据好。应用Mixup增强方法可以提升2.46%</p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646137280265.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>2、On Data Augmentation for Extreme Multi-label Classification</p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646186960277.png"
alt="Alt text|center|700x300" />
<figcaption aria-hidden="true">Alt text|center|700x300</figcaption>
</figure>
<p>3、分类算法中的数据增强方法：综述 <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1645604082568.png"
alt="Alt text|center|600x400" /> <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1645604849595.png"
alt="Alt text" /></p>
<p>这些在线blog或者paper<a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a><a href="#fn9" class="footnote-ref"
id="fnref9" role="doc-noteref"><sup>9</sup></a><a href="#fn10"
class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a>中提到了很多增强方法，主要有如下特点
- 多分类任务，为英文任务 -
有针对不同应用场景进行分析的增强方法。虽然现在都用预训练模型，但是在数据增强方法中，通过额外的静态词embedding进行数据增强也是常见的方法。</p>
<p>4、EDA <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646222933734.png"
alt="Alt text" /> - paper:EDA: Easy Data Augmentation Techniques for
Boosting Performance on Text Classification Tasks - github:
http://github.com/jasonwei20/eda_nlp</p>
<table>
<colgroup>
<col style="width: 57%" />
<col style="width: 42%" />
</colgroup>
<thead>
<tr class="header">
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646222990348.png"
alt="Alt text" /></th>
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646223064013.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>EDA主要采用表一中的同义词替换，随机插入，随机交换，随机删除，从可视化结果中来看，增强样本与原始样本分布基本是一致的。
作者给出了在实际使用EDA方法的建议，表格的左边是数据的规模<span
class="math inline">\(N_{train}\)</span>, 右边<span
class="math inline">\(\alpha\)</span>是概率、比率
比如同义词替换中，替换的单词数<span class="math inline">\(n=\alpha *
l\)</span> , <span
class="math inline">\(l\)</span>是句子长度。随机插入、随机替换类似.
<span class="math inline">\(p=\alpha * n_{aug}\)</span>
代表使用EDA方法从每一个句子拓展出的句子数量。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646223830686.png"
alt="@作者的一些建议|center|400x250" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="作者的一些建议">@作者的一些建议</span>|center|400x250</figcaption>
</figure>
<p>之后，又有新的AEDA <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646706227382.png"
alt="Alt text" /></p>
<p><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646706325216.png"
alt="Alt text" /> <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646706374163.png"
alt="Alt text" /></p>
<h3 id="text-smoothing">Text Smoothing</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646230538691.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<table>
<colgroup>
<col style="width: 40%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr class="header">
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646231331146.png"
alt="Alt text" /></th>
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646231274699.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentence = <span class="string">&quot;My favorite fruit is pear .&quot;</span></span><br><span class="line">lambd = <span class="number">0.1</span> <span class="comment"># interpolation hyperparameter</span></span><br><span class="line">mlm.train() <span class="comment"># enable dropout, dynamically mask</span></span><br><span class="line">tensor_input = tokenizer(sentence, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">onehot_repr = convert_to_onehot(**tensor_input)</span><br><span class="line">smoothed_repr = softmax(mlm(**tensor_input).logits[<span class="number">0</span>])</span><br><span class="line">interpolated_repr = lambd * onehot_repr + (<span class="number">1</span> - lambd) * smoothed_repr</span><br></pre></td></tr></table></figure>
<p>-code: https://github.com/1024er/cbert_aug</p>
<h3 id="promda">PromDA</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646230729158.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li>paper:https://arxiv.org/pdf/2202.12230.pdf</li>
<li>论文目的: low-resource Natural Language Understanding (NLU)
tasks</li>
</ul>
<p>少数据的场景，可能使用PLM不是最优的方案 我们期望构造的数据<span
class="math inline">\(\mathcal{T}_{LM}\)</span>与已有的数据集<span
class="math inline">\(\mathcal{T}\)</span>不同，能够从中学习到一些新的信息。
冻结PLMs参数可能有助于在训练过程中进行泛化。然而，寻找合适的离散任务引入并不容易以端到端方式进行优化，而且需要额外的人力。</p>
<p>引入<strong><span class="math inline">\(soft Prompt\)</span></strong>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646293404485.png"
alt="Alt text" /></p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646293377383.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<table>
<colgroup>
<col style="width: 42%" />
<col style="width: 57%" />
</colgroup>
<thead>
<tr class="header">
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646293978880.png"
alt="Alt text" /></th>
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646293992580.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<h3 id="dualcl">DualCL</h3>
<p><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646310646415.png"
alt="Alt text" /> - paper: Dual Contrastive Learning: Text
Classification via Label-Aware Data Augmentation - github:
https://github.com/hiyouga/Dual-Contrastive-Learning - 设计主要思想:
将类别与文本表征map到同一个空间</p>
<p>传统自监督对比学习损失函数定义如下左侧公式，但是没有利用标注信息。将标注信息考虑进去，
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646312021136.png"
alt="Alt text" />|<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646312125044.png"
alt="Alt text" /> ---|---</p>
<p>到目前为止发展起来的监督对比学习似乎是对分类问题的无监督对比学习的一种简单朴素的适配。</p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646310912179.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646311085696.png"
alt="Alt text" /> - K+1+ 其他文本 -
学习到多个表征，其中1个原来的[CLS],另外K个是用来判断分类的结果的。<span
class="math display">\[ \hat{y}_i = \arg\max_k(\theta_i^k \cdot
z_i)\]</span></p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646314581520.png"
alt="Alt text" /></th>
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646314822901.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>算法对比结果，少样本与全样本的对比： <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646314344445.png"
alt="Alt text" /></p>
<h3
id="sample-efficiency-of-data-augmentation-consistency-regularization">Sample
Efficiency of Data Augmentation Consistency Regularization</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646275561190.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>DA-ERM（data augmentation empirical risk minimization）:
DAC可以使用未标记的样本，因为可以在不知道真实标签的情况下增加训练样本并执行一致的预测。这绕过了传统算法只能增加标记样本并将其添加到训练集的限制
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646279148266.png"
alt="Alt text" /></p>
<p>少量数据+data augmentation 少量数据+unlabel data</p>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646277330450.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646277346685.png"
alt="Alt text|center" /> 我们可以看到对标注样本<span
class="math inline">\(\phi(x_i)\)</span>和增强产生的样本<span
class="math inline">\(\phi(x_{i,j})\)</span>之间的差异作为惩罚项。</p>
<p>我们从经验和理论上论证了DAC与DA-ERM(用增强样本扩展训练集)相比的优点。理论上，线性回归和逻辑回归的泛化误差更小，两层神经网络的泛化上界更紧。另一个好处是，DAC可以更好地处理由强扩充数据引起的模型错误规范。在经验上，我们提供了关于增广ERM和一致性正则化的比较。这些共同证明了一致性规则化优于DA-ERM的有效性</p>
<h3
id="alp-data-augmentation-using-lexicalized-pcfgs-for-few-shot-text-classification">ALP:
Data Augmentation using Lexicalized PCFGs for Few-Shot Text
Classification</h3>
<ul>
<li>标题：ALP：基于词汇化PCFGS的Few-Shot文本分类数据增强</li>
<li>链接：https://arxiv.org/abs/2112.11916</li>
<li>作者：Hazel Kim,Daecheol Woo,Seong Joon Oh,Jeong-Won Cha,Yo-Sub
Han</li>
<li>机构： Yonsei University, Seoul, Republic of Korea, NAVER AI Lab,
Changwon National University, Changwon, Republic of Korea</li>
<li>备注：Accepted to AAAI2022</li>
</ul>
<p>这个是基于文法分析树的方式进行数据增强的</p>
<h2 id="nerprompt-base在ner中的应用">NER[^prompt base在NER中的应用]</h2>
<p>该任务中需要生成句子和token级别的标签。且序列标注为细粒度的文本任务。
现有的生成模型智能生成没有标签的序列；
启发式的数据增强方法不可行，直接对标签替换或者上下文替换，被注入错误的可能性比较大，相比较分类任务更容易破坏序列上下文关系。</p>
<h3
id="an-analysis-of-simple-data-augmentation-for-named-entity-recognition">An
Analysis of Simple Data Augmentation for Named Entity Recognition</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646365385449.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646362751796.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li><strong>Label-wise token replacement (LwTR)
</strong>：即同标签token替换，对于每一token通过二项分布来选择是否被替换；如果被替换，则从训练集中选择相同的token进行替换。</li>
<li><strong>Synonym replacement (SR)
</strong>：即同义词替换，利用WordNet查询同义词，然后根据二项分布随机替换。如果替换的同义词大于1个token，那就依次延展BIO标签。</li>
<li><strong>Mention replacement (MR)
</strong>：即实体提及替换，与同义词方法类似，利用训练集中的相同实体类型进行替换，如果替换的mention大于1个token，那就依次延展BIO标签，如上图：「headache」替换为「neuropathic
pain syndrome」，依次延展BIO标签。</li>
<li><strong>Shuffle within segments (SiS)</strong>
：按照mention来切分句子，然后再对每个切分后的片段进行shuffle。如上图，共分为5个片段：
[She did not complain of], [headache], [or], [any other neurological
symptoms], [.].
。也是通过二项分布判断是否被shuffle（mention片段不会被shuffle），如果shuffle，则打乱片段中的token顺序。</li>
</ul>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646362972193.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>由上图可以看出： -
各种数据增强方法都超过不使用任何增强时的baseline效果。 -
对于RNN网络，实体提及替换优于其他方法；对于Transformer网络，同义词替换最优。
- 总体上看，所有增强方法一起使用（ALL）会优于单独的增强方法。 -
低资源条件下，数据增强效果增益更加明显；充分数据条件下，数据增强可能会带来噪声，甚至导致指标下降；</p>
<h3
id="daga-data-augmentatino-with-a-generation-approach-for-low-resource-tagging-tasks">DAGA:
Data Augmentatino with a Generation Approach for Low-resource Tagging
Tasks</h3>
<figure>
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646360274558.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>DAGA的思想简单来讲就是标签线性化：即将原始的<strong>「序列标注标签」与「句子token」进行混合，也就是变成「Tag-Word」</strong>的形式，如下图：将「B-PER」放置在「Jose」之前，将「E-PER」放置在「Valentin」之前；对于标签「O」则不与句子混合。标签线性化后就可以生成一个句子了，文章基于此句子就可以进行「语言模型生成」了。
<img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646360089845.png"
alt="Alt text" /></p>
<h3 id="seqmix">SeqMix</h3>
<p><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646315932079.png"
alt="Alt text" /> - 标题: SeqMix: Augmenting Active Sequence Labeling
via Sequence Mixup - 链接:
https://rongzhizhang.org/pdf/emnlp20_SeqMix.pdf - 开源代码:
https://github.com/rz-zhang/SeqMix - 备注: EMNLP 2020 <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646375796885.png"
alt="Alt text" /></p>
<h3 id="boundary-smoothing-for-named-entity-recognition">Boundary
Smoothing for Named Entity Recognition</h3>
<p><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646817503789.png"
alt="Alt text" /> - 标题: 针对命名实体识别的span类的算法的边界平滑 -
code: https://github.com/syuoni/eznlp</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646816331157.png"
alt="Alt text" /></th>
<th><img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646816353297.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>An example of hard and smoothed boundaries. The example sentence has
ten tokens and two entities of spans (1, 2) and (3, 7), colored in red
and blue, respectively. The first subfigure presents the entity
recognition targets of hard boundaries. The second subfigure presents
the corresponding targets of smoothed boundaries, where the span (1, 2)
is smoothed by a size of 1, and the span (3, 7) is smoothed by a size of
2. 其中周边区域有<span
class="math inline">\(\epsilon\)</span>的概率会被赋值，此时原标注位置值为<span
class="math inline">\(1 - \epsilon\)</span>，周边区域<span
class="math inline">\(D\)</span>赋值<span class="math inline">\(\epsilon
/ D\)</span>,</p>
<p>对NER标签位置的平滑处理，提升模型的泛化性。边界平滑可以防止模型对预测实体过于自信，从而获得更好的定标效果。D一般不用太大，1或者2即可，
<span class="math inline">\(\epsilon\)</span>一般取[0.1, 0.2, 0.3] <img data-src="https://cwlseu.github.io/images/nlp/NLP文本场景的数据优化/1646816933595.png"
alt="Alt text" /></p>
<p>[^prompt
base在NER中的应用]:https://zhuanlan.zhihu.com/p/462332297</p>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Steven Y. Feng, Varun Gangal, Jason
Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, &amp; Eduard
Hovy (2021). A Survey of Data Augmentation Approaches for NLP Meeting of
the Association for Computational Linguistics.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Markus Bayer, Marc-André Kaufhold,
&amp; Christian Reuter (2021). A Survey on Data Augmentation for Text
Classification.. arXiv: Computation and Language.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Li, B. , Hou, Y. , &amp; Che, W. .
(2021). Data augmentation approaches in natural language processing: a
survey.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://github.com/jasonwei20/eda_nlp<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>https://github.com/google-research/uda<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://github.com/zhanlaoban/eda_nlp_for_Chinese<a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"
role="doc-endnote"><p>https://github.com/makcedward/nlpaug<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Steven Y. Feng, Varun Gangal, Jason
Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, &amp; Eduard
Hovy (2021). A Survey of Data Augmentation Approaches for NLP Meeting of
the Association for Computational Linguistics.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Markus Bayer, Marc-André Kaufhold,
&amp; Christian Reuter (2021). A Survey on Data Augmentation for Text
Classification.. arXiv: Computation and Language.<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Amit Chaudhary(2020). A Visual
Survey of Data Augmentation in NLP.
https://amitness.com/2020/05/data-augmentation-for-nlp<a href="#fnref10"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
</search>

<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>开发: Linux常用命令</title>
    <url>/201601/20160131-basic-linux-command/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>Linux中的命令的确是非常多，但是我们只需要掌握我们最常用的命令就可以了。当然你也可以在使用时去找一下man，他会帮你解决不少的问题。然而每个人玩Linux的目的都不同，所以他们常用的命令也就差异非常大。因为不想在使用是总是东查西找，所以在此总结一下，方便一下以后的查看。不多说，</p>
<h2 id="常用的linux命令">常用的Linux命令。</h2>
<ol type="1">
<li>cd命令</li>
</ol>
<p>这是一个非常基本，也是大家经常需要使用的命令，它用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径。如：</p>
<pre><code>cd /root/Docements # 切换到目录/root/Docements  
cd ./path          # 切换到当前目录下的path目录中，“.”表示当前目录    
cd ../path         # 切换到上层目录中的path目录中，“..”表示上一层目录 </code></pre>
<ol start="2" type="1">
<li>ls命令</li>
</ol>
<p>这是一个非常有用的查看文件与目录的命令，list之意，它的参数非常多，下面就列出一些我常用的参数吧，如下：</p>
<pre><code>-l ：列出长数据串，包含文件的属性与权限数据等  
-a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用）  
-d ：仅列出目录本身，而不是列出目录的文件数据  
-h ：将文件容量以较易读的方式（GB，kB等）列出来  
-R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来  </code></pre>
<p>注：这些参数也可以组合使用，下面举两个例子：</p>
<pre><code>ls -l #以长数据串的形式列出当前目录下的数据文件和目录  
ls -lR #以长数据串的形式列出当前目录下的所有文件  </code></pre>
<ol start="3" type="1">
<li>grep命令
该命令常用于分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等等，它的简单语法为
<code>grep [-acinv] [--color=auto] '查找字符串' filename</code></li>
</ol>
<p>它的常用参数如下：</p>
<pre><code>-a ：将binary文件以text文件的方式查找数据  
-c ：计算找到‘查找字符串’的次数  
-i ：忽略大小写的区别，即把大小写视为相同  
-v ：反向选择，即显示出没有‘查找字符串’内容的那一行  </code></pre>
<p>例如：<br />
取出文件/etc/man.config中包含MANPATH的行，并把找到的关键字加上颜色<br />
<code>grep --color=auto 'MANPATH' /etc/man.config</code><br />
把ls -l的输出中包含字母file（不区分大小写）的内容输出<br />
<code>ls -l | grep -i file</code> 4. find命令
find是一个基于查找的功能非常强大的命令，相对而言，它的使用也相对较为复杂，参数也比较多，所以在这里将给把它们分类列出，它的基本语法如下：
<code>find [PATH] [option] [action]</code></p>
<p><em>与时间有关的参数</em></p>
<pre><code>-mtime n : n为数字，意思为在n天之前的“一天内”被更改过的文件；  
-mtime +n : 列出在n天之前（不含n天本身）被更改过的文件名；  
-mtime -n : 列出在n天之内（含n天本身）被更改过的文件名；  
-newer file : 列出比file还要新的文件名  </code></pre>
<p>例如：<br />
<code>find /root -mtime 0 # 在当前目录下查找今天之内有改动的文件</code></p>
<p><em>与用户或用户组名有关的参数</em></p>
<pre><code>-user name : 列出文件所有者为name的文件  
-group name : 列出文件所属用户组为name的文件  
-uid n : 列出文件所有者为用户ID为n的文件  
-gid n : 列出文件所属用户组为用户组ID为n的文件  </code></pre>
<p>例如：<br />
<code>find /home/charles -user charles #</code>在目录/home/ljianhui中找出所有者为ljianhui的文件</p>
<p><em>与文件权限及名称有关的参数</em>：</p>
<pre><code>-name filename ：找出文件名为filename的文件  
-size [+-]SIZE ：找出比SIZE还要大（+）或小（-）的文件  
-tpye TYPE ：查找文件的类型为TYPE的文件，TYPE的值主要有：一般文件（f)、设备文件（b、c）、  
             目录（d）、连接文件（l）、socket（s）、FIFO管道文件（p）；  
-perm mode ：查找文件权限刚好等于mode的文件，mode用数字表示，如0755；  
-perm -mode ：查找文件权限必须要全部包括mode权限的文件，mode用数字表示  
-perm +mode ：查找文件权限包含任一mode的权限的文件，mode用数字表示  </code></pre>
<p>例如：</p>
<pre><code>find / -name passwd # 查找文件名为passwd的文件  
find . -perm 0755 # 查找当前目录中文件权限的0755的文件  
find . -size +12k # 查找当前目录中大于12KB的文件，注意c表示byte  </code></pre>
<ol start="5" type="1">
<li>cp命令</li>
</ol>
<p>该命令用于复制文件，copy之意，它还可以把多个文件一次性地复制到一个目录下，它的
常用参数如下：</p>
<pre><code>-a ：将文件的特性一起复制  
-p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份  
-i ：若目标文件已经存在时，在覆盖时会先询问操作的进行  
-r ：递归持续复制，用于目录的复制行为  
-u ：目标文件与源文件有差异时才会复制  </code></pre>
<p>例如 ：</p>
<pre><code>cp -a file1 file2 #连同文件的所有特性把文件file1复制成文件file2  
cp file1 file2 file3 dir #把文件file1、file2、file3复制到目录dir中</code></pre>
<ol start="6" type="1">
<li>mv命令</li>
</ol>
<p>该命令用于移动文件、目录或更名，move之意，它的常用参数如下：</p>
<pre><code>-f ：force强制的意思，如果目标文件已经存在，不会询问而直接覆盖  
-i ：若目标文件已经存在，就会询问是否覆盖  
-u ：若目标文件已经存在，且比目标文件新，才会更新  </code></pre>
<p>注：该命令可以把一个文件或多个文件一次移动一个文件夹中，但是最后一个目标文件一定要是“目录”。</p>
<p>例如：</p>
<pre><code>mv file1 file2 file3 dir # 把文件file1、file2、file3移动到目录dir中  
mv file1 file2 # 把文件file1重命名为file2  </code></pre>
<ol start="7" type="1">
<li>rm命令</li>
</ol>
<p>该命令用于删除文件或目录，remove之间，它的常用参数如下：</p>
<pre><code>-f ：就是force的意思，忽略不存在的文件，不会出现警告消息  
-i ：互动模式，在删除前会询问用户是否操作  
-r ：递归删除，最常用于目录删除，它是一个非常危险的参数  </code></pre>
<p>例如：</p>
<pre><code>rm -i file # 删除文件file，在删除之前会询问是否进行该操作  
rm -fr dir # 强制删除目录dir中的所有文件</code></pre>
<ol start="8" type="1">
<li>ps命令</li>
</ol>
<p>该命令用于将某个时间点的进程运行情况选取下来并输出，process之意，它的常用参数如下：</p>
<pre><code>-A ：所有的进程均显示出来  
-a ：不与terminal有关的所有进程  
-u ：有效用户的相关进程  
-x ：一般与a参数一起使用，可列出较完整的信息  
-l ：较长，较详细地将PID的信息列出  </code></pre>
<p>其实我们只要记住ps一般使用的命令参数搭配即可，它们并不多，如下：</p>
<pre><code>ps aux # 查看系统所有的进程数据  
ps ax # 查看不与terminal有关的所有进程  
ps -lA # 查看系统所有的进程数据  
ps axjf # 查看连同一部分进程树状态  </code></pre>
<ol start="9" type="1">
<li>kill命令
该命令用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用，它的基本语法如下：</li>
</ol>
<p>kill -signal PID<br />
signal的常用参数如下：
注：最前面的数字为信号的代号，使用时可以用代号代替相应的信号。</p>
<pre><code>1：SIGHUP，启动被终止的进程  
2：SIGINT，相当于输入ctrl+c，中断一个程序的进行  
9：SIGKILL，强制中断一个进程的进行  
15：SIGTERM，以正常的结束进程方式来终止进程  
17：SIGSTOP，相当于输入ctrl+z，暂停一个进程的进行  </code></pre>
<p>例如：</p>
<p>以正常的结束进程方式来终于第一个后台工作，可用jobs命令查看后台中的第一个工作进程<br />
kill -SIGTERM %1<br />
重新改动进程ID为PID的进程，PID可用ps命令通过管道命令加上grep命令进行筛选获得<br />
kill -SIGHUP PID</p>
<ol start="10" type="1">
<li>killall命令
该命令用于向一个命令启动的进程发送一个信号，它的一般语法如下：</li>
</ol>
<p><code>killall [-iIe] [command name]</code><br />
它的参数如下：</p>
<pre><code>-i ：交互式的意思，若需要删除时，会询问用户  
-e ：表示后面接的command name要一致，但command name不能超过15个字符  
-I ：命令名称忽略大小写  </code></pre>
<p>例如：<br />
<code>killall -SIGHUP syslogd</code> # 重新启动syslogd</p>
<ol start="11" type="1">
<li>file命令
该命令用于判断接在file命令后的文件的基本数据，因为在Linux下文件的类型并不是以后缀为分的，所以这个命令对我们来说就很有用了，它的用法非常简单，基本语法如下：</li>
</ol>
<p>file filename<br />
例如：<br />
file ./test</p>
<ol start="12" type="1">
<li>tar命令</li>
</ol>
<p>该命令用于对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如gzip和bzip等）进行压缩和解压。它的常用参数如下：</p>
<pre><code>-c ：新建打包文件  
-t ：查看打包文件的内容含有哪些文件名  
-x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中  
-j ：通过bzip2的支持进行压缩/解压缩  
-z ：通过gzip的支持进行压缩/解压缩  
-v ：在压缩/解压缩过程中，将正在处理的文件名显示出来  
-f filename ：filename为要处理的文件  
-C dir ：指定压缩/解压缩的目录dir  </code></pre>
<p>上面的解说可以已经让你晕过去了，但是通常我们只需要记住下面三条命令即可：</p>
<pre><code>压缩：tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称  
查询：tar -jtv -f filename.tar.bz2  
解压：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录  </code></pre>
<p>注：文件名并不定要以后缀tar.bz2结尾，这里主要是为了说明使用的压缩程序为bzip2</p>
<ol start="13" type="1">
<li><p>cat命令
该命令用于查看文本文件的内容，后接要查看的文件名，通常可用管道与more和less一起使用，从而可以一页页地查看数据。例如：</p>
<p>cat text | less # 查看text文件中的内容<br />
注：这条命令也可以使用less text来代替<br />
</p></li>
<li><p>chgrp命令
该命令用于改变文件所属用户组，它的使用非常简单，它的基本用法如下：</p></li>
</ol>
<p><code>chgrp [-R] dirname/filename</code><br />
-R ：进行递归的持续对所有文件和子目录更改<br />
例如：<br />
<code>chgrp users -R ./dir #</code>递归地把dir目录下中的所有文件和子目录下所有文件的用户组修改为users<br />
15. chown命令
该命令用于改变文件的所有者，与chgrp命令的使用方法相同，只是修改的文件属性不同，不再详述。</p>
<ol start="16" type="1">
<li>chmod命令 该命令用于改变文件的权限，一般的用法如下：
<code>chmod [-R] xyz 文件或目录</code>
<code>-R：进行递归的持续更改，即连同子目录下的所有文件都会更改</code><br />
同时，chmod还可以使用u（user）、g（group）、o（other）、a（all）和+（加入）、-（删除）、=（设置）跟rwx搭配来对文件的权限进行更改。</li>
</ol>
<p>例如：</p>
<pre><code>chmod 0755 file # 把file的文件权限改变为-rxwr-xr-x  
chmod g+w file # 向file的文件权限中加入用户组可写权限 </code></pre>
<ol start="18" type="1">
<li><p>vim命令
该命令主要用于文本编辑，它接一个或多个文件名作为参数，如果文件存在就打开，如果文件不存在就以该文件名创建一个文件。vim是一个非常好用的文本编辑器，它里面有很多非常好用的命令，在这里不再多说。你可以从这里下载vim常用操作的详细说明。</p></li>
<li><p>gcc命令
对于一个用Linux开发C程序的人来说，这个命令就非常重要了，它用于把C语言的源程序文件，编译成可执行程序，由于g++的很多参数跟它非常相似，所以这里只介绍gcc的参数，它的常用参数如下：</p>
<p>-o ：output之意，用于指定生成一个可执行文件的文件名<br />
-c ：用于把源文件生成目标文件（.o)，并阻止编译器创建一个完整的程序<br />
-I ：增加编译时搜索头文件的路径<br />
-L ：增加编译时搜索静态连接库的路径<br />
-S ：把源文件生成汇编代码文件<br />
-lm：表示标准库的目录中名为libm.a的函数库<br />
-lpthread ：连接NPTL实现的线程库<br />
-std= ：用于指定把使用的C语言的版本</p></li>
</ol>
<p>例如：<br />
把源文件test.c按照c99标准编译成可执行程序test<br />
gcc -o test test.c -lm -std=c99<br />
把源文件test.c转换为相应的汇编程序源文件test.s<br />
gcc -S test.c</p>
<p>20。time命令
该命令用于测算一个命令（即程序）的执行时间。它的使用非常简单，就像平时输入命令一样，不过在命令的前面加入一个time即可，例如：</p>
<pre><code>time ./process  
time ps aux  </code></pre>
<p>在程序或命令运行结束后，在最后输出了三个时间，它们分别是：
user：用户CPU时间，命令执行完成花费的用户CPU时间，即命令在用户态中执行时间总和；
system：系统CPU时间，命令执行完成花费的系统CPU时间，即命令在核心态中执行时间总和；
real：实际时间，从command命令行开始执行到运行终止的消逝时间；</p>
<p>注：用户CPU时间和系统CPU时间之和为CPU时间，即命令占用CPU执行的时间总和。实际时间要大于CPU时间，因为Linux是多任务操作系统，往往在执行一条命令时，系统还要处理其它任务。另一个需要注意的问题是即使每次执行相同命令，但所花费的时间也是不一样，其花费时间是与系统运行相关的。</p>
<h2 id="系统信息">系统信息</h2>
<ol type="1">
<li><p>uname</p>
<p>Usage: uname [OPTION]... Print certain system information. With no
OPTION, same as -s.</p>
<p>-a, --all print all information, in the following order, except omit
-p and -i if unknown: -s, --kernel-name print the kernel name -n,
--nodename print the network node hostname -r, --kernel-release print
the kernel release -v, --kernel-version print the kernel version -m,
--machine print the machine hardware name -p, --processor print the
processor type (non-portable) -i, --hardware-platform print the hardware
platform (non-portable) -o, --operating-system print the operating
system --help display this help and exit --version output version
information and exit 如<code>uname -p</code>
将得到处理器类型为<code>x86_64</code></p></li>
<li><p>nvidia-smi -l 1 循环显示当前显卡状态 <img
src="https://cwlseu.github.io/images/linux/nvidia-smi.JPG"
alt="@nvidia显示示例图" /></p></li>
<li><p>查看机器cpu信息</p></li>
</ol>
<ul>
<li><p>查看物理CPU的个数
<code>cat /proc/cpuinfo | grep "physical id" | sort | uniq | wc -l</code></p></li>
<li><p>查看逻辑CPU的个数
<code>cat /proc/cpuinfo | grep "processor" | wc -l</code></p></li>
<li><p>查看CPU是几核
<code>cat /proc/cpuinfo | grep "cores" | uniq</code></p></li>
<li><p>查看CPU的主频
<code>cat /proc/cpuinfo | grep MHz | uniq</code></p></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux开发</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>开发：Shell 学习之路</title>
    <url>/201609/20160901-basic-shell-in-linux/</url>
    <content><![CDATA[<h2 id="简单介绍">简单介绍</h2>
<p>你能不能用shell判断一个文件中的数字是否有序啊？想想这不挺简单的吗，就开始动手写了，然后就有了这个版本。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!bin/sh</span></span><br><span class="line"></span><br><span class="line">filename=<span class="variable">$1</span></span><br><span class="line">before=-1;</span><br><span class="line">flag=1;</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> `<span class="built_in">cat</span> data.txt`;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    after=<span class="variable">$&#123;line&#125;</span>;</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$line</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$before</span>&quot;</span>&gt;<span class="string">&quot;<span class="variable">$after</span>&quot;</span> ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;FAILED&quot;</span>;</span><br><span class="line">        flag=0;</span><br><span class="line">        <span class="built_in">break</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        before=<span class="variable">$&#123;line&#125;</span>;</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$flag</span> = 1 ];<span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;SUCCESS&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>哎呀，shell里不是有自带的<code>sort</code>命令吗，怎么不懂得试试那个<code>sort</code>呢。于是我就查阅了相关博客
* <a
href="http://www.hustyx.com/ubuntu/72/">Linux下Sort命令的一些使用技巧</a>
* <a
href="http://www.wklken.me/posts/2013/07/04/note-of-linux-shell-scripting-cookbook.html">LINUX
SHELL脚本攻略笔记[速查]</a></p>
<h2 id="返回值">返回值</h2>
<p>原来shell脚本的返回值不是直接返回啊，而是通过
linux中shell变量<code>$#</code>,<code>$@</code>,<code>$0</code>,<code>$1</code>,<code>$2</code>的含义解释:</p>
<blockquote>
<p>变量说明:</p>
</blockquote>
<pre><code>`$$` 
Shell本身的PID（ProcessID） 
`$!` 
Shell最后运行的后台Process的PID 
`$?` 
最后运行的命令的结束代码（返回值） 
`$-` 
使用Set命令设定的Flag一览 
`$*` 
所有参数列表。如&quot;$*&quot;用「&quot;」括起来的情况、以`$1 $2 … $n`的形式输出所有参数。 
`$@` 
所有参数列表。如&quot;`$@`&quot;用「&quot;」括起来的情况、以&quot;`$1`&quot; &quot;`$2`&quot; … &quot;`$n`&quot; 的形式输出所有参数。 
`$#` 
添加到Shell的参数个数 
`$0` 
Shell本身的文件名 
`$1～$n` 
添加到Shell的各参数值。`$1`是第1参数、`$2`是第2参数…。 </code></pre>
<p>因此判断一个文件是否是有序的sort返回结果需要通过<code>$?</code>的值进行判断。可是sort是按照行来判断是否有序的，而不是判断所有的是否有序的。比如说datafile
中内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 2 3 4 5 6 8 9</span><br><span class="line">2 3 4 5 6 7 5 32</span><br><span class="line">3 4 5 6 6 34 3 </span><br></pre></td></tr></table></figure>
<p>按照默认sort
情况下，上述文件是有序的。但是实际上总体来说，我们需要返回该文件为无序的，因此，sort的方案只好作罢。</p>
<h2 id="数字比较">数字比较</h2>
<p>后来看看之前那个实现的逻辑，应该是没有什么大问题的呀。</p>
<h3 id="数字的比较">数字的比较</h3>
<p>-eq 相等（equal） -ne 不等（not equal） -gt 大于（greater than） -lt
小于（less than） -ge 大于等于 （greater than or equal） -le 小于等于
（less than or equal）</p>
<h3 id="字符串的比较">字符串的比较</h3>
<p><code>[ $str1 = $str2 ]</code> # 等于 <code>[ $str1 != $str2 ]</code>
# 不等于 <code>[ -z $str ]</code> #空字符串返回true
<code>[ -n $str ]</code>或者<code>[ $str ]</code>
#非空字符串返回true</p>
<p>OMG，
原来shell里的<code>&gt;</code>不是大于号啊，而是表示输入输出，下面就查找了一下关于linux标准文件描述符：
| 文件描述符| 缩写| 描述| |----:|------:|------:| |0 | STDIN |标准输入 |
|1 |STDOUT | 标准输出| |2 |STDERR | 标准错误|<br />
标准输入和标准输出指的就是键盘和显示器。
当文件描述符（0,1,2）与重定向符号<code>&lt;</code>组合之后，就可以重新定向输入，输出，及错误。
* <code>command    2&gt;file1</code>
命令执行的错误信息保存到了file1文件中。显示屏只是显示正确的信息。 *
<code>command    1&gt;file1  2&gt;file2</code>
命令执行后，没有显示。因为正确输出到file1，错误定向到file2 *
<code>command    &amp;&gt;file1</code>
命令执行后，输出和错误都定向到file1中
在shell脚本中，可以定义“错误”输出到STDERR指定的文件.需要在重定向符和文件描述符之间加一个and符<code>&amp;</code></p>
<p>经过这番折腾，终于在shell下将这个简单的问题搞定了！！！</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!bin/sh</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">is_sorted</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">    before=-1;</span><br><span class="line">    flag=1;</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> $(&lt;<span class="variable">$1</span>); <span class="keyword">do</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="variable">$before</span> -gt <span class="variable">$line</span> ];<span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;Failed at <span class="variable">$before</span>, <span class="variable">$line</span>&quot;</span></span><br><span class="line">            flag=0</span><br><span class="line">            <span class="built_in">break</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        before=<span class="variable">$line</span>;</span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> [ <span class="variable">$flag</span> = 1 ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;SUCCESS&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">is_sorted <span class="variable">$1</span></span><br></pre></td></tr></table></figure>
<p>调用函数的方法为 <code>is_sorted datafilename</code> 或者调用bash脚本
<code>bashfilename.sh datafilename</code></p>
<h2 id="一个脚本">一个脚本</h2>
<h3 id="功能介绍">功能介绍</h3>
<ul>
<li>支持简单模型，符合模型的解压</li>
<li>支持目录下所有模型的解压</li>
<li>解压模型按照模型名称创建目录</li>
</ul>
<h3 id="编写过程中一些问题总结">编写过程中一些问题总结</h3>
<ol type="1">
<li>models=(<code>find .  -name "*.model"</code>)
将找到的结果保存为一个数组需要加一个 (),否则是独立的多个元素；</li>
<li>善于利用linux提供的命令工具</li>
</ol>
<p>例如通过basename的操作将文件的路径前缀（文件夹路径）去掉。强烈推荐 <a
href="http://deepindeed.cn/2017/04/01/Better-linuxer/">linux开发常用的文本处理命令</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/sh</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Decrypt the model</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">create: 2019-05-22</span> </span><br><span class="line">function export_tar_model() &#123;</span><br><span class="line">	tar_name=$1</span><br><span class="line">	target=&quot;$&#123;tar_name%.*&#125;&quot;</span><br><span class="line">	if [ -d $&#123;target&#125; ]; then  rm -rf $&#123;target&#125;; fi</span><br><span class="line">	mkdir $&#123;target&#125;</span><br><span class="line">	tar -xf $&#123;tar_fname&#125; -C $&#123;target&#125;</span><br><span class="line">	cd $&#123;target&#125;</span><br><span class="line">	models=(`find .  -name &quot;*.model&quot;`) # 将找到的结果保存为一个数组需要加 () 	</span><br><span class="line">	for model in $models; do</span><br><span class="line">		base_m=`basename $&#123;model&#125;`     # 通过basename的操作将文件的文件夹路径去掉</span><br><span class="line"><span class="meta prompt_">		# </span><span class="language-bash"><span class="built_in">echo</span> <span class="variable">$base_m</span></span> </span><br><span class="line">		t=&quot;$&#123;base_m%.*&#125;&quot;</span><br><span class="line">		mkdir $&#123;t&#125;</span><br><span class="line">		tar -xf $&#123;base_m&#125; -C $&#123;t&#125;      # 解压子模型</span><br><span class="line">	done</span><br><span class="line">	cd .. </span><br><span class="line">&#125;</span><br><span class="line">function decrypt() &#123;</span><br><span class="line">	input=$1</span><br><span class="line">	tar_fname=&quot;$&#123;input%.*&#125;.tar&quot;</span><br><span class="line">	target=&quot;$&#123;input%.*&#125;&quot;</span><br><span class="line">	model_tool decrypt $1 $&#123;tar_fname&#125; </span><br><span class="line">	export_tar_model $&#123;tar_fname&#125;</span><br><span class="line">	rm $tar_fname</span><br><span class="line">&#125;</span><br><span class="line">function decrypt_models() &#123;</span><br><span class="line">	cd $1</span><br><span class="line">	models=(`find .  -name &quot;*.model&quot;`) # 将找到的结果保存为一个数组需要加 () 	</span><br><span class="line">	for model in $models; do</span><br><span class="line">		decrypt $model </span><br><span class="line">	done</span><br><span class="line">&#125;</span><br><span class="line">decrypt $1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">decrypt_models <span class="variable">$1</span></span></span><br></pre></td></tr></table></figure>
<h2 id="crontab定时任务">crontab定时任务</h2>
<p>这个功能在linux下定时执行一个任务，特别适合我这种需要每天查看日志，分析日志的人。比如现在我们的组项目中的dailybuild，被我写了一个脚本，每天将问题提取之后的内容分发的各位同事，非常方便。</p>
<h3 id="使用注意">使用注意</h3>
<ul>
<li>执行时间要再三确认，往往配置crontab之后，3~5min之后才会生效</li>
<li>需要用的语言解析器，例如python2.7,
要写绝对路径，绝对路径，绝对路径，这个比较保险。</li>
<li>运行的输出最好重定向到文件，方便查看问题
<code>/usr/bin/python2.7 /data/xxxxx.py &gt; runtime.log 2&gt;&amp;1</code></li>
</ul>
<h2 id="leetcode-shell-test">LeetCode Shell Test</h2>
<h4 id="word-frequency"><a
href="https://leetcode.com/problems/word-frequency/">Word
Frequency</a></h4>
<p>Write a bash script to calculate the frequency of each word in a text
file words.txt.</p>
<p>For simplicity sake, you may assume:</p>
<p>words.txt contains only lowercase characters and space ' '
characters. Each word must consist of lowercase characters only. Words
are separated by one or more whitespace characters.</p>
<p><code>cat words.txt | tr -s ' ' '\n' | sort | uniq -c | sort -r | awk '&#123; print $2, $1 &#125;'</code></p>
<ul>
<li><p><code>tr -s</code>: truncate the string with target string, but
only remaining one instance (e.g. multiple whitespaces)</p></li>
<li><p><code>sort</code>: To make the same string successive so that
uniq could count the same string fully and correctly.</p></li>
<li><p><code>uniq -c</code>: uniq is used to filter out the repeated
lines which are successive, -c means counting</p></li>
<li><p><code>sort -r</code>: -r means sorting in descending
order</p></li>
<li><p><code>awk '&#123; print $2, $1 &#125;'</code>: To format the output, see
here.</p></li>
<li><p><a href="https://linux.cn/article-3945-1.html">Linux
中使用awk</a></p></li>
<li><p><a
href="http://www.pement.org/awk/awk1line.txt">awk_1line</a></p></li>
<li><p><a
href="http://github.com/cwlseu/cwlseu.github.io/raw/master/pdf/#Shell%20programming.pdf">shell基础知识</a></p></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux开发</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>实际项目中的红黑树与跳表</title>
    <url>/201609/20160907-rbtree-skiplist/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>日常开发过程中，像大量文本中查找相似文本，缓存数据这些功能，我们并不是直接利用语言原生支持的数据结构来实现。这些专门的应用领域，工程师们会有专门优化的解决方案。例如flann进行相似文本查询，redis进行kv字段缓存。那么这些专门的解决方案，他们的基本的数据结构是什么呢？</p>
<h2 id="红黑树">红黑树</h2>
<p>https://blog.csdn.net/weewqrer/article/details/51866488</p>
<h3 id="用途">用途</h3>
<p>C++中的set,map,multimap,multiset底层结构均是红黑树</p>
<p>红黑树严格来说是一种更高效的<strong>二叉查找树</strong>，它比BST（二叉查找树）和AVL（平衡二叉查找树）更加高效，能够将插入和删除操作的时间复杂度控制在O(log
n),
因为高效，被应用在库容器的底层，如STL::map，正是由于高效，因此也多了很多的规则。红黑树的规则一共有五条：</p>
<ul>
<li>节点必须是红色或者是黑色；</li>
<li>根节点是黑色；</li>
<li>所有叶子节点都是黑色（叶子节点为NULL）；</li>
<li>任何一个节点和它的父节点不能同时为红色；</li>
<li>从根节点到任何一个叶子节点所经过的黑色的节点的数目必须是相同的。</li>
</ul>
<h3 id="红黑树-vs-avl树">红黑树 VS AVL树</h3>
<p>红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保。对于查找、插入、删除、最大、最小等动态操作的时间复杂度为<span
class="math inline">\(O(logn)\)</span>.常见的用途有以下几种：</p>
<ul>
<li>STL（标准模板库）中在set map是基于红黑树实现的。</li>
<li>Java中在TreeMap使用的也是红黑树。</li>
<li>epoll在内核中的实现，用红黑树管理事件块。</li>
<li>linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块</li>
</ul>
<p>常见的平衡树有红黑树和AVL平衡树，为什么STL和linux都使用红黑树作为平衡树的实现？大概有以下几个原因：</p>
<p>从实现细节上来讲，如果插入一个结点引起了树的不平衡，AVL树和红黑树都最多需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度</p>
<p>从两种平衡树对平衡的要求来讲，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，<strong>AVL需要rebalance的频率会更高</strong>。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。</p>
<p>总体来说，<strong>RB-tree的统计性能是高于AVL的</strong></p>
<h3 id="相关应用">相关应用</h3>
<p>近似近邻算法在大型应用中是解决搜索的关键技术。而近似近邻算法的研究中，一部分是基于树结构实现的，一部分是基于hash算法。今FLANN是一个开源库，opencv中已经集成了该module.</p>
<ul>
<li>github: <a href="https://github.com/mariusmuja/flann.git">FLANN -
Fast Library for Approximate Nearest Neighbors</a></li>
</ul>
<h4 id="flann概述">FLANN概述</h4>
<p>首先阐述了近似结果查询的重要性，通过实验结果分析了最有效的近似nn算法中，随机KD森林是最有效的，另外提出了一个新的方法：优先查找k-means树，尤其是针对视觉任务中常用的二进制特征，提出了多层聚类树。为了应用于大数据环境下，还有分布式环境下nn查找框架。</p>
<h4 id="相关名词定义">相关名词定义</h4>
<ol type="1">
<li>KNN(K-nearest neighbor
search)：说白了，就是从数据集合了找K个最接近的</li>
<li>RNN(radius nearest neighbor
search)：就是返回一定半径范围内的所有数据。当然这个半径有很多不同的定义。</li>
</ol>
<h3 id="参考文献">参考文献</h3>
<ol type="1">
<li><a
href="http://www.cnblogs.com/eyeszjwang/articles/2429382.html">K-D
Tree</a></li>
<li><a
href="http://blog.csdn.net/zhouxuguang236/article/details/7898272">R
树简介</a></li>
<li><a
href="http://blog.csdn.net/v_JULY_v/article/details/6530142/">从B树、B+树、B*树谈到R
树</a></li>
<li><a
href="http://www.ahathinking.com/archives/136.html">线段树</a></li>
<li><a
href="https://blog.csdn.net/v_JULY_v/article/details/6285620">红黑树</a></li>
<li><a
href="https://blog.csdn.net/qq_42214953/article/details/105218063?utm_medium=distribute.pc_relevant.none-task-blog-2defaultbaidujs_title~default-1-105218063-blog-88691077.pc_relevant_aa&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=4">RBTree的实现</a></li>
</ol>
<h2 id="skiplist">SkipList</h2>
<p>skiplist本质上也是一种查找结构，用于解决算法中的查找问题（Searching），即根据给定的key，快速查到它所在的位置（或者对应的value）。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209040030773.png"
alt="image-20220904003021649" />
<figcaption aria-hidden="true">image-20220904003021649</figcaption>
</figure>
<p><strong>skiplist与平衡树、哈希表的比较</strong></p>
<p>skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在<strong>哈希表上只能做单个key的查找，不适宜做范围查找</strong>。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。</p>
<p><strong>范围查找的时候，平衡树比skiplist操作要复杂。</strong>在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。</p>
<p><strong>平衡树的插入和删除操作可能引发子树的调整</strong>，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。</p>
<p>从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。</p>
<p>查找单个key，skiplist和平衡树的时间复杂度都为O(log
n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。</p>
<p>从算法实现难度上来比较，skiplist比平衡树要简单得多。</p>
<p><a
href="https://blog.csdn.net/helloworld_ptt/article/details/105801262">Redis
为什么用跳表而不用平衡树</a></p>
<p><a
href="https://blog.csdn.net/Day_DreamX/article/details/109038616?utm_medium=distribute.pc_relevant.none-task-blog-2defaultbaidujs_baidulandingword~default-1-109038616-blog-106573897.pc_relevant_default&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=4">SkipList
C++实现</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title>STL源码剖析与C++面向对象</title>
    <url>/201612/20161230-basic-cpp-stl-traits/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>一个方法实现过程中，业务逻辑很多都是相似的，但是与具体的特化类型的不同有一定的差异。
这个时候可以采用特化模板的方式实现，不同的类型使用不同的特化实现。但是这种情况造成一定的业务逻辑的冗余。而trait技术可以将特化类型通过封装，以一个统一的调用方式实现相同的业务逻辑。</p>
<h2 id="type_traits技术">Type_traits技术</h2>
<p>type_traits可以翻译为类型提取器或者类型萃取器，很直白的说就是通过这个机制可以获取被操作数据类型的一些特征。这个机制在编写模板代码的时候特别有用，可以在编译期间就根据数据类型的特征分派给不同的代码进行处理。</p>
<p>STL中关于copy的代码 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// This header file provides a framework for allowing compile time dispatch</span></span><br><span class="line"><span class="comment">// based on type attributes. This is useful when writing template code.</span></span><br><span class="line"><span class="comment">// For example, when making a copy of an array of an unknown type, it helps</span></span><br><span class="line"><span class="comment">// to know if the type has a trivial copy constructor or not, to help decide</span></span><br><span class="line"><span class="comment">// if a memcpy can be used.</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">true_type</span> &#123;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">false_type</span> &#123;</span></span><br><span class="line">&#125;;</span><br><span class="line">template &lt;<span class="class"><span class="keyword">class</span> _<span class="title">Tp</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">type_traits</span> &#123;</span> </span><br><span class="line">   <span class="keyword">typedef</span> __true_type     this_dummy_member_must_be_first;</span><br><span class="line">                   <span class="comment">/* Do not remove this member. It informs a compiler which</span></span><br><span class="line"><span class="comment">                      automatically specializes __type_traits that this</span></span><br><span class="line"><span class="comment">                      __type_traits template is special. It just makes sure that</span></span><br><span class="line"><span class="comment">                      things work if an implementation is using a template</span></span><br><span class="line"><span class="comment">                      called __type_traits for something unrelated. */</span></span><br><span class="line">   <span class="comment">/* The following restrictions should be observed for the sake of</span></span><br><span class="line"><span class="comment">      compilers which automatically produce type specific specializations </span></span><br><span class="line"><span class="comment">      of this class:</span></span><br><span class="line"><span class="comment">          - You may reorder the members below if you wish</span></span><br><span class="line"><span class="comment">          - You may remove any of the members below if you wish</span></span><br><span class="line"><span class="comment">          - You must not rename members without making the corresponding</span></span><br><span class="line"><span class="comment">            name change in the compiler</span></span><br><span class="line"><span class="comment">          - Members you add will be treated like regular members unless</span></span><br><span class="line"><span class="comment">            you add the appropriate support in the compiler. */</span></span><br><span class="line"> </span><br><span class="line">   <span class="keyword">typedef</span> __false_type    has_trivial_default_constructor;</span><br><span class="line">   <span class="keyword">typedef</span> __false_type    has_trivial_copy_constructor;</span><br><span class="line">   <span class="keyword">typedef</span> __false_type    has_trivial_assignment_operator;</span><br><span class="line">   <span class="keyword">typedef</span> __false_type    has_trivial_destructor;</span><br><span class="line">   <span class="keyword">typedef</span> __false_type    is_POD_type;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// The class template __type_traits provides a series of typedefs each of</span></span><br><span class="line"><span class="comment">// which is either __true_type or __false_type. The argument to</span></span><br><span class="line"><span class="comment">// __type_traits can be any type. The typedefs within this template will</span></span><br><span class="line"><span class="comment">// attain their correct values by one of these means:</span></span><br><span class="line"><span class="comment">//     1. The general instantiation contain conservative values which work</span></span><br><span class="line"><span class="comment">//        for all types.</span></span><br><span class="line"><span class="comment">//     2. Specializations may be declared to make distinctions between types.</span></span><br><span class="line"><span class="comment">//     3. Some compilers (such as the Silicon Graphics N32 and N64 compilers)</span></span><br><span class="line"><span class="comment">//        will automatically provide the appropriate specializations for all</span></span><br><span class="line"><span class="comment">//        types.</span></span><br><span class="line"><span class="comment">// EXAMPLE:</span></span><br><span class="line"><span class="comment">//Copy an array of elements which have non-trivial copy constructors</span></span><br><span class="line">template &lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span> <span class="type">void</span> <span class="title function_">copy</span><span class="params">(T* source, T* destination, <span class="type">int</span> n, __false_type)</span>;</span><br><span class="line"><span class="comment">//Copy an array of elements which have trivial copy constructors. Use memcpy.</span></span><br><span class="line">template &lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span> <span class="type">void</span> <span class="title function_">copy</span><span class="params">(T* source, T* destination, <span class="type">int</span> n, __true_type)</span>;</span><br><span class="line"><span class="comment">//Copy an array of any type by using the most efficient copy mechanism</span></span><br><span class="line">template &lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">copy</span><span class="params">(T* source,T* destination,<span class="type">int</span> n)</span> &#123;</span><br><span class="line">   copy(source, destination, n,</span><br><span class="line">        typename __type_traits&lt;T&gt;::has_trivial_copy_constructor());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>POD意思是Plain Old Data,也就是标量性别或者传统的C
struct型别。POD性别必然拥有trivial ctor/doct/copy/assignment
函数,因此我们就可以对POD型别采用最为有效的复制方法，而对non-POD型别采用最保险安全的方法</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// uninitialized_copy</span></span><br><span class="line"><span class="comment">// Valid if copy construction is equivalent to assignment, and if the</span></span><br><span class="line"><span class="comment">//  destructor is trivial.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_InputIter</span>, <span class="keyword">class</span> <span class="title class_">_ForwardIter</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> _ForwardIter </span><br><span class="line">__uninitialized_copy_aux(_InputIter __first, _InputIter __last,</span><br><span class="line">                         _ForwardIter __result,</span><br><span class="line">                         __true_type)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">copy</span>(__first, __last, __result);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_InputIter</span>, <span class="keyword">class</span> <span class="title class_">_ForwardIter</span>&gt;</span><br><span class="line">_ForwardIter </span><br><span class="line">__uninitialized_copy_aux(_InputIter __first, _InputIter __last,</span><br><span class="line">                         _ForwardIter __result,</span><br><span class="line">                         __false_type)</span><br><span class="line">&#123;</span><br><span class="line">  _ForwardIter __cur = __result;</span><br><span class="line">  __STL_TRY &#123;</span><br><span class="line">    <span class="keyword">for</span> ( ; __first != __last; ++__first, ++__cur)</span><br><span class="line">      _Construct(&amp;*__cur, *__first);</span><br><span class="line">    <span class="keyword">return</span> __cur;</span><br><span class="line">  &#125;</span><br><span class="line">  __STL_UNWIND(_Destroy(__result, __cur));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_InputIter</span>, <span class="keyword">class</span> <span class="title class_">_ForwardIter</span>, <span class="keyword">class</span> <span class="title class_">_Tp</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> _ForwardIter</span><br><span class="line">__uninitialized_copy(_InputIter __first, _InputIter __last, _ForwardIter __result, _Tp*)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">typedef</span> <span class="keyword">typename</span> __type_traits&lt;_Tp&gt;::is_POD_type _Is_POD;</span><br><span class="line">  <span class="keyword">return</span> __uninitialized_copy_aux(__first, __last, __result, _Is_POD());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="trait技术和template-元编程的例子">trait技术和template
元编程的例子</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">template</span>&lt;<span class="type">int</span>&gt; <span class="keyword">class</span> <span class="title class_">LOGICAL</span>, <span class="keyword">class</span> <span class="title class_">SEQUENCE</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">sequence_any</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">template</span>&lt;<span class="type">int</span>&gt; <span class="keyword">class</span> <span class="title class_">LOGICAL</span>, <span class="type">int</span> NUM, <span class="type">int</span>...NUMS&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">sequence_any</span>&lt;LOGICAL, sequence&lt;NUM, NUMS...&gt; &gt;</span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">static</span> <span class="type">const</span> <span class="type">bool</span> value = LOGICAL&lt;NUM&gt;::value || sequence_any&lt;LOGICAL, sequence&lt;NUMS...&gt;&gt;::value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">template</span>&lt;<span class="type">int</span>&gt; <span class="keyword">class</span> <span class="title class_">LOGICAL</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">sequence_any</span>&lt;LOGICAL, sequence&lt;&gt; &gt;</span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">static</span> <span class="type">const</span> <span class="type">bool</span> value = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="type">int</span> A&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">static_is_zero</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">static</span> <span class="type">const</span> <span class="type">bool</span> value = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">template</span>&lt;&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">static_is_zero</span>&lt;<span class="number">0</span>&gt;</span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">static</span> <span class="type">const</span> <span class="type">bool</span> value = <span class="literal">true</span>;</span><br><span class="line">&#125;;</span><br><span class="line"> <span class="type">const</span> <span class="type">bool</span> SINGLEROWOPT = </span><br><span class="line">sequence_any&lt;static_is_zero, sequence&lt;SPECIALIZATIONS...&gt;&gt;::value;</span><br></pre></td></tr></table></figure>
<h2 id="函数的调用过程">函数的调用过程</h2>
<p>如果一个程序中很多多个同名的函数，那编译器是如何找应该调用哪一个函数呢？
编译器会通过如下顺序进行查找。 1. 函数直接匹配 2. 模板函数 3.
通过一定的隐形转换数据类型可以调用</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">float</span> a)</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;float func:&quot;</span> &lt;&lt; a &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span> a)</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;int func:&quot;</span> &lt;&lt; a &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(T a)</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;template func:&quot;</span> &lt;&lt; a &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> <span class="type">const</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> ia = <span class="number">1</span>;</span><br><span class="line">  <span class="built_in">func</span>(ia);</span><br><span class="line">  <span class="built_in">func</span>&lt;<span class="type">int</span>&gt;(ia);</span><br><span class="line">  <span class="type">float</span> fb = <span class="number">2</span>;</span><br><span class="line">  <span class="built_in">func</span>(fb);</span><br><span class="line">  <span class="built_in">func</span>&lt;<span class="type">float</span>&gt;(fb);</span><br><span class="line">  <span class="type">double</span> db = <span class="number">3</span>;</span><br><span class="line">  <span class="built_in">func</span>(db);</span><br><span class="line">  <span class="built_in">func</span>&lt;<span class="type">double</span>&gt;(db);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>结果输出</p>
</blockquote>
<p>int func:1 template func:1 float func:2 template func:2 template
func:3 template func:3</p>
<h2
id="模板函数的声明与定义一般有两种方式">模板函数的声明与定义一般有两种方式</h2>
<ol type="1">
<li>声明定义在header文件中。这种情况往往是模板针对不同的类型处理方式是一样的，这样可以直接放到头文件中。当实际调用过程中实现template的调用</li>
<li>声明+特化在头文件中，实际定义在cpp文件中。这种情况往往特化几种就是几种。</li>
</ol>
<h3 id="模板invoke模板函数">模板invoke模板函数</h3>
<p>两个模板函数,
如果<strong>被调用的模板函数的只有声明在头文件中,定义与特化</strong>.
而模板的实际定义在cpp文件中，就会出现undefined的问题.</p>
<p>这是由于在头文件中进行调用模板函数过程中，找不到特化的被调用函数.
在头文件中显示特化声明被调用的函数,
这种情况比较适合针对不同的类型的特化有不同的处理方案.
或者直接将模板函数定义放到头文件中,这种比较适合所有的函数都适用一种情况.</p>
<h2 id="纯虚类">纯虚类</h2>
<h4 id="定义1">定义1</h4>
<blockquote>
<p>含有一个纯虚函数的类，叫做纯虚类。纯虚类不可以定义对象。</p>
</blockquote>
<p>我个人觉得这个说法应该就是把纯虚类的主要特点说明了：</p>
<blockquote>
<p>只要有一个纯虚函数。就称为纯虚类。所以如果子类没有实现纯虚函数，相当子类也有纯虚函数，所以子类也是纯虚类。</p>
</blockquote>
<p>其他类的定义与使用方式都与一般的类差不多。大致有如下地方： *
纯虚类可以有成员变量 （可以) * 纯虚类可以有普通的成员函数（可以） *
纯虚类可不可以有其他虚函数（可以） *
纯虚类可不可以又带有参数的构造函数？ (可以) *
可不可以在纯虚类的派生类的构造函数中显式调用纯虚类的带参数构造函数(可以)</p>
<blockquote>
<p>使用方式上：<strong>不可以定义一个对象。</strong></p>
</blockquote>
<h4 id="定义2">定义2</h4>
<blockquote>
<p>纯虚类也称为抽象类
<strong>带有纯虚函数的类称为抽象类。</strong>抽象类是一种特殊的类，它是为了抽象和设计的目的而建立的，它处于继承层次结构的较上层（而不是绝对的上层，也有可能是中层，甚至底层？）。抽象类是不能定义对象的，在实际中为了强调一个类是抽象类，可将该类的构造函数（设置为protected)说明为保护的访问控制权限。</p>
</blockquote>
<p>抽象类的主要作用是将有关的组织在一个继承层次结构中，由它来为它们提供一个公共的根(其实不一定是根)，相关的子类是从这个根派生出来的。</p>
<p>抽象类刻画了一组子类的操作接口的通用语义，这些语义也传给子类。一般而言，抽象类只描述这组子类共同的操作接口，而完整的实现留给子类。</p>
<p><strong>抽象类只能作为基类来使用(大多数情况是其他类的基类，但是抽象类本身也有可能是子类），其纯虚函数的实现由派生类给出。</strong>如果派生类没有重新定义纯虚函数，而派生类只是继承基类的纯虚函数，则这个派生类仍然还是一个抽象类。如果派生类中给出了基类纯虚函数的实现，则该派生类就不再是抽象类了，它是一个可以建立对象的具体类了。</p>
<h2 id="模板继承接口类">模板继承接口类</h2>
<h3 id="安全类型转换">安全类型转换</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TFrom&gt;</span><br><span class="line"><span class="function">T <span class="title">safe_cast</span><span class="params">(TFrom &amp;input)</span> </span>&#123;</span><br><span class="line">	<span class="built_in">FW_ASSERT</span>(input.<span class="built_in">type</span>() == blob_elem_trait&lt;<span class="keyword">typename</span> T::value_type&gt;::type_enum);</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;T&gt;(input);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="cvmat-与cvmat_t就是典型的案例"><code>cv::Mat</code>
与<code>cv::Mat_&lt;T&gt;</code>就是典型的案例</h3>
<ol type="1">
<li>采用enum类型或者整数类型进行区分类型</li>
<li>采用<code>trait</code>技术将自定义类型与系统类型映射</li>
<li>采用模板继承接口，实现接口的统一调用</li>
</ol>
<h2 id="附录">附录：</h2>
<ul>
<li><a
href="http://github.com/cwlseu/cwlseu.github.io/images/codes/iterator.cpp">Trait技术实现迭代器</a></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>STL容器底层实现</title>
    <url>/201612/20161230-cpp-stl-note/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>STL全程是Standard Template Library，也就是这个库通过C++
Template的方式实现的标准库。这里面包括容器、迭代器、仿函数、常用的基本算法等。
几乎所有的代码都采用了模板类或者模板函数，这相比传统的由函数和类组成的库来说提供了更好的代码重用机会。本文主要对日常开发中常用的容器进行总结。</p>
<h2 id="vector"><strong>vector</strong></h2>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030848232.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>vector 的数据安排以及操作方式，与 array
非常相似。两者的唯一区别在于空间的运用的灵活性。array
是静态空间，一旦配置了就不能改变，vector
是动态数组。在<strong>堆上分配空间</strong>。vector
是动态空间，随着元素的加入，它的内部机制会自行扩充空间以容纳新元素（有保留内存，如果减少大小后内存也不会释放。如果新值&gt;当前大小时才会再分配内存，这大大影响了
vector 的效率）。因此，vector
的运用对于内存的合理利用与运用的灵活性有很大的帮助，我们再也不必因为害怕空间不足而一开始要求一个大块的
array。</p>
<p>vector
动态增加大小，并不是在原空间之后持续新空间（因为无法保证原空间之后尚有可供配置的空间），而是以原大小的两倍<strong>另外配置</strong>一块较大的空间，然后将原内容拷贝过来，然后才开始在原内容之后构造新元素，并释放原空间。因此，对
vector 的任何操作，一旦引起空间重新配置，同时指向原vector
的所有迭代器就都失效了。</p>
<p>对最后元素操作最快（在后面添加删除最快），此时一般不需要移动内存。对中间和开始处进行添加删除元素操作需要移动内存。<strong>如果你的元素是结构或是类,那么移动的同时还会进行构造和析构操作，所以性能不高</strong>（最好将结构或类的指针放入
vector
中，而不是结构或类本身，这样可以避免移动时的构造与析构）。访问方面，对任何元素的访问都是
O(1)，也就是常数时间的。</p>
<blockquote>
<p><strong>总结：</strong></p>
</blockquote>
<p>vector
常用来保存需要<strong>经常进行随机访问</strong>的内容，并且不需要经常对中间元素进行添加删除操作。</p>
<p>STL源码剖析：</p>
<p>https://blog.csdn.net/weixin_40673608/article/details/87103742</p>
<h2 id="list"><strong>list</strong></h2>
<p>相对于 vector 的连续空间，list
就显得复杂许多，它的好处是每次插入或删除一个元素，就配置或释放一个元素空间，元素也是在堆中。因此，list
对于空间的运用有绝对的精准，一点也不浪费。而且，对于<strong>任何位置的元素插入或元素移除，永远是常数时间</strong>。STL
中的list
底层是一个双向链表，而且是一个环状双向链表。这个特点使得它的随即存取变的非常没有效率，因此它没有提供
[] 操作符的重载。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209040049339.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<blockquote>
<p><strong>总结：</strong></p>
</blockquote>
<p>如果你喜欢经常添加删除大对象的话，那么请使用 list；</p>
<p>要保存的对象不大，构造与析构操作不复杂，那么可以使用 vector
代替。</p>
<p>list<指针> 完全是性能最低的做法，这种情况下还是使用 vector<指针>
好，因为指针没有构造与析构，也不占用很大内存</p>
<h2 id="deque"><strong>deque</strong></h2>
<p>deque
是一种双向开口的连续线性空间，元素也是在堆中。所谓双向开口，意思是可以在队尾两端分别做元素的插入和删除操作。deque
和 vector 的最大差异，一在于 deque
允许于常数时间内对起头端进行元素的插入或移除操作，二在于deque没有所谓容量观念，因为<strong>它是动态地以分段连续空间组合而成，随时可以增加一段新的空间并链接在一起</strong>。换句话说，像
vector
那样“因旧空间不足而重新配置一块更大空间，然后复制元素，再释放旧空间”这样的事情在
deque 是不会发生的。它的保存形式如下:</p>
<blockquote>
<p>[堆1] --&gt; [堆2] --&gt;[堆3] --&gt; ...</p>
</blockquote>
<p>deque 是由一段一段的定量连续空间构成。一旦有必要在 deque
的前端或尾端增加新空间，便配置一段定量连续空间，串接在整个 deque
的头端或尾端。deque
的最大任务，便是在这些分段的定量连续空间上，维护其整体连续的假象，并提供随机存取的接口。避开了“重新配置，复制，释放”的轮回，代价则是复杂的迭代器架构。因为有分段连续线性空间，就必须有中央控制器，而为了维持整体连续的假象，数据结构的设计及迭代器前进后退等操作都颇为繁琐。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030848812.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>deque 采用一块所谓的 map 作为主控。这里的 map
是一小块连续空间，其中每个元素都是指针，指向另一段连续线性空间，称为缓冲区。缓冲区才是
deque 的存储空间主体</strong>。（
底层数据结构为一个中央控制器和多个缓冲区）SGI STL
允许我们指定缓冲区大小，默认值 0 表示将使用 512 bytes 缓冲区。</p>
<p>支持[]操作符，也就是支持随即存取，可以在前面快速地添加删除元素，或是在后面快速地添加删除元素，然后还可以有比较高的随机访问速度和vector
的效率相差无几。deque
支持在两端的操作：<code>push_back</code>,<code>push_front</code>,<code>pop_back</code>,<code>pop_front</code>等，并且在两端操作上与
list 的效率也差不多。</p>
<p>在标准库中 vector 和 deque
提供几乎相同的接口，在结构上区别主要在于在组织内存上不一样，<strong>deque
是按页或块来分配存储器的，每页包含固定数目的元素；相反 vector
分配一段连续的内存，vector
只是在序列的尾段插入元素时才有效率</strong>，而 deque
的分页组织方式即使在容器的前端也可以提供常数时间的 insert 和 erase
操作，而且在体积增长方面也比 vector 更具有效率。</p>
<p>详细实现信息可以参考: http://c.biancheng.net/view/6908.html</p>
<p><strong>如果deque中的map满了怎么办？</strong></p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030848240.png"
alt="img" /><strong>总结：</strong></p>
<ul>
<li>vector
是可以快速地在最后添加删除元素，并可以快速地访问任意元素；</li>
<li>list
是可以快速地在所有地方添加删除元素，但是只能快速地访问最开始与最后的元素；</li>
<li>deque
在开始和最后添加元素都一样快，并提供了随机访问方法，像vector一样使用 []
访问任意元素，但是随机访问速度比不上vector快，因为它要内部处理堆跳转。deque
也有保留空间。另外，由于 deque 不要求连续空间，所以可以保存的元素比
vector
更大。还有就是在前面和后面添加元素时都不需要移动其它块的元素，所以性能也很高。</li>
</ul>
<p>因此在实际使用时，如何选择这三个容器中哪一个，一般应遵循下面的原则：</p>
<ul>
<li>如果你需要高效的随即存取，而不在乎插入和删除的效率，使用
vector；</li>
<li>如果你需要大量的插入和删除，而不关心随即存取，则应使用 list；</li>
<li>如果你需要随即存取，而且关心两端数据的插入和删除，则应使用deque。</li>
</ul>
<h2 id="stack"><strong>stack</strong></h2>
<p>stack 是一种先进后出（First In Last Out ,
FILO）的数据结构。它只有一个出口，stack
允许新增元素，移除元素，取得最顶端元素。但除了最顶端外，没有任何其它方法可以存取stack的其它元素，stack不允许遍历行为。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030848810.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>以某种容器（ <strong>一般用 list 或 deque
实现，封闭头部即可</strong>，不用 vector
的原因应该是容量大小有限制，扩容耗时）作为底部结构，将其接口改变，使之符合“先进后出”的特性，形成一个
stack，是很容易做到的。deque 是双向开口的数据结构，若以 deque
为底部结构并封闭其头端开口，便轻而易举地形成了一个stack。因此，SGI STL
便以 deque 作为缺省情况下的 stack 底部结构，由于 stack
系以底部容器完成其所有工作，而具有这种“修改某物接口，形成另一种风貌”之性质者，称为
adapter（配接器），因此，STL stack 往往不被归类为
container(容器)，而被归类为 container adapter。</p>
<h2 id="queue"><strong>queue</strong></h2>
<p>queue 是一种先进先出（First In First
Out,FIFO）的数据结构。它有两个出口，queue
允许新增元素，移除元素，从最底端加入元素，取得最顶端元素。但除了最底端可以加入，最顶端可以取出外，没有任何其它方法可以存取
queue 的其它元素。</p>
<p>以某种容器 （ <strong>一般用 list 或 deque
实现，封闭头部即可</strong> ，不用 vector
的原因应该是容量大小有限制，扩容耗时
）作为底部结构，将其接口改变，使之符合“先进先出”的特性，形成一个
queue，是很容易做到的。deque 是双向开口的数据结构，若以 deque
为底部结构并封闭其底部的出口和前端的入口，便轻而易举地形成了一个
queue。因此，SGI STL 便以 deque 作为缺省情况下的 queue 底部结构，由于
queue
系以底部容器完成其所有工作，而具有这种“修改某物接口，形成另一种风貌”之性质者，称为
adapter（配接器），因此，STL queue
往往不被归类为container(容器)，而被归类为 container adapter。</p>
<p>stack 和 queue 其实是适配器，而不叫容器，因为是对容器的再封装。</p>
<h2 id="heap"><strong>heap</strong></h2>
<p>heap 并不归属于 STL 容器组件，它是个幕后英雄，扮演 priority
queue（优先队列）的助手。priority queue
允许用户以任何次序将任何元素推入容器中，但取出时一定按从优先权最高的元素开始取。按照元素的排列方式，heap
可分为 max-heap 和 min-heap
两种，前者每个节点的键值(key)都大于或等于其子节点键值，后者的每个节点键值(key)都小于或等于其子节点键值。因此，
max-heap 的最大值在根节点，并总是位于底层array或vector的起头处；min-heap
的最小值在根节点，亦总是位于底层array或vector起头处。STL 供应的是
max-heap，用 C++ 实现。</p>
<h2 id="priority_queue"><strong>priority_queue</strong></h2>
<p>priority_queue 是一个拥有权值观念的
queue，它允许加入新元素，移除旧元素，审视元素值等功能。由于这是一个
queue，所以只允许在底端加入元素，并从顶端取出元素，除此之外别无其它存取元素的途径。priority_queue
带有权值观念，其内的元素并非依照被推入的次序排列，而是自动依照元素的权值排列（通常权值以实值表示）。权值最高者，排在最前面。缺省情况下
priority_queue 系利用一个 max-heap 完成，后者是一个以vector 表现的
complete binary tree.max-heap 可以满足 priority_queue
所需要的“依权值高低自动递减排序”的特性。</p>
<p>priority_queue
完全<strong>以底部容器（一般为vector为底层容器）作为根据</strong>，再加上
heap 处理规则，所以其实现非常简单。缺省情况下是以 vector
为底部容器。queue
以底部容器完成其所有工作。具有这种“修改某物接口，形成另一种风貌“”之性质者，称为
adapter(配接器)，因此，STL priority_queue 往往不被归类为
container(容器)，而被归类为 container adapter。</p>
<h2 id="set-和-multiset-容器"><strong>set 和 multiset 容器</strong></h2>
<p>set 的特性是，所有元素都会根据元素的键值自动被排序。set 的元素不像
map 那样可以同时拥有实值(value)和键值(key)，set
元素的键值就是实值，实值就是键值，set不允许两个元素有相同的值。set
底层是通过红黑树（RB-tree）来实现的，由于红黑树是一种<strong>平衡二叉搜索树</strong>，自动排序的效果很不错，所以标准的
STL 的 set 即以 RB-Tree 为底层机制。又由于 set
所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 set
操作行为，都只有转调用 RB-tree 的操作行为而已。</p>
<p><strong>multiset</strong>的特性以及用法和 set
完全相同，唯一的差别在于它<strong>允许键值重复</strong>，因此它的插入操作采用的是底层机制是
RB-tree 的 insert_equal() 而非 insert_unique()。</p>
<h2 id="map-和-multimap-容器"><strong>map 和 multimap 容器</strong></h2>
<p>map的特性是，所有元素都会根据元素的键值自动被排序。map 的所有元素都是
pair，同时拥有实值（value）和键值（key）。pair
的第一元素被视为键值，第二元素被视为实值。map不允许两个元素拥有相同的键值。由于
RB-tree 是一种平衡二叉搜索树，自动排序的效果很不错，所以标准的STL map
即以 RB-tree 为底层机制。又由于 map 所开放的各种操作接口，RB-tree
也都提供了，所以几乎所有的 map 操作行为，都只是转调 RB-tree
的操作行为。</p>
<p>multimap 的特性以及用法与 map
完全相同，唯一的差别在于它允许键值重复，因此它的插入操作采用的是底层机制
RB-tree 的 insert_equal() 而非 insert_unique。</p>
<h2
id="unordered_setunordered_map"><strong>unordered_set、unordered_map</strong></h2>
<p>hashtable作为unordered_set和unordered_map的底层数据结构，是隐藏起来的，正常不会直接用到它，但要理解好unordered_set和unordered_map，需要先理解好hashtable</p>
<p>hashtable的底层数据结构是vector，vector中的元素是链表</p>
<p>vector代表篮子，初始化大小为53（GNU的做法），存的是结点指针</p>
<p>元素放进来的时候，会经过一个hash函数，找到对应的篮子，然后连在篮子的后面</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030848924.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>当放进去的元素的数量超过vector的长度的时候，就会执行rehashing：</p>
<p>vector的大小会先变大为2倍，但不一定是2倍，会变成2倍左右的一个素数</p>
<p>vector变大后，原先的每一个元素都需要重新用hash函数计算并放到对应的篮子里</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030848225.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>如果还需要rehashing的话，vector的大小会按照以下增长，这些数字是已经先算好的，vector在扩充的时候，不会再花时间去计算，而是直接在下面抓取对应的大小</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030848474.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>算法的乐趣：算法设计的基础</title>
    <url>/201702/20170228-the-fun-of-algorithm/</url>
    <content><![CDATA[<h2 id="算法模式">算法模式</h2>
<ol type="1">
<li>处理最优化问题，贪婪法和动态规划</li>
<li>迷宫问题： 穷尽式和回溯</li>
<li>算法需要频繁查表操作：需要有序表实现</li>
<li>使用树和图实现，一定不要忘了递归。</li>
</ol>
<h2 id="算法实现中的数据结构">算法实现中的数据结构</h2>
<h3 id="线性表">线性表</h3>
<blockquote>
<p>数组<vector></p>
</blockquote>
<p>数组可以直接通过下标进行访问，数组直接访问时没有开销的，但是插入和删除需要移动数组元素，开销比较大，因此插入和删除比较频繁地情况下不适合使用数组。数组中查找一个元素的时间复杂度是O(n)，但是有序数组的情况下可以使用二分查找降到O(logn)</p>
<blockquote>
<p>链表<list></p>
</blockquote>
<p>链表的插入和删除时间是固定的时间，就是更改指针的时间，比数组的插入删除效率高。，但是访问链表元素的效率比较低，需要从链表的头部向后搜索，查找操作的时间是O(n),理论上链表的长度是不受限制的，但是时间使用过程中，链表受存储空间的限制，因此也是不能够无限增长的。</p>
<p>注意的是链表的头结点。因为在头结点之前进行插入或者删除头结点会导致头结点的指针失效。为了解决这个问题，我们设计了一个称谓哨兵节点或者哑节点的头节点，该节点没有数据域，只有指针域的特殊节点。这样我们就可以使用一致的方法处理空链表和非空链表；同时对链表进行插入删除不需要对数据元素的首届点和中间节点进行差异处理。</p>
<blockquote>
<p>栈<stack></p>
</blockquote>
<p>具有后进先出的特点。常常用栈： * 算法转化为非递归实现 *
穷经搜索是存储当前状态 * 深度优先搜索</p>
<blockquote>
<p>队列<queue>
队列是一种先进先出的特点的数据结构。此外尤其要注意优先队列的应用。</p>
</blockquote>
<h3 id="复杂数据结构-树">复杂数据结构-树</h3>
<p>没有环路的图 &gt; 二叉查找树</p>
<blockquote>
<p>AVL树和红黑树</p>
</blockquote>
<blockquote>
<p>B树</p>
</blockquote>
<p>B
树的节点大小为什么是4K？而不是采用更小的，例如二叉树一样一个节点有两个。</p>
<blockquote>
<p>区间树：以区间为数据元素的红黑树</p>
</blockquote>
<blockquote>
<p>线段树：以区间为数据元素的二叉查找树</p>
</blockquote>
<blockquote>
<p>堆 - 最大堆：每个节点的值都大于其子树所有节点的值 -
最小堆：每个节点的值都小于其子树所有节点的值</p>
</blockquote>
<h2 id="算法设计常用思想">算法设计常用思想</h2>
<h3 id="二分查找">二分查找</h3>
<p>一个循环有序数组（如：3, 4, 5, 6, 7, 8, 9, 0, 1,
2），不知道其最小值的位置，要查找任一数值的位置。要求算法时间复杂度为<span
class="math inline">\(log_2(n)\)</span></p>
<pre><code>1.将一个循环有序数组一分为二，一定得到一个有序数组和另一个循环有序数组 
2.长度不超过2的循环有序数组其实就是有序数组。</code></pre>
<ul>
<li>我们要先弄清楚这个循环有序数组的原数组是单调减的还是单调增，如果a1&gt;an,那么a一定是增加型的循环有序数组，如果a1&lt;an,那么a一定是减少型的循环有序数组。</li>
</ul>
<p>注意：a1=an这种情况。 *
判断左边一半和右边一半哪一个是有序的。这里以增加型的举例，减少型的同理。如果a[mid]
&gt;=
a[start]，那么左边一定是有序的。因为如果左边是循环有序的，那么最大值点一定出现在左侧，且最大值点左侧的数恒大于最大值点右侧的数。这与a[mid]
&gt;= a[start]矛盾。反之同理。</p>
<ul>
<li><p>确定了有序的一侧后，就要判断是不是在这一侧搜索了。这个判断非常简单，只要确定待搜索的数的值是否在有序数列的两个端点值之间即可。</p></li>
<li><p>最后通过循环，就可以类似二分法，找到待搜索的数的位置。</p></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习：玩转caffe之安装</title>
    <url>/201701/20170122-dev-install-caffe/</url>
    <content><![CDATA[<h1 id="caffe安装初探">Caffe安装初探</h1>
<h2 id="引言">引言</h2>
<p>做深度学习，没用玩过深度学习框架caffe就有点说不过去了。虽然自己的小机器显卡计算能力很弱，但是希望在cuda上跑caffe的心却没有停止过。从ubuntu12.04一直折腾到16.04，cuda从6.5也release到了8.0，中间走过的弯路很多。
- cuda与系统的适配能力问题 - ubuntu系统的问题 - caffe的框架的问题
经过这几年的发展，现在caffe的安装已经变得异常简单便捷。在此记录一下曾经的坑。
建议:
直接在机器上安装linux进行下面操作，要是在虚拟机里整，几乎没有什么戏，而且会把你给整疯的。</p>
<h2 id="安装blas">安装BLAS</h2>
<p>BLAS 可以通过mkl atlas openblas等实现，<a
href="http://stackoverflow.com/questions/7596612/benchmarking-python-vs-c-using-blas-and-numpy">性能比较</a>
发现这个mkl是不错的，但是要<a
href="https://software.intel.com/en-us/intel-mkl/">收费</a>
最后选择默认的<a
href="http://sourceforge.net/settings/mirror_choices?projectname=math-atlas&amp;filename=Stable/3.10.2/atlas3.10.2.tar.bz2">Atlas</a></p>
<p>********** Important Install Information: CPU THROTTLING ***********
Architecture configured as Corei2 (27) /tmp/ccp8Kkgo.o: In function
<code>ATL_tmpnam':     /home/charles/Repo/ATLAS//CONFIG/include/atlas_sys.h:224: warning: the use of</code>tmpnam'
is dangerous, better use `mkstemp'</p>
<pre><code>Clock rate configured as 800Mhz

Maximum number of threads configured as  4
probe_pmake.o: In function `ATL_tmpnam&#39;:
/home/charles/Repo/ATLAS//CONFIG/include/atlas_sys.h:224: warning: the use of `tmpnam` is dangerous, better use `mkstemp`
Parallel make command configured as &#39;$(MAKE) -j 4&#39;
CPU Throttling apparently enabled!
It appears you have cpu throttling enabled, which makes timings
unreliable and an ATLAS install nonsensical.  Aborting.
See ATLAS/INSTALL.txt for further information
xconfig exited with 1</code></pre>
<p>******************************* Solution ***************************
use ubuntu main software source switch to root admin</p>
<p>apt-get install gnome-applets cpufreq-selector -g performance -c
0</p>
<p><code>sudo apt-get install libatlas-base-dev</code></p>
<h2 id="安装boost">安装BOOST</h2>
<ul>
<li>preinstall boost should install following software</li>
<li>compile the source code 下载源代码，当前最新版本为version 1.60</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://downloads.sourceforge.net/project/boost/boost/1.60.0/boost_1_60_0.tar.gz</span><br><span class="line">unpacking boost 1.60.tar.gz</span><br><span class="line">source boot</span><br><span class="line">./b2</span><br><span class="line">./b2 install --prefix=/usr/local</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/lexical_cast.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">using</span> boost::lexical_cast;</span><br><span class="line">    <span class="type">int</span> a = <span class="built_in">lexical_cast</span>&lt;<span class="type">int</span>&gt;(<span class="string">&quot;123&quot;</span>);</span><br><span class="line">    <span class="type">double</span> b = <span class="built_in">lexical_cast</span>&lt;<span class="type">double</span>&gt;(<span class="string">&quot;123.12&quot;</span>);</span><br><span class="line">    std::cout&lt;&lt;a&lt;&lt;std::endl;</span><br><span class="line">    std::cout&lt;&lt;b&lt;&lt;std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>或者直接<code>apt-get install libboost-all-dev</code></p>
<h2 id="从7.5之后安装的方法简单得多">从7.5之后安装的方法简单得多</h2>
<p><code>sudo apt-get --purge remove nvidia-*</code>
到https://developer.nvidia.com/cuda-downloads下载对应的deb文件
到deb的下载目录下</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i cuda-repo-ubuntu1404_7.5-18_amd64.deb </span><br><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get install cuda</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>
<p>完成，cuda和显卡驱动就都装好了；其他的什么都不用动
而网上大部分中文和英文的参考教程都是过时的，折腾几个小时不说还容易装不成。</p>
<h3
id="查看机器参数是否满足cuda计算的最低要求">查看机器参数是否满足CUDA计算的最低要求</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lspci | grep -i nvidia</span><br><span class="line">01:00.0 3D controller: NVIDIA Corporation GF117M [GeForce 610M/710M/820M / GT 620M/625M/630M/720M] (rev a1)</span><br></pre></td></tr></table></figure>
<p>参照nvidia <a
href="http://developer.nvidia.com/cuda-gpus">往年发布的gpus</a>
我的机器为Compute Capability 2.1，是可以使用CUDA加速的。: )</p>
<h3
id="不是所有nvida显卡都支持cudnn的">不是所有Nvida显卡都支持cuDNN的</h3>
<p>折腾了很久的cuDNN安装，后来才发现是自己的显卡太low了，不支持cuDNN，因为Compute
Capability 才2.1，要支持cuDNN， Capability &gt;= 3.0，<a
href="https://developer.nvidia.com/cuda-gpus">查看自己显卡的计算能力</a></p>
<h3 id="install-cudnn">install cuDNN</h3>
<p>PREREQUISITES CUDA 7.0 and a GPU of compute capability 3.0 or higher
are required. Extract the cuDNN archive to a directory of your choice,
referred to below as <installpath>.Then follow the platform-specific
instructions as follows.</p>
<blockquote>
<p>LINUX</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd &lt;installpath&gt;</span><br><span class="line">export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<p>Add <installpath> to your build and link process by adding
-I<installpath> to your compile line and -L<installpath> -lcuDNN to your
link line.</p>
<blockquote>
<p>WINDOWS</p>
</blockquote>
<p>Add <installpath> to the PATH environment variable.</p>
<p>In your Visual Studio project properties, add <installpath> to the
Include Directories and Library Directories lists and add cuDNN.lib to
Linker-&gt;Input-&gt;Additional Dependencies.</p>
<h2 id="非gpu的自动安装脚本">非GPU的自动安装脚本</h2>
<p><a
href="https://github.com/cwlseu/script-ubuntu-debian/blob/master/install-caffe.sh">Install
Caffe Script</a></p>
<h2 id="pycaffe编译安装">pyCaffe编译安装</h2>
<ol type="1">
<li>首先要编译caffe成功，make pycaffe也成功</li>
<li>使得pycaffe可以被访问到, set
<code>PYTHONPATH=$PYTHONPATH:/path/to/caffe/python</code></li>
<li>install dependencies python
package.在python文件夹下面有requirements.txt文件，列出了所有有关的python
package. <code>pip install -r requirements.txt</code>
<strong>Note</strong>
这里一定要弄明白，默认情况下是使用python2.x的，如果你使用python3.x的话，请安装python3-pip,使用pip3进行安装，</li>
</ol>
<h1 id="综合一个安装cuda的教程">综合一个安装cuda的教程</h1>
<p>可以参考<a href="https://gwyve.github.io/"
class="uri">https://gwyve.github.io/</a>博客，为了方便把gwyve的cuda
安装部分blog放到这里。</p>
<h2 id="引言-1">引言</h2>
<p>使用NVIDIA
GPU进行dnn目前已经成为了主流，年前就打算自行安装一遍，拖了这么长时间，到今天才弄得差不多了。本来觉得这个不打算写个东西的，后来怕忘了，还是写下来吧</p>
<h2 id="设备介绍">设备介绍</h2>
<p>主机: ThinkStation-P300<br />
CPU: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz<br />
GPU: Tesla K20c</p>
<h2 id="所需软件">所需软件</h2>
<p>以下软件，在国内只有tensorflow需要翻墙，NVIDIA的都可以直接下载，速度还可以的</p>
<h3 id="ubuntu">Ubuntu</h3>
<p><a
href="https://www.ubuntu.com/download/alternative-downloads">Ubuntu
16.04.2 LTS</a><br />
<a
href="http://releases.ubuntu.com/16.04/ubuntu-16.04.2-desktop-amd64.iso.torrent?_ga=1.169319585.1810803403.1486517128">file_torrent</a></p>
<h3 id="驱动">驱动</h3>
<p><a
href="http://www.nvidia.cn/download/driverResults.aspx/115286/cn">Nvidia-375.39</a><br />
<a
href="http://cn.download.nvidia.com/XFree86/Linux-x86_64/375.39/NVIDIA-Linux-x86_64-375.39.run">file</a></p>
<h3 id="cuda">cuda</h3>
<p><a
href="https://developer.nvidia.com/cuda-downloads">cuda-8.0</a><br />
<a
href="https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda_8.0.61_375.26_linux-run">file</a></p>
<h3 id="cudnn">cuDNN</h3>
<p><a
href="https://developer.nvidia.com/rdp/cuDNN-download">cuDNN_5.1</a><br />
<a
href="https://developer.nvidia.com/compute/machine-learning/cuDNN/secure/v5.1/prod_20161129/8.0/cuDNN-8.0-linux-x64-v5.1-tgz">file</a></p>
<h2 id="安装步骤">安装步骤</h2>
<h3 id="系统安装">系统安装</h3>
<p>安装Ubuntu的过程自行搜索吧，教程很多，在此不说了。 ###
选择正确的源</p>
<p>此处采用<a href="mirror.aliyun.com">mirror.aliyun.com</a></p>
<h3 id="安装nvidia-driver">安装NVIDIA Driver</h3>
<p>起初，我是选择使用直接安装cuda的，cuda中有driver，但是，cuda安装完了之后，重复出现登录界面，无法进入系统，所以，我选择单独安装driver，然后，再安装cuda。解决重复登录界面参考<a
href="http://blog.csdn.net/u012759136/article/details/53355781">参考1</a></p>
<p>1.<a
href="http://www.nvidia.cn/Download/index.aspx?lang=cn">选择</a>机子所需要的驱动，并下载。<br />
2.卸载原有驱动：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get remove –purge nvidia*</span><br></pre></td></tr></table></figure>
<p>3.关闭nouveau<br />
创建 /etc/modprobe.d/blacklist-nouveau.conf并包含</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br></pre></td></tr></table></figure>
<p>在terminal输入</p>
<p><code>sudo update-initramfs -u</code></p>
<p>4.进入命令行模式<br />
Ctrl+Alt+F1<br />
5.关闭lightdm服务</p>
<p><code>sudo service lightdm stop</code></p>
<p>6.运行驱动文件 改变权限</p>
<p><code>sudo chmod a+x NVIDIA-Linux-x86_64-375.39.run</code></p>
<p>运行 <strong>注意参数</strong></p>
<p><code>sudo ./NVIDIA-Linux-x86_64-375.39.run –no-x-check –no-nouveau-check –no-opengl-files</code></p>
<pre><code>- no-x-check 安装驱动时关闭X服务
- no-nouveau-check 安装驱动时禁用nouveau
- no-opengl-files 只安装驱动文件，不安装OpenGL文件</code></pre>
<p>7.重启，不出现循环登录问题,如果出现循环登陆, 请看后面的问题。</p>
<h3 id="安装cuda">安装cuda</h3>
<p>本来是按照deb安装的，后来各种问题，就改成选择runfile的方式了。</p>
<p>这里主要参考<a
href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/#runfile-nouveau-ubuntu">参考2</a>，全是英文的，要是不想看英文的话，我觉得，那还是放弃做dnn吧，目前这个前沿领域中文文献比较少～</p>
<p>1.在运行.run文件之后，在选择是否安装驱动的位置选择no，剩下的都是yes。<br />
2.添加环境变量<br />
打开 ～/.bashrc在最后添加</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>
<p>在terminal输入<br />
<code>source ~/.bashrc</code> 3.测试cuda安装是否成功
<code>nvcc -V</code> 输入cuda的版本信息<br />
4.测试samples<br />
这部分参考<a
href="http://blog.csdn.net/u012235003/article/details/54575758">参考3</a></p>
<p>进入 <code>NVIDIA_CUDA-8.0-Samples/</code> <code>make</code>
运行NVIDIA_CUDA-8.0-Samples/bin/x86_64/linux/release/deviceQuery</p>
<p>显示最后出现“Resalt=PASS”，代表成功</p>
<h3 id="安装cudnn">安装cuDNN</h3>
<p>安装之前一定要确认你的GPU是支持cuDNN的。
这个都不应该叫做安装，就是一个创建链接的过程。这个主要参考<a
href="http://blog.csdn.net/jk123vip/article/details/50361951">参考4</a></p>
<p>1.下载tar文件，解压<br />
解压出一个叫做cuda的文件夹，以下操作都是在该文件夹下进行<br />
2.复制文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">cp</span> include/cuDNN.h /usr/local/include</span><br><span class="line">sudo <span class="built_in">cp</span> lib64/libcuDNN.so* /usr/local/lib</span><br></pre></td></tr></table></figure>
<p>3.创建cuDNN的软链接</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo <span class="built_in">ln</span> -sf /usr/local/lib/libcuDNN.so.5.1.10 /usr/local/lib/libcuDNN.so.5</span><br><span class="line">$ sudo <span class="built_in">ln</span> -sf /usr/local/lib/libcuDNN.so.5 /usr/local/lib/libcuDNN.so</span><br><span class="line">$ sudo ldconfig -v</span><br></pre></td></tr></table></figure>
<h2 id="caffe-install-prepare-dependencies">Caffe install Prepare
Dependencies</h2>
<p><a
href="https://github.com/cwlseu/recipes/blob/master/script/install-caffe.sh">安装caffe之前，自动化安装的各种依赖脚本</a></p>
<h2 id="install-opencv-from-source">Install OpenCV from Source</h2>
<p>自行进行官网查询或者采用如下脚本进行安装。 <a
href="https://github.com/cwlseu/recipes/blob/master/script/install-opencv.sh">Install
OpenCV scripts</a>
当然cmake可以采用最基本的：<code>cmake ..</code>进行就完全ok</p>
<pre><code>安装结束之后，请务必添加OpenCV lib所在的路径添加到`LD_LIBRARY_PATH`，因为OpenCV 默认安装路径`/usr/local/lib`并不在`LD_LIBRARY_PATH`中。</code></pre>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/lib:/usr/local/cuda/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>
<h2 id="install-python-dependencies">Install Python dependencies</h2>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-get install -y python-pip</span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$CAFFE_ROOT</span>/python</span><br><span class="line"><span class="keyword">for</span> pack <span class="keyword">in</span> $(<span class="built_in">cat</span> requirements.txt); <span class="keyword">do</span> sudo pip install <span class="variable">$pack</span>; <span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>等待python依赖的库安装完毕。 ok，
现在应该就可以运行example/下的某些例子了。</p>
<h1 id="faq总结">FAQ总结</h1>
<h2 id="hdf5.h没有找到">hdf5.h没有找到</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">CXX src/caffe/layer_factory.cpp</span><br><span class="line">CXX src/caffe/util/insert_splits.cpp</span><br><span class="line">CXX src/caffe/util/db.cpp</span><br><span class="line">CXX src/caffe/util/upgrade_proto.cpp</span><br><span class="line">In file included from src/caffe/util/upgrade_proto.cpp:<span class="number">10</span>:<span class="number">0</span>:</span><br><span class="line">./include/caffe/util/io.hpp:<span class="number">8</span>:<span class="number">18</span>: fatal error: hdf5.h: no such file <span class="keyword">or</span> directory</span><br><span class="line"> <span class="meta">#<span class="keyword">include</span> <span class="string">&quot;hdf5.h&quot;</span></span></span><br><span class="line">                  ^</span><br><span class="line">compilation terminated.</span><br><span class="line">Makefile:<span class="number">512</span>: recipe <span class="keyword">for</span> target <span class="string">&#x27;.build_release/src/caffe/util/upgrade_proto.o&#x27;</span> failed</span><br><span class="line">make: *** [.build_release/src/caffe/util/upgrade_proto.o] Error <span class="number">1</span></span><br><span class="line">make: *** 正在等待未完成的任务....</span><br><span class="line">In file included from ./include/caffe/common_layers.hpp:<span class="number">10</span>:<span class="number">0</span>,</span><br><span class="line">                 from ./include/caffe/vision_layers.hpp:<span class="number">10</span>,</span><br><span class="line">                 from src/caffe/layer_factory.cpp:<span class="number">6</span>:</span><br><span class="line">./include/caffe/data_layers.hpp:<span class="number">9</span>:<span class="number">18</span>: fatal error: hdf5.h: no such file <span class="keyword">or</span> directory</span><br><span class="line"> <span class="meta">#<span class="keyword">include</span> <span class="string">&quot;hdf5.h&quot;</span></span></span><br><span class="line">                  ^</span><br><span class="line">compilation terminated.</span><br><span class="line">Makefile:<span class="number">512</span>: recipe <span class="keyword">for</span> target <span class="string">&#x27;.build_release/src/caffe/layer_factory.o&#x27;</span> failed</span><br><span class="line">make: *** [.build_release/src/caffe/layer_factory.o] Error <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>参看<a href="https://github.com/NVIDIA/DIGITS/issues/156">caffe
issues</a></p>
<h3 id="方案一">方案一：</h3>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/lib/x86_64-linux-gnu</span><br><span class="line">sudo <span class="built_in">ln</span> -s libhdf5_serial.so.8.0.2 libhdf5.so</span><br><span class="line">sudo <span class="built_in">ln</span> -s libhdf5_serial_hl.so.8.0.2 libhdf5_hl.so</span><br></pre></td></tr></table></figure>
<h3 id="方案二">方案二</h3>
<p>just modify the Makefile.config INCLUDE_DIRS := $(PYTHON_INCLUDE)
/usr/local/include /usr/include/hdf5/serial/ LIBRARY_DIRS :=
$(PYTHON_LIB) /usr/local/lib /usr/lib
/usr/lib/x86_64-linux-gnu/hdf5/serial/ <a
href="https://github.com/BVLC/caffe/issues/2690">issues 2690</a></p>
<h2 id="编译opencv-syntax-error-identifier-nppigraphcutstate">编译OpenCV
syntax error: identifier 'NppiGraphcutState'</h2>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030356322.png"
alt="@build opencv using cuda" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="build">@build</span> opencv using cuda</figcaption>
</figure>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1&gt;------ Build started: Project: opencv_cudalegacy, Configuration: Debug x64 ------</span><br><span class="line">1&gt;  graphcuts.cpp</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(120): error C2061: syntax error: identifier <span class="string">&#x27;NppiGraphcutState&#x27;</span></span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(135): error C2833: <span class="string">&#x27;operator NppiGraphcutState&#x27;</span> is not a recognized operator or <span class="built_in">type</span></span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(135): error C2059: syntax error: <span class="string">&#x27;newline&#x27;</span></span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(136): error C2334: unexpected token(s) preceding <span class="string">&#x27;&#123;&#x27;</span>; skipping apparent <span class="keyword">function</span> body</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(141): error C2143: syntax error: missing <span class="string">&#x27;;&#x27;</span> before <span class="string">&#x27;*&#x27;</span></span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(141): error C4430: missing <span class="built_in">type</span> specifier - int assumed. Note: C++ does not support default-int</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(141): error C2238: unexpected token(s) preceding <span class="string">&#x27;;&#x27;</span></span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(127): error C2065: <span class="string">&#x27;pState&#x27;</span>: undeclared identifier</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(132): error C2065: <span class="string">&#x27;pState&#x27;</span>: undeclared identifier</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(132): error C3861: <span class="string">&#x27;nppiGraphcutFree&#x27;</span>: identifier not found</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(174): error C3861: <span class="string">&#x27;nppiGraphcutGetSize&#x27;</span>: identifier not found</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(182): error C2065: <span class="string">&#x27;nppiGraphcutInitAlloc&#x27;</span>: undeclared identifier</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(190): error C3861: <span class="string">&#x27;nppiGraphcut_32s8u&#x27;</span>: identifier not found</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(195): error C3861: <span class="string">&#x27;nppiGraphcut_32f8u&#x27;</span>: identifier not found</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(246): error C3861: <span class="string">&#x27;nppiGraphcut8GetSize&#x27;</span>: identifier not found</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(254): error C2065: <span class="string">&#x27;nppiGraphcut8InitAlloc&#x27;</span>: undeclared identifier</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(264): error C3861: <span class="string">&#x27;nppiGraphcut8_32s8u&#x27;</span>: identifier not found</span><br><span class="line">1&gt;V:\Opencv31\opencv\sources\modules\cudalegacy\src\graphcuts.cpp(271): error C3861: <span class="string">&#x27;nppiGraphcut8_32f8u&#x27;</span>: identifier not found</span><br><span class="line">2&gt;------ Build started: Project: opencv_cudaoptflow, Configuration: Debug x64 ------</span><br><span class="line">2&gt;LINK : warning LNK4044: unrecognized option <span class="string">&#x27;/LV:/NVIDIA GPU Computing Toolkit/Cuda8/lib/x64&#x27;</span>; ignored</span><br><span class="line">2&gt;LINK : fatal error LNK1104: cannot open file <span class="string">&#x27;..\..\lib\Debug\opencv_cudalegacy310d.lib&#x27;</span></span><br></pre></td></tr></table></figure>
<p><a
href="http://answers.opencv.org/question/95148/cudalegacy-not-compile-nppigraphcut-missing/">cudalegacy-not-compile-nppigraphcut-missing</a>
这个问题在opencv中已经fix掉了。</p>
<p>将opencv.cpp中的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &quot;precomp.hpp&quot;</span><br><span class="line">#if !defined (HAVE_CUDA) || defined (CUDA_DISABLER)</span><br></pre></td></tr></table></figure>
<p>修改为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &quot;precomp.hpp&quot;</span><br><span class="line"></span><br><span class="line">#if !defined (HAVE_CUDA) || defined (CUDA_DISABLER)  || (CUDART_VERSION &gt;= 8000)</span><br></pre></td></tr></table></figure>
<h2 id="ld链接失败或者.o没有生成">ld链接失败，或者.o没有生成</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030309814.png"
alt="caffe make-j8 recipe failed" />
如果你使用的是<code>make -j8</code>进行编译的，并且你需要的lib已经都加到<code>LD_LIBRARY_PATH</code>中了，那么你可以再试一遍<code>make -j8</code>或者使用<code>make -j4</code>
or
<code>make -j</code>，最保险的情况就是使用<code>make</code>进行编译，虽然慢点但是不会出现各种依赖找不到的情况。</p>
<pre><code>因为使用多线程编译的时候，不同线程编译不同的cpp文件，尤其是caffe编译过程中首先是要调用 `protoc` 进行生成 `caffe.pb.h` 的，如果多线程编译过程中，一个线程编译的cpp依赖caffe.pb.h，但是此时还没有生成完毕caffe.pb.h,就会出现类似错误。</code></pre>
<h2 id="opencv库找不到问题">Opencv库找不到问题</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CXX/LD -o .build_release/tools/extract_features.bin</span><br><span class="line">.build_release/lib/libcaffe.so: undefined reference to `cv::imread(cv::String const&amp;, int)&#x27;</span><br><span class="line">.build_release/lib/libcaffe.so: undefined reference to `cv::imencode(cv::String const&amp;, cv::_InputArray const&amp;, std::vector&lt;unsigned char, std::allocator&lt;unsigned char&gt; &gt;&amp;, std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;)&#x27;</span><br><span class="line">.build_release/lib/libcaffe.so: undefined reference to `cv::imdecode(cv::_InputArray const&amp;, int)&#x27;</span><br><span class="line">collect2: error: ld returned 1 exit status</span><br><span class="line">Makefile:562: recipe for target &#x27;.build_release/tools/extract_features.bin&#x27; failed</span><br><span class="line">make: *** [.build_release/tools/extract_features.bin] Error 1</span><br></pre></td></tr></table></figure>
<p>在Makefile中LIBRARES中添加 opencv_imgcodecs项</p>
<h2 id="循环登陆界面">循环登陆界面</h2>
<h3 id="方案一-1">方案一</h3>
<ol type="1">
<li>卸掉nvidia-driver
<code>sudo apt-get remove --purge nvidia*</code></li>
<li>看看能不能登陆guest，可以的话 删除home/user/目录下的
<code>.Xauthority  .xsession-errors</code></li>
<li>reboot</li>
</ol>
<h3 id="方案二-1">方案二</h3>
<ol type="1">
<li><p>卸掉nvidia-driver
<code>sudo apt-get remove --purge nvidia*</code></p></li>
<li><p>进入grub启动界面，可是使用advance
启动方式，进行修复界面。通过选择<code>recovery mode</code>进行恢复之后，然后重启。</p>
<p>后来经过调研和重新格式化系统进行安装之后发现，原来是CUDA7.5
的<code>.deb</code>对Ubuntu 14.04
的支持性不好，导致显示驱动程序有问题，从而无法正常进入系统。而且有人建议采用<code>.run</code>的toolkit进行安装,
所以后面使用<code>.run</code>进行安装</p></li>
</ol>
<h2 id="双电源供电的一些坑"><a
href="http://gwyve.com/blog/2017/05/02/double-power.html">双电源供电的一些坑</a></h2>
<h2 id="没有sudu权限安装caffe">没有sudu权限，安装caffe</h2>
<ol type="1">
<li>下载<a
href="链接：http://pan.baidu.com/s/1kUZoq7H%20密码：aumh">caffe
依赖包</a>，解压到某个路径下。如果失活了, emailto:<a
href="mailto:caowenlong92@gmail.com"
class="email">caowenlong92@gmail.com</a></li>
<li>添加caffelib/lib的绝对路径到~/.bashrc 中
<code>export LD_LIBRARY_PATH=/home/.../caffelib/lib$LD_LIBRARY_PATH</code></li>
<li>在Makefile.config中<code>INCLUDE_DIRS</code>中添加caffelib/include的绝对路径；<code>LIBRARY_DIRS</code>中添加添加caffelib/lib的绝对路径</li>
<li>cuda啥的一般管理员就帮你搞定了，实在不行咱自己安装到某个路径下，在Makefile.config中配置一下路径就ok了</li>
<li>python 依赖可以通过<code>virtualenv</code>解决掉的，<a
href="https://virtualenv.pypa.io/en/stable/userguide/">如何使用<code>virtualenv</code></a>可以看官网</li>
</ol>
<h2 id="quarto-fx580">Quarto Fx580</h2>
<p>查看显卡型号<code>lspci | grep "VGA"</code></p>
<pre><code>01:00.0 VGA compatible controller: NVIDIA Corporation G96GL [Quadro FX 580] (rev a1)</code></pre>
<p><a
href="http://www.nvidia.com/content/DriverDownload-March2009/confirmation.php?url=/XFree86/Linux-x86_64/340.102/NVIDIA-Linux-x86_64-340.102.run&amp;lang=us&amp;type=geforcem">驱动下载</a></p>
<p><a
href="https://developer.nvidia.com/cuda-gpus">查看GPU卡是否支持cuda</a>
哦哦，并不支持，好吧，换卡吧。</p>
<h2
id="error-kemptystring-is-not-a-member-of-googleprotobufinternal">error:
‘kEmptyString’ is not a member of ‘google::protobuf::internal’</h2>
<p>这个比较玄，有的人使用protobuf
2.5就OK，有的人使用这个版本就爆出这个错误。我是使用libprotoc
2.5.0版本，当
使用<code>make</code>进行编译的时候就会出现该问题。当时如果采用make -j
https://blog.csdn.net/ahbbshenfeng/article/details/52065676</p>
<h2 id="参考文献">参考文献</h2>
<p>1.<a
href="http://blog.csdn.net/u012759136/article/details/53355781">【解决】Ubuntu安装NVIDIA驱动后桌面循环登录问题</a><br />
2.<a
href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/#runfile-nouveau-ubuntu">NVIDIA
CUDA Installation Guide for Linux</a></p>
<p>3.<a
href="http://blog.csdn.net/u012235003/article/details/54575758">CUDA安装和测试</a></p>
<p>4.<a
href="http://blog.csdn.net/jk123vip/article/details/50361951">import
TensorFlow提示Unable to load cuDNN DSO</a><br />
5.<a href="https://www.tensorflow.org/install/install_linux">Installing
TensorFlow on Ubuntu</a></p>
<p>6.<a
href="https://github.com/cwlseu/recipes/blob/master/script/install-opencv.sh">Install
OpenCV Scripts</a></p>
<p>7.<a
href="https://virtualenv.pypa.io/en/stable/userguide/">virtualenv user
guide</a></p>
<p>8.<a
href="https://developer.nvidia.com/cuda-gpus">查看GPU卡是否支持cuda</a></p>
<p>9.<a
href="https://developer.nvidia.com/cuda-toolkit-archive">cuda各个版本库</a></p>
<p>10.<a
href="http://www.ibm.com/developerworks/cn/linux/l-cn-gpb/">IBM的google
protocol buffer的介绍链接</a></p>
<p>11.<a
href="https://stackoverflow.com/questions/37983310/protobuf-on-ubuntu-not-compiling">protobuf-on-ubuntu-not-compiling</a></p>
<p>12.<a
href="https://stackoverflow.com/questions/36360188/c-protobuf-error-googleprotobufinternalkemptystring-error">googleprotobufinternalkemptystring</a></p>
<h1 id="docker安装caffe">Docker安装caffe</h1>
<p>The <code>standalone</code> subfolder contains docker files for
generating both CPU and GPU executable images for Caffe. The images can
be built using make, or by running:
<code>docker build -t caffe:cpu standalone/cpu</code> for example. (Here
<code>gpu</code> can be substituted for <code>cpu</code>, but to keep
the readme simple, only the <code>cpu</code> case will be discussed in
detail).</p>
<p>Note that the GPU standalone requires a CUDA 8.0 capable driver to be
installed on the system and [nvidia-docker] for running the Docker
containers. Here it is generally sufficient to use
<code>nvidia-docker</code> instead of <code>docker</code> in any of the
commands mentioned.</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 基础镜像</span></span><br><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">14.04</span></span><br><span class="line"><span class="comment"># 进行维护者信息</span></span><br><span class="line"><span class="keyword">MAINTAINER</span> caffe-maint@googlegroups.com</span><br><span class="line"><span class="comment"># 在基础镜像上执行一些命令，安装caffe依赖的libs</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y --no-install-recommends \</span></span><br><span class="line"><span class="language-bash">        build-essential \</span></span><br><span class="line"><span class="language-bash">        cmake \</span></span><br><span class="line"><span class="language-bash">        git \</span></span><br><span class="line"><span class="language-bash">        wget \</span></span><br><span class="line"><span class="language-bash">        libatlas-base-dev \</span></span><br><span class="line"><span class="language-bash">        libboost-all-dev \</span></span><br><span class="line"><span class="language-bash">        libgflags-dev \</span></span><br><span class="line"><span class="language-bash">        libgoogle-glog-dev \</span></span><br><span class="line"><span class="language-bash">        libhdf5-serial-dev \</span></span><br><span class="line"><span class="language-bash">        libleveldb-dev \</span></span><br><span class="line"><span class="language-bash">        liblmdb-dev \</span></span><br><span class="line"><span class="language-bash">        libopencv-dev \</span></span><br><span class="line"><span class="language-bash">        libprotobuf-dev \</span></span><br><span class="line"><span class="language-bash">        libsnappy-dev \</span></span><br><span class="line"><span class="language-bash">        protobuf-compiler \</span></span><br><span class="line"><span class="language-bash">        python-dev \</span></span><br><span class="line"><span class="language-bash">        python-numpy \</span></span><br><span class="line"><span class="language-bash">        python-pip \</span></span><br><span class="line"><span class="language-bash">        python-scipy &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 声明变量并初始化</span></span><br><span class="line"><span class="keyword">ENV</span> CAFFE_ROOT=/opt/caffe</span><br><span class="line"><span class="comment"># 切换当前工作路径为</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> <span class="variable">$CAFFE_ROOT</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">FIXME:</span> clone a specific git tag and use ARG instead of ENV once DockerHub supports this.</span></span><br><span class="line"><span class="keyword">ENV</span> CLONE_TAG=master</span><br><span class="line"><span class="comment"># clone caffe源代码，安装python依赖库，编译caffe</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> git <span class="built_in">clone</span> -b <span class="variable">$&#123;CLONE_TAG&#125;</span> --depth 1 https://github.com/BVLC/caffe.git . &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="keyword">for</span> req <span class="keyword">in</span> $(<span class="built_in">cat</span> python/requirements.txt) pydot; <span class="keyword">do</span> pip install <span class="variable">$req</span>; <span class="keyword">done</span> &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    cmake -DCPU_ONLY=1 .. &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    make -j<span class="string">&quot;<span class="subst">$(nproc)</span>&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置环境变量</span></span><br><span class="line"><span class="keyword">ENV</span> PYCAFFE_ROOT $CAFFE_ROOT/python</span><br><span class="line"><span class="keyword">ENV</span> PYTHONPATH $PYCAFFE_ROOT:$PYTHONPATH</span><br><span class="line"><span class="keyword">ENV</span> PATH $CAFFE_ROOT/build/tools:$PYCAFFE_ROOT:$PATH</span><br><span class="line"><span class="comment"># 像链接文件中写入当前caffe库</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$CAFFE_ROOT</span>/build/lib&quot;</span> &gt;&gt; /etc/ld.so.conf.d/caffe.conf &amp;&amp; ldconfig</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换工作路径</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /workspace</span></span><br></pre></td></tr></table></figure>
<h2 id="在docker镜像中运行caffe">在docker镜像中运行caffe</h2>
<p>In order to test the Caffe image, run:
<code>docker run -ti caffe:cpu caffe --version</code></p>
<p>which should show a message like:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">libdc1394 error: Failed to initialize libdc1394</span><br><span class="line">caffe version 1.0.0-rc3</span><br></pre></td></tr></table></figure>
<p>One can also build and run the Caffe tests in the image using:</p>
<p><code>docker run -ti caffe:cpu bash -c "cd /opt/caffe/build; make runtest"</code></p>
<p>In order to get the most out of the caffe image, some more advanced
<code>docker run</code> options could be used. For example, running:</p>
<p><code>docker run -ti --volume=$(pwd):/workspace caffe:cpu caffe train --solver=example_solver.prototxt</code></p>
<p>will train a network defined in the
<code>example_solver.prototxt</code> file in the current directory
(<code>$(pwd)</code> is maped to the container volume
<code>/workspace</code> using the <code>--volume=</code> Docker
flag).</p>
<p>Note that docker runs all commands as root by default, and thus any
output files (e.g. snapshots) generated will be owned by the root user.
In order to ensure that the current user is used instead, the following
command can be used:</p>
<p><code>docker run -ti --volume=$(pwd):/workspace -u $(id -u):$(id -g) caffe:cpu caffe train --solver=example_solver.prototxt</code></p>
<p>where the <code>-u</code> Docker command line option runs the
commands in the container as the specified user, and the shell command
<code>id</code> is used to determine the user and group ID of the
current user. Note that the Caffe docker images have
<code>/workspace</code> defined as the default working directory. This
can be overridden using the <code>--workdir=</code> Docker command line
option.</p>
<h2 id="其他案例">其他案例</h2>
<p>Although running the <code>caffe</code> command in the docker
containers as described above serves many purposes, the container can
also be used for more interactive use cases. For example, specifying
<code>bash</code> as the command instead of <code>caffe</code> yields a
shell that can be used for interactive tasks. (Since the caffe build
requirements are included in the container, this can also be used to
build and run local versions of caffe).</p>
<p>Another use case is to run python scripts that depend on
<code>caffe</code>'s Python modules. Using the <code>python</code>
command instead of <code>bash</code> or <code>caffe</code> will allow
this, and an interactive interpreter can be started by running:</p>
<p><code>docker run -ti caffe:cpu python</code></p>
<p>(<code>ipython</code> is also available in the container).</p>
<p>Since the <code>caffe/python</code> folder is also added to the path,
the utility executable scripts defined there can also be used as
executables. This includes <code>draw_net.py</code>,
<code>classify.py</code>, and <code>detect.py</code></p>
<h2 id="挂载本地目录到容器中">挂载本地目录到容器中</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> cafferoot</span><br><span class="line"></span><br><span class="line">docker -run -ti --volume=$(<span class="built_in">pwd</span>):/workspace caffe:cpu /bin/bash</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>解析：<code>--volume=$(pwd):/workspace</code>是挂载本机目录到容器中，<code>--volume or -v</code>是docker的挂载命令，<code>=$(pwd):/workspace</code>是挂载信息，是将<code>$(pwd)</code>即本机当前目录，:是挂载到哪，<code>/workspace</code>是容器中的目录，就是把容器中的<code>workspace</code>目录换成本机的当前目录，这样就可以在本机与容器之间进行交互了，本机当前目录可以编辑，容器中同时能看到。容器中的workspace目录的修改也直接反应到了本机上。<code>$()</code>是Linux中的命令替换，即将<span
class="math inline">\(()中的命令内容替换为参数，pwd是Linux查看当前目录，我的本机当前目录为cafferoot，`--volume=\)</span>(pwd):/workspace<code>就等于</code>--volume=/Users/<strong><em>/cafferoot:/workspace<code>，</code>/Users/</em></strong>/cafferoot<code>为</code>pwd`的执行结果，$()是将pwd的执行结果作为参数执行。</p>
<h2 id="一些有用的命令">一些有用的命令</h2>
<ol type="1">
<li><p>基于image
<code>nvidia/cuda</code>运行某条命令<code>nvidia-smi</code>
<code>nvidia-docker run  nvidia/cuda nvidia-smi</code></p></li>
<li><p>查看当前有哪些镜像
<code>sudo nvidia-docker images</code></p></li>
<li><p>查看当前有哪些运行中的实例
<code>sudo nvidia-docker ps -l</code></p></li>
<li><p>运行某个镜像的实例
<code>sudo nvidia-docker run -it nvidia/cuda</code></p></li>
<li><p>链接运行中的镜像
<code>sudo nvidia-docker attach d641ab33bec2</code></p></li>
<li><p>跳出运行中的image镜像，但是不退出 <code>ctrl+p</code>,
<code>ctrl+q</code></p></li>
<li><p>使用linux命令对镜像实例进行操作
<code>sudo nvidia-docker cp zeyu/VOCtrainval_11-May-2012.tar  e6a0961ab4cf:/workspace/data</code>
<code>sudo nvidia-docker run -it -t nvidia/cuda nvidia-smi</code></p></li>
<li><p>在host机器上启动新的bash
<code>sudo nvidia-docker exec -it d641ab33bec2 bash</code></p></li>
</ol>
<h2 id="tls-handshake-timeout-问题">TLS handshake timeout 问题</h2>
<p>iscas@ZXC-Lenovo:~/Repo$ sudo docker build -t caffe:cpu docker/caffe
Sending build context to Docker daemon 3.072 kB Step 1/12 : FROM
ubuntu:14.04 Get https://registry-1.docker.io/v2/: net/http: TLS
handshake timeout</p>
<p>很明显可以看出是连接不到 docker
hub，那就需要查看网络原因了。当然较简单的解决办法就是用国内的仓库，
下面的方法就是使用国内的 daocloud 的仓库：</p>
<blockquote>
<p>添加国内库的依赖</p>
</blockquote>
<p><code>$ echo "DOCKER_OPTS="$DOCKER_OPTS --registry-mirror=http://f2d6cb40.m.daocloud.io"" | sudo tee -a /etc/default/docker</code></p>
<blockquote>
<p>重启服务</p>
</blockquote>
<p><code>$ sudo service docker restart</code></p>
<p>更多问题可以查看[3]</p>
<h2 id="docker相关的参考文献">Docker相关的参考文献</h2>
<ol type="1">
<li><p>[Docker理论与实践]<a
href="http://noahsnail.com/2016/12/01/2016-12-1-Docker%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%88%E5%9B%9B%EF%BC%89/"
class="uri">http://noahsnail.com/2016/12/01/2016-12-1-Docker%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%88%E5%9B%9B%EF%BC%89/</a></p></li>
<li><p>[docker install caffe]<a
href="https://github.com/cwlseu/caffe/edit/master/docker/README.md"
class="uri">https://github.com/cwlseu/caffe/edit/master/docker/README.md</a></p></li>
<li><p>[Pull Docker image的时候遇到docker pull TLS handshake timeout]<a
href="https://blog.csdn.net/han_cui/article/details/55190319"
class="uri">https://blog.csdn.net/han_cui/article/details/55190319</a></p></li>
<li><p>[caffe cpu docker]<a
href="https://hub.docker.com/r/elezar/caffe/"
class="uri">https://hub.docker.com/r/elezar/caffe/</a></p></li>
</ol>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>framework</tag>
      </tags>
  </entry>
  <entry>
    <title>算法的乐趣：再看深度优先搜索</title>
    <url>/201703/20170315-based-algorithm-2/</url>
    <content><![CDATA[<h2 id="适用场景">适用场景</h2>
<p><strong>输入数据</strong>：如果是递归数据结构，如单链表，二叉树，集合，则百分之百可以用深搜；如果是
非递归数据结构，如一维数组，二维数组，字符串，图，则概率小一些。
<strong>状态转换图</strong>：树或者图。
<strong>求解目标</strong>：必须要走到最深（例如对于树，必须要走到叶子节点）才能得到一个解，这种情况
适合用深搜。</p>
<h2 id="思考步骤">思考步骤</h2>
<ol type="1">
<li>是求路径条数，还是路径本身（或动作序列）？深搜最常见的三个问题，求可行解的总数，求一个可行解，求所有可行解。</li>
</ol>
<ul>
<li>如果是求路径本身，则要用一个数组 <code>path[]</code>
存储路径。跟宽搜不同，宽搜虽然最终求的也是一条路径，但是需要存储扩展过程中的所有路径，在没找到答案之前所有路径都不能放弃；而深搜，在搜索过程中始终只有一条路径，因此用一个数组就足够了。</li>
<li>如果是路径条数，则不需要存储路径。</li>
</ul>
<ol start="2" type="1">
<li><p>只要求一个解，还是要求所有解？
如果只要求一个解，那找到一个就可以返回；如果要求所有解，找到了一个后，还要继续扩展，直到遍历完。广搜一般只要求一个解，因而不需要考虑这个问题（广搜当然也可以求所有解，这时需要扩展到所有叶子节点，相当于在内存中存储整个状态转换图，非常占内存，因此广搜不适合解这类问题）。</p></li>
<li><p>如何表示状态？
即一个状态需要存储哪些些必要的数据，才能够完整提供如何扩展到下一步状态的所有信息。跟广搜不同，深搜的惯用写法，不是把数据记录在状态
struct 里，而是添加函数参数（有时为了节省递归堆栈，用全局变量）， struct
里的字段与函数参数一一对应。</p></li>
<li><p>如何扩展状态？
这一步跟上一步相关。状态里记录的数据不同，扩展方法就不同。对于固定不变的数据结构（一般题目直接给出，作为输入数据），如二叉树，图等，扩展方法很简单，直接往下一层走，对于隐式图，要先在第
1
步里想清楚状态所带的数据，想清楚了这点，那如何扩展就很简单了。</p></li>
<li><p>关于判重</p></li>
</ol>
<ul>
<li>如果状态转换图是一棵树，则不需要判重，因为在遍历过程中不可能重复。</li>
<li>如果状态转换图是一个图，则需要判重，方法跟广搜相同，见第 §9.4
节。这里跟第 8 步
中的加缓存是相同的，如果有重叠子问题，则需要判重，此时加缓存自然也是有效果的。</li>
</ul>
<ol start="6" type="1">
<li><p>终止条件是什么？
终止条件是指到了不能扩展的末端节点。对于树，是叶子节点，对于图或隐式图，是出度为
0 的节点。</p></li>
<li><p>收敛条件是什么？ 收敛条件是指找到了一个合法解的时刻。</p></li>
</ol>
<ul>
<li>如果是正向深搜（父状态处理完了才进行递归，即父状态不依赖子状态，递归语句一定是在最后，尾递归），则是指是否达到目标状态；</li>
<li>如果是逆向深搜（处理父状态时需要先知道子状态的结果，此时递归语句不在最后），则是指是否到达初始状态。</li>
<li>由于很多时候终止条件和收敛条件是是合二为一的，因此很多人不区分这两种条件。仔细区分这两种条件，还是很有必要的。
为了判断是否到了收敛条件，要在函数接口里用一个参数记录当前的位置（或距离目标还有多远）。如果是求一个解，直接返回这个解；<em>如果是求所有解，要在这里收集解，即把第一步中表示路径的数组
path[] 复制到解集合里</em>。</li>
</ul>
<ol start="8" type="1">
<li>如何加速？</li>
</ol>
<ul>
<li>剪枝。深搜一定要好好考虑怎么剪枝，成本小收益大，加几行代码，就能大大加速。这里没有通用方法，只能具体问题具体分析，要充分观察，充分利用各种信息来剪枝，在中间节点提前返回。</li>
<li>缓存。如果子问题的解会被重复利用，可以考虑使用缓存。
<ul>
<li>前提条件：子问题的解会被重复利用，即子问题之间的依赖关系是有向无环图(DAG)。如果依赖关系是树状的（例如树，单链表），没必要加缓存，因为子问题只会一层层往下，用一次就再也不会用到，加了缓存也没什么加速效果。</li>
<li>具体实现：可以用数组或
HashMap。维度简单的，用数组；维度复杂的，用HashMap， C++ 有 map， C++ 11
以后有 unordered_map，比 map 快。</li>
</ul></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/******************************************************************************</span></span><br><span class="line"><span class="comment"> * @description：</span></span><br><span class="line"><span class="comment"> *    走迷宫问题</span></span><br><span class="line"><span class="comment"> * 考虑要点：</span></span><br><span class="line"><span class="comment"> *  1.</span></span><br><span class="line"><span class="comment"> 拓展状态+表示状态。当前步与下一步之间如何转换，本题目中采用一个book进行记录已经走过的步骤。</span></span><br><span class="line"><span class="comment"> *  当前步骤与下一步至今采用重置book值的方式实现切换</span></span><br><span class="line"><span class="comment"> *  2. 一次搜索终止条件是什么?</span></span><br><span class="line"><span class="comment"> *  3. 优化：</span></span><br><span class="line"><span class="comment">      是否可以进行剪枝操作？判断条件是什么？</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> ******************************************************************************/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;dfs_format_print.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cassert&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;climits&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">//迷宫</span></span><br><span class="line"><span class="type">static</span> std::vector&lt;std::vector&lt;<span class="type">bool</span>&gt;&gt; maze;</span><br><span class="line"><span class="comment">//迷宫的长宽</span></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> maze_h, maze_w;</span><br><span class="line"><span class="comment">//标记是否走过了</span></span><br><span class="line"><span class="type">static</span> std::vector&lt;std::vector&lt;<span class="type">bool</span>&gt;&gt; book;</span><br><span class="line"><span class="comment">// 初始位置和目标位置</span></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> startx, starty;</span><br><span class="line"><span class="type">static</span> <span class="type">int</span> p, q; <span class="comment">//目标的位置</span></span><br><span class="line"><span class="comment">// 记录最小路径长度</span></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> min_step = INT_MAX;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> std::vector&lt;std::pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt;&gt; min_path;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> total = <span class="number">0</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 走迷宫</span></span><br><span class="line"><span class="comment"> * @param x, y 当前的位置坐标</span></span><br><span class="line"><span class="comment"> * @param step 当前走了多少步了</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span> step, std::vector&lt;std::pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt;&gt; &amp;path)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (x == p &amp;&amp; q == y)</span><br><span class="line">   &#123;</span><br><span class="line">      min_step = step &lt; min_step ? step : min_step;</span><br><span class="line">      min_path = path;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// 进行合理性剪枝, 当前步骤已经比最小步骤多了的话，这种情况我们可以不考虑了</span></span><br><span class="line">   <span class="comment">// 直接舍弃掉，可以通过输出total进行验证</span></span><br><span class="line">   <span class="keyword">if</span> (step &gt;= min_step)</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">   <span class="type">int</span> tx, ty;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i)</span><br><span class="line">   &#123;</span><br><span class="line">      tx = x + next_[i][<span class="number">0</span>];</span><br><span class="line">      ty = y + next_[i][<span class="number">1</span>];</span><br><span class="line">      <span class="keyword">if</span> (!<span class="built_in">inMaze</span>(tx, ty, maze_w, maze_h))</span><br><span class="line">         <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (maze[tx][ty] &amp;&amp; !book[tx][ty])</span><br><span class="line">      &#123;</span><br><span class="line">         path.<span class="built_in">push_back</span>(std::<span class="built_in">make_pair</span>(tx, ty));</span><br><span class="line">         book[tx][ty] = <span class="literal">true</span>;</span><br><span class="line">         <span class="built_in">dfs</span>(tx, ty, step + <span class="number">1</span>, path);</span><br><span class="line">         path.<span class="built_in">pop_back</span>();</span><br><span class="line">         book[tx][ty] = <span class="literal">false</span>;</span><br><span class="line">         <span class="comment">// total ++;</span></span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> <span class="type">const</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="comment">// 读取数据</span></span><br><span class="line">   <span class="function">ifstream <span class="title">cin</span><span class="params">(<span class="string">&quot;dfs_find_maze.txt&quot;</span>)</span></span>;</span><br><span class="line">   <span class="comment">// ofstream cout(&quot;result.txt&quot;);</span></span><br><span class="line"></span><br><span class="line">   cin &gt;&gt; maze_h &gt;&gt; maze_w;</span><br><span class="line">   maze.<span class="built_in">resize</span>(maze_h, std::<span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt;(maze_w, <span class="literal">true</span>));</span><br><span class="line">   book.<span class="built_in">resize</span>(maze_h, std::<span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt;(maze_w, <span class="literal">false</span>));</span><br><span class="line"></span><br><span class="line">   <span class="type">int</span> c;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; maze_h; ++i)</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; maze_w; ++j)</span><br><span class="line">      &#123;</span><br><span class="line">         cin &gt;&gt; c;</span><br><span class="line">         maze[i][j] = (c == <span class="number">0</span>);</span><br><span class="line">      &#125;</span><br><span class="line">   cin &gt;&gt; startx &gt;&gt; starty &gt;&gt; p &gt;&gt; q;</span><br><span class="line"></span><br><span class="line">   <span class="comment">//检查输入</span></span><br><span class="line">   <span class="built_in">assert</span>(p &lt; maze_h &amp;&amp; p &gt;= <span class="number">0</span>);</span><br><span class="line">   <span class="built_in">assert</span>(q &lt; maze_w &amp;&amp; q &gt;= <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">   cout &lt;&lt; <span class="string">&quot; startx:&quot;</span> &lt;&lt; startx &lt;&lt; <span class="string">&quot; starty: &quot;</span> &lt;&lt; starty &lt;&lt; std::endl;</span><br><span class="line">   cout &lt;&lt; <span class="string">&quot; endx:&quot;</span> &lt;&lt; p &lt;&lt; <span class="string">&quot; endy: &quot;</span> &lt;&lt; q &lt;&lt; std::endl;</span><br><span class="line">   cout &lt;&lt; <span class="string">&quot; maze_h:&quot;</span> &lt;&lt; maze_h &lt;&lt; <span class="string">&quot; maze_w: &quot;</span> &lt;&lt; maze_w &lt;&lt; std::endl;</span><br><span class="line">   std::vector&lt;std::pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt;&gt; path;</span><br><span class="line">   path.<span class="built_in">clear</span>();</span><br><span class="line"></span><br><span class="line">   path.<span class="built_in">push_back</span>(std::<span class="built_in">make_pair</span>(startx, starty));</span><br><span class="line">   <span class="comment">// 走迷宫</span></span><br><span class="line">   <span class="built_in">dfs</span>(startx, starty, <span class="number">0</span>, path);</span><br><span class="line">   <span class="comment">//结果输出</span></span><br><span class="line">   cout &lt;&lt;<span class="string">&quot; min_step:&quot;</span> &lt;&lt; min_step &lt;&lt; std::endl &lt;&lt; <span class="string">&quot; step list:\n  &quot;</span>;</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">int</span>  i = <span class="number">0</span>; i &lt; min_path.<span class="built_in">size</span>() <span class="number">-1</span>; ++i)</span><br><span class="line">        cout &lt;&lt;<span class="string">&quot;(&quot;</span> &lt;&lt;min_path[i].first &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; min_path[i].second&lt;&lt;<span class="string">&quot;) -&gt; &quot;</span>;</span><br><span class="line">   cout &lt;&lt;<span class="string">&quot;(&quot;</span> &lt;&lt;min_path[min_path.<span class="built_in">size</span>() <span class="number">-1</span>].first &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; min_path[min_path.<span class="built_in">size</span>() <span class="number">-1</span>].second&lt;&lt;<span class="string">&quot;)&quot;</span>;</span><br><span class="line">   cout &lt;&lt; std::endl;</span><br><span class="line">   <span class="comment">//cout &lt;&lt; total &lt;&lt; std::endl;</span></span><br><span class="line">   cout &lt;&lt; <span class="string">&quot; Format result:\n&quot;</span>;</span><br><span class="line">   format_path(min_path, maze_w, maze_h, cout);</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><a
href="https://github.com/cwlseu/Algorithm/tree/master/aha/ch4">github示例代码</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>算法优化的一些技巧</title>
    <url>/201703/20170317-algorithm-optimization/</url>
    <content><![CDATA[<h2 id="实战算法优化">实战算法优化</h2>
<p>对于这方面的姿势，也是属于意外。在使用Caffe的过程中，需要依赖一个关于矩阵计算的库，可是
使用atlas或者openblas, 当然有资金支持的话可以使用更快地MKL,
而一个穷小白就只能从开源免费的计算库中选了，就选了OpenBlas。
后来因为缘分，认识了OpenBlas的创始人，从他们公司的工作中了解到还有机器学习算法优化加速的这么个工作。其中涉及到如OpenMP,
SIMD,
当然编译器优化也是不容忽视的。在此，总结一下工作中用到的一些函数，免得下次见到不认识了。</p>
<h2 id="intrinsic-function1">Intrinsic function[^1]</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/intrinsics.png"
alt="@intrinsics snapshot from intel" />
我对这个的理解就是在汇编的基础上进行向量化的封装的一些宏或者函数,
同时可以操作很多个数据，如使用SSE可以操作128位的数据，可以使4个int类型，也可以使用8个short类型也可以是16个char类型的数据。</p>
<p>从intrinsic
guide[^2]中就可以看出Intel关于SIMD方面的发展历程。MMX(主要是16位指令)到后面的SSE2
SSE4.2(32位指令)等等。 查阅文档的时候后可以按照计算的类别：</p>
<h3 id="计算类型">计算类型</h3>
<p>计算类型根据操作数据的类型分别封装了加减乘除,文档中对接口函数说明得很是清楚，还包括生成目标指令是什么。如：</p>
<pre><code> Synopsis
    __m128i _mm_add_epi16 (__m128i a, __m128i b)
    #include &quot;emmintrin.h&quot;
    Instruction: paddw xmm, xmm
    CPUID Flags: SSE2
Description
    Add packed 16-bit integers in a and b, and store the results in dst.
Operation
    FOR j := 0 to 7
        i := j*16
        dst[i+15:i] := a[i+15:i] + b[i+15:i]
    ENDFOR</code></pre>
<p>从外，函数命名很有规律 <code>_mm_操作_操作的数据类型</code>，
数据类型<code>__m128i</code>
表示integer类型的向量数组，<code>__m128</code>表示单精度类型的向量数组,<code>__128d</code>表示双精度类型的向量数组。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">__m128i _mm_add_epi16 (__m128i a, __m128i b); <span class="comment">//Add packed 16-bit integers in a and b</span></span><br><span class="line">__m128d _mm_div_pd (__m128d a, __m128d b); <span class="comment">// Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b</span></span><br><span class="line">__m128d _mm_mul_sd (__m128d a, __m128d b); <span class="comment">// Multiply the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.</span></span><br><span class="line">__m128i _mm_subs_epi16 (__m128i a, __m128i b)</span><br><span class="line">__m128i _mm_subs_epu16 (__m128i a, __m128i b)</span><br></pre></td></tr></table></figure>
<h2 id="设置">设置</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">__m128i _mm_set_epi16 (<span class="type">short</span> e7, <span class="type">short</span> e6, <span class="type">short</span> e5, <span class="type">short</span> e4, <span class="type">short</span> e3, <span class="type">short</span> e2, <span class="type">short</span> e1, <span class="type">short</span> e0);</span><br><span class="line">__m128i _mm_set_epi32 (<span class="type">int</span> e3, <span class="type">int</span> e2, <span class="type">int</span> e1, <span class="type">int</span> e0);</span><br><span class="line"></span><br><span class="line">__m128i _mm_set_epi8 (<span class="type">char</span> e15, <span class="type">char</span> e14, <span class="type">char</span> e13, <span class="type">char</span> e12, <span class="type">char</span> e11, <span class="type">char</span> e10, <span class="type">char</span> e9, <span class="type">char</span> e8, <span class="type">char</span> e7, <span class="type">char</span> e6, <span class="type">char</span> e5, <span class="type">char</span> e4, <span class="type">char</span> e3, <span class="type">char</span> e2, <span class="type">char</span> e1, <span class="type">char</span> e0);</span><br><span class="line"></span><br><span class="line">__m128d _mm_set_pd (<span class="type">double</span> e1, <span class="type">double</span> e0);</span><br><span class="line"></span><br><span class="line">__m128d _mm_set_pd1 (<span class="type">double</span> a); <span class="comment">// Broadcast double-precision (64-bit) floating-point value a to all elements of dst.</span></span><br><span class="line"></span><br><span class="line">__m128 _mm_set_ps (<span class="type">float</span> e3, <span class="type">float</span> e2, <span class="type">float</span> e1, <span class="type">float</span> e0);</span><br><span class="line">__m128 _mm_set_ps1 (<span class="type">float</span> a);</span><br><span class="line">__m128d _mm_set_sd (<span class="type">double</span> a);</span><br><span class="line">__m128 _mm_set_ss (<span class="type">float</span> a);</span><br><span class="line">__m128i _mm_set1_epi16 (<span class="type">short</span> a);</span><br><span class="line"></span><br><span class="line">__m128i _mm_set1_epi32 (<span class="type">int</span> a);</span><br><span class="line"></span><br><span class="line">__m128i _mm_set1_epi64 (__m64 a);</span><br><span class="line"></span><br><span class="line">__m128i _mm_set1_epi64x (__int64 a);</span><br><span class="line">__m128i _mm_set1_epi8 (<span class="type">char</span> a);</span><br><span class="line">__m128d _mm_set1_pd (<span class="type">double</span> a);</span><br><span class="line">__m128 _mm_set1_ps (<span class="type">float</span> a);</span><br><span class="line">__m128i _mm_setr_epi16 (<span class="type">short</span> e7, <span class="type">short</span> e6, <span class="type">short</span> e5, <span class="type">short</span> e4, <span class="type">short</span> e3, <span class="type">short</span> e2, <span class="type">short</span> e1, <span class="type">short</span> e0);</span><br><span class="line">__m128i _mm_setr_epi32 (<span class="type">int</span> e3, <span class="type">int</span> e2, <span class="type">int</span> e1, <span class="type">int</span> e0);</span><br><span class="line">__m128i _mm_setr_epi64 (__m64 e1, __m64 e0);</span><br><span class="line">__m128i _mm_setr_epi8 (<span class="type">char</span> e15, <span class="type">char</span> e14, <span class="type">char</span> e13, <span class="type">char</span> e12, <span class="type">char</span> e11, <span class="type">char</span> e10, <span class="type">char</span> e9, <span class="type">char</span> e8, <span class="type">char</span> e7, <span class="type">char</span> e6, <span class="type">char</span> e5, <span class="type">char</span> e4, <span class="type">char</span> e3, <span class="type">char</span> e2, <span class="type">char</span> e1, <span class="type">char</span> e0);</span><br><span class="line">__m128d _mm_setr_pd (<span class="type">double</span> e1, <span class="type">double</span> e0);</span><br><span class="line">__m128 _mm_setr_ps (<span class="type">float</span> e3, <span class="type">float</span> e2, <span class="type">float</span> e1, <span class="type">float</span> e0);</span><br><span class="line">__m128d _mm_setzero_pd (<span class="type">void</span>);</span><br><span class="line">__m128 _mm_setzero_ps (<span class="type">void</span>);</span><br><span class="line">__m128i _mm_setzero_si128 ();</span><br></pre></td></tr></table></figure>
<h2 id="从内存中加载数据">从内存中加载数据</h2>
<p>从内存中加载数据，根据数据的类型(整数，单精度浮点数，双精度浮点数，向量数组等类型)，数据存储地址是否对齐等属性有不同的函数接口封装。常常数据不对齐(SSE2函数名称中常常带一个u表示不要求地址对齐，
SSE函数中常用1表示不要求地址对齐)的接口要比对齐的接口效率低很多。地址对齐常常是以16bit对齐。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*Load 128-bits of integer data from unaligned memory into dst. This intrinsic may perform better than _mm_loadu_si128 when the data crosses a cache line boundary.*/</span></span><br><span class="line">__m128i _mm_lddqu_si128 (__m128i <span class="type">const</span>* mem_addr)</span><br><span class="line">__m128 _mm_load_ps (<span class="type">float</span> <span class="type">const</span>* mem_addr)</span><br><span class="line">__m128 _mm_load_ps1 (<span class="type">float</span> <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br><span class="line">__m128i _mm_load_si128 (__m128i <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br><span class="line"><span class="comment">/*Load 128-bits of integer data from memory into dst. mem_addr does not need to be aligned on any particular boundary.*/</span></span><br><span class="line">__m128i _mm_loadu_si128 (__m128i <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br><span class="line"><span class="comment">/*Load 64-bit integer from memory into the first element of dst.*/</span></span><br><span class="line">__m128i _mm_loadl_epi64 (__m128i <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br><span class="line">__m128d _mm_loadl_pd (__m128d a, <span class="type">double</span> <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br><span class="line">__m128 _mm_loadl_pi (__m128 a, __m64 <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> Load 2 double-precision (64-bit) floating-point elements from memory into dst in reverse order. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated. </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">__m128d _mm_loadr_pd (<span class="type">double</span> <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into dst. mem_addr does not need to be aligned on any particular boundary.*/</span></span><br><span class="line">__m128d _mm_loadu_pd (<span class="type">double</span> <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br><span class="line">__m128 _mm_loadu_ps (<span class="type">float</span> <span class="type">const</span>* mem_addr)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="图像中进行亮点查找的关键函数">图像中进行亮点查找的关键函数</h2>
<p><code>int _mm_movemask_epi8 (__m128i a)</code> Create mask from the
most significant bit of each 8-bit element in a, and store the result in
dst. 创建从签名的最高有效位的 16 位掩码 16 或在 a 和零的无符号 8
位整数扩展上面的位。</p>
<h2 id="编译器buidin函数">编译器buidin函数</h2>
<h3
id="void-__builtin___clear_cache-char-begin-char-end"><code>void __builtin___clear_cache (char *begin, char *end)</code></h3>
<p>This function is used to flush the processor’s instruction cache for
the region of memory between begin inclusive and end exclusive. Some
targets require that the instruction cache be flushed, after modifying
memory containing code, in order to obtain deterministic behavior.
有的时候为了获取确定性的性能测试结果，使用该函数对处理器的指令和数据进行清空操作。</p>
<p>If the target does not require instruction cache flushes,
<code>__builtin___clear_cache</code> has no effect. Otherwise either
instructions are emitted in-line to clear the instruction cache or a
call to the <code>__clear_cache function</code>in libgcc is made.
如何设置begin和end的信息，请参见[^5]</p>
<h3
id="void-__builtin_prefetch-const-void-addr-..."><code>void __builtin_prefetch (const void *addr, ...)</code></h3>
<p>This function is used to minimize cache-miss latency by moving data
into a cache before it is accessed. You can insert calls
to<code>__builtin_prefetch</code> into code for which you know addresses
of data in memory that is likely to be accessed soon. If the target
supports them, data prefetch instructions are generated. If the prefetch
is done early enough before the access then the data will be in the
cache by the time it is accessed.</p>
<p>The value of addr is the address of the memory to prefetch. There are
two optional arguments, rw and locality. The value of rw is a
compile-time constant one or zero; one means that the prefetch is
preparing for a write to the memory address and zero, the default, means
that the prefetch is preparing for a read. The value locality must be a
compile-time constant integer between zero and three. A value of zero
means that the data has no temporal locality, so it need not be left in
the cache after the access. A value of three means that the data has a
high degree of temporal locality and should be left in all levels of
cache possible. Values of one and two mean, respectively, a low or
moderate degree of temporal locality. The default is three.
<code>__builtin_prefetch (const void *addr, ...)</code>它通过对数据手工预取的方法，在使用地址addr的值之前就将其放到cache中，减少了读取延迟，从而提高了性能，但该函数也需要
CPU
的支持。该函数可接受三个参数，第一个参数addr是要预取的数据的地址，第二个参数可设置为0或1（1表示我对地址addr要进行写操作，0表示要进行读操作），第三个参数可取0-3（0表示不用关心时间局部性，取完addr的值之后便不用留在cache中，而1、2、3表示时间局部性逐渐增强）</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">  &#123;</span><br><span class="line">    a[i] = a[i] + b[i];</span><br><span class="line">    __builtin_prefetch (&amp;a[i+j], <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">    __builtin_prefetch (&amp;b[i+j], <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="comment">/* … */</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>Data prefetch does not generate faults if addr is invalid, but the
address expression itself must be valid. For example, a prefetch of
p-&gt;next does not fault if p-&gt;next is not a valid address, but
evaluation faults if p is not a valid address.</p>
<p>If the target does not support data prefetch, the address expression
is evaluated if it includes side effects but no other code is generated
and GCC does not issue a warning.</p>
<h3
id="int-__builtin_clz-unsigned-int-x"><code>int __builtin_clz (unsigned int x)</code></h3>
<p>Returns the number of leading 0-bits in x, starting at the most
significant bit position. If x is 0, the result is undefined.
返回从左边起第一个1之前的0个个数</p>
<h3
id="int-__builtin_ctz-unsigned-int-x"><code>int __builtin_ctz (unsigned int x)</code></h3>
<p>Returns the number of trailing 0-bits in x, starting at the least
significant bit position. If x is 0, the result is undefined.
返回从右边其第一个1之后的0个个数</p>
<h3
id="int-__builtin_clz-unsigned-int-x-1"><code>int __builtin_clz (unsigned int x)</code></h3>
<p>Returns the number of leading 0-bits in x, starting at the most
significant bit position. If x is 0, the result is undefined.
返回左起第一个‘1’之前0的个数。</p>
<h3
id="int-__builtin_ffs-unsigned-int-x"><code>int __builtin_ffs (unsigned int x)</code></h3>
<p>Returns one plus the index of the least significant 1-bit of x, or if
x is zero, returns zero. 返回右起第一个‘1’的位置。</p>
<h3
id="int-__builtin_popcount-unsigned-int-x"><code>int __builtin_popcount (unsigned int x)</code></h3>
<p>Returns the number of 1-bits in x. 返回‘1’的个数。</p>
<h3
id="int-__builtin_parity-unsigned-int-x"><code>int __builtin_parity (unsigned int x)</code></h3>
<p>Returns the parity of x, i.e. the number of 1-bits in x modulo 2.
返回‘1’的个数的奇偶性。</p>
<h3 id="例子">例子</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> <span class="type">const</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; ++i)</span><br><span class="line">    &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(__GNUC__) || defined(__GNUG__)</span></span><br><span class="line">    <span class="comment">//printf(&quot;the number of trailing 0-bits in %d is %d \n&quot;, i,  __builtin_ctz(i));</span></span><br><span class="line">    <span class="comment">//printf(&quot;%d have %d 1-bits\n&quot;, i, __builtin_popcount(i));</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d parity value: %d\n&quot;</span>, i, __builtin_parity(i));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d swap32 %d\n&quot;</span>, i, __builtin_bswap32(i));</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(__GNUC__) || defined(__GNUG__)</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;test __builtin___clear_cache\n&quot;</span>);</span><br><span class="line">    <span class="type">char</span>* a;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        __builtin___clear_cache(a, a + <span class="number">4096</span>);</span><br><span class="line">        a = <span class="keyword">new</span> <span class="type">char</span>[<span class="number">4096</span>];</span><br><span class="line">        <span class="keyword">delete</span>[] a;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="result">Result:</h3>
<pre><code>0 have 0 1-bits
0 parity value: 0
0 swap32 0
the number of trailing 0-bits in 1 is 0 
1 have 1 1-bits
1 parity value: 1
1 swap32 16777216
the number of trailing 0-bits in 2 is 1 
2 have 1 1-bits
2 parity value: 1
2 swap32 33554432
the number of trailing 0-bits in 3 is 0 
3 have 2 1-bits
3 parity value: 0
3 swap32 50331648
the number of trailing 0-bits in 4 is 2 
4 have 1 1-bits
4 parity value: 1
4 swap32 67108864
the number of trailing 0-bits in 5 is 0 
5 have 2 1-bits
5 parity value: 0
5 swap32 83886080
the number of trailing 0-bits in 6 is 1 
6 have 2 1-bits
6 parity value: 0
6 swap32 100663296
the number of trailing 0-bits in 7 is 0 
7 have 3 1-bits
7 parity value: 1
7 swap32 117440512
the number of trailing 0-bits in 8 is 3 
8 have 1 1-bits
8 parity value: 1
8 swap32 134217728
the number of trailing 0-bits in 9 is 0 
9 have 2 1-bits
9 parity value: 0
9 swap32 150994944
test __builtin___clear_cache</code></pre>
<h2
id="example寻找数组中第一个非0元素的位置的intrinsic-函数">Example:寻找数组中第一个非0元素的位置的intrinsic
函数</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">findStartContourPoint</span><span class="params">(<span class="type">const</span> uchar *src_data,<span class="type">int</span> width, <span class="type">int</span> j)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span>  CV_SSE_4_2</span></span><br><span class="line">        __m128i v_zero = _mm_setzero_si128();</span><br><span class="line">        <span class="type">int</span> v_size = width - <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (; j &lt;= v_size; j += <span class="number">32</span>) &#123;</span><br><span class="line">            __m128i v_p1 = _mm_loadu_si128((<span class="type">const</span> __m128i*)(src_data + j));</span><br><span class="line">            __m128i v_p2 = _mm_loadu_si128((<span class="type">const</span> __m128i*)(src_data + j + <span class="number">16</span>));</span><br><span class="line"></span><br><span class="line">            __m128i v_cmp1 = _mm_cmpeq_epi8(v_p1, v_zero);</span><br><span class="line">            __m128i v_cmp2 = _mm_cmpeq_epi8(v_p2, v_zero);</span><br><span class="line"></span><br><span class="line">            <span class="type">unsigned</span> <span class="type">int</span> mask1 = _mm_movemask_epi8(v_cmp1);</span><br><span class="line">            <span class="type">unsigned</span> <span class="type">int</span> mask2 = _mm_movemask_epi8(v_cmp2);</span><br><span class="line"></span><br><span class="line">            mask1 ^= <span class="number">0x0000ffff</span>;</span><br><span class="line">            mask2 ^= <span class="number">0x0000ffff</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (mask1) &#123;</span><br><span class="line">                j += <span class="built_in">trailingZeros</span>(mask1);</span><br><span class="line">                <span class="keyword">return</span> j;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (mask2) &#123;</span><br><span class="line">                j += <span class="built_in">trailingZeros</span>(mask2 &lt;&lt; <span class="number">16</span>);</span><br><span class="line">                <span class="keyword">return</span> j;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (j &lt;= width - <span class="number">16</span>) &#123;</span><br><span class="line">            __m128i v_p = _mm_loadu_si128((<span class="type">const</span> __m128i*)(src_data + j));</span><br><span class="line"></span><br><span class="line">            <span class="type">unsigned</span> <span class="type">int</span> mask = _mm_movemask_epi8(_mm_cmpeq_epi8(v_p, v_zero)) ^ <span class="number">0x0000ffff</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (mask) &#123;</span><br><span class="line">                j += <span class="built_in">trailingZeros</span>(mask);</span><br><span class="line">                <span class="keyword">return</span> j;</span><br><span class="line">            &#125;</span><br><span class="line">            j += <span class="number">16</span>;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="keyword">for</span> (; j &lt; width &amp;&amp; !src_data[j]; ++j)</span><br><span class="line">        ;</span><br><span class="line">    <span class="keyword">return</span> j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中<code>trailingZeros</code>就是调用编译器的内置函数实现的。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">if</span> CV_SSE_4_2</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">unsigned</span> <span class="type">int</span> <span class="title">trailingZeros</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span> value)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(value != <span class="number">0</span>); <span class="comment">// undefined for zero input (https://en.wikipedia.org/wiki/Find_first_set)</span></span><br><span class="line"><span class="function"><span class="keyword">if</span> <span class="title">defined</span><span class="params">(__GNUC__)</span> || <span class="title">defined</span><span class="params">(__GNUG__)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">return</span> __<span class="title">builtin_ctz</span><span class="params">(value)</span></span>;</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined(__ICC) || defined(__INTEL_COMPILER)</span></span><br><span class="line">    <span class="keyword">return</span> _bit_scan_forward(value);</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined(__clang__)</span></span><br><span class="line">    <span class="keyword">return</span> llvm.cttz.<span class="built_in">i32</span>(value, <span class="literal">true</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="type">static</span> <span class="type">const</span> <span class="type">int</span> MultiplyDeBruijnBitPosition[<span class="number">32</span>] = &#123;</span><br><span class="line">        <span class="number">0</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">2</span>, <span class="number">29</span>, <span class="number">14</span>, <span class="number">24</span>, <span class="number">3</span>, <span class="number">30</span>, <span class="number">22</span>, <span class="number">20</span>, <span class="number">15</span>, <span class="number">25</span>, <span class="number">17</span>, <span class="number">4</span>, <span class="number">8</span>,</span><br><span class="line">        <span class="number">31</span>, <span class="number">27</span>, <span class="number">13</span>, <span class="number">23</span>, <span class="number">21</span>, <span class="number">19</span>, <span class="number">16</span>, <span class="number">7</span>, <span class="number">26</span>, <span class="number">12</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">11</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">9</span> &#125;;</span><br><span class="line">    <span class="keyword">return</span> MultiplyDeBruijnBitPosition[((<span class="type">uint32_t</span>)((value &amp; -value) * <span class="number">0x077CB531</span>U)) &gt;&gt; <span class="number">27</span>];</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="memcopy汇编实现代码">MemCopy汇编实现代码</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">CopyMMX</span><span class="params">(<span class="type">void</span>* destination, <span class="type">void</span>* sorce, <span class="type">int</span> count )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> nCount64 = ( count / <span class="number">128</span> ) * <span class="number">128</span>;</span><br><span class="line">    <span class="type">int</span> nRemainder = ( count % <span class="number">128</span> );</span><br><span class="line">    _asm</span><br><span class="line">    &#123;</span><br><span class="line">        MOV ESI, sorce</span><br><span class="line">        MOV EDI, destination</span><br><span class="line">        MOV ECX, nCount64</span><br><span class="line">        CMP ECX, <span class="number">0</span></span><br><span class="line">        JZ BYTEBYTE</span><br><span class="line">        MOV EDX, <span class="number">128</span></span><br><span class="line">        SHR ECX, <span class="number">7</span></span><br><span class="line">        TOP:</span><br><span class="line">        PREFETCHNTA <span class="number">64</span>[ESI] <span class="comment">// Pre-fetch data for Next loop</span></span><br><span class="line">        PREFETCHNTA <span class="number">128</span>[ESI]</span><br><span class="line">        <span class="comment">// Copy data from source</span></span><br><span class="line">        MOVDQU XMM0, <span class="number">0</span>[ESI]</span><br><span class="line">        MOVDQU XMM1, <span class="number">16</span>[ESI]</span><br><span class="line">        MOVDQU XMM2, <span class="number">32</span>[ESI]</span><br><span class="line">        MOVDQU XMM3, <span class="number">48</span>[ESI]</span><br><span class="line">        MOVDQU XMM4, <span class="number">64</span>[ESI]</span><br><span class="line">        MOVDQU XMM5, <span class="number">80</span>[ESI]</span><br><span class="line">        MOVDQU XMM6, <span class="number">96</span>[ESI]</span><br><span class="line">        MOVDQU XMM7, <span class="number">112</span>[ESI]</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Save the data from MM registers to Destination</span></span><br><span class="line">        MOVNTDQ <span class="number">0</span>[EDI], XMM0 <span class="comment">//(A)-&gt;Program gets crashed here</span></span><br><span class="line">        MOVNTDQ <span class="number">16</span>[EDI], XMM1</span><br><span class="line">        MOVNTDQ <span class="number">32</span>[EDI], XMM2</span><br><span class="line">        MOVNTDQ <span class="number">48</span>[EDI], XMM3</span><br><span class="line">        MOVNTDQ <span class="number">64</span>[EDI], XMM4</span><br><span class="line">        MOVNTDQ <span class="number">80</span>[EDI], XMM5</span><br><span class="line">        MOVNTDQ <span class="number">96</span>[EDI], XMM6</span><br><span class="line">        MOVNTDQ <span class="number">112</span>[EDI], XMM7</span><br><span class="line"></span><br><span class="line">        ADD ESI, EDX</span><br><span class="line">        ADD EDI, EDX</span><br><span class="line">        DEC ECX</span><br><span class="line">        JNZ TOP</span><br><span class="line">        <span class="comment">// Copy remaining data BYTE by BYTE</span></span><br><span class="line">        BYTEBYTE:</span><br><span class="line">        MOV ECX, nRemainder</span><br><span class="line">        CMP ECX, <span class="number">0</span></span><br><span class="line">        JZ ENDS</span><br><span class="line">        PREFETCHNTA [ESI+ECX]</span><br><span class="line">        REM:</span><br><span class="line">        MOV AL, <span class="number">0</span>[ESI]</span><br><span class="line">        MOV <span class="number">0</span>[EDI], AL</span><br><span class="line">        INC ESI</span><br><span class="line">        INC EDI</span><br><span class="line">        DEC ECX</span><br><span class="line">        JNZ REM</span><br><span class="line">        ENDS:</span><br><span class="line">        EMMS</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="reference">Reference</h2>
<ol type="1">
<li><a
href="https://en.wikipedia.org/wiki/Intrinsic_function">定义https://en.wikipedia.org/wiki/Intrinsic_function</a></li>
<li><a
href="https://software.intel.com/sites/landingpage/IntrinsicsGuide">指令集API文档
https://software.intel.com/sites/landingpage/IntrinsicsGuide</a></li>
<li><a
href="https://msdn.microsoft.com/zh-cn/library/0d4dtzhb(v=vs.110).aspx">微软对intrinsics的文档https://msdn.microsoft.com/zh-cn/library/</a></li>
<li><a
href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html">GCC编译器文档https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html</a></li>
<li><a
href="http://stackoverflow.com/questions/35741814/how-does-builtin-clear-cache-work">stackoverflow关于<code>buildin_clear_cache</code>
的讨论：http://stackoverflow.com/questions/35741814/how-does-builtin-clear-cache-work</a></li>
<li><a
href="https://software.intel.com/zh-cn/articles/introduction-to-intel-advanced-vector-extensions">intel-advanced-vector-extensions</a></li>
</ol>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux开发</tag>
        <tag>HPC</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习：玩转Caffe</title>
    <url>/201703/20170321-train-use-caffe/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>最近实验中又跟caffe打交道，虽然caffe好用，但是要想让caffe启动训练起来，还真得费一番功夫。数据处理，模型文件编写，预训练模型的选择等等。</p>
<h2 id="imagenet的数据预处理">ImageNet的数据预处理</h2>
<h3 id="常见image-list">1. 常见image list</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">root_dir=$HOME/data/VOCdevkit/</span><br><span class="line">sub_dir=ImageSets/Main</span><br><span class="line">bash_dir=&quot;$(cd &quot;$(dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot;)&quot; &amp;&amp; pwd)&quot;</span><br><span class="line">for dataset in trainval test</span><br><span class="line">do</span><br><span class="line">  dst_file=$bash_dir/$dataset.txt</span><br><span class="line">  if [ -f $dst_file ]</span><br><span class="line">  then</span><br><span class="line">    rm -f $dst_file</span><br><span class="line">  fi</span><br><span class="line">  for name in VOC2007 VOC2012</span><br><span class="line">  do</span><br><span class="line">    if [[ $dataset == &quot;test&quot; &amp;&amp; $name == &quot;VOC2012&quot; ]]</span><br><span class="line">    then</span><br><span class="line">      continue</span><br><span class="line">    fi</span><br><span class="line">    echo &quot;Create list for $name $dataset...&quot;</span><br><span class="line">    dataset_file=$root_dir/$name/$sub_dir/$dataset.txt</span><br><span class="line"></span><br><span class="line">    img_file=$bash_dir/$dataset&quot;_img.txt&quot;</span><br><span class="line">    cp $dataset_file $img_file</span><br><span class="line">    sed -i &quot;s/^/$name\/JPEGImages\//g&quot; $img_file</span><br><span class="line">    sed -i &quot;s/$/.jpg/g&quot; $img_file</span><br><span class="line"></span><br><span class="line">    label_file=$bash_dir/$dataset&quot;_label.txt&quot;</span><br><span class="line">    cp $dataset_file $label_file</span><br><span class="line">    sed -i &quot;s/^/$name\/Annotations\//g&quot; $label_file</span><br><span class="line">    sed -i &quot;s/$/.xml/g&quot; $label_file</span><br><span class="line"></span><br><span class="line">    paste -d&#x27; &#x27; $img_file $label_file &gt;&gt; $dst_file</span><br><span class="line"></span><br><span class="line">    rm -f $label_file</span><br><span class="line">    rm -f $img_file</span><br><span class="line">  done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Generate image name and size infomation.</span></span><br><span class="line">  if [ $dataset == &quot;test&quot; ]</span><br><span class="line">  then</span><br><span class="line">    $bash_dir/../../build/tools/get_image_size $root_dir $dst_file $bash_dir/$dataset&quot;_name_size.txt&quot;</span><br><span class="line">  fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Shuffle trainval file.</span></span><br><span class="line">  if [ $dataset == &quot;trainval&quot; ]</span><br><span class="line">  then</span><br><span class="line">    rand_file=$dst_file.random</span><br><span class="line">    cat $dst_file | perl -MList::Util=shuffle -e &#x27;print shuffle(&lt;STDIN&gt;);&#x27; &gt; $rand_file</span><br><span class="line">    mv $rand_file $dst_file</span><br><span class="line">  fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h3 id="生成backend为leveldb或者lmdb">2.
生成backend为leveldb或者lmdb</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env sh</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Create the imagenet lmdb inputs</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">N.B. <span class="built_in">set</span> the path to the imagenet train + val data <span class="built_in">dirs</span></span></span><br><span class="line">set -e</span><br><span class="line"></span><br><span class="line">DATA=$HOME/data/VOCdevkit</span><br><span class="line">TOOLS=$HOME/caffe/build/tools</span><br><span class="line"></span><br><span class="line">EXAMPLE=$&#123;DATA&#125;/VOC0712/lmdb</span><br><span class="line">TRAIN_DATA_ROOT=$&#123;DATA&#125;/</span><br><span class="line">VAL_DATA_ROOT=$&#123;DATA&#125;/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Set RESIZE=<span class="literal">true</span> to resize the images to 256x256. Leave as <span class="literal">false</span> <span class="keyword">if</span> images have</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">already been resized using another tool.</span></span><br><span class="line">RESIZE=true</span><br><span class="line">if $RESIZE; then</span><br><span class="line">  RESIZE_HEIGHT=256</span><br><span class="line">  RESIZE_WIDTH=256</span><br><span class="line">else</span><br><span class="line">  RESIZE_HEIGHT=0</span><br><span class="line">  RESIZE_WIDTH=0</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo &quot;Creating train lmdb...&quot;</span><br><span class="line"></span><br><span class="line">GLOG_logtostderr=1 $TOOLS/convert_imageset \</span><br><span class="line">    --resize_height=$RESIZE_HEIGHT \</span><br><span class="line">    --resize_width=$RESIZE_WIDTH \</span><br><span class="line">    --shuffle \</span><br><span class="line">    $TRAIN_DATA_ROOT \</span><br><span class="line">    $DATA/trainval.txt \</span><br><span class="line">    $EXAMPLE/voc0712_train_lmdb</span><br><span class="line"></span><br><span class="line">echo &quot;Creating val lmdb...&quot;</span><br><span class="line"></span><br><span class="line">GLOG_logtostderr=1 $TOOLS/convert_imageset \</span><br><span class="line">    --resize_height=$RESIZE_HEIGHT \</span><br><span class="line">    --resize_width=$RESIZE_WIDTH \</span><br><span class="line">    --shuffle \</span><br><span class="line">    $VAL_DATA_ROOT \</span><br><span class="line">    $DATA/test.txt \</span><br><span class="line">    $EXAMPLE/voc0712_val_lmdb</span><br><span class="line"></span><br><span class="line">echo &quot;Done.&quot;</span><br></pre></td></tr></table></figure>
<h3 id="proto中配置使用">3. proto中配置使用</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Data&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    source: &quot;/home/lixx/data/VOCdevkit/VOC0712/lmdb/voc0712_train_lmdb&quot;</span><br><span class="line">    #source: &quot; /home/lixx/data/VOCdevkit/VOC0712/voc0712_train_leveldb&quot;</span><br><span class="line">    mean_file: &quot;/home/lixx/data/VOCdevkit/VOC0712/voc0712_mean.binaryproto&quot;</span><br><span class="line">    batch_size: 16 </span><br><span class="line">    crop_size: 227 </span><br><span class="line">    # 数据类型，默认情况下为leveldb</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param&#123;</span><br><span class="line">    mirror: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中具体的参数需要参考caffe.proto文件进行查看，进行正确的配置</p>
<h2 id="训练模型">训练模型</h2>
<h3 id="学习率">1、学习率</h3>
<p>步长的选择：你走的距离长短，越短当然不会错过，但是耗时间。步长的选择比较麻烦。步长越小，越容易得到局部最优化（到了比较大的山谷，就出不去了），而大了会全局最优。一般来说，如ResNet前32k步，很大，0.1；到了后面，迭代次数增高，下降0.01，再多，然后再小一些。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/lr.png"
alt="@lr 随着epoch的增加变化曲线" /></p>
<h3 id="caffe训练时loss变为nan的原因2">2、caffe训练时Loss变为nan的原因<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h3>
<h4 id="由小变大易出nan">由小变大易出nan</h4>
<p><strong>原因</strong>：有小变大过程中，某个梯度值变得特别大，使得学习过程难以为继</p>
<p>例如：<code>10x10x256</code>的输入，输出如果是<code>20x20x256</code>或者<code>10x10x512</code>，如果是使用Inception-ResNet-v2或者直接进行卷积操作，很容易出现nan的情况。</p>
<blockquote>
<p>具体解决方案： - 参考<a
href="http://cwlseu.github.io/Inception">Inception的设计原则</a>重新设计网络
- 添加Batch normalization试试</p>
</blockquote>
<h4
id="使用resnet-block或者inception技术最后的结果通过bitwise-operation进行组合而不是采用按channel-concatenate进行的">使用ResNet-Block或者Inception技术，最后的结果通过Bitwise
Operation进行组合，而不是采用按channel Concatenate进行的。</h4>
<blockquote>
<p>尤其是BitWise
multi进行组合的时候，往往会产生很大的数据悬殊，会导致梯度爆炸现象从而出现Loss
为nan</p>
</blockquote>
<h3 id="梯度爆炸">3、梯度爆炸</h3>
<p><strong>原因</strong>：梯度变得非常大，使得学习过程难以继续</p>
<p><strong>现象</strong>：观察log，注意每一轮迭代后的loss。loss随着每轮迭代越来越大，最终超过了浮点型表示的范围，就变成了NaN。</p>
<p><strong>措施</strong>： -
减小solver.prototxt中的<code>base_lr</code>，至少减小一个数量级。如果有多个<code>loss layer</code>，需要找出哪个损失层导致了梯度爆炸，并在train_val.prototxt中减小该层的<code>loss_weight</code>，而非是减小通用的<code>base_lr</code>。
- 设置<code>clip gradient</code>，用于限制过大的<code>diff</code></p>
<h4 id="不当的损失函数">不当的损失函数</h4>
<p><strong>原因</strong>：有时候损失层中loss的计算可能导致NaN的出现。比如，给InfogainLoss层（信息熵损失）输入没有归一化的值，使用带有bug的自定义损失层等等。</p>
<p><strong>现象</strong>：观测训练产生的log时一开始并不能看到异常，loss也在逐步的降低，但突然之间NaN就出现了。</p>
<p><strong>措施</strong>：看看你是否能重现这个错误，在loss
layer中加入一些输出以进行调试。
示例：有一次我使用的loss归一化了batch中label错误的次数。如果某个label从未在batch中出现过，loss就会变成NaN。在这种情况下，可以用足够大的batch来尽量避免这个错误。</p>
<h4 id="不当的输入">不当的输入</h4>
<p><strong>原因</strong>：输入中就含有NaN。</p>
<p><strong>现象</strong>：每当学习的过程中碰到这个错误的输入，就会变成NaN。观察log的时候也许不能察觉任何异常，loss逐步的降低，但突然间就变成NaN了。</p>
<p><strong>措施</strong>：重整你的数据集，确保训练集和验证集里面没有损坏的图片。调试中你可以使用一个简单的网络来读取输入层，有一个缺省的loss，并过一遍所有输入，如果其中有错误的输入，这个缺省的层也会产生NaN。</p>
<h3 id="caffe-debug-info34">4、Caffe Debug info<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a><a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></h3>
<p>当我们训练过程面临nan,
loss不收敛的情况，可以打开<code>solver.prototxt</code>中的<code>debuf_info:true</code>进行查错。</p>
<pre><code>    I1109 ...]     [Forward] Layer data, top blob data data: 0.343971    
    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037
    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114
    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0
    I1109 ...]     [Forward] Layer relu1, top blob conv1 data: 0.0337982
    I1109 ...]     [Forward] Layer conv2, top blob conv2 data: 0.0249297
    I1109 ...]     [Forward] Layer conv2, param blob 0 data: 0.00875855
    I1109 ...]     [Forward] Layer conv2, param blob 1 data: 0
    I1109 ...]     [Forward] Layer relu2, top blob conv2 data: 0.0128249
    . 
    .
    .
    I1109 ...]     [Forward] Layer fc1, top blob fc1 data: 0.00728743
    I1109 ...]     [Forward] Layer fc1, param blob 0 data: 0.00876866
    I1109 ...]     [Forward] Layer fc1, param blob 1 data: 0
    I1109 ...]     [Forward] Layer loss, top blob loss data: 2031.85
    I1109 ...]     [Backward] Layer loss, bottom blob fc1 diff: 0.124506
    I1109 ...]     [Backward] Layer fc1, bottom blob conv6 diff: 0.00107067
    I1109 ...]     [Backward] Layer fc1, param blob 0 diff: 0.483772
    I1109 ...]     [Backward] Layer fc1, param blob 1 diff: 4079.72
    .
    .
    .
    I1109 ...]     [Backward] Layer conv2, bottom blob conv1 diff: 5.99449e-06
    I1109 ...]     [Backward] Layer conv2, param blob 0 diff: 0.00661093
    I1109 ...]     [Backward] Layer conv2, param blob 1 diff: 0.10995
    I1109 ...]     [Backward] Layer relu1, bottom blob conv1 diff: 2.87345e-06
    I1109 ...]     [Backward] Layer conv1, param blob 0 diff: 0.0220984
    I1109 ...]     [Backward] Layer conv1, param blob 1 diff: 0.0429201
    E1109 ...]     [Backward] All net params (data, diff): L1 norm = (2711.42, 7086.66); L2 norm = (6.11659, 4085.07) </code></pre>
<p>At first glance you can see this log section divided into two:
<code>[Forward]</code> and <code>[Backward]</code>. Recall that neural
network training is done via forward-backward propagation: A training
example (batch) is fed to the net and a forward pass outputs the current
prediction. Based on this prediction a loss is computed. The loss is
then derived, and a gradient is estimated and propagated backward using
the chain rule.</p>
<h4 id="caffe-blob-data-structure">Caffe Blob data structure</h4>
<p>Just a quick re-cap. Caffe uses Blob data structure to store
data/weights/parameters etc. For this discussion it is important to note
that <code>Blob</code> has two "parts": <code>data</code> and
<code>diff</code>. The values of the Blob are stored in the data part.
The diff part is used to store element-wise gradients for the
backpropagation step.</p>
<h4 id="forward-pass">Forward pass</h4>
<p>You will see all the layers from bottom to top listed in this part of
the log. For each layer you'll see:</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037
    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114
    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0</code></pre>
<p>Layer "conv1" is a convolution layer that has 2 param blobs: the
filters and the bias. Consequently, the log has three lines. The filter
blob (param <code>blob 0</code>) has data</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114</code></pre>
<p>That is the current L2 norm of the convolution filter weights is
0.00899. The current bias (param <code>blob 1</code>):</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0</code></pre>
<p>meaning that currently the bias is set to 0.</p>
<p>Last but not least, "conv1" layer has an output, "top" named "conv1"
(how original...). The L2 norm of the output is</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037</code></pre>
<p>Note that all L2 values for the [Forward] pass are reported on the
data part of the Blobs in question.</p>
<h4 id="loss-and-gradient">Loss and gradient</h4>
<p>At the end of the [Forward] pass comes the loss layer:</p>
<pre><code>    I1109 ...]     [Forward] Layer loss, top blob loss data: 2031.85
    I1109 ...]     [Backward] Layer loss, bottom blob fc1 diff: 0.124506</code></pre>
<p>In this example the batch loss is 2031.85, the gradient of the loss
w.r.t. <code>fc1</code> is computed and passed to <code>diff</code> part
of fc1 Blob. The L2 magnitude of the gradient is 0.1245.</p>
<h4 id="backward-pass">Backward pass</h4>
<p>All the rest of the layers are listed in this part top to bottom. You
can see that the L2 magnitudes reported now are of the diff part of the
Blobs (params and layers' inputs).</p>
<h4 id="finally">Finally</h4>
<p>The last log line of this iteration:</p>
<pre><code>    [Backward] All net params (data, diff): L1 norm = (2711.42, 7086.66); L2 norm = (6.11659, 4085.07)</code></pre>
<p>reports the total L1 and L2 magnitudes of both data and
gradients.</p>
<h4 id="what-should-i-look-for">What should I look for?</h4>
<ul>
<li>If you have nans in your loss, see at what point your data or diff
turns into nan: at which layer? at which iteration?</li>
<li>Look at the gradient magnitude, they should be reasonable. IF you
are starting to see values with e+8 your data/gradients are starting to
blow off. Decrease your learning rate!</li>
<li>See that the diffs are not zero. Zero diffs mean no gradients = no
updates = no learning.</li>
</ul>
<h2 id="tools事半功倍">Tools事半功倍</h2>
<h3 id="caffe-tools">1、caffe tools</h3>
<p><code>caffe</code>可执行文件可以有不同的选项进行选择功能，功能选择是通过功能函数指针注册的方式实现的，在<code>tools/caffe.cpp</code>中有，其中的<a
href="http://cwlseu.github.io/Cpp-Relearn">注册功能部分</a>大家有兴趣可以学习一下，这块还是很有趣的。</p>
<h3 id="分析train-log">2、分析train log</h3>
<p>在<code>caffe/tools/extra</code>下有分析log的各种脚本，你可以使用<code>gnuplot</code>继续绘制，也可以采用python的<code>matplot</code></p>
<ol type="1">
<li><p>如果想提取log的关键信息，可以查看<code>parse_log.sh</code>或者<code>parse_log.py</code></p></li>
<li><p>如果想绘制采用绘制
<code>python tools/extra/plot_training_log.py 2 examples/ooxx/result/result.png jobs/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321.log</code></p></li>
</ol>
<p>This script mainly serves as the basis of your customizations.
Customization is a must. You can copy, paste, edit them in whatever way
you want. Be warned that the fields in the training log may change in
the future. You had better check the data files and change the mapping
from field name to field index in create_field_index before designing
your own plots.</p>
<pre><code>Usage:
    ./plot_training_log.py chart_type[0-7] /where/to/save.png /path/to/first.log ...
Notes:
    1. Supporting multiple logs.
    2. Log file name must end with the lower-cased &quot;.log&quot;.
Supported chart types:
    0: Test accuracy  vs. Iters
    1: Test accuracy  vs. Seconds
    2: Test loss  vs. Iters
    3: Test loss  vs. Seconds
    4: Train learning rate  vs. Iters
    5: Train learning rate  vs. Seconds
    6: Train loss  vs. Iters
    7: Train loss  vs. Seconds</code></pre>
<h3 id="显示模型结果">3、显示模型结果</h3>
<blockquote>
<p>classification</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./build/examples/cpp_classification/classification.bin \</span><br><span class="line">  models/bvlc_reference_caffenet/deploy.prototxt \</span><br><span class="line">  models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel \</span><br><span class="line">  data/ilsvrc12/imagenet_mean.binaryproto \</span><br><span class="line">  data/ilsvrc12/synset_words.txt \</span><br><span class="line">  examples/images/cat.jpg</span><br></pre></td></tr></table></figure>
<p>The output should look like this:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">---------- Prediction <span class="keyword">for</span> examples/images/cat.jpg ----------</span><br><span class="line"><span class="number">0.3134</span> - <span class="string">&quot;n02123045 tabby, tabby cat&quot;</span></span><br><span class="line"><span class="number">0.2380</span> - <span class="string">&quot;n02123159 tiger cat&quot;</span></span><br><span class="line"><span class="number">0.1235</span> - <span class="string">&quot;n02124075 Egyptian cat&quot;</span></span><br><span class="line"><span class="number">0.1003</span> - <span class="string">&quot;n02119022 red fox, Vulpes vulpes&quot;</span></span><br><span class="line"><span class="number">0.0715</span> - <span class="string">&quot;n02127052 lynx, catamount&quot;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>ssd_detection</p>
<p><a
href="https://github.com/cwlseu/caffe/blob/ssdplus/examples/stairsnet/ssd_detect_once.py">ssd_detection脚本</a></p>
</blockquote>
<blockquote>
<p>stairsNet detection</p>
<p><a
href="https://github.com/cwlseu/caffe/blob/ssdplus/examples/stairsnet/stairsnet_detect.py">stairnet的结果展示脚本</a></p>
</blockquote>
<p>其中需要配置一些依赖文件信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># caffe的root路劲</span></span><br><span class="line">caffe_root=</span><br><span class="line">labelmap_file = <span class="string">&#x27;data/VOC0712/labelmap_voc.prototxt&#x27;</span></span><br><span class="line">model_def = <span class="string">&#x27;models/ResNet/VOC0712/OOXX_321x321/deploy.prototxt&#x27;</span></span><br><span class="line">model_weights = <span class="string">&#x27;models/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321_iter_70000.caffemodel&#x27;</span></span><br><span class="line">image_dir = <span class="string">&quot;examples/ooxx/test&quot;</span></span><br><span class="line">save_dir = <span class="string">&quot;examples/ooxx/result&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="对多个snapshot模型进行打分">4、对多个snapshot模型进行打分</h3>
<ol type="1">
<li>首先运行模型自带的score脚本,
如<code>examples/ssd/score_ssd_pascal.py</code>，该脚本会调用当前最新的model进行评测，在jobs的子目录下生成一个XXXXX_score的路径，其中包含solver.prototxt等等文件。然后ctrl+C暂停运行。</li>
<li>运行脚本<a
href="https://github.com/cwlseu/caffe/blob/ssdplus/tools/score_model.py"><code>model score script</code></a>(先去玩几个小时，时间很漫长的...)，将会在jobs的某个路径下找到生成的各个模型对应的shell脚本和log文件。</li>
</ol>
<h3 id="inference-time5">5、Inference Time<a href="#fn4"
class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></h3>
<ol type="1">
<li>(These example calls require you complete the LeNet / MNIST example
first.) time LeNet training on CPU for 10 iterations
<code>./build/tools/caffe time -model examples/mnist/lenet_train_test.prototxt -iterations 10</code></li>
<li>time LeNet training on GPU for the default 50 iterations
<code>./build/tools/caffe time -model examples/mnist/lenet_train_test.prototxt -gpu 0</code></li>
<li>time a model architecture with the given weights on no GPU for 10
iterations
<code>./build/tools/caffe time --model=models/ResNet/VOC0712/OOXX_321x321/deploy.prototxt --weights models/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321_iter_115000.caffemodel --iterations 10</code>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/inference_time.JPG"
alt="@inference time result" /></li>
</ol>
<h2 id="为什么要用google-protocol-buffer序列化协议6">为什么要用Google
Protocol Buffer序列化协议？<a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a></h2>
<table>
<colgroup>
<col style="width: 11%" />
<col style="width: 10%" />
<col style="width: 11%" />
<col style="width: 15%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 15%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">#</th>
<th style="text-align: center;">protobuf</th>
<th style="text-align: center;">jackson</th>
<th style="text-align: center;">xstream</th>
<th style="text-align: center;">serialization</th>
<th style="text-align: center;">hessian2</th>
<th style="text-align: center;">hessian2压缩</th>
<th style="text-align: center;">hessian 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">序列化 ns</td>
<td style="text-align: center;">1154</td>
<td style="text-align: center;">5421</td>
<td style="text-align: center;">92406</td>
<td style="text-align: center;">10189</td>
<td style="text-align: center;">26794</td>
<td style="text-align: center;">100766</td>
<td style="text-align: center;">29027</td>
</tr>
<tr class="even">
<td style="text-align: center;">反序列化ns</td>
<td style="text-align: center;">1334</td>
<td style="text-align: center;">8743</td>
<td style="text-align: center;">117329</td>
<td style="text-align: center;">64027</td>
<td style="text-align: center;">37871</td>
<td style="text-align: center;">188432</td>
<td style="text-align: center;">37596</td>
</tr>
<tr class="odd">
<td style="text-align: center;">bytes</td>
<td style="text-align: center;">97</td>
<td style="text-align: center;">311</td>
<td style="text-align: center;">664</td>
<td style="text-align: center;">824</td>
<td style="text-align: center;">374</td>
<td style="text-align: center;">283</td>
<td style="text-align: center;">495</td>
</tr>
</tbody>
</table>
<ul>
<li><p>protobuf
不管是处理时间上，还是空间占用上都优于现有的其他序列化方式。内存暂用是java序列化的1/9，
时间也是差了一个数量级，一次操作在1us左右。缺点：就是对象结构体有限制，只适合于内部系统使用。</p></li>
<li><p>json格式在空间占用还是有一些优势，是java序列化的1/2.6。序列化和反序列化处理时间上差不多，也就在5us。当然这次使用的jackson，如果使用普通的jsonlib可能没有这样好的性能，jsonlib估计跟java序列化差不多。</p></li>
<li><p>xml相比于java序列化来说，空间占用上有点优势，但不明显。处理时间上比java序列化多了一个数量级，在100us左右。</p></li>
<li><p>以前一种的java序列化，表现得有些失望</p></li>
<li><p>hessian测试有点意外，具体序列化数据上还步入json。性能上也不如jackjson，输得比较彻底。</p></li>
<li><p>hessian使用压缩，虽然在字节上有20%以上的空间提升，但性能上差了4,5倍，典型的以时间换空间。总的来说还是google
protobuf比较给力
以后在内部系统，数据cache存储上可以考虑使用protobuf。跟外部系统交互上可以考虑使用json。</p></li>
</ul>
<h2 id="开发过程中一些问题">开发过程中一些问题</h2>
<h3 id="如果一直在如下位置夯住不继续运行了的话">1.
如果一直在如下位置夯住，不继续运行了的话：</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">name: &quot;conv5_1/linear&quot;</span><br><span class="line">type: &quot;Convoluti</span><br><span class="line">I0320 15:59:15.669935 20624 layer_factory.hpp:77] Creating layer data</span><br><span class="line">I0320 15:59:15.670370 20624 net.cpp:100] Creating Layer data</span><br><span class="line">I0320 15:59:15.670387 20624 net.cpp:408] data -&gt; data</span><br><span class="line">I0320 15:59:15.670454 20624 net.cpp:408] data -&gt; label</span><br></pre></td></tr></table></figure>
<p>可能是训练数据类型是对的，但是去取过程中出现了，这个时候就要检查是不是训练数据的使用的是测试数据的地址。我就是犯了
这么错误，找了好久终于找到了。</p>
<h3
id="进行模型funetune的时候prototxt和.caffemodel一定要对应否则真的会出现各种shape-size不匹配的问题">2.
进行模型funetune的时候，prototxt和.caffemodel一定要对应，否则真的会出现各种shape
size不匹配的问题</h3>
<h3 id="编写prototxt的时候要风格统一不要layers和layer模式混用">3.
编写prototxt的时候要风格统一。不要layers和layer模式混用。</h3>
<blockquote>
<p>风格1: Layers开头，type为全部大写不带引号</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layers &#123;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">  name: &quot;drop7&quot;</span><br><span class="line">  type: DROPOUT</span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: 0.5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>风格2：layer开头，类型为首字母大写的字符串</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 20</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;xavier&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>风格3：layers和layer嵌套类型</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layers &#123;</span><br><span class="line">  layer &#123;</span><br><span class="line">    name: &quot;conv2&quot;</span><br><span class="line">    type: &quot;conv&quot;</span><br><span class="line">    num_output: 256</span><br><span class="line">    group: 2</span><br><span class="line">    kernelsize: 5</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;gaussian&quot;</span><br><span class="line">      std: 0.01</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">      value: 1.</span><br><span class="line">    &#125;</span><br><span class="line">    blobs_lr: 1.</span><br><span class="line">    blobs_lr: 2.</span><br><span class="line">    weight_decay: 1.</span><br><span class="line">    weight_decay: 0.</span><br><span class="line">  &#125;</span><br><span class="line">  bottom: &quot;pad2&quot;</span><br><span class="line">  top: &quot;conv2&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编写的时候保持风格统一就好。</p>
<h2 id="参考文献">参考文献</h2>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a
href="http://stackoverflow.com/questions/33962226/common-causes-of-NaNs-during-training">Common
causes of nans during training</a><a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a
href="http://stackoverflow.com/questions/40510706/how-to-interpret-caffe-log-with-debug-info">Caffe
debug info 的使用</a><a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><a
href="http://caffe.berkeleyvision.org/tutorial/interfaces.html">caffe
interface manual</a><a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><a
href="http://stackoverflow.com/questions/36867591/how-to-estimate-inference-time-from-average-forward-pass-time-in-caffe">estimate
Inference time from average forward pass time in caffe</a><a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>http://agapple.iteye.com/blog/859052<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>framework</tag>
        <tag>caffe</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>算法的乐趣：完美的图算法</title>
    <url>/201703/20170331-based-algorithm-3/</url>
    <content><![CDATA[<h2 id="图的表示方法">图的表示方法</h2>
<h2 id="图的邻接矩阵存储方法">图的邻接矩阵存储方法</h2>
<p>二维数组中第i行第j列表示顶点i到顶点j是否有边。1表示有边，-1或者无穷表示无边，激励我们将自己到自己设为0.如果表示的为无向图，则矩阵为对称矩阵。
graph_adjacent_1.txt中先输入有V个顶点有E条边
然后接下来E行为边的两个顶点。</p>
<p>5 5 1 2 1 3 1 5 2 4 3 5</p>
<h2 id="图的邻接表的存储方法">图的邻接表的存储方法</h2>
<p>邻接表是图的一种链式存储结构。对图的每个顶点建立一个单链表（n个顶点建立n个单链表），第i个单链表中的结点包含顶点Vi的所有邻接顶点。又称链接表。适用于<strong>稀疏图</strong>的存储。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> u[MAX_LEN];</span><br><span class="line"><span class="type">int</span> v[MAX_LEN];</span><br><span class="line"><span class="type">int</span> w[MAX_LEN];</span><br><span class="line"><span class="type">int</span> first[MAX_LEN]; <span class="comment">// 存储第i个顶点的第一条边的编号总长度为V</span></span><br><span class="line"><span class="type">int</span> next[MAX_LEN];  <span class="comment">// 存储编号为i的边的下一条的编号总长度为E</span></span><br><span class="line"><span class="comment">// 读入边的格式为u v w</span></span><br><span class="line"><span class="comment">// weight(u, v) = w</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">read_graph</span><span class="params">(FILE *f, <span class="type">int</span> E)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="built_in">memset</span>(first, <span class="number">-1</span>, <span class="built_in">sizeof</span>(first));</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= E; i++)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="built_in">fscanf</span>(f, <span class="string">&quot;%d %d %d&quot;</span>, &amp;u[i], &amp;v[i], &amp;w[i]);</span><br><span class="line">      <span class="comment">//关键</span></span><br><span class="line">      next[i]     = first[u[i]];</span><br><span class="line">      first[u[i]] = i;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">access_graph</span><span class="params">(<span class="type">const</span> <span class="type">int</span> V)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= V; i++)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="type">int</span> k = first[i];</span><br><span class="line">      <span class="keyword">while</span> (k != <span class="number">-1</span>)</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="built_in">printf</span>(<span class="string">&quot;w(%d,%d) = %d\n&quot;</span>, u[k], v[k], w[k]);</span><br><span class="line">         k = next[k];</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中Dijstra算法使用堆进行选择最小距离，基于连接表的存储方式的时间复杂度为<span
class="math inline">\(O((V+E)logV)\)</span> ,如果<a
href="https://github.com/cwlseu/Algorithm/blob/master/aha/ch6/dijkstra.cpp">基于邻接矩阵的表示方法</a>,
时间复杂度为<span class="math inline">\(O(V^2)\)</span>.
当图比较稀疏的时候，E &lt;&lt; V^2, 这个时候<span
class="math inline">\(O((V+E)logV)\)</span>比<span
class="math inline">\(O(V^2)\)</span>小得多。</p>
<h2 id="遍历方法">遍历方法</h2>
<p><strong>深度优先遍历</strong>的主要思想就是首先以一个未被访问过的顶点作为起始出发点，沿着当前顶点的边走到未被访问过的顶点：当没有未被访问过的顶点的是偶，则回到上一个顶点，继续试探访问别的顶点，知道所有的顶点都被访问过。显然，深度优先遍历是沿着图的某一条分支遍历直到末端，然后回溯，再沿着另一条进行同样的遍历，直到所有的顶点都被访问过为止。</p>
<p><strong>广度优先遍历</strong>更加适用于所有边的权值相同的情况。</p>
<h2 id="最小生成树的构造">最小生成树的构造</h2>
<h3 id="定义">定义</h3>
<p>最小生成树是一副连通加权无向图中一棵权值最小的生成树。在一给定的无向图
G = (V, E) 中，(u, v) 代表连接顶点 u 与顶点 v 的边（即 <span
class="math inline">\((u,v)\in E\)</span>），而 <span
class="math inline">\(w(u, v)\)</span> 代表此边的权重，若存在 T 为 E
的子集（即 <span class="math inline">\(T\subseteq
E\)</span>）且为无循环图，使得 <span class="math display">\[ w(T)=\sum
_{(u,v)\in T} w(u,v)\]</span> 的 w(T) 最小，则此 T 为 G
的最小生成树。最小生成树其实是最小权重生成树的简称。 <a
href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91">最小生成树</a></p>
<h3 id="普里姆算法prim算法">普里姆算法（Prim算法）</h3>
<p>从单一顶点开始，普里姆算法按照以下步骤逐步扩大树中所含顶点的数目，直到遍及连通图的所有顶点。</p>
<ul>
<li>输入：一个加权连通图，其中顶点集合为V，边集合为E；</li>
<li>初始化：Vnew = {x}，其中x为集合V中的任一节点（起始点），Enew = {}；
重复下列操作，直到Vnew = V： 1. 在集合E中选取<strong>权值最小的边（u,
v）</strong>，其中
<em>u为集合Vnew中的元素，而v则是V中没有加入Vnew的顶点</em>（如果存在有多条满足前述条件即具有相同权值的边，则可任意选取其中之一）；
2. 将v加入集合Vnew中，将（u, v）加入集合Enew中；</li>
<li>输出：使用集合Vnew和Enew来描述所得到的最小生成树。</li>
<li>从任意一个顶点开发构造生成树，假设从1号顶点开始。首先将顶点1加入生成树中，用一个一维数组book来标记那些顶点已经加入了生成树</li>
<li>用数组dist记录生成树到各个顶点的距离。最初生成树中只有1号顶点。有直连边的时候，dist存储的就是一号顶点到该点的权值，没有直连边的时候为Infinity</li>
<li>从数组dist中选出离生成树最近的点（假设该点为j），加入到生成树中。再以j为中间点，更新生成树到每一个非树顶点的距离。即<code>dist[k] &gt; e[j][k]</code>
更新 <code>dist[k] = e[j][k]</code></li>
<li>重复第三步，直到所有的节点被加入为止。</li>
</ul>
<h4 id="采用邻接矩阵表示的实现">采用邻接矩阵表示的实现</h4>
<p>时间复杂度为O(V^2)</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化距离矩阵</span></span><br><span class="line">   <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= V; ++i) dist[i] =  graph[<span class="number">1</span>][i];</span><br><span class="line">   book[<span class="number">1</span>] = <span class="literal">true</span>;</span><br><span class="line">   <span class="type">int</span> sum = <span class="number">0</span>;</span><br><span class="line">   <span class="type">int</span> count = <span class="number">1</span>;</span><br><span class="line">   <span class="keyword">while</span>(count &lt; V)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="comment">// 查找距离当前树最小的点</span></span><br><span class="line">      <span class="comment">// 时间复杂度为O(V), 如果采用堆进行优化的话可以降到O(logV)</span></span><br><span class="line">      <span class="type">int</span> j = <span class="number">0</span>;</span><br><span class="line">      <span class="type">int</span> min = MAX_VAL;</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= V; ++i)</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="keyword">if</span>(!book[i] &amp;&amp; dist[i] &lt; min)</span><br><span class="line">         &#123;</span><br><span class="line">            min = dist[i]; j = i;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      book[j] = <span class="literal">true</span>;</span><br><span class="line">      count++;</span><br><span class="line">      sum += dist[j];</span><br><span class="line">      <span class="comment">// 更新各点到树的距离</span></span><br><span class="line">      <span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">1</span>; k &lt;= V; ++k)</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="keyword">if</span>(!book[k] &amp;&amp; dist[k] &gt; graph[j][k])</span><br><span class="line">            dist[k] = graph[j][k];</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p><a
href="https://github.com/cwlseu/Algorithm/blob/master/aha/ch8/prim_arr_minimal_spanning_tree.cpp"
class="uri">https://github.com/cwlseu/Algorithm/blob/master/aha/ch8/prim_arr_minimal_spanning_tree.cpp</a></p>
<h4 id="采用邻接表表示的方法oelogv">采用邻接表表示的方法O(ElogV)</h4>
<p>其中推荐最小距离点的时候采用堆实现推荐，其中获取顶点元素时间为O(1)，调整堆时间为O(logV)。
调整代码实现如下:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 从i节点向下调整堆</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">minheap_shiftdown</span><span class="params">(<span class="type">int</span> i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="type">int</span> t, flag = <span class="number">0</span>;</span><br><span class="line">   <span class="keyword">while</span> (i * <span class="number">2</span> &lt;= size &amp;&amp; flag == <span class="number">0</span>)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="keyword">if</span> (dist[h[i]] &gt; dist[h[i &lt;&lt; <span class="number">1</span>]])</span><br><span class="line">         t = i &lt;&lt; <span class="number">1</span>;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">         t = i;</span><br><span class="line">      <span class="keyword">if</span> (i * <span class="number">2</span> + <span class="number">1</span> &lt;= size)</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="keyword">if</span> (dist[h[t]] &gt; dist[h[i * <span class="number">2</span> + <span class="number">1</span>]])</span><br><span class="line">         &#123;</span><br><span class="line">            t = i * <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (t != i)</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="built_in">swap</span>(t, i);</span><br><span class="line">         i = t;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">         flag = <span class="number">1</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Prim算法关键部分如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//弹出堆顶元素</span></span><br><span class="line">   <span class="built_in">minheap_pop</span>();</span><br><span class="line">   <span class="keyword">while</span> (count &lt; V)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="comment">// 查找距离当前树最小的点</span></span><br><span class="line">      <span class="type">int</span> j = <span class="built_in">minheap_pop</span>();</span><br><span class="line"></span><br><span class="line">      book[j] = <span class="literal">true</span>;</span><br><span class="line">      count++;</span><br><span class="line">      sum += dist[j];</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 更新各点到树的距离</span></span><br><span class="line">      k = first[j]; <span class="comment">// 获取顶点i的所有相连边的头</span></span><br><span class="line">      <span class="keyword">while</span>(k != <span class="number">-1</span>)</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="keyword">if</span>(!book[v[k]] &amp;&amp; dist[v[k]] &gt; w[k])</span><br><span class="line">         &#123;</span><br><span class="line">            dist[v[k]] = w[k];</span><br><span class="line">            <span class="built_in">minheap_shiftup</span>(pos[v[k]]);</span><br><span class="line">         &#125;</span><br><span class="line">         k = next[k];</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p><a
href="https://github.com/cwlseu/Algorithm/blob/master/aha/ch8/prim_heap_minimal_spanning_tree.cpp"
class="uri">https://github.com/cwlseu/Algorithm/blob/master/aha/ch8/prim_heap_minimal_spanning_tree.cpp</a></p>
<h4 id="时间复杂度">时间复杂度</h4>
<table>
<colgroup>
<col style="width: 42%" />
<col style="width: 57%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">最小边、权的数据结构</th>
<th style="text-align: center;">时间复杂度（总计</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">邻接矩阵、搜索</td>
<td style="text-align: center;">O(V2)</td>
</tr>
<tr class="even">
<td
style="text-align: center;">二叉堆（后文伪代码中使用的数据结构）、邻接表</td>
<td style="text-align: center;">O((V + E) log(V)) = O(E log(V))</td>
</tr>
<tr class="odd">
<td style="text-align: center;">斐波那契堆、邻接表</td>
<td style="text-align: center;">O(E + V log(V))</td>
</tr>
</tbody>
</table>
<p>通过邻接矩阵图表示的简易实现中，找到所有最小权边共需O（V2）的运行时间。使用简单的二叉堆与邻接表来表示的话，普里姆算法的运行时间则可缩减为O(E
log
V)，其中E为连通图的边数，V为顶点数。如果使用较为<strong>复杂的斐波那契堆</strong>，则可将运行时间进一步缩短为O(E
+ V log V)，这在<strong>连通图足够密集</strong>时（当E满足Ω（V log
V）条件时），可较显著地提高运行速度。</p>
<h3 id="kruskal算法">Kruskal算法</h3>
<h4 id="算法描述">算法描述</h4>
<ul>
<li>新建图G，G中拥有原图中相同的节点，但没有边</li>
<li>将原图中所有的边按权值从小到大排序</li>
<li>从权值最小的边开始，如果这条边连接的两个节点于图G中不在同一个连通分量中，则添加这条边到图G中</li>
<li>重复3，直至图G中所有的节点都在同一个连通分量中</li>
</ul>
<h4 id="实现">实现</h4>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> std::vector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">tEdge</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="type">int</span> u;</span><br><span class="line">   <span class="type">int</span> v;</span><br><span class="line">   <span class="type">int</span> val;</span><br><span class="line">   <span class="built_in">tEdge</span>()</span><br><span class="line">      : <span class="built_in">u</span>(<span class="number">-1</span>)</span><br><span class="line">      , <span class="built_in">v</span>(<span class="number">-1</span>)</span><br><span class="line">      , <span class="built_in">val</span>(<span class="number">0</span>)</span><br><span class="line">   &#123;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="built_in">tEdge</span>(<span class="type">int</span> _u, <span class="type">int</span> _v, <span class="type">int</span> _val)</span><br><span class="line">      : <span class="built_in">u</span>(_u)</span><br><span class="line">      , <span class="built_in">v</span>(_v)</span><br><span class="line">      , <span class="built_in">val</span>(_val)</span><br><span class="line">   &#123;</span><br><span class="line">   &#125;</span><br><span class="line">&#125; tEdge;</span><br><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="type">int</span> MAX_LEN = <span class="number">101</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">comp_edge</span><span class="params">(tEdge e1, tEdge e2)</span> </span>&#123; <span class="keyword">return</span> e1.val &lt; e2.val; &#125;</span><br><span class="line"></span><br><span class="line">tEdge edges[MAX_LEN];</span><br><span class="line"><span class="type">int</span> find[MAX_LEN];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">init</span><span class="params">(<span class="type">int</span>* f, <span class="type">const</span> <span class="type">int</span> n)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; ++i) f[i] = i;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">getfather</span><span class="params">(<span class="type">int</span> v)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="comment">// 采用递归方式实现</span></span><br><span class="line">   <span class="comment">// 每次在函数返回的时候，将</span></span><br><span class="line">   <span class="keyword">if</span>(find[v] == v)</span><br><span class="line">      <span class="keyword">return</span> v;</span><br><span class="line">   find[v] = <span class="built_in">getfather</span>(find[v]);</span><br><span class="line">   <span class="keyword">return</span> find[v];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">merge</span><span class="params">(<span class="type">int</span> v, <span class="type">int</span> u)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="keyword">if</span>(v &gt; u) <span class="keyword">return</span> <span class="built_in">merge</span>(u, v);</span><br><span class="line">   <span class="type">int</span> t1, t2;</span><br><span class="line">   t1 = <span class="built_in">getfather</span>(v);</span><br><span class="line">   t2 = <span class="built_in">getfather</span>(u);</span><br><span class="line">   <span class="keyword">if</span>(t1 != t2)</span><br><span class="line">   &#123;</span><br><span class="line">      find[t2] = t1;<span class="comment">// 靠左原则，左边的变成右边的boss</span></span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> <span class="type">const</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">   FILE *f;</span><br><span class="line">   f = <span class="built_in">fopen</span>(<span class="string">&quot;minimal_spanning_tree.txt&quot;</span>, <span class="string">&quot;r&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span> (f == <span class="literal">NULL</span>) <span class="built_in">perror</span> (<span class="string">&quot;Error opening file&quot;</span>);</span><br><span class="line"></span><br><span class="line">   <span class="type">int</span> V, E;</span><br><span class="line">   <span class="type">int</span> u, v, val;</span><br><span class="line">   <span class="type">int</span> sum = <span class="number">0</span>; <span class="comment">// 最小生成树的花费</span></span><br><span class="line">   <span class="type">int</span> count_v = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">   <span class="built_in">fscanf</span>(f, <span class="string">&quot;%d %d&quot;</span>, &amp;V, &amp;E);</span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= E; ++i)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="built_in">fscanf</span>(f, <span class="string">&quot;%d %d %d&quot;</span>, &amp;u, &amp;v, &amp;val);</span><br><span class="line">      edges[i] = <span class="built_in">tEdge</span>(u, v, val);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function">std::vector&lt;tEdge&gt; <span class="title">edgev</span><span class="params">(edges+<span class="number">1</span>, edges+E+<span class="number">1</span>)</span></span>;</span><br><span class="line">   std::<span class="built_in">sort</span>(edgev.<span class="built_in">begin</span>(), edgev.<span class="built_in">end</span>(), comp_edge);</span><br><span class="line">   <span class="built_in">init</span>(find, V);</span><br><span class="line">   <span class="comment">// kruskal 算法</span></span><br><span class="line">   <span class="comment">// 从小到大枚举每一条边</span></span><br><span class="line">   <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; E; ++i)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="comment">// 判断两个顶点是否已经联通，是否在一个集合里</span></span><br><span class="line">      <span class="keyword">if</span>(<span class="built_in">merge</span>(edgev[i].u, edgev[i].v))</span><br><span class="line">      &#123;</span><br><span class="line">         count_v++;</span><br><span class="line">         sum += edgev[i].val;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 选择v - 1条边即可</span></span><br><span class="line">      <span class="keyword">if</span>(count_v == V - <span class="number">1</span>) <span class="keyword">break</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// for(int i = 1 ; i &lt;= V; ++i) printf(&quot;%d &quot;, find[i]);</span></span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;总共要花费银票是： %d\n&quot;</span>, sum);</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="算法时间复杂度">算法时间复杂度</h4>
<p>O(Elog(E)) E为图中的边数</p>
<h2 id="最短路径问题">最短路径问题</h2>
<h3 id="floyd-warshall">Floyd-warshall</h3>
<p>Floyd-Warshall算法,中文亦称弗洛伊德算法,是解决<strong>任意两点</strong>间的最短路径的一种算法,可以正确处理有向图或负权（<strong>但不可存在负权回路</strong>)的最短路径问题,
同时也被用于计算有向图的传递闭包。Floyd-Warshall算法的时间复杂度为<span
class="math inline">\(O(N^3)\)</span>，空间复杂度为<span
class="math inline">\(O(N^{2})\)</span>。</p>
<h4
id="floyd-warshall算法的原理是动态规划">Floyd-Warshall算法的原理是动态规划</h4>
<p>设 <span class="math inline">\(D_{i,j,k}\)</span>为从<span
class="math inline">\(i\)</span>到<span
class="math inline">\(j\)</span>的只以<span
class="math inline">\((1..k)\)</span>集合中的节点为中间节点的最短路径的长度。
若最短路径经过点k,则 <span
class="math inline">\(D_{i,j,k}=D_{i,k,k-1}+D_{k,j,k-1}\)</span>；
若最短路径不经过点k,则 <span
class="math inline">\(D_{i,j,k}=D_{i,j,k-1}\)</span>。 因此，<span
class="math inline">\(D_{i,j,k}=min(D_{i,j,k-1},D_{i,k,k-1}+D_{k,j,k-1})\)</span>。
在实际算法中,为了节约空间,可以直接在原来空间上进行迭代,这样空间可降至二维。</p>
<h4 id="伪代码">伪代码</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">letdistbea |V|x|V| arrayofminimumdistanceinitializedtoinfinity</span></span><br><span class="line"><span class="string">其中dist[i][j]表示由点i到点j的代价,当其为 ∞ 表示两点之间没有任何连接</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># initthegraph</span></span><br><span class="line">forvinvertex:</span><br><span class="line">    dist[v][v] = <span class="number">0</span></span><br><span class="line">foredge(u, v) inedge:</span><br><span class="line">    dist[u][v] = w(u, v)</span><br><span class="line"></span><br><span class="line"><span class="comment"># startthemainalgorithm</span></span><br><span class="line">forkrange(<span class="number">1</span>,|V|):</span><br><span class="line">    forirange(<span class="number">1</span>, |V|):</span><br><span class="line">        forjrange(<span class="number">1</span>, |V|):</span><br><span class="line">            ifdist[i][j] &gt; dist[i][k] + dist[k][j]: </span><br><span class="line">                dist[i][j] = dist[i][k] + dist[k][j]</span><br><span class="line">            endif</span><br><span class="line">        endfor</span><br><span class="line">    endfor</span><br><span class="line">endfor</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>为什么不能解决带有"负权回路"的图,因为带有负权回路的图没有最短路径。因为1-&gt;2-&gt;3-&gt;1-&gt;2-&gt;3-&gt;1-&gt;2-&gt;3,每次绕一次就减少1,
永远都找不到最短路径。</strong></p>
</blockquote>
<h3 id="dijkstra最短路径算法">Dijkstra最短路径算法</h3>
<figure>
<img src="../../images/algorithm/Dijkstra_Animation.gif"
alt="@Dijkstra最短路径算法示意图, ref:wikipedia" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="Dijkstra最短路径算法示意图">@Dijkstra最短路径算法示意图</span>,
ref:wikipedia</figcaption>
</figure>
<p>戴克斯特拉算法是由荷兰计算机科学家艾兹赫尔·戴克斯特拉提出。迪科斯彻算法使用了<strong>广度优先</strong>搜索解决赋权有向图的单源最短路径问题,算法最终得到一个最短路径树。该算法常用于路由算法或者作为其他图算法的一个子模块。
举例来说,如果图中的顶点表示城市,而边上的权重表示城市间开车行经的距离,该算法可以用来找到两个城市之间的最短路径。该算法的输入包含了一个有权重的有向图G,以及G中的一个来源顶点S。我们以V表示G中所有顶点的集合。每一个图中的边,都是两个顶点所形成的有序元素对。(u,
v)
表示从顶点u到v有路径相连。我们以E表示G中所有边的集合,而边的权重则由权重函数w:
E → [0, ∞] 定义。因此,w(u, v)
就是从顶点u到顶点v的<strong>非负权重</strong>（weight）。边的权重可以想像成两个顶点之间的距离。任两点间路径的权重,就是该路径上所有边的权重总和。已知有V中有顶点s及t,Dijkstra算法可以找到s到t的最低权重路径(例如,最短路径)。这个算法也可以在一个图中,
找到从<strong>一个顶点s到任何其他顶点</strong>的最短路径。</p>
<h4 id="伪代码-1">伪代码</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Dijkstra</span>(<span class="params">Graph, source</span>):</span><br><span class="line">     dist[source] ← <span class="number">0</span>                 <span class="comment"># Initialization</span></span><br><span class="line">     create vertex <span class="built_in">set</span> Q</span><br><span class="line"></span><br><span class="line">     <span class="keyword">for</span> each vertex v <span class="keyword">in</span> Graph:           </span><br><span class="line">         <span class="keyword">if</span> v ≠ source</span><br><span class="line">             dist[v] ← INFINITY       <span class="comment"># Unknown distance from source to v</span></span><br><span class="line">             prev[v] ← UNDEFINED      <span class="comment"># Predecessor of v</span></span><br><span class="line"></span><br><span class="line">         Q.add_with_priority(v, dist[v])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     <span class="keyword">while</span> Q <span class="keyword">is</span> <span class="keyword">not</span> empty:            <span class="comment"># The main loop</span></span><br><span class="line">        u ← Q.extract_min()           <span class="comment"># Remove and return best vertex</span></span><br><span class="line">        <span class="keyword">for</span> each neighbor v of u:     <span class="comment"># only v that is still in Q</span></span><br><span class="line">            alt ← dist[u] + length(u, v) </span><br><span class="line">            <span class="keyword">if</span> alt &lt; dist[v]</span><br><span class="line">                 dist[v] ← alt</span><br><span class="line">                 prev[v] ← u</span><br><span class="line">                 Q.decrease_priority(v, alt)</span><br><span class="line">     <span class="keyword">return</span> dist[], prev[]</span><br></pre></td></tr></table></figure>
<h3 id="bellman-ford算法">Bellman Ford算法</h3>
<p>对所有的E条<strong>边</strong>进行V-1次松弛操作。因为最短路径上最多有V-1条边.
第一次循环相当于经过一条边到达各个顶点的最短路径，经过k次循环相当于经过k条边到达各个顶点的最短路径。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">1</span>; k &lt;= V - <span class="number">1</span>; k++)</span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= E; ++i)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="keyword">if</span>(dist[v[i]] &gt; dist[u[i]] + w[i])</span><br><span class="line">         dist[v[i]] = dist[u[i]] + w[i]; </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>除此之外，Bellman
ford算法还可以用来检查是否有<strong>负权回路</strong>.
如果在进行V-1次松弛操作之后，仍然存在</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(dist[v[i]] &gt; dist[u[i]] + w[i])</span><br><span class="line">          dist[v[i]] = dist[u[i]] + w[i]; </span><br></pre></td></tr></table></figure>
<p>的情况的话，也就是说V-1轮松弛之后，仍然可以松弛，那么必存在负权回路。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">1</span>; k &lt;= V - <span class="number">1</span>; k++)</span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= E; ++i)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="keyword">if</span>(dist[v[i]] &gt; dist[u[i]] + w[i])</span><br><span class="line">         dist[v[i]] = dist[u[i]] + w[i]; </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 检查是否有负权回路</span></span><br><span class="line"><span class="type">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= E; ++i)</span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">if</span>(dist[v[i]] &gt; dist[u[i]] + w[i])</span><br><span class="line">     flag = <span class="literal">true</span>; </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (flag) <span class="built_in">printf</span>(<span class="string">&quot;这图有负权回路\n&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="复杂度总结">复杂度总结</h3>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 18%" />
<col style="width: 22%" />
<col style="width: 20%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">Floyd</th>
<th style="text-align: center;">Dijkstra</th>
<th style="text-align: center;">Bellman Ford</th>
<th style="text-align: center;">Bellman Ford Proiority</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">空间复杂度</td>
<td style="text-align: center;">O(V^2)</td>
<td style="text-align: center;">O(E)</td>
<td style="text-align: center;">O(E)</td>
<td style="text-align: center;">O(E)</td>
</tr>
<tr class="even">
<td style="text-align: center;">时间复杂度</td>
<td style="text-align: center;">O(V^3)</td>
<td style="text-align: center;">O((V+E)lgV)</td>
<td style="text-align: center;">O(VE)</td>
<td style="text-align: center;">最坏O(VE)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">适应情景</td>
<td style="text-align: center;">稠密图和顶点关系密切</td>
<td style="text-align: center;">稠密图和顶点关系密切</td>
<td style="text-align: center;">稀疏图和边关系密切</td>
<td style="text-align: center;">稀疏图和边关系密切</td>
</tr>
<tr class="even">
<td style="text-align: center;">负权</td>
<td style="text-align: center;">不可以</td>
<td style="text-align: center;">不能解决</td>
<td style="text-align: center;">可以解决</td>
<td style="text-align: center;">可以解决负权</td>
</tr>
</tbody>
</table>
<h3 id="有向图的拓扑排序">有向图的拓扑排序</h3>
<h2 id="参考">参考</h2>
<p>1.<a href="http://www.ahalei.com/">aha!算法</a></p>
<p>2.<a
href="https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95">wikipedia-
Dijstra算法</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>沧海遗珠:面试中碰到若干的问题</title>
    <url>/201705/20170511-algorithm-and-datastructure/</url>
    <content><![CDATA[<h2 id="缺省情况下c在global作用域内">缺省情况下C++在global作用域内</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(std::<span class="type">size_t</span>)</span> <span class="title">throw</span><span class="params">(std::bad_alloc)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(std::<span class="type">size_t</span>, <span class="type">void</span>*)</span> <span class="title">throw</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="keyword">operator</span> <span class="title">new</span><span class="params">(std::<span class="type">size_t</span>, <span class="type">const</span> std::<span class="type">nothrow_t</span>&amp;)</span> <span class="title">throw</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<h2 id="接口与实现分离">接口与实现分离</h2>
<p>关键在于声明的依存性替换定义的依存性。 如果使用object
reference或者obj
pointers可以完成任务，就不要使用objects。你可以只依靠一个类型声明式
就定义出指向该类型的references和pointers</p>
<h2 id="从前序与中序遍历序列构造二叉树">1.
从前序与中序遍历序列构造二叉树</h2>
<p>根据一棵树的前序遍历与中序遍历构造二叉树。 &gt;
注意:你可以假设树中没有重复的元素。 ### 例如， 给出 前序遍历 preorder =
[3,9,20,15,7] 中序遍历 inorder = [9,3,15,20,7] 返回如下的二叉树：</p>
<pre><code>3</code></pre>
<p>/<br />
9 20 /<br />
15 7</p>
<h3 id="分析">分析</h3>
<p>前序遍历顺序是遍历根节点，左子树，右子树，而中序遍历则是左子树，根节点，右子树，因此这类题目的解题思路是根据前序遍历的第一个元素确定根节点，然后在中顺遍历中找到根节点的位置。在中序遍历的左侧是左子树，右侧是右子树。
如上面的例子，首先我们根据前序的第一个节点确定3是根节点，那么在中序遍历结果中找到3，那么中序遍历结果中左侧的序列【9】则是3为根节点的左子树的中序结果，而右侧的序列【15，20，7】则是右子树的中序结果。
    确定了左右子树，继续在左子树的中序遍历结果中找到出现在先序遍历结果的元素，因为在先序遍历结果首先出现的一定是子树的根节点。如本题，左子树的中序遍历结果为【9】，只有一个元素，那么一定是9先出现在先序的结果中，因此左子树根节点为9。右子树的中序遍历结果为【15，20，7】，那么首先出现在先序遍历结果【3，9，20，15，7】的元素是20，那么20是右子树的根节点。
    因为左子树根节点9在其子树对应的中序结果【9】中没有左侧和右侧的序列，那么9则是一个叶子节点。而右子树根节点20在其对应子树的中序结果【15，20，7】中存在左侧序列【15】和右侧序列【7】，那么【15】对应的则是以20为根节点的左子树的中序结果，而【7】则是以20为根节点的右子树的中序结果。循环递归上面的过程构造子树。
反应到程序中需要解决两个重要的问题： 1.
先序遍历结果的第一个元素（根节点）在中序遍历结果中的位置如何确定？ 2.
左子树中序遍历子序列的根节点，即左子树的根节点如何确定？同样，右子树中序遍历子序列的根节点，即右子树的根节点如何确定？</p>
<p>代码 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">TreeNode* <span class="title">buildTree</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; preorder, vector&lt;<span class="type">int</span>&gt;&amp; inorder)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(preorder.<span class="built_in">size</span>()==<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;    <span class="comment">//空树</span></span><br><span class="line">        TreeNode* root = <span class="keyword">new</span> <span class="built_in">TreeNode</span>(preorder[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">if</span>(preorder.<span class="built_in">size</span>()==<span class="number">1</span>) <span class="keyword">return</span> root;    <span class="comment">//只有一个节点</span></span><br><span class="line"></span><br><span class="line">        vector&lt;<span class="type">int</span>&gt; leftIn,leftPre,rightIn,rightPre;</span><br><span class="line">        <span class="type">int</span> location = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(inorder[location]!=root-&gt;val)&#123;</span><br><span class="line">            leftIn.<span class="built_in">push_back</span>(inorder[location]);</span><br><span class="line">            location++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=location;i++) leftPre.<span class="built_in">push_back</span>(preorder[i]);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=location+<span class="number">1</span>;i&lt;preorder.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            rightPre.<span class="built_in">push_back</span>(preorder[i]);</span><br><span class="line">            rightIn.<span class="built_in">push_back</span>(inorder[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        root-&gt;left = <span class="built_in">buildTree</span>(leftPre, leftIn);</span><br><span class="line">        root-&gt;right = <span class="built_in">buildTree</span>(rightPre, rightIn);</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="二叉树的层次遍历">2. 二叉树的层次遍历</h2>
<p>思路
二叉树或一般树的水平层次遍历，可以使用BFS（广度搜素）算法，使用队列
Queue标记每一层的结点元素； Queue：先进先出，
后进后出。可以保证每一层遍历时的结点顺序；
BFS：类似于电影中的病毒传染，先感染靠近自己的，再由易感染层感染更外层；
该题二叉树中，先把根结点压入队列，当队列不为空时，移除队首结点，并判断该结点的左右子树中有无非空结点，若存在，则再次入队对应的左右子树结点……同一层的每个结点循环以上操作，直至队列为空，循环结束。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">TreeNode</span> &#123;</span><br><span class="line">    <span class="type">int</span> val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    <span class="built_in">TreeNode</span>(<span class="type">int</span> x) : <span class="built_in">val</span>(x), <span class="built_in">left</span>(<span class="literal">NULL</span>), <span class="built_in">right</span>(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">levelOrder</span>(TreeNode* root) &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; result;</span><br><span class="line">        queue&lt;TreeNode*&gt; que;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="literal">NULL</span>) <span class="keyword">return</span> result;</span><br><span class="line">        que.<span class="built_in">push</span>(root);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (!que.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="type">int</span> size = que.<span class="built_in">size</span>();</span><br><span class="line">            vector&lt;<span class="type">int</span>&gt; temp;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                TreeNode* node = que.<span class="built_in">front</span>();</span><br><span class="line">                que.<span class="built_in">pop</span>();</span><br><span class="line">                temp.<span class="built_in">push_back</span>(node-&gt;val);</span><br><span class="line">                <span class="keyword">if</span> (node-&gt;left != <span class="literal">NULL</span>) que.<span class="built_in">push</span>(node-&gt;left);</span><br><span class="line">                <span class="keyword">if</span> (node-&gt;right != <span class="literal">NULL</span>) que.<span class="built_in">push</span>(node-&gt;right);</span><br><span class="line">            &#125;</span><br><span class="line">            result.<span class="built_in">push_back</span>(temp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    string a = <span class="string">&quot;3,9,20,null,null,15,7&quot;</span>;</span><br><span class="line">    <span class="keyword">auto</span> tree = <span class="built_in">stringToTreeNode</span>(a);</span><br><span class="line">    <span class="keyword">auto</span> res = <span class="built_in">Solution</span>().<span class="built_in">levelOrder</span>(tree);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二叉树的中序遍历">3. 二叉树的中序遍历</h2>
<h3 id="迭代法">迭代法</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">inorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        stack&lt;TreeNode&gt; s;</span><br><span class="line">        vector&lt;<span class="type">int</span>&gt; ans;</span><br><span class="line">        TreeNode* t = root;</span><br><span class="line">        <span class="keyword">while</span>(t || !s.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="keyword">while</span>(t)&#123;  <span class="comment">//遍历到最左边的叶结点</span></span><br><span class="line">                s.<span class="built_in">push</span>(*t);</span><br><span class="line">                t = t-&gt;left;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(!s.<span class="built_in">empty</span>())&#123;</span><br><span class="line">                ans.<span class="built_in">push_back</span>(s.<span class="built_in">top</span>().val);</span><br><span class="line">                t = s.<span class="built_in">top</span>().right;</span><br><span class="line">                s.<span class="built_in">pop</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="复杂度">复杂度</h4>
<p>时间复杂度：O(n) 空间复杂度：O(n)</p>
<h3 id="递归法">递归法</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; ans;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">inorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root) &#123;</span><br><span class="line">            <span class="built_in">inorderTraversal</span>(root-&gt;left);</span><br><span class="line">            ans.<span class="built_in">push_back</span>(root-&gt;val);</span><br><span class="line">            <span class="built_in">inorderTraversal</span>(root-&gt;right);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="复杂度分析">复杂度分析</h4>
<ul>
<li>时间复杂度：<span class="math inline">\(O(n)\)</span>, 递归函数
<span class="math inline">\(T(n) = 2 \cdot T(n/2)+1\)</span></li>
<li>空间复杂度：最坏情况下需要空间<span
class="math inline">\(O(n)\)</span>，平均情况为<span
class="math inline">\(O(\log n)\)</span></li>
</ul>
<h2 id="一棵btree如下我们从右边看会看到135输出这个vectorint">4.
一棵BTree如下，我们从右边看会看到{1,3,5},输出这个<code>vector&lt;int&gt;</code></h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">     <span class="number">1</span></span><br><span class="line">    / \</span><br><span class="line">   <span class="number">2</span>   <span class="number">3</span></span><br><span class="line"> /   \</span><br><span class="line"><span class="number">4</span>     <span class="number">5</span></span><br></pre></td></tr></table></figure>
<p>这个问题可以通过广度有限搜索的方式实现，关键是要找到每一层最右边的那个节点。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;deque&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">btreenode</span> &#123;</span><br><span class="line">    btreenode* left;</span><br><span class="line">    btreenode* right;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">&#125; btreenode;</span><br><span class="line"></span><br><span class="line"><span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">get_right_slice_btree</span><span class="params">(btreenode* root)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(root == <span class="literal">nullptr</span>) <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; result;</span><br><span class="line">    std::deque&lt;btreenode*&gt; dp;</span><br><span class="line">    dp.<span class="built_in">push_back</span>(root);</span><br><span class="line">    <span class="type">int</span> prelevel_child_cnt = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> curlevel_child_cnt = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(!dp.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        btreenode* node = dp.<span class="built_in">pop_front</span>();</span><br><span class="line">        <span class="keyword">if</span>(node-&gt;left) &#123;</span><br><span class="line">            dp.<span class="built_in">push_back</span>(node-&gt;left);</span><br><span class="line">            curlevel_child_cnt++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(node-&gt;right) &#123;</span><br><span class="line">            dp.<span class="built_in">push_back</span>(node-&gt;right);</span><br><span class="line">            curlevel_child_cnt++;</span><br><span class="line">        &#125;</span><br><span class="line">        prelevel_child_cnt --;</span><br><span class="line">        <span class="keyword">if</span>(prelevel_child_cnt == <span class="number">0</span>) &#123;</span><br><span class="line">            prelevel_child_cnt = curlevel_child_cnt;</span><br><span class="line">            curlevel_child_cnt = <span class="number">0</span>;</span><br><span class="line">            result.<span class="built_in">push_back</span>(node-&gt;value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>btree如果一共有<span
class="math inline">\(n\)</span>个节点，该算法的时间复杂度是<span
class="math inline">\(O(n)\)</span>, 因为我们是遍历了一遍所有的节点。
空间复杂度： <span class="math display">\[x(1 + \frac{1}{2} +
\frac{1}{4} + ..) = x(\frac{1}{1- \frac{1}{2}}) = n  \]</span> <span
class="math display">\[x = \frac{n}{2}\]</span>
所以最长的队列长度是<span
class="math inline">\(\frac{n}{2}\)</span>,那么空间复杂度为<span
class="math inline">\(O(n)\)</span></p>
<p>首先最简单的实现方法是使用两个deque来实现，这样每次deque保存当前的层，然后最后出队的就是尾部节点。但是这个是采用两个队列，空间上有一些浪费资源，需要二外的<span
class="math inline">\(k/2\)</span>的空间资源。</p>
<h2 id="find-all-anagrams-in-a-string-找出字符串中所有的变位词">5. Find
All Anagrams in a String 找出字符串中所有的变位词</h2>
<p>Given a string s and a non-empty string p, find all the start indices
of p's anagrams in s.</p>
<p>Strings consists of lowercase English letters only and the length of
both strings s and p will not be larger than 20,100.</p>
<p>The order of output does not matter.</p>
<p>Example 1:</p>
<p>Input: s: "cbaebabacd" p: "abc"</p>
<p>Output: [0, 6]</p>
<p>Explanation: The substring with start index = 0 is "cba", which is an
anagram of "abc". The substring with start index = 6 is "bac", which is
an anagram of "abc".</p>
<p>Example 2:</p>
<p>Input: s: "abab" p: "ab"</p>
<p>Output: [0, 1, 2]</p>
<p>Explanation: The substring with start index = 0 is "ab", which is an
anagram of "ab". The substring with start index = 1 is "ba", which is an
anagram of "ab". The substring with start index = 2 is "ab", which is an
anagram of "ab".</p>
<h3 id="采用hash表法">采用hash表法</h3>
<p>用两个哈希表，分别记录p的字符个数，和s中前p字符串长度的字符个数，然后比较，如果两者相同，则将0加入结果res中，然后开始遍历s中剩余的字符，每次右边加入一个新的字符，然后去掉左边的一个旧的字符，每次再比较两个哈希表是否相同即可，参见代码如下：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">findAnagrams</span><span class="params">(string s, string p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (s.<span class="built_in">empty</span>()) <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">        vector&lt;<span class="type">int</span>&gt; res, <span class="built_in">m1</span>(<span class="number">256</span>, <span class="number">0</span>), <span class="built_in">m2</span>(<span class="number">256</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; p.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            ++m1[s[i]]; ++m2[p[i]];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (m1 == m2) res.<span class="built_in">push_back</span>(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = p.<span class="built_in">size</span>(); i &lt; s.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            ++m1[s[i]]; </span><br><span class="line">            --m1[s[i - p.<span class="built_in">size</span>()]];</span><br><span class="line">            <span class="keyword">if</span> (m1 == m2) res.<span class="built_in">push_back</span>(i - p.<span class="built_in">size</span>() + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<h3 id="滑动窗口sliding-window的方法">滑动窗口Sliding Window的方法</h3>
<p>首先统计字符串p的字符个数，然后用两个变量left和right表示滑动窗口的左右边界，用变量cnt表示字符串p中需要匹配的字符个数，然后开始循环，
- Step1:
如果右边界的字符已经在哈希表中了，说明该字符在p中有出现，则cnt自减1，然后哈希表中该字符个数自减1，右边界自加1，
-
Step2:如果此时cnt减为0了，说明p中的字符都匹配上了，那么将此时左边界加入结果res中。
-
Step3:如果此时right和left的差为p的长度，说明此时应该去掉最左边的一个字符，我们看如果该字符在哈希表中的个数大于等于0，说明该字符是p中的字符，因为上面Step1我们有让每个字符自减1，如果不是p中的字符，那么在哈希表中个数应该为0，自减1后就为-1，所以这样就知道该字符是否属于p，如果我们去掉了属于p的一个字符，cnt自增1.
参见代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">findAnagrams</span><span class="params">(string s, string p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (s.<span class="built_in">empty</span>()) <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">        vector&lt;<span class="type">int</span>&gt; res, <span class="built_in">m</span>(<span class="number">256</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="type">int</span> left = <span class="number">0</span>, right = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> cnt = p.<span class="built_in">size</span>(), n = s.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">char</span> c : p) ++m[c];</span><br><span class="line">        <span class="keyword">while</span> (right &lt; n) &#123;</span><br><span class="line">            <span class="keyword">if</span> (m[s[right++]]-- &gt;= <span class="number">1</span>) --cnt;</span><br><span class="line">            <span class="keyword">if</span> (cnt == <span class="number">0</span>) res.<span class="built_in">push_back</span>(left);</span><br><span class="line">            <span class="keyword">if</span> (right - left == p.<span class="built_in">size</span>() &amp;&amp; m[s[left++]]++ &gt;= <span class="number">0</span>) ++cnt;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>https://www.cnblogs.com/grandyang/p/6014408.html</p>
<h2 id="最长公共子序列问题lcs问题">6. 最长公共子序列问题(LCS问题)</h2>
<p>给定两个字符串A和B，长度分别为m和n，要求找出它们最长的公共子序列，并返回其长度。例如：
A = "HelloWorld" B = "loop"</p>
<p>则A与B的最长公共子序列为
"loo",返回的长度为3。此处只给出动态规划的解法：定义子问题dp[i][j]为字符串A的第一个字符到第
i 个字符串和字符串B的第一个字符到第 j
个字符的最长公共子序列，如A为“app”,B为“apple”，dp[2][3]表示 “ap” 和
“app” 的最长公共字串。注意到代码中 dp 的大小为 (n + 1) x (m + 1)
，这多出来的一行和一列是第 0 行和第 0 列，初始化为
0，表示空字符串和另一字符串的子串的最长公共子序列，例如dp[0][3]表示 ""
和 “app” 的最长公共子串。</p>
<p>当我们要求dp[i][j]，我们要先判断A的第i个元素B的第j个元素是否相同即判断A[i
- 1]和 B[j -1]是否相同，如果相同它就是dp[i-1][j-1]+
1，相当于在两个字符串都去掉一个字符时的最长公共子序列再加
1；否则最长公共子序列取dp[i][j - 1] 和dp[i -
1][j]中大者。所以整个问题的</p>
<ul>
<li>初始状态为： <span class="math display">\[dp[i][0]=0,
dp[0][j]=0\]</span></li>
<li>相应的状态转移方程为： <span class="math display">\[
dp[i][j] = \begin{cases} \max\{dp[i - 1][j], dp[i][j - 1]\} ,&amp; {A[i
- 1]  != B[j - 1]}
\\ dp[i - 1][j - 1] + 1 , &amp; {A[i - 1]  == B[j - 1]} \end{cases}
\]</span></li>
<li>代码的实现如下： <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">findLCS</span><span class="params">(string A, <span class="type">int</span> n, string B, <span class="type">int</span> m)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">0</span> || m == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    std::vector&lt;std::vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dp</span>(n + <span class="number">1</span>,std::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(m + <span class="number">1</span>, <span class="number">0</span>)); <span class="comment">//定义状态数组</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span> ; i &lt;= n; i++) dp[i][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt;= m; i++) dp[<span class="number">0</span>][i] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>; j&lt;= m; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(A[i - <span class="number">1</span>] == B[j - <span class="number">1</span>])<span class="comment">//判断A的第i个字符和B的第j个字符是否相同</span></span><br><span class="line">                dp[i][j] = dp[i <span class="number">-1</span>][j - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n][m];<span class="comment">//最终的返回结果就是dp[n][m]</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 该算法的时间复杂度为<span
class="math inline">\(O(n*m)\)</span>，空间复杂度为<span
class="math inline">\(O(n*m)\)</span>。此外，由于遍历时是从下标1开始的，因为下标为0表示空字符串；所以第A的第i个字符实际上为A[i
-1]，B的第j个字符为B[j-1]。</li>
</ul>
<h2 id="最长公共子串问题">7. 最长公共子串问题</h2>
<p>给定两个字符串A和B，长度分别为m和n，要求找出它们最长的公共子串，并返回其长度。例如：
A = "HelloWorld" B = "loop" 则A与B的最长公共子串为 "lo",返回的长度为2。
我们可以看到子序列和子串的区别：子序列和子串都是字符集合的子集，但是子序列不一定连续，但是子串一定是连续的。</p>
<p>这里只给出动态规划的解法：定义dp[i][j]表示以A中第i个字符结尾的子串和B中第j个字符结尾的子串的的最大公共子串(公共子串实际上指的是这两个子串的所有部分)的长度(要注意这里和LCS的不同，LCS中的dp[i+1][j+1]一定是大于等于dp[i][j]的；但最长公共子串问题就不一定了，它的dp[i][j]表示的子串不一定是以A[0]开头B[0]开头的，但是一定是以A[i-1]、B[j-1]结尾的)，同样地，
dp 的大小也为 (n + 1) x (m + 1) ，这多出来的一行和一列是第 0 行和第 0
列，初始化为 0，表示空字符串和另一字符串的子串的最长公共子串。</p>
<p>当我们要求dp[i][j]，我们要先判断A的第i个元素B的第j个元素是否相同即判断A[i
- 1]和 B[j -1]是否相同，如果相同它就是dp[i - 1][j- 1] +
1，相当于在两个字符串都去掉一个字符时的最长公共子串再加
1；否则最长公共子串取0。</p>
<ul>
<li><p>整个问题的初始状态为： dp[i][0]=0, dp[0][j]=0</p></li>
<li><p>相应的状态转移方程为： <span class="math display">\[dp[i][j] =
\begin{cases} 0 ,&amp; {A[i - 1]  != B[j - 1]} \\ dp[i - 1][j - 1] + 1 ,
&amp; {A[i - 1]  == B[j - 1]} \end{cases}\]</span></p></li>
<li><p>代码的实现如下：</p></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LongestSubstring</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findLongest</span><span class="params">(std::string A, <span class="type">int</span> n, std::string B, <span class="type">int</span> m)</span> </span>&#123;</span><br><span class="line">         <span class="keyword">if</span>(n == <span class="number">0</span> || m == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> rs = <span class="number">0</span>;</span><br><span class="line">        std::vector&lt;std::vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dp</span>(n + <span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(m + <span class="number">1</span>, <span class="number">0</span>));</span><br><span class="line">        <span class="comment">//初始状态</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span> ; i &lt;= n; i++) dp[i][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt;= m; i++) dp[<span class="number">0</span>][i] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>; j&lt;= m; j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(A[i - <span class="number">1</span>] == B[j - <span class="number">1</span>]) &#123;</span><br><span class="line">                    dp[i][j] = dp[i <span class="number">-1</span>][j - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">                    rs = <span class="built_in">max</span>(rs, dp[i][j]);<span class="comment">//每次更新记录最大值</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;<span class="comment">//不相等的情况</span></span><br><span class="line">                    dp[i][j] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> rs;<span class="comment">//返回的结果为rs</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>该算法的时间复杂度为O(n<em>m)，空间复杂度为O(n</em>m)。同样地，遍历下标也是从1开始的。不过关于最长公共子串问题，有几点需要注意下：</p>
<p>1.由于dp[i][j]不像LCS是个递增的数组，所以它在每次更新时需要同时更新最大值rs，且最后返回的结果是rs。而LCS中返回的直接就是dp[n][m]。
2.从代码上来看，两者的结构其实差不多，只不过状态转移方程有些小许的不同，分析过程也类似。</p>
<h2
id="leetcode-673-number-of-longest-increasing-subsequence-最长递增序列的个数">8.
[leetcode 673] Number of Longest Increasing Subsequence
最长递增序列的个数</h2>
<p>Given an unsorted array of integers, find the number of longest
increasing subsequence.</p>
<p>Example 1:</p>
<pre><code>Input: [1,3,5,4,7]
Output: 2
Explanation: The two longest increasing subsequence are [1, 3, 4, 7] and [1, 3, 5, 7].</code></pre>
<p>Example 2:</p>
<pre><code>Input: [2,2,2,2,2]
Output: 5
Explanation: The length of longest continuous increasing subsequence is 1, and there are 5 subsequences&#39; length is 1, so output 5.</code></pre>
<p>https://www.cnblogs.com/grandyang/p/7603903.html</p>
<h2 id="给定一个数组将数组中的元素向右移动-k-个位置其中-k-是非负数">9.
给定一个数组，将数组中的元素向右移动 k 个位置，其中 k 是非负数。</h2>
<p>示例 1: - 输入: [1,2,3,4,5,6,7] 和 k = 3 - 输出: [5,6,7,1,2,3,4] -
解释: - 向右旋转 1 步: [7,1,2,3,4,5,6] - 向右旋转 2 步: [6,7,1,2,3,4,5]
- 向右旋转 3 步: [5,6,7,1,2,3,4]</p>
<p>示例 2: - 输入: [-1,-100,3,99] 和 k = 2 - 输出: [3,99,-1,-100] -
解释: - 向右旋转 1 步: [99,-1,-100,3] - 向右旋转 2 步:
[3,99,-1,-100]</p>
<p>说明:
尽可能想出更多的解决方案，至少有三种不同的方法可以解决这个问题。
要求使用空间复杂度为 O(1) 的原地算法。 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">rotate</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        k %= nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">temp</span><span class="params">(k)</span></span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; k; i++) temp[i] = nums[nums.<span class="built_in">size</span>() - <span class="number">1</span> - i];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = nums.<span class="built_in">size</span>() - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">            nums[i] = nums[i - k];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; k; i++) &#123;</span><br><span class="line">            nums[i] = temp[k - i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>类似翻转字符的方法，先把前n-k个数字翻转一下，再把后k个数字翻转一下，最后再把整个数组翻转一下
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">rotate</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;nums, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> count = k % nums.<span class="built_in">size</span>();</span><br><span class="line">        <span class="type">int</span> bounder= nums.<span class="built_in">size</span>() - count;</span><br><span class="line">        <span class="built_in">reverse</span>(nums,<span class="number">0</span>,bounder<span class="number">-1</span>);</span><br><span class="line">        <span class="built_in">reverse</span>(nums,bounder, nums.<span class="built_in">size</span>() - <span class="number">1</span>);</span><br><span class="line">        <span class="built_in">reverse</span>(nums,<span class="number">0</span>,nums.<span class="built_in">size</span>() - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="type">void</span> <span class="title">reverse</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;arr,<span class="type">int</span> st,<span class="type">int</span> end)</span></span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(st &lt; end)&#123;</span><br><span class="line">            <span class="type">int</span> temp = arr[st];</span><br><span class="line">            arr[st] = arr[end];</span><br><span class="line">            arr[end] = temp;</span><br><span class="line">            st++;</span><br><span class="line">            end--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<h2 id="leetcode-sort-characters-by-frequency-根据字符出现频率排序">10.
[LeetCode] Sort Characters By Frequency 根据字符出现频率排序</h2>
<p>Given a string, sort it in decreasing order based on the frequency of
characters.</p>
<p>Example 1:</p>
<pre><code>Input: &quot;tree&quot;
Output: &quot;eert&quot;</code></pre>
<p>Explanation: 'e' appears twice while 'r' and 't' both appear once. So
'e' must appear before both 'r' and 't'. Therefore "eetr" is also a
valid answer.</p>
<p>Example 2:</p>
<pre><code>Input: &quot;cccaaa&quot;
Output:&quot;cccaaa&quot;</code></pre>
<p>Explanation: Both 'c' and 'a' appear three times, so "aaaccc" is also
a valid answer. Note that "cacaca" is incorrect, as the same characters
must be together.</p>
<p>Example 3:</p>
<pre><code>Input: &quot;Aabb&quot;
Output: &quot;bbAa&quot;</code></pre>
<p>Explanation: "bbaA" is also a valid answer, but "Aabb" is incorrect.
Note that 'A' and 'a' are treated as two different characters.</p>
<p>这道题让我们给一个字符串按照字符出现的频率来排序，那么毫无疑问肯定要先统计出每个字符出现的个数，那么之后怎么做呢？我们可以利用优先队列的自动排序的特点，把个数和字符组成pair放到优先队列里排好序后，再取出来组成结果res即可，参见代码如下：</p>
<h3 id="解法一">解法一：</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">string <span class="title">frequencySort</span><span class="params">(string s)</span> </span>&#123;</span><br><span class="line">        string res = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        priority_queue&lt;pair&lt;<span class="type">int</span>, <span class="type">char</span>&gt;&gt; q;</span><br><span class="line">        unordered_map&lt;<span class="type">char</span>, <span class="type">int</span>&gt; m;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">char</span> c : s) ++m[c];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> a : m) q.<span class="built_in">push</span>(&#123;a.second, a.first&#125;);</span><br><span class="line">        <span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="keyword">auto</span> t = q.<span class="built_in">top</span>(); q.<span class="built_in">pop</span>();</span><br><span class="line">            <span class="comment">// 向str中添加t.sencond个t.first的char</span></span><br><span class="line">            res.<span class="built_in">append</span>(t.first, t.second);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>我们也可以使用STL自带的sort来做，关键就在于重写comparator，由于需要使用外部变量，记得中括号中放入＆，然后我们将频率大的返回，注意一定还要处理频率相等的情况，要不然两个频率相等的字符可能穿插着出现在结果res中，这样是不对的。参见代码如下：</p>
<h3 id="解法二">解法二：</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">string <span class="title">frequencySort</span><span class="params">(string s)</span> </span>&#123;</span><br><span class="line">        unordered_map&lt;<span class="type">char</span>, <span class="type">int</span>&gt; m;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">char</span> c : s) ++m[c];</span><br><span class="line">        <span class="built_in">sort</span>(s.<span class="built_in">begin</span>(), s.<span class="built_in">end</span>(), [&amp;](<span class="type">char</span>&amp; a, <span class="type">char</span>&amp; b)&#123;</span><br><span class="line">            <span class="keyword">return</span> m[a] &gt; m[b] || (m[a] == m[b] &amp;&amp; a &lt; b);</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>我们也可以不使用优先队列，而是建立一个字符串数组，因为某个字符的出现次数不可能超过s的长度，所以我们将每个字符根据其出现次数放入数组中的对应位置，那么最后我们只要从后往前遍历数组所有位置，将不为空的位置的字符串加入结果res中即可，参见代码如下：</p>
<h3 id="解法三">解法三：</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">string <span class="title">frequencySort</span><span class="params">(string s)</span> </span>&#123;</span><br><span class="line">        string res;</span><br><span class="line">        <span class="function">vector&lt;string&gt; <span class="title">v</span><span class="params">(s.size() + <span class="number">1</span>)</span></span>;</span><br><span class="line">        unordered_map&lt;<span class="type">char</span>, <span class="type">int</span>&gt; m;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">char</span> c : s) ++m[c];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;a : m) &#123;</span><br><span class="line">            v[a.second].<span class="built_in">append</span>(a.second, a.first);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = s.<span class="built_in">size</span>(); i &gt; <span class="number">0</span>; --i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!v[i].<span class="built_in">empty</span>()) res.<span class="built_in">append</span>(v[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="search-a-2d-matrix搜索二维矩阵">11. Search a 2D
Matrix（搜索二维矩阵）</h2>
<p>编写一个高效的算法来判断<span class="math inline">\(m \times
n\)</span>矩阵中，是否存在一个目标值。该矩阵具有如下特性： -
每行中的整数从左到右按升序排列。 -
每行的第一个整数大于前一行的最后一个整数。 - 示例输入:</p>
<p>matrix = [ [1, 3, 5, 7], [10, 11, 16, 20], [23, 30, 34, 50]] target =
3</p>
<p>输出: true</p>
<h3 id="算法思路1">算法思路1</h3>
<p>1.找规律，首先此二维数组是有序的，我们可以从右上角开始查找，每次只需要左移或下移即可，也就是row++或col--；
2.初始化右上角数字下标的指针常量，如果target等于当前数则return
true，如果大于右上角的数字，那么target肯定不在当前行，row++，省去了一行的比较，如果target小于右上角的数字，则target肯定不在当前列，那么col++即可。
3.完结。</p>
<h3 id="算法思路2">算法思路2</h3>
<p>根据二维数组数值特点，将其想象成为我们熟悉的一维数组求解。而这里二维转成一维的关键是一维数组的下标mid和二维数组下标[i][j]的换算关系：[i][j]=[mid/列数][mid%列数]。直接上代码，比较简介应该很容易看懂，就不再赘述了。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">searchMatrix</span><span class="params">(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; matrix, <span class="type">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> m = matrix.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">if</span> (m == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="type">int</span> n = matrix[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 二分查找</span></span><br><span class="line">    <span class="type">int</span> left = <span class="number">0</span>, right = m * n - <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> pivotIdx, pivotElement;</span><br><span class="line">    <span class="keyword">while</span> (left &lt;= right) &#123;</span><br><span class="line">      pivotIdx = (left + right) / <span class="number">2</span>;</span><br><span class="line">      pivotElement = matrix[pivotIdx / n][pivotIdx % n];</span><br><span class="line">      <span class="keyword">if</span> (target == pivotElement) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (target &lt; pivotElement) right = pivotIdx - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> left = pivotIdx + <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="写一个申请二维数组的实现">写一个申请二维数组的实现</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span>** <span class="title function_">mymalloc</span><span class="params">(<span class="type">const</span> <span class="type">int</span> m, <span class="type">const</span> <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(m &lt;=<span class="number">0</span> || n &lt;=<span class="number">0</span>) <span class="keyword">return</span> nullptr;</span><br><span class="line">    <span class="type">char</span>** ret = (<span class="type">char</span>**) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">char</span>*)* m);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;</span><br><span class="line">        ret[i] = (<span class="type">char</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">char</span>)* n);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">myfree</span><span class="params">(<span class="type">char</span>** a, <span class="type">const</span> <span class="type">int</span> m, <span class="type">const</span> <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="comment">// param n is useless</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;</span><br><span class="line">        <span class="built_in">free</span>(a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">free</span>(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>CV算法</tag>
      </tags>
  </entry>
  <entry>
    <title>图像视觉：行人检测任务之FHOG算子</title>
    <url>/201704/20170410-feature-descriptor-fhog/</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<p>在计算机视觉和图像处理中用来进行物体检测的特征描述子，它通过计算和统计图像局部区域
的梯度方向直方图构成特征。Hog特征结合分类算法广泛应用于图像识别中，尤其是
在行人检测中获得极大成功。HOG+SVM的行人检测方法2005年提出来之后，如今很多
行人检测算法都是以此为思路的。</p>
<h1 id="从特征描述子说起">从特征描述子说起</h1>
<ol type="1">
<li>Haar</li>
<li>SIFT</li>
<li>HOG(Histogram of Oriented Gradient)
在计算机视觉和图像处理中用来进行物体检测的特征描述子，它通过计算和统计图像局部区域
的梯度方向直方图构成特征。Hog特征结合分类算法广泛应用于图像识别中，尤其是
在行人检测中获得极大成功。HOG+SVM的行人检测方法2005年提出来之后，如今很多
行人检测算法都是以此为思路的。</li>
</ol>
<h2 id="基本的一些特征检测方法">基本的一些特征检测方法</h2>
<ul>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node1.html">Sharpening</a></li>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node2.html">High-boost
filtering</a></li>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node3.html">The
Gradient Operator</a></li>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node3.html">Digital
Gradient</a></li>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node3.html">Compass
Gradient Operations</a></li>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node3.html">Edge
Detection</a></li>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node3.html">The
Laplace Operator</a></li>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node3.html">Laplacian
of Gaussian (LoG)</a></li>
<li><a
href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node3.html">Difference
of Gaussian (DoG)</a></li>
</ul>
<h1 id="hog特征描述子有什么特性">HOG特征描述子有什么特性</h1>
<p>在一副图像中，局部目标的表象和形状（appearance and
shape）能够被梯度或边缘的方向密度分布很好地描述。（本质：梯度的统计信息，而梯度主要存在于边缘的地方）</p>
<h2 id="实现方法">实现方法</h2>
<ol type="1">
<li>首先将图像分成小的连通区域，我们把它叫<strong>细胞单元</strong>。然后采集细胞单元中各像素点的梯度的或边缘的方向直方图。最后把这些直方图组合起来就可以构成特征描述器。</li>
<li>为了提高性能，把这些局部直方图在图像的<strong>更大的范围内（我们把它叫区间或block）</strong>进行对比度归一化（contrast-normalized），所采用的方法是：先计算各直方图在这个<strong>block</strong>中的密度，然后根据这个密度对<strong>block</strong>中的各个<strong>细胞单元</strong>做归一化。通过这个归一化后，能对光照变化和阴影获得更好的效果。</li>
</ol>
<h2 id="算法步骤">算法步骤</h2>
<p>HOG特征提取方法就是将一个image（你要检测的目标或者扫描窗口): <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/process.jpg"
alt="@HOG特征提取算法的实现过程" /></p>
<h4
id="灰度化将图像看做一个xyh灰度的三维图像">灰度化（将图像看做一个x,y,h（灰度）的三维图像）；</h4>
<h4
id="采用gamma校正法对输入图像进行颜色空间的标准化归一化">采用Gamma校正法对输入图像进行<strong>颜色空间的标准化（归一化）</strong></h4>
<p>目的是调节图像的对比度，降低图像局部的阴影和光照变化所造成的影响，同时可以抑制噪音的干扰；
为了减少光照因素的影响，首先需要将整个图像进行规范化（归一化）。在图像的纹理强度中，局部的表层曝光贡献的比重较大，所以，这种压缩处理能够有效地降低图像局部的阴影和光照变化。因为颜色信息作用不大，通常先转化为灰度图；</p>
<p><span class="math display">\[I(x, y) = I(x, y)^{\gamma}\]</span></p>
<p>通常<span class="math inline">\(\gamma\)</span>取0.5</p>
<h4
id="计算图像每个像素的梯度包括大小和方向主要是为了捕获轮廓信息同时进一步弱化光照的干扰">计算图像每个像素的梯度（包括大小和方向）；主要是为了捕获轮廓信息，同时进一步弱化光照的干扰。</h4>
<p>图像中像素点的梯度：</p>
<p><span class="math display">\[G_x(x, y) = H(x+1, y) - H(x-1,
y)\]</span> <span class="math display">\[G_y(x, y) = H(x, y+1) - H(x,
y-1)\]</span> <span class="math display">\[G(x, y) = \sqrt{G_x(x, y)^2 +
G_y(x, y)^2}\]</span> <span class="math display">\[\alpha(x, y) =
tan^{-1}{\frac{G_y(x, y)}{G_x(x, y)}}\]</span></p>
<h4
id="将图像划分成小cells例如1616像素cell">将图像划分成小<code>cells</code>（例如16*16像素/cell）；</h4>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/cell.jpg"
alt="@" />
每一个点的梯度角度可能是0~180度之间的任意值，而程序中将其离散化为9个bin，即每个bin占20度。所以滑动窗口中每个像素点的梯度角度如果要离散化到这9个bin中，则一般它都会有2个相邻的bin(如果恰好位于某个bin的中心，则可认为对该bin的权重为1即可)。从源码中可以看到梯度的幅值是用来计算梯度直方图时权重投票的，所以每个像素点的梯度幅值就分解到了其角度相邻的2个bin了，越近的那个bin得到的权重越大。因此幅度图像用了2个通道，每个通道都是原像素点幅度的一个分量。同理，不难理解，像素点的梯度角度也用了2个通道，每个通道中存储的是它相邻2个bin的bin序号。序号小的放在第一通道。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/bin.png"
alt="@每个cell中的像素梯度最后离散化为9个bin中，其中的bins统计各个bin中hist信息" />
其中，假设那3条半径为离散化后bin的中心，红色虚线为像素点O(像素点在圆心处)的梯度方向，梯度幅值为A，该梯度方向与最近的相邻bin为bin0,这两者之间的夹角为a.这该像素点O处存储的梯度幅值第1通道为A<em>(1-a),第2通道为A</em>a;该像素点O处存储的角度第1通道为0(bin的序号为0)，第2通道为1(bin的序号为1)。
另外在计算图像的梯度图和相位图时，如果该图像时3通道的，则3通道分别取梯度值，并且取梯度最大的那个通道的值为该点的梯度幅值。</p>
<h4
id="统计每个cell的梯度直方图不同梯度的个数即可形成每个cell的descriptor">统计每个cell的梯度直方图（不同梯度的个数），即可形成每个cell的descriptor；</h4>
<h4
id="将每几个cell组成一个block例如22个cellblock">将每几个cell组成一个block（例如2*2个cell/block）</h4>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/cell2block.png"
alt="@cell与block之间的关系" />，一个block内所有cell的特征descriptor串联起来便得到该block的HOG特征descriptor。这个在OpenCV中有HogCache中getBlock进行实现的。
如图所示，黑色框代表1个block，红实线隔开的为4个cell，每个cell用绿色虚线隔开的我们称之为4个区域，所以该block中共有16个区域，分别为A、B、C、…、O、P。
将这16个区域分为4组：
第1组：A、D、M、P;该组内的像素点计算梯度方向直方图时只对其所在的cell有贡献。
第2组：B、C、N、O;该组内的像素点计算梯度直方图时对其所在的左右cell有贡献。
第3组：E、I、H、L;该组内的像素点计算梯度直方图时对其所在的上下cell有贡献。
第4组：F、G、J、K;该组内的像素点对其上下左右的cell计算梯度直方图时都有贡献。</p>
<p>那到底是怎么对cell贡献的呢？举个例子来说，E区域内的像素点对cell0和cell2有贡献。本来1个block对滑动窗口贡献的向量维数为36维，即每个cell贡献9维，其顺序分别为cell0,cell1,cell2,cell3.而E区域内的像素由于同时对cell0和cell2有贡献，所以在计算E区域内的像素梯度投票时，不仅要投向它本来的cell0，还要投向下面的cell2，即投向cell0和cell2有一个权重，该权重与该像素点所在位置与cell0，cell2中心位置的距离有关。具体的关系可以去查看源码。</p>
<h4
id="将图像image内的所有block的hog特征descriptor串联起来就可以得到该image你要检测的目标的hog特征descriptor了这个就是最终的可供分类使用的特征向量了">将图像image内的所有block的HOG特征descriptor串联起来就可以得到该image（你要检测的目标）的HOG特征descriptor了。这个就是最终的可供分类使用的特征向量了。</h4>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/cell-block-window-image.png"
alt="@HOG算法名词之间的关系结构图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="HOG算法名词之间的关系结构图">@HOG算法名词之间的关系结构图</span></figcaption>
</figure>
<blockquote>
<p>实际实现的时候，首先用[-1,0,1]梯度算子对原图像做卷积运算，得到x方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用[1,0,-1]T梯度算子对原图像做卷积运算，得到y方向（竖直方向，以向上为正方向）的梯度分量gradscaly。然后再用以上公式计算该像素点的梯度大小和方向。</p>
</blockquote>
<h2 id="hog源码分析">HOG源码分析</h2>
<p>在读源码时，由于里面用到了intel的ipp库，优化了算法的速度。为了学习方便，我对OpenCV中关于加速的
部分进行了删减，只剩下算法的精要部分。 <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/opencv-hog.png"
alt="@OpenCV中关于HogDescriptor的实现" /></p>
<pre><code>头文件中有关于一些参数的默认设置：
检测窗口大小为128*64;
Block大小为16*16；
Cell大小为8*8；
Block在检测窗口中上下移动尺寸为8*8；
1个cell的梯度直方图化成9个bin；
滑动窗口在检测图片中滑动的尺寸为8*8；</code></pre>
<h3 id="头文件">头文件</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//HOG (Histogram-of-Oriented-Gradients) Descriptor and Object Detector //</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//! struct for detection region of interest (ROI)</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">DetectionROI</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="comment">//! scale(size) of the bounding box</span></span><br><span class="line">   <span class="type">double</span> scale;</span><br><span class="line">   <span class="comment">//! set of requrested locations to be evaluated</span></span><br><span class="line">   std::vector&lt;cv::Point&gt; locations;</span><br><span class="line">   <span class="comment">//! vector that will contain confidence values for each location</span></span><br><span class="line">   std::vector&lt;<span class="type">double</span>&gt; confidences;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">HOGDescriptor</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">enum</span> &#123; L2Hys = <span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">enum</span> &#123; DEFAULT_NLEVELS = <span class="number">64</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">HOGDescriptor</span>() : <span class="built_in">winSize</span>(<span class="number">64</span>,<span class="number">128</span>), <span class="built_in">blockSize</span>(<span class="number">16</span>,<span class="number">16</span>), <span class="built_in">blockStride</span>(<span class="number">8</span>,<span class="number">8</span>),</span><br><span class="line">        <span class="built_in">cellSize</span>(<span class="number">8</span>,<span class="number">8</span>), <span class="built_in">nbins</span>(<span class="number">9</span>), <span class="built_in">derivAperture</span>(<span class="number">1</span>), <span class="built_in">winSigma</span>(<span class="number">-1</span>),</span><br><span class="line">        <span class="built_in">histogramNormType</span>(HOGDescriptor::L2Hys), <span class="built_in">L2HysThreshold</span>(<span class="number">0.2</span>), <span class="built_in">gammaCorrection</span>(<span class="literal">true</span>),</span><br><span class="line">        <span class="built_in">free_coef</span>(<span class="number">-1.f</span>), <span class="built_in">nlevels</span>(HOGDescriptor::DEFAULT_NLEVELS), <span class="built_in">signedGradient</span>(<span class="literal">false</span>)</span><br><span class="line">    &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//! with found weights output</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">detect</span><span class="params">(<span class="type">const</span> Mat&amp; img, std::vector&lt;Point&gt;&amp; foundLocations,</span></span></span><br><span class="line"><span class="params"><span class="function">                        std::vector&lt;<span class="type">double</span>&gt;&amp; weights,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">double</span> hitThreshold = <span class="number">0</span>, Size winStride = Size(),</span></span></span><br><span class="line"><span class="params"><span class="function">                        Size padding = Size(),</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">const</span> std::vector&lt;Point&gt;&amp; searchLocations = std::vector&lt;Point&gt;())</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="comment">//! without found weights output</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">detect</span><span class="params">(<span class="type">const</span> Mat&amp; img, std::vector&lt;Point&gt;&amp; foundLocations,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">double</span> hitThreshold = <span class="number">0</span>, Size winStride = Size(),</span></span></span><br><span class="line"><span class="params"><span class="function">                        Size padding = Size(),</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">const</span> std::vector&lt;Point&gt;&amp; searchLocations=std::vector&lt;Point&gt;())</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//! with result weights output</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">detectMultiScale</span><span class="params">(InputArray img, std::vector&lt;Rect&gt;&amp; foundLocations,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  std::vector&lt;<span class="type">double</span>&gt;&amp; foundWeights, <span class="type">double</span> hitThreshold = <span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  Size winStride = Size(), Size padding = Size(), <span class="type">double</span> scale = <span class="number">1.05</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  <span class="type">double</span> finalThreshold = <span class="number">2.0</span>,<span class="type">bool</span> useMeanshiftGrouping = <span class="literal">false</span>)</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="comment">//! without found weights output</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">detectMultiScale</span><span class="params">(InputArray img, std::vector&lt;Rect&gt;&amp; foundLocations,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  <span class="type">double</span> hitThreshold = <span class="number">0</span>, Size winStride = Size(),</span></span></span><br><span class="line"><span class="params"><span class="function">                                  Size padding = Size(), <span class="type">double</span> scale = <span class="number">1.05</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  <span class="type">double</span> finalThreshold = <span class="number">2.0</span>, <span class="type">bool</span> useMeanshiftGrouping = <span class="literal">false</span>)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">computeGradient</span><span class="params">(<span class="type">const</span> Mat&amp; img, Mat&amp; grad, Mat&amp; angleOfs,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 Size paddingTL = Size(), Size paddingBR = Size())</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">static</span> std::vector&lt;<span class="type">float</span>&gt; <span class="title">getDefaultPeopleDetector</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">static</span> std::vector&lt;<span class="type">float</span>&gt; <span class="title">getDaimlerPeopleDetector</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    Size winSize;		<span class="comment">// 窗口大小 64x128</span></span><br><span class="line">    Size blockSize;		<span class="comment">// block size 16x16</span></span><br><span class="line">    Size blockStride;	<span class="comment">// block 之间的stride</span></span><br><span class="line">    Size cellSize;		<span class="comment">// cell的size</span></span><br><span class="line">    <span class="type">int</span> nbins;			<span class="comment">// </span></span><br><span class="line">    <span class="type">int</span> derivAperture;	<span class="comment">//</span></span><br><span class="line">    <span class="type">double</span> winSigma;</span><br><span class="line">    <span class="type">int</span> histogramNormType;</span><br><span class="line">    <span class="type">double</span> L2HysThreshold;</span><br><span class="line">    <span class="type">bool</span> gammaCorrection;</span><br><span class="line">    std::vector&lt;<span class="type">float</span>&gt; svmDetector;</span><br><span class="line">    UMat oclSvmDetector;</span><br><span class="line">    <span class="type">float</span> free_coef;</span><br><span class="line">    <span class="type">int</span> nlevels;</span><br><span class="line">    <span class="type">bool</span> signedGradient;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//! evaluate specified ROI and return confidence value for each location</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">detectROI</span><span class="params">(<span class="type">const</span> cv::Mat&amp; img, <span class="type">const</span> std::vector&lt;cv::Point&gt; &amp;locations,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   std::vector&lt;cv::Point&gt;&amp; foundLocations, std::vector&lt;<span class="type">double</span>&gt;&amp; confidences,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   <span class="type">double</span> hitThreshold = <span class="number">0</span>, cv::Size winStride = Size(),</span></span></span><br><span class="line"><span class="params"><span class="function">                                   cv::Size padding = Size())</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//! evaluate specified ROI and return confidence value for each location in multiple scales</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">detectMultiScaleROI</span><span class="params">(<span class="type">const</span> cv::Mat&amp; img,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                       std::vector&lt;cv::Rect&gt;&amp; foundLocations,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                       std::vector&lt;DetectionROI&gt;&amp; locations,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                       <span class="type">double</span> hitThreshold = <span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                       <span class="type">int</span> groupThreshold = <span class="number">0</span>)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//! @&#125; objdetect</span></span><br></pre></td></tr></table></figure>
<h2 id="源文件">源文件</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cascadedetect.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;opencv2/core/core_c.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;opencl_kernels_objdetect.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iterator&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;limits&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/****************************************************************************************\</span></span><br><span class="line"><span class="comment">      The code below is implementation of HOG (Histogram-of-Oriented Gradients)</span></span><br><span class="line"><span class="comment">      descriptor and object detection, introduced by Navneet Dalal and Bill Triggs.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">      The computed feature vectors are compatible with the</span></span><br><span class="line"><span class="comment">      INRIA Object Detection and Localization Toolkit</span></span><br><span class="line"><span class="comment">      (http://pascal.inrialpes.fr/soft/olt/)</span></span><br><span class="line"><span class="comment">\****************************************************************************************/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> cv</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NTHREADS 256</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> &#123;DESCR_FORMAT_COL_BY_COL, DESCR_FORMAT_ROW_BY_ROW&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">numPartsWithin</span><span class="params">(<span class="type">int</span> size, <span class="type">int</span> part_size, <span class="type">int</span> stride)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (size - part_size + stride) / stride;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> Size <span class="title">numPartsWithin</span><span class="params">(cv::Size size, cv::Size part_size,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                cv::Size stride)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Size</span>(<span class="built_in">numPartsWithin</span>(size.width, part_size.width, stride.width),</span><br><span class="line">        <span class="built_in">numPartsWithin</span>(size.height, part_size.height, stride.height));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">size_t</span> <span class="title">getBlockHistogramSize</span><span class="params">(Size block_size, Size cell_size, <span class="type">int</span> nbins)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Size cells_per_block = <span class="built_in">Size</span>(block_size.width / cell_size.width,</span><br><span class="line">        block_size.height / cell_size.height);</span><br><span class="line">    <span class="keyword">return</span> (<span class="type">size_t</span>)(nbins * cells_per_block.<span class="built_in">area</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">size_t</span> <span class="title">HOGDescriptor::getDescriptorSize</span><span class="params">()</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_Assert</span>(blockSize.width % cellSize.width == <span class="number">0</span> &amp;&amp;</span><br><span class="line">        blockSize.height % cellSize.height == <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">CV_Assert</span>((winSize.width - blockSize.width) % blockStride.width == <span class="number">0</span> &amp;&amp;</span><br><span class="line">        (winSize.height - blockSize.height) % blockStride.height == <span class="number">0</span> );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (<span class="type">size_t</span>)nbins*</span><br><span class="line">        (blockSize.width/cellSize.width)*</span><br><span class="line">        (blockSize.height/cellSize.height)*</span><br><span class="line">        ((winSize.width - blockSize.width)/blockStride.width + <span class="number">1</span>)*</span><br><span class="line">        ((winSize.height - blockSize.height)/blockStride.height + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">HOGDescriptor::getWinSigma</span><span class="params">()</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> winSigma &gt;= <span class="number">0</span> ? winSigma : (blockSize.width + blockSize.height)/<span class="number">8.</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">HOGDescriptor::checkDetectorSize</span><span class="params">()</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">size_t</span> detectorSize = svmDetector.<span class="built_in">size</span>(), descriptorSize = <span class="built_in">getDescriptorSize</span>();</span><br><span class="line">    <span class="keyword">return</span> detectorSize == <span class="number">0</span> ||</span><br><span class="line">        detectorSize == descriptorSize ||</span><br><span class="line">        detectorSize == descriptorSize + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::setSVMDetector</span><span class="params">(InputArray _svmDetector)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    _svmDetector.<span class="built_in">getMat</span>().<span class="built_in">convertTo</span>(svmDetector, CV_32F);</span><br><span class="line">    <span class="built_in">CV_Assert</span>(<span class="built_in">checkDetectorSize</span>());</span><br><span class="line"></span><br><span class="line">    <span class="function">Mat <span class="title">detector_reordered</span><span class="params">(<span class="number">1</span>, (<span class="type">int</span>)svmDetector.size(), CV_32FC1)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> block_hist_size = <span class="built_in">getBlockHistogramSize</span>(blockSize, cellSize, nbins);</span><br><span class="line">    cv::Size blocks_per_img = <span class="built_in">numPartsWithin</span>(winSize, blockSize, blockStride);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; blocks_per_img.height; ++i)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; blocks_per_img.width; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">const</span> <span class="type">float</span> *src = &amp;svmDetector[<span class="number">0</span>] + (j * blocks_per_img.height + i) * block_hist_size;</span><br><span class="line">            <span class="type">float</span> *dst = detector_reordered.<span class="built_in">ptr</span>&lt;<span class="type">float</span>&gt;() + (i * blocks_per_img.width + j) * block_hist_size;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">size_t</span> k = <span class="number">0</span>; k &lt; block_hist_size; ++k)</span><br><span class="line">                dst[k] = src[k];</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="type">size_t</span> descriptor_size = <span class="built_in">getDescriptorSize</span>();</span><br><span class="line">    free_coef = svmDetector.<span class="built_in">size</span>() &gt; descriptor_size ? svmDetector[descriptor_size] : <span class="number">0</span>;</span><br><span class="line">    detector_reordered.<span class="built_in">copyTo</span>(oclSvmDetector);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CV_TYPE_NAME_HOG_DESCRIPTOR <span class="string">&quot;opencv-object-detector-hog&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// @img [input] 计算图像img</span></span><br><span class="line"><span class="comment">// @grad [output] 梯度幅度图像`grad`</span></span><br><span class="line"><span class="comment">// @qangle [output] 梯度方向图像`qangle`.</span></span><br><span class="line"><span class="comment">// @paddingTL为需要在原图像img左上角扩增的尺寸，同理paddingBR</span></span><br><span class="line"><span class="comment">// @paddingBR 为需要在img图像右下角扩增的尺寸。</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::computeGradient</span><span class="params">(<span class="type">const</span> Mat&amp; img, Mat&amp; grad, Mat&amp; qangle,</span></span></span><br><span class="line"><span class="params"><span class="function">    Size paddingTL, Size paddingBR)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_INSTRUMENT_REGION</span>()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CV_Assert</span>( img.<span class="built_in">type</span>() == CV_8U || img.<span class="built_in">type</span>() == CV_8UC3 );</span><br><span class="line">    <span class="comment">// padding之后的输出大小</span></span><br><span class="line">    <span class="function">Size <span class="title">gradsize</span><span class="params">(img.cols + paddingTL.width + paddingBR.width,</span></span></span><br><span class="line"><span class="params"><span class="function">        img.rows + paddingTL.height + paddingBR.height)</span></span>;</span><br><span class="line">    grad.<span class="built_in">create</span>(gradsize, CV_32FC2);  <span class="comment">// &lt;magnitude*(1-alpha), magnitude*alpha&gt;</span></span><br><span class="line">    qangle.<span class="built_in">create</span>(gradsize, CV_8UC2); <span class="comment">// [0..nbins-1] - quantized gradient orientation</span></span><br><span class="line"></span><br><span class="line">    Size wholeSize;</span><br><span class="line">    Point roiofs;</span><br><span class="line">    img.<span class="built_in">locateROI</span>(wholeSize, roiofs);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> i, x, y;</span><br><span class="line">    <span class="type">int</span> cn = img.<span class="built_in">channels</span>();</span><br><span class="line"></span><br><span class="line">    Mat_&lt;<span class="type">float</span>&gt; _lut(<span class="number">1</span>, <span class="number">256</span>);</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> lut = &amp;_lut(<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( gammaCorrection )</span><br><span class="line">        <span class="keyword">for</span>( i = <span class="number">0</span>; i &lt; <span class="number">256</span>; i++ )</span><br><span class="line">            _lut(<span class="number">0</span>,i) = std::<span class="built_in">sqrt</span>((<span class="type">float</span>)i);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">for</span>( i = <span class="number">0</span>; i &lt; <span class="number">256</span>; i++ )</span><br><span class="line">            _lut(<span class="number">0</span>,i) = (<span class="type">float</span>)i;</span><br><span class="line"></span><br><span class="line">    <span class="function">AutoBuffer&lt;<span class="type">int</span>&gt; <span class="title">mapbuf</span><span class="params">(gradsize.width + gradsize.height + <span class="number">4</span>)</span></span>;</span><br><span class="line">    <span class="type">int</span>* xmap = (<span class="type">int</span>*)mapbuf + <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span>* ymap = xmap + gradsize.width + <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> borderType = (<span class="type">int</span>)BORDER_REFLECT_101;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>( x = <span class="number">-1</span>; x &lt; gradsize.width + <span class="number">1</span>; x++ )</span><br><span class="line">        xmap[x] = <span class="built_in">borderInterpolate</span>(x - paddingTL.width + roiofs.x,</span><br><span class="line">        wholeSize.width, borderType) - roiofs.x;</span><br><span class="line">    <span class="keyword">for</span>( y = <span class="number">-1</span>; y &lt; gradsize.height + <span class="number">1</span>; y++ )</span><br><span class="line">        ymap[y] = <span class="built_in">borderInterpolate</span>(y - paddingTL.height + roiofs.y,</span><br><span class="line">        wholeSize.height, borderType) - roiofs.y;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// x- &amp; y- derivatives for the whole row</span></span><br><span class="line">    <span class="type">int</span> width = gradsize.width;</span><br><span class="line">    AutoBuffer&lt;<span class="type">float</span>&gt; _dbuf(width*<span class="number">4</span>);</span><br><span class="line">    <span class="type">float</span>* <span class="type">const</span> dbuf = _dbuf;</span><br><span class="line">    <span class="function">Mat <span class="title">Dx</span><span class="params">(<span class="number">1</span>, width, CV_32F, dbuf)</span></span>;</span><br><span class="line">    <span class="function">Mat <span class="title">Dy</span><span class="params">(<span class="number">1</span>, width, CV_32F, dbuf + width)</span></span>;</span><br><span class="line">    <span class="function">Mat <span class="title">Mag</span><span class="params">(<span class="number">1</span>, width, CV_32F, dbuf + width*<span class="number">2</span>)</span></span>;</span><br><span class="line">    <span class="function">Mat <span class="title">Angle</span><span class="params">(<span class="number">1</span>, width, CV_32F, dbuf + width*<span class="number">3</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cn == <span class="number">3</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> end = gradsize.width + <span class="number">2</span>;</span><br><span class="line">        xmap -= <span class="number">1</span>, x = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> ( ; x &lt; end; ++x)</span><br><span class="line">            xmap[x] *= <span class="number">3</span>;</span><br><span class="line">        xmap += <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> angleScale = signedGradient ? (<span class="type">float</span>)(nbins/(<span class="number">2.0</span>*CV_PI)) : (<span class="type">float</span>)(nbins/CV_PI);</span><br><span class="line">    <span class="keyword">for</span>( y = <span class="number">0</span>; y &lt; gradsize.height; y++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">const</span> uchar* imgPtr  = img.<span class="built_in">ptr</span>(ymap[y]);</span><br><span class="line">        <span class="comment">//In case subimage is used ptr() generates an assert for next and prev rows</span></span><br><span class="line">        <span class="comment">//(see http://code.opencv.org/issues/4149)</span></span><br><span class="line">        <span class="type">const</span> uchar* prevPtr = img.data + img.step*ymap[y<span class="number">-1</span>];</span><br><span class="line">        <span class="type">const</span> uchar* nextPtr = img.data + img.step*ymap[y+<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="type">float</span>* gradPtr = grad.<span class="built_in">ptr</span>&lt;<span class="type">float</span>&gt;(y);</span><br><span class="line">        uchar* qanglePtr = qangle.<span class="built_in">ptr</span>(y);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>( cn == <span class="number">1</span> )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>( x = <span class="number">0</span>; x &lt; width; x++ )</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> x1 = xmap[x];</span><br><span class="line">                dbuf[x] = (<span class="type">float</span>)(lut[imgPtr[xmap[x+<span class="number">1</span>]]] - lut[imgPtr[xmap[x<span class="number">-1</span>]]]);</span><br><span class="line">                dbuf[width + x] = (<span class="type">float</span>)(lut[nextPtr[x1]] - lut[prevPtr[x1]]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            x = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>( ; x &lt; width; x++ )</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> x1 = xmap[x];</span><br><span class="line">                <span class="type">float</span> dx0, dy0, dx, dy, mag0, mag;</span><br><span class="line">                <span class="type">const</span> uchar* p2 = imgPtr + xmap[x+<span class="number">1</span>];</span><br><span class="line">                <span class="type">const</span> uchar* p0 = imgPtr + xmap[x<span class="number">-1</span>];</span><br><span class="line"></span><br><span class="line">                dx0 = lut[p2[<span class="number">2</span>]] - lut[p0[<span class="number">2</span>]];</span><br><span class="line">                dy0 = lut[nextPtr[x1+<span class="number">2</span>]] - lut[prevPtr[x1+<span class="number">2</span>]];</span><br><span class="line">                mag0 = dx0*dx0 + dy0*dy0;</span><br><span class="line"></span><br><span class="line">                dx = lut[p2[<span class="number">1</span>]] - lut[p0[<span class="number">1</span>]];</span><br><span class="line">                dy = lut[nextPtr[x1+<span class="number">1</span>]] - lut[prevPtr[x1+<span class="number">1</span>]];</span><br><span class="line">                mag = dx*dx + dy*dy;</span><br><span class="line">                <span class="keyword">if</span>( mag0 &lt; mag )</span><br><span class="line">                &#123;</span><br><span class="line">                    dx0 = dx;</span><br><span class="line">                    dy0 = dy;</span><br><span class="line">                    mag0 = mag;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                dx = lut[p2[<span class="number">0</span>]] - lut[p0[<span class="number">0</span>]];</span><br><span class="line">                dy = lut[nextPtr[x1]] - lut[prevPtr[x1]];</span><br><span class="line">                mag = dx*dx + dy*dy;</span><br><span class="line">                <span class="keyword">if</span>( mag0 &lt; mag )</span><br><span class="line">                &#123;</span><br><span class="line">                    dx0 = dx;</span><br><span class="line">                    dy0 = dy;</span><br><span class="line">                    mag0 = mag;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                dbuf[x] = dx0;</span><br><span class="line">                dbuf[x+width] = dy0;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// computing angles and magnidutes</span></span><br><span class="line">        <span class="built_in">cartToPolar</span>( Dx, Dy, Mag, Angle, <span class="literal">false</span> );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// filling the result matrix</span></span><br><span class="line">        x = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>( ; x &lt; width; x++ )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">float</span> mag = dbuf[x+width*<span class="number">2</span>], angle = dbuf[x+width*<span class="number">3</span>]*angleScale - <span class="number">0.5f</span>;</span><br><span class="line">            <span class="type">int</span> hidx = <span class="built_in">cvFloor</span>(angle);</span><br><span class="line">            angle -= hidx;</span><br><span class="line">            gradPtr[x*<span class="number">2</span>] = mag*(<span class="number">1.f</span> - angle);</span><br><span class="line">            gradPtr[x*<span class="number">2</span>+<span class="number">1</span>] = mag*angle;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>( hidx &lt; <span class="number">0</span> )</span><br><span class="line">                hidx += nbins;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>( hidx &gt;= nbins )</span><br><span class="line">                hidx -= nbins;</span><br><span class="line"></span><br><span class="line">            <span class="built_in">CV_Assert</span>( (<span class="type">unsigned</span>)hidx &lt; (<span class="type">unsigned</span>)nbins );</span><br><span class="line"></span><br><span class="line">            qanglePtr[x*<span class="number">2</span>] = (uchar)hidx;</span><br><span class="line">            hidx++;</span><br><span class="line">            hidx &amp;= hidx &lt; nbins ? <span class="number">-1</span> : <span class="number">0</span>;</span><br><span class="line">            qanglePtr[x*<span class="number">2</span>+<span class="number">1</span>] = (uchar)hidx;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">HOGCache</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">// 1个BlockData结构体是对应的一个block数据。</span></span><br><span class="line">	<span class="comment">// 其中histOfs表示为该block对整个滑动窗口内hog描述算子的贡献那部分向量的起始位置；</span></span><br><span class="line">	<span class="comment">// imgOffset为该block在滑动窗口图片中的坐标(当然是指左上角坐标)</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">BlockData</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">BlockData</span>() :</span><br><span class="line">            <span class="built_in">histOfs</span>(<span class="number">0</span>), <span class="built_in">imgOffset</span>()</span><br><span class="line">        &#123; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> histOfs;</span><br><span class="line">        Point imgOffset;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// PixData结构体是对应的block中1个像素点的数据。</span></span><br><span class="line">    <span class="comment">// 其中gradOfs表示该点的梯度幅度在滑动窗口图片梯度幅度图中的位置坐标；</span></span><br><span class="line">    <span class="comment">// qangleOfs表示该点的梯度角度在滑动窗口图片梯度角度图中的位置坐标；</span></span><br><span class="line">    <span class="comment">// histOfs[]表示该像素点对1个或2个或4个cell贡献的hog描述子向量的起始位置坐标（比较抽象，需要看源码才懂）。</span></span><br><span class="line">    <span class="comment">// histWeight[]表示该像素点对1个或2个或4个cell贡献的权重。</span></span><br><span class="line">    <span class="comment">// gradWeight表示该点本身由于处在block中位置的不同因而对梯度直方图贡献也不同，其权值按照二维高斯分布(以block中心为二维高斯的中心)来决定。</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">PixData</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">size_t</span> gradOfs, qangleOfs;</span><br><span class="line">        <span class="type">int</span> histOfs[<span class="number">4</span>];</span><br><span class="line">        <span class="type">float</span> histWeights[<span class="number">4</span>];</span><br><span class="line">        <span class="type">float</span> gradWeight;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">HOGCache</span>();</span><br><span class="line">    <span class="built_in">HOGCache</span>(<span class="type">const</span> HOGDescriptor* descriptor,</span><br><span class="line">        <span class="type">const</span> Mat&amp; img, <span class="type">const</span> Size&amp; paddingTL, <span class="type">const</span> Size&amp; paddingBR,</span><br><span class="line">        <span class="type">bool</span> useCache, <span class="type">const</span> Size&amp; cacheStride);</span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">HOGCache</span>() &#123; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">init</span><span class="params">(<span class="type">const</span> HOGDescriptor* descriptor,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> Mat&amp; img, <span class="type">const</span> Size&amp; paddingTL, <span class="type">const</span> Size&amp; paddingBR,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">bool</span> useCache, <span class="type">const</span> Size&amp; cacheStride)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">Size <span class="title">windowsInImage</span><span class="params">(<span class="type">const</span> Size&amp; imageSize, <span class="type">const</span> Size&amp; winStride)</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function">Rect <span class="title">getWindow</span><span class="params">(<span class="type">const</span> Size&amp; imageSize, <span class="type">const</span> Size&amp; winStride, <span class="type">int</span> idx)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">const</span> <span class="type">float</span>* <span class="title">getBlock</span><span class="params">(Point pt, <span class="type">float</span>* buf)</span></span>;</span><br><span class="line">    <span class="comment">// 指对block获取到的hog部分描述子进行归一化，其实该归一化有2层，具体看代码。</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">normalizeBlockHistogram</span><span class="params">(<span class="type">float</span>* histogram)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;PixData&gt; pixData;</span><br><span class="line">    std::vector&lt;BlockData&gt; blockData;</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> useCache;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; ymaxCached;</span><br><span class="line">    Size winSize;</span><br><span class="line">    Size cacheStride;</span><br><span class="line">    Size nblocks, ncells;</span><br><span class="line">    <span class="type">int</span> blockHistogramSize;</span><br><span class="line">    <span class="type">int</span> count1, count2, count4;</span><br><span class="line">    Point imgoffset;</span><br><span class="line">    Mat_&lt;<span class="type">float</span>&gt; blockCache;</span><br><span class="line">    Mat_&lt;uchar&gt; blockCacheFlags;</span><br><span class="line"></span><br><span class="line">    Mat grad, qangle;</span><br><span class="line">    <span class="type">const</span> HOGDescriptor* descriptor;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">HOGCache::<span class="built_in">HOGCache</span>() :</span><br><span class="line">    <span class="built_in">blockHistogramSize</span>(), <span class="built_in">count1</span>(), <span class="built_in">count2</span>(), <span class="built_in">count4</span>()</span><br><span class="line">&#123;</span><br><span class="line">    useCache = <span class="literal">false</span>;</span><br><span class="line">    descriptor = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">HOGCache::<span class="built_in">HOGCache</span>(<span class="type">const</span> HOGDescriptor* _descriptor,</span><br><span class="line">    <span class="type">const</span> Mat&amp; _img, <span class="type">const</span> Size&amp; _paddingTL, <span class="type">const</span> Size&amp; _paddingBR,</span><br><span class="line">    <span class="type">bool</span> _useCache, <span class="type">const</span> Size&amp; _cacheStride)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">init</span>(_descriptor, _img, _paddingTL, _paddingBR, _useCache, _cacheStride);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGCache::init</span><span class="params">(<span class="type">const</span> HOGDescriptor* _descriptor,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> Mat&amp; _img, <span class="type">const</span> Size&amp; _paddingTL, <span class="type">const</span> Size&amp; _paddingBR,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">bool</span> _useCache, <span class="type">const</span> Size&amp; _cacheStride)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    descriptor = _descriptor;</span><br><span class="line">    cacheStride = _cacheStride;</span><br><span class="line">    useCache = _useCache;</span><br><span class="line">    <span class="comment">// 计算输入图像的权值梯度幅度图和角度量化图</span></span><br><span class="line">    descriptor-&gt;<span class="built_in">computeGradient</span>(_img, grad, qangle, _paddingTL, _paddingBR);</span><br><span class="line">    imgoffset = _paddingTL;</span><br><span class="line"></span><br><span class="line">    winSize = descriptor-&gt;winSize;</span><br><span class="line">    Size blockSize = descriptor-&gt;blockSize;</span><br><span class="line">    Size blockStride = descriptor-&gt;blockStride;</span><br><span class="line">    Size cellSize = descriptor-&gt;cellSize;</span><br><span class="line">    <span class="type">int</span> i, j, nbins = descriptor-&gt;nbins;</span><br><span class="line">    <span class="comment">// rawBlockSize为block中包含像素点的个数</span></span><br><span class="line">    <span class="type">int</span> rawBlockSize = blockSize.width*blockSize.height;</span><br><span class="line">    <span class="comment">// block的数目</span></span><br><span class="line">    nblocks = <span class="built_in">Size</span>((winSize.width - blockSize.width)/blockStride.width + <span class="number">1</span>,</span><br><span class="line">        (winSize.height - blockSize.height)/blockStride.height + <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// cell的数目</span></span><br><span class="line">    ncells = <span class="built_in">Size</span>(blockSize.width/cellSize.width, blockSize.height/cellSize.height);</span><br><span class="line">    <span class="comment">// blockHistogramSize表示一个block中贡献给hog描述子向量的长度</span></span><br><span class="line">    blockHistogramSize = ncells.width*ncells.height*nbins;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( useCache )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">Size <span class="title">cacheSize</span><span class="params">((grad.cols - blockSize.width)/cacheStride.width+<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            (winSize.height/cacheStride.height)+<span class="number">1</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">        blockCache.<span class="built_in">create</span>(cacheSize.height, cacheSize.width*blockHistogramSize);</span><br><span class="line">        blockCacheFlags.<span class="built_in">create</span>(cacheSize);</span><br><span class="line"></span><br><span class="line">        <span class="type">size_t</span> cacheRows = blockCache.rows;</span><br><span class="line">        ymaxCached.<span class="built_in">resize</span>(cacheRows);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">size_t</span> ii = <span class="number">0</span>; ii &lt; cacheRows; ii++ )</span><br><span class="line">            ymaxCached[ii] = <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// weights为一个尺寸为blockSize的二维高斯表,下面的代码就是计算二维高斯的系数</span></span><br><span class="line">    <span class="function">Mat_&lt;<span class="type">float</span>&gt; <span class="title">weights</span><span class="params">(blockSize)</span></span>;</span><br><span class="line">    <span class="type">float</span> sigma = (<span class="type">float</span>)descriptor-&gt;<span class="built_in">getWinSigma</span>();</span><br><span class="line">    <span class="type">float</span> scale = <span class="number">1.f</span>/(sigma*sigma*<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">AutoBuffer&lt;<span class="type">float</span>&gt; <span class="title">di</span><span class="params">(blockSize.height)</span>, <span class="title">dj</span><span class="params">(blockSize.width)</span></span>;</span><br><span class="line">        <span class="type">float</span>* _di = (<span class="type">float</span>*)di, *_dj = (<span class="type">float</span>*)dj;</span><br><span class="line">        <span class="type">float</span> bh = blockSize.height * <span class="number">0.5f</span>, bw = blockSize.width * <span class="number">0.5f</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; blockSize.height; ++i)</span><br><span class="line">        &#123;</span><br><span class="line">            _di[i] = i - bh;</span><br><span class="line">            _di[i] *= _di[i];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>;; j &lt; blockSize.width; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            _dj[j] = j - bw;</span><br><span class="line">            _dj[j] *= _dj[j];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; blockSize.height; i++)</span><br><span class="line">            <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; blockSize.width; j++)</span><br><span class="line">                <span class="built_in">weights</span>(i,j) = std::<span class="built_in">exp</span>(-(_di[i] + _dj[j])*scale);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// vector&lt;BlockData&gt; blockData;而BlockData为HOGCache的一个结构体成员</span></span><br><span class="line">	<span class="comment">// nblocks.width*nblocks.height表示一个检测窗口中block的个数，</span></span><br><span class="line">	<span class="comment">// 而cacheSize.width*cacheSize.heigh表示一个已经扩充的图片中的block的个数</span></span><br><span class="line">    blockData.<span class="built_in">resize</span>(nblocks.width*nblocks.height);</span><br><span class="line">    <span class="comment">// vector&lt;PixData&gt; pixData; 同理，Pixdata也为HOGCache中的一个结构体成员</span></span><br><span class="line">    <span class="comment">// rawBlockSize表示每个block中像素点的个数</span></span><br><span class="line">    <span class="comment">// resize表示将其转换成列向量</span></span><br><span class="line">    <span class="comment">// rawBlockSize*3表示的是存储同时对1个cell，2个cell，4个cell的贡献</span></span><br><span class="line">    pixData.<span class="built_in">resize</span>(rawBlockSize*<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Initialize 2 lookup tables, pixData &amp; blockData.</span></span><br><span class="line">    <span class="comment">// Here is why:</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// The detection algorithm runs in 4 nested loops (at each pyramid layer):</span></span><br><span class="line">    <span class="comment">//  loop over the windows within the input image</span></span><br><span class="line">    <span class="comment">//    loop over the blocks within each window</span></span><br><span class="line">    <span class="comment">//      loop over the cells within each block</span></span><br><span class="line">    <span class="comment">//        loop over the pixels in each cell</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// As each of the loops runs over a 2-dimensional array,</span></span><br><span class="line">    <span class="comment">// we could get 8(!) nested loops in total, which is very-very slow.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// To speed the things up, we do the following:</span></span><br><span class="line">    <span class="comment">//   1. loop over windows is unrolled in the HOGDescriptor::&#123;compute|detect&#125; methods;</span></span><br><span class="line">    <span class="comment">//         inside we compute the current search window using getWindow() method.</span></span><br><span class="line">    <span class="comment">//         Yes, it involves some overhead (function call + couple of divisions),</span></span><br><span class="line">    <span class="comment">//         but it&#x27;s tiny in fact.</span></span><br><span class="line">    <span class="comment">//   2. loop over the blocks is also unrolled. Inside we use **pre-computed** blockData[j]</span></span><br><span class="line">    <span class="comment">//         to set up gradient and histogram pointers.</span></span><br><span class="line">    <span class="comment">//   3. loops over cells and pixels in each cell are merged</span></span><br><span class="line">    <span class="comment">//       (since there is no overlap between cells, each pixel in the block is processed once)</span></span><br><span class="line">    <span class="comment">//      and also unrolled. Inside we use PixData[k] to access the gradient values and</span></span><br><span class="line">    <span class="comment">//      update the histogram</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// count1, count2, count4分别表示block中同时对1个cell，2个cell，4个cell有贡献的像素点的个数。</span></span><br><span class="line">    count1 = count2 = count4 = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; blockSize.width; j++ )</span><br><span class="line">        <span class="keyword">for</span>( i = <span class="number">0</span>; i &lt; blockSize.height; i++ )</span><br><span class="line">        &#123;</span><br><span class="line">            PixData* data = <span class="number">0</span>;</span><br><span class="line">            <span class="type">float</span> cellX = (j+<span class="number">0.5f</span>)/cellSize.width - <span class="number">0.5f</span>;</span><br><span class="line">            <span class="type">float</span> cellY = (i+<span class="number">0.5f</span>)/cellSize.height - <span class="number">0.5f</span>;</span><br><span class="line">            <span class="type">int</span> icellX0 = <span class="built_in">cvFloor</span>(cellX);</span><br><span class="line">            <span class="type">int</span> icellY0 = <span class="built_in">cvFloor</span>(cellY);</span><br><span class="line">            <span class="type">int</span> icellX1 = icellX0 + <span class="number">1</span>, icellY1 = icellY0 + <span class="number">1</span>;</span><br><span class="line">            cellX -= icellX0;</span><br><span class="line">            cellY -= icellY0;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>( (<span class="type">unsigned</span>)icellX0 &lt; (<span class="type">unsigned</span>)ncells.width &amp;&amp;</span><br><span class="line">               (<span class="type">unsigned</span>)icellX1 &lt; (<span class="type">unsigned</span>)ncells.width )</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>( (<span class="type">unsigned</span>)icellY0 &lt; (<span class="type">unsigned</span>)ncells.height &amp;&amp;</span><br><span class="line">                   (<span class="type">unsigned</span>)icellY1 &lt; (<span class="type">unsigned</span>)ncells.height )</span><br><span class="line">                &#123;</span><br><span class="line">                    data = &amp;pixData[rawBlockSize*<span class="number">2</span> + (count4++)];</span><br><span class="line">                    data-&gt;histOfs[<span class="number">0</span>] = (icellX0*ncells.height + icellY0)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">0</span>] = (<span class="number">1.f</span> - cellX)*(<span class="number">1.f</span> - cellY);</span><br><span class="line">                    data-&gt;histOfs[<span class="number">1</span>] = (icellX1*ncells.height + icellY0)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">1</span>] = cellX*(<span class="number">1.f</span> - cellY);</span><br><span class="line">                    data-&gt;histOfs[<span class="number">2</span>] = (icellX0*ncells.height + icellY1)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">2</span>] = (<span class="number">1.f</span> - cellX)*cellY;</span><br><span class="line">                    data-&gt;histOfs[<span class="number">3</span>] = (icellX1*ncells.height + icellY1)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">3</span>] = cellX*cellY;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                &#123;</span><br><span class="line">                    data = &amp;pixData[rawBlockSize + (count2++)];</span><br><span class="line">                    <span class="keyword">if</span>( (<span class="type">unsigned</span>)icellY0 &lt; (<span class="type">unsigned</span>)ncells.height )</span><br><span class="line">                    &#123;</span><br><span class="line">                        icellY1 = icellY0;</span><br><span class="line">                        cellY = <span class="number">1.f</span> - cellY;</span><br><span class="line">                    &#125;</span><br><span class="line">                    data-&gt;histOfs[<span class="number">0</span>] = (icellX0*ncells.height + icellY1)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">0</span>] = (<span class="number">1.f</span> - cellX)*cellY;</span><br><span class="line">                    data-&gt;histOfs[<span class="number">1</span>] = (icellX1*ncells.height + icellY1)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">1</span>] = cellX*cellY;</span><br><span class="line">                    data-&gt;histOfs[<span class="number">2</span>] = data-&gt;histOfs[<span class="number">3</span>] = <span class="number">0</span>;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">2</span>] = data-&gt;histWeights[<span class="number">3</span>] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>( (<span class="type">unsigned</span>)icellX0 &lt; (<span class="type">unsigned</span>)ncells.width )</span><br><span class="line">                &#123;</span><br><span class="line">                    icellX1 = icellX0;</span><br><span class="line">                    cellX = <span class="number">1.f</span> - cellX;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>( (<span class="type">unsigned</span>)icellY0 &lt; (<span class="type">unsigned</span>)ncells.height &amp;&amp;</span><br><span class="line">                   (<span class="type">unsigned</span>)icellY1 &lt; (<span class="type">unsigned</span>)ncells.height )</span><br><span class="line">                &#123;</span><br><span class="line">                    data = &amp;pixData[rawBlockSize + (count2++)];</span><br><span class="line">                    data-&gt;histOfs[<span class="number">0</span>] = (icellX1*ncells.height + icellY0)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">0</span>] = cellX*(<span class="number">1.f</span> - cellY);</span><br><span class="line">                    data-&gt;histOfs[<span class="number">1</span>] = (icellX1*ncells.height + icellY1)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">1</span>] = cellX*cellY;</span><br><span class="line">                    data-&gt;histOfs[<span class="number">2</span>] = data-&gt;histOfs[<span class="number">3</span>] = <span class="number">0</span>;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">2</span>] = data-&gt;histWeights[<span class="number">3</span>] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                &#123;</span><br><span class="line">                    data = &amp;pixData[count1++];</span><br><span class="line">                    <span class="keyword">if</span>( (<span class="type">unsigned</span>)icellY0 &lt; (<span class="type">unsigned</span>)ncells.height )</span><br><span class="line">                    &#123;</span><br><span class="line">                        icellY1 = icellY0;</span><br><span class="line">                        cellY = <span class="number">1.f</span> - cellY;</span><br><span class="line">                    &#125;</span><br><span class="line">                    data-&gt;histOfs[<span class="number">0</span>] = (icellX1*ncells.height + icellY1)*nbins;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">0</span>] = cellX*cellY;</span><br><span class="line">                    data-&gt;histOfs[<span class="number">1</span>] = data-&gt;histOfs[<span class="number">2</span>] = data-&gt;histOfs[<span class="number">3</span>] = <span class="number">0</span>;</span><br><span class="line">                    data-&gt;histWeights[<span class="number">1</span>] = data-&gt;histWeights[<span class="number">2</span>] = data-&gt;histWeights[<span class="number">3</span>] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            data-&gt;gradOfs = (grad.cols*i + j)*<span class="number">2</span>;</span><br><span class="line">            data-&gt;qangleOfs = (qangle.cols*i + j)*<span class="number">2</span>;</span><br><span class="line">            data-&gt;gradWeight = <span class="built_in">weights</span>(i,j);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">assert</span>( count1 + count2 + count4 == rawBlockSize );</span><br><span class="line">    <span class="comment">// defragment pixData</span></span><br><span class="line">    <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; count2; j++ )</span><br><span class="line">        pixData[j + count1] = pixData[j + rawBlockSize];</span><br><span class="line">    <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; count4; j++ )</span><br><span class="line">        pixData[j + count1 + count2] = pixData[j + rawBlockSize*<span class="number">2</span>];</span><br><span class="line">    count2 += count1;</span><br><span class="line">    count4 += count2;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// initialize blockData</span></span><br><span class="line">    <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; nblocks.width; j++ )</span><br><span class="line">        <span class="keyword">for</span>( i = <span class="number">0</span>; i &lt; nblocks.height; i++ )</span><br><span class="line">        &#123;</span><br><span class="line">            BlockData&amp; data = blockData[j*nblocks.height + i];</span><br><span class="line">            data.histOfs = (j*nblocks.height + i)*blockHistogramSize;</span><br><span class="line">            data.imgOffset = <span class="built_in">Point</span>(j*blockStride.width,i*blockStride.height);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 计算一个block中的特征子</span></span><br><span class="line"><span class="function"><span class="type">const</span> <span class="type">float</span>* <span class="title">HOGCache::getBlock</span><span class="params">(Point pt, <span class="type">float</span>* buf)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">float</span>* blockHist = buf;</span><br><span class="line">    <span class="built_in">assert</span>(descriptor != <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//    Size blockSize = descriptor-&gt;blockSize;</span></span><br><span class="line">    pt += imgoffset;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    CV_Assert( (unsigned)pt.x &lt;= (unsigned)(grad.cols - blockSize.width) &amp;&amp;</span></span><br><span class="line"><span class="comment">//        (unsigned)pt.y &lt;= (unsigned)(grad.rows - blockSize.height) );</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( useCache )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">CV_Assert</span>( pt.x % cacheStride.width == <span class="number">0</span> &amp;&amp;</span><br><span class="line">                   pt.y % cacheStride.height == <span class="number">0</span> );</span><br><span class="line">        <span class="function">Point <span class="title">cacheIdx</span><span class="params">(pt.x/cacheStride.width,</span></span></span><br><span class="line"><span class="params"><span class="function">                       (pt.y/cacheStride.height) % blockCache.rows)</span></span>;</span><br><span class="line">        <span class="keyword">if</span>( pt.y != ymaxCached[cacheIdx.y] )</span><br><span class="line">        &#123;</span><br><span class="line">            Mat_&lt;uchar&gt; cacheRow = blockCacheFlags.<span class="built_in">row</span>(cacheIdx.y);</span><br><span class="line">            cacheRow = (uchar)<span class="number">0</span>;</span><br><span class="line">            ymaxCached[cacheIdx.y] = pt.y;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        blockHist = &amp;blockCache[cacheIdx.y][cacheIdx.x*blockHistogramSize];</span><br><span class="line">        uchar&amp; computedFlag = <span class="built_in">blockCacheFlags</span>(cacheIdx.y, cacheIdx.x);</span><br><span class="line">        <span class="keyword">if</span>( computedFlag != <span class="number">0</span> )</span><br><span class="line">            <span class="keyword">return</span> blockHist;</span><br><span class="line">        computedFlag = (uchar)<span class="number">1</span>; <span class="comment">// set it at once, before actual computing</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> k, C1 = count1, C2 = count2, C4 = count4;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span>* gradPtr = grad.<span class="built_in">ptr</span>&lt;<span class="type">float</span>&gt;(pt.y) + pt.x*<span class="number">2</span>;</span><br><span class="line">    <span class="type">const</span> uchar* qanglePtr = qangle.<span class="built_in">ptr</span>(pt.y) + pt.x*<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    CV_Assert( blockHist != 0 );</span></span><br><span class="line">    <span class="built_in">memset</span>(blockHist, <span class="number">0</span>, <span class="built_in">sizeof</span>(<span class="type">float</span>) * blockHistogramSize);</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> PixData* _pixData = &amp;pixData[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// 统计各个cell中的bin信息</span></span><br><span class="line">    <span class="keyword">for</span>( k = <span class="number">0</span>; k &lt; C1; k++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">const</span> PixData&amp; pk = _pixData[k];</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> a = gradPtr + pk.gradOfs;</span><br><span class="line">        <span class="type">float</span> w = pk.gradWeight*pk.histWeights[<span class="number">0</span>];</span><br><span class="line">        <span class="type">const</span> uchar* h = qanglePtr + pk.qangleOfs;</span><br><span class="line">        <span class="type">int</span> h0 = h[<span class="number">0</span>], h1 = h[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="type">float</span>* hist = blockHist + pk.histOfs[<span class="number">0</span>];</span><br><span class="line">        <span class="type">float</span> t0 = hist[h0] + a[<span class="number">0</span>]*w;</span><br><span class="line">        <span class="type">float</span> t1 = hist[h1] + a[<span class="number">1</span>]*w;</span><br><span class="line">        hist[h0] = t0; hist[h1] = t1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>( ; k &lt; C2; k++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">const</span> PixData&amp; pk = _pixData[k];</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* <span class="type">const</span> a = gradPtr + pk.gradOfs;</span><br><span class="line">        <span class="type">float</span> w, t0, t1, a0 = a[<span class="number">0</span>], a1 = a[<span class="number">1</span>];</span><br><span class="line">        <span class="type">const</span> uchar* <span class="type">const</span> h = qanglePtr + pk.qangleOfs;</span><br><span class="line">        <span class="type">int</span> h0 = h[<span class="number">0</span>], h1 = h[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="type">float</span>* hist = blockHist + pk.histOfs[<span class="number">0</span>];</span><br><span class="line">        w = pk.gradWeight*pk.histWeights[<span class="number">0</span>];</span><br><span class="line">        t0 = hist[h0] + a0*w;</span><br><span class="line">        t1 = hist[h1] + a1*w;</span><br><span class="line">        hist[h0] = t0; hist[h1] = t1;</span><br><span class="line"></span><br><span class="line">        hist = blockHist + pk.histOfs[<span class="number">1</span>];</span><br><span class="line">        w = pk.gradWeight*pk.histWeights[<span class="number">1</span>];</span><br><span class="line">        t0 = hist[h0] + a0*w;</span><br><span class="line">        t1 = hist[h1] + a1*w;</span><br><span class="line">        hist[h0] = t0; hist[h1] = t1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>( ; k &lt; C4; k++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">const</span> PixData&amp; pk = _pixData[k];</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* a = gradPtr + pk.gradOfs;</span><br><span class="line">        <span class="type">float</span> w, t0, t1, a0 = a[<span class="number">0</span>], a1 = a[<span class="number">1</span>];</span><br><span class="line">        <span class="type">const</span> uchar* h = qanglePtr + pk.qangleOfs;</span><br><span class="line">        <span class="type">int</span> h0 = h[<span class="number">0</span>], h1 = h[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="type">float</span>* hist = blockHist + pk.histOfs[<span class="number">0</span>];</span><br><span class="line">        w = pk.gradWeight*pk.histWeights[<span class="number">0</span>];</span><br><span class="line">        t0 = hist[h0] + a0*w;</span><br><span class="line">        t1 = hist[h1] + a1*w;</span><br><span class="line">        hist[h0] = t0; hist[h1] = t1;</span><br><span class="line"></span><br><span class="line">        hist = blockHist + pk.histOfs[<span class="number">1</span>];</span><br><span class="line">        w = pk.gradWeight*pk.histWeights[<span class="number">1</span>];</span><br><span class="line">        t0 = hist[h0] + a0*w;</span><br><span class="line">        t1 = hist[h1] + a1*w;</span><br><span class="line">        hist[h0] = t0; hist[h1] = t1;</span><br><span class="line"></span><br><span class="line">        hist = blockHist + pk.histOfs[<span class="number">2</span>];</span><br><span class="line">        w = pk.gradWeight*pk.histWeights[<span class="number">2</span>];</span><br><span class="line">        t0 = hist[h0] + a0*w;</span><br><span class="line">        t1 = hist[h1] + a1*w;</span><br><span class="line">        hist[h0] = t0; hist[h1] = t1;</span><br><span class="line"></span><br><span class="line">        hist = blockHist + pk.histOfs[<span class="number">3</span>];</span><br><span class="line">        w = pk.gradWeight*pk.histWeights[<span class="number">3</span>];</span><br><span class="line">        t0 = hist[h0] + a0*w;</span><br><span class="line">        t1 = hist[h1] + a1*w;</span><br><span class="line">        hist[h0] = t0; hist[h1] = t1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 归一化 block中的Hist</span></span><br><span class="line">    <span class="built_in">normalizeBlockHistogram</span>(blockHist);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> blockHist;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGCache::normalizeBlockHistogram</span><span class="params">(<span class="type">float</span>* _hist)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">float</span>* hist = &amp;_hist[<span class="number">0</span>], sum = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="type">size_t</span> i = <span class="number">0</span>, sz = blockHistogramSize;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span> ; i &lt; sz; ++i)</span><br><span class="line">        sum += hist[i]*hist[i];</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> scale = <span class="number">1.f</span>/(std::<span class="built_in">sqrt</span>(sum)+sz*<span class="number">0.1f</span>), thresh = (<span class="type">float</span>)descriptor-&gt;L2HysThreshold;</span><br><span class="line">    sum = <span class="number">0.0f</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; sz; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        hist[i] = std::<span class="built_in">min</span>(hist[i]*scale, thresh);</span><br><span class="line">        sum += hist[i]*hist[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    scale = <span class="number">1.f</span>/(std::<span class="built_in">sqrt</span>(sum)+<span class="number">1e-3</span>f), i = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ( ; i &lt; sz; ++i)</span><br><span class="line">        hist[i] *= scale;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Size <span class="title">HOGCache::windowsInImage</span><span class="params">(<span class="type">const</span> Size&amp; imageSize, <span class="type">const</span> Size&amp; winStride)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Size</span>((imageSize.width - winSize.width)/winStride.width + <span class="number">1</span>,</span><br><span class="line">        (imageSize.height - winSize.height)/winStride.height + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Rect <span class="title">HOGCache::getWindow</span><span class="params">(<span class="type">const</span> Size&amp; imageSize, <span class="type">const</span> Size&amp; winStride, <span class="type">int</span> idx)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> nwindowsX = (imageSize.width - winSize.width)/winStride.width + <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> y = idx / nwindowsX;</span><br><span class="line">    <span class="type">int</span> x = idx - nwindowsX*y;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Rect</span>( x*winStride.width, y*winStride.height, winSize.width, winSize.height );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">int</span> <span class="title">gcd</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>( a &lt; b )</span><br><span class="line">        std::<span class="built_in">swap</span>(a, b);</span><br><span class="line">    <span class="keyword">while</span>( b &gt; <span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> r = a % b;</span><br><span class="line">        a = b;</span><br><span class="line">        b = r;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::compute</span><span class="params">(InputArray _img, std::vector&lt;<span class="type">float</span>&gt;&amp; descriptors,</span></span></span><br><span class="line"><span class="params"><span class="function">    Size winStride, Size padding, <span class="type">const</span> std::vector&lt;Point&gt;&amp; locations)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_INSTRUMENT_REGION</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( winStride == <span class="built_in">Size</span>() )</span><br><span class="line">        winStride = cellSize;</span><br><span class="line">    <span class="function">Size <span class="title">cacheStride</span><span class="params">(gcd(winStride.width, blockStride.width),</span></span></span><br><span class="line"><span class="params"><span class="function">                     gcd(winStride.height, blockStride.height))</span></span>;</span><br><span class="line"></span><br><span class="line">    Size imgSize = _img.<span class="built_in">size</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> nwindows = locations.<span class="built_in">size</span>();</span><br><span class="line">    padding.width = (<span class="type">int</span>)<span class="built_in">alignSize</span>(std::<span class="built_in">max</span>(padding.width, <span class="number">0</span>), cacheStride.width);</span><br><span class="line">    padding.height = (<span class="type">int</span>)<span class="built_in">alignSize</span>(std::<span class="built_in">max</span>(padding.height, <span class="number">0</span>), cacheStride.height);</span><br><span class="line">    <span class="function">Size <span class="title">paddedImgSize</span><span class="params">(imgSize.width + padding.width*<span class="number">2</span>, imgSize.height + padding.height*<span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    Mat img = _img.<span class="built_in">getMat</span>();</span><br><span class="line">    <span class="function">HOGCache <span class="title">cache</span><span class="params">(<span class="keyword">this</span>, img, padding, padding, nwindows == <span class="number">0</span>, cacheStride)</span></span>;</span><br><span class="line">    <span class="comment">// 获取图片中windows的个数</span></span><br><span class="line">    <span class="keyword">if</span>( !nwindows )</span><br><span class="line">        nwindows = cache.<span class="built_in">windowsInImage</span>(paddedImgSize, winStride).<span class="built_in">area</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> HOGCache::BlockData* blockData = &amp;cache.blockData[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nblocks = cache.nblocks.<span class="built_in">area</span>();</span><br><span class="line">    <span class="type">int</span> blockHistogramSize = cache.blockHistogramSize;</span><br><span class="line">    <span class="type">size_t</span> dsize = <span class="built_in">getDescriptorSize</span>();</span><br><span class="line">    descriptors.<span class="built_in">resize</span>(dsize*nwindows);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// for each window</span></span><br><span class="line">    <span class="keyword">for</span>( <span class="type">size_t</span> i = <span class="number">0</span>; i &lt; nwindows; i++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">float</span>* descriptor = &amp;descriptors[i*dsize];</span><br><span class="line"></span><br><span class="line">        Point pt0;</span><br><span class="line">        <span class="keyword">if</span>( !locations.<span class="built_in">empty</span>() )</span><br><span class="line">        &#123;</span><br><span class="line">            pt0 = locations[i];</span><br><span class="line">            <span class="keyword">if</span>( pt0.x &lt; -padding.width || pt0.x &gt; img.cols + padding.width - winSize.width ||</span><br><span class="line">                pt0.y &lt; -padding.height || pt0.y &gt; img.rows + padding.height - winSize.height )</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            pt0 = cache.<span class="built_in">getWindow</span>(paddedImgSize, winStride, (<span class="type">int</span>)i).<span class="built_in">tl</span>() - <span class="built_in">Point</span>(padding);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>( <span class="type">int</span> j = <span class="number">0</span>; j &lt; nblocks; j++ )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">const</span> HOGCache::BlockData&amp; bj = blockData[j];</span><br><span class="line">            Point pt = pt0 + bj.imgOffset;</span><br><span class="line"></span><br><span class="line">            <span class="type">float</span>* dst = descriptor + bj.histOfs;</span><br><span class="line">            <span class="type">const</span> <span class="type">float</span>* src = cache.<span class="built_in">getBlock</span>(pt, dst);</span><br><span class="line">            <span class="keyword">if</span>( src != dst ) <span class="built_in">memcpy</span>(dst, src, blockHistogramSize * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::detect</span><span class="params">(<span class="type">const</span> Mat&amp; img,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::vector&lt;Point&gt;&amp; hits, std::vector&lt;<span class="type">double</span>&gt;&amp; weights, <span class="type">double</span> hitThreshold,</span></span></span><br><span class="line"><span class="params"><span class="function">    Size winStride, Size padding, <span class="type">const</span> std::vector&lt;Point&gt;&amp; locations)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_INSTRUMENT_REGION</span>()</span><br><span class="line"></span><br><span class="line">    hits.<span class="built_in">clear</span>();</span><br><span class="line">    weights.<span class="built_in">clear</span>();</span><br><span class="line">    <span class="keyword">if</span>( svmDetector.<span class="built_in">empty</span>() )</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( winStride == <span class="built_in">Size</span>() )</span><br><span class="line">        winStride = cellSize;</span><br><span class="line">    <span class="function">Size <span class="title">cacheStride</span><span class="params">(gcd(winStride.width, blockStride.width),</span></span></span><br><span class="line"><span class="params"><span class="function">        gcd(winStride.height, blockStride.height))</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> nwindows = locations.<span class="built_in">size</span>();</span><br><span class="line">    padding.width = (<span class="type">int</span>)<span class="built_in">alignSize</span>(std::<span class="built_in">max</span>(padding.width, <span class="number">0</span>), cacheStride.width);</span><br><span class="line">    padding.height = (<span class="type">int</span>)<span class="built_in">alignSize</span>(std::<span class="built_in">max</span>(padding.height, <span class="number">0</span>), cacheStride.height);</span><br><span class="line">    <span class="function">Size <span class="title">paddedImgSize</span><span class="params">(img.cols + padding.width*<span class="number">2</span>, img.rows + padding.height*<span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">HOGCache <span class="title">cache</span><span class="params">(<span class="keyword">this</span>, img, padding, padding, nwindows == <span class="number">0</span>, cacheStride)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( !nwindows )</span><br><span class="line">        nwindows = cache.<span class="built_in">windowsInImage</span>(paddedImgSize, winStride).<span class="built_in">area</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> HOGCache::BlockData* blockData = &amp;cache.blockData[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nblocks = cache.nblocks.<span class="built_in">area</span>();</span><br><span class="line">    <span class="type">int</span> blockHistogramSize = cache.blockHistogramSize;</span><br><span class="line">    <span class="type">size_t</span> dsize = <span class="built_in">getDescriptorSize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">double</span> rho = svmDetector.<span class="built_in">size</span>() &gt; dsize ? svmDetector[dsize] : <span class="number">0</span>;</span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">blockHist</span><span class="params">(blockHistogramSize)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>( <span class="type">size_t</span> i = <span class="number">0</span>; i &lt; nwindows; i++ )</span><br><span class="line">    &#123;</span><br><span class="line">        Point pt0;</span><br><span class="line">        <span class="keyword">if</span>( !locations.<span class="built_in">empty</span>() )</span><br><span class="line">        &#123;</span><br><span class="line">            pt0 = locations[i];</span><br><span class="line">            <span class="keyword">if</span>( pt0.x &lt; -padding.width || pt0.x &gt; img.cols + padding.width - winSize.width ||</span><br><span class="line">                    pt0.y &lt; -padding.height || pt0.y &gt; img.rows + padding.height - winSize.height )</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            pt0 = cache.<span class="built_in">getWindow</span>(paddedImgSize, winStride, (<span class="type">int</span>)i).<span class="built_in">tl</span>() - <span class="built_in">Point</span>(padding);</span><br><span class="line">            <span class="built_in">CV_Assert</span>(pt0.x % cacheStride.width == <span class="number">0</span> &amp;&amp; pt0.y % cacheStride.height == <span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">double</span> s = rho;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* svmVec = &amp;svmDetector[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> j, k;</span><br><span class="line">        <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; nblocks; j++, svmVec += blockHistogramSize )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">const</span> HOGCache::BlockData&amp; bj = blockData[j];</span><br><span class="line">            Point pt = pt0 + bj.imgOffset;</span><br><span class="line"></span><br><span class="line">            <span class="type">const</span> <span class="type">float</span>* vec = cache.<span class="built_in">getBlock</span>(pt, &amp;blockHist[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span> ; k &lt; blockHistogramSize; k++ )</span><br><span class="line">                s += vec[k]*svmVec[k];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>( s &gt;= hitThreshold )</span><br><span class="line">        &#123;</span><br><span class="line">            hits.<span class="built_in">push_back</span>(pt0);</span><br><span class="line">            weights.<span class="built_in">push_back</span>(s);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::detect</span><span class="params">(<span class="type">const</span> Mat&amp; img, std::vector&lt;Point&gt;&amp; hits, <span class="type">double</span> hitThreshold,</span></span></span><br><span class="line"><span class="params"><span class="function">    Size winStride, Size padding, <span class="type">const</span> std::vector&lt;Point&gt;&amp; locations)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_INSTRUMENT_REGION</span>()</span><br><span class="line"></span><br><span class="line">    std::vector&lt;<span class="type">double</span>&gt; weightsV;</span><br><span class="line">    <span class="built_in">detect</span>(img, hits, weightsV, hitThreshold, winStride, padding, locations);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HOGInvoker</span> : <span class="keyword">public</span> ParallelLoopBody</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">HOGInvoker</span>( <span class="type">const</span> HOGDescriptor* _hog, <span class="type">const</span> Mat&amp; _img,</span><br><span class="line">        <span class="type">double</span> _hitThreshold, <span class="type">const</span> Size&amp; _winStride, <span class="type">const</span> Size&amp; _padding,</span><br><span class="line">        <span class="type">const</span> <span class="type">double</span>* _levelScale, std::vector&lt;Rect&gt; * _vec, Mutex* _mtx,</span><br><span class="line">        std::vector&lt;<span class="type">double</span>&gt;* _weights=<span class="number">0</span>, std::vector&lt;<span class="type">double</span>&gt;* _scales=<span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        hog = _hog;</span><br><span class="line">        img = _img;</span><br><span class="line">        hitThreshold = _hitThreshold;</span><br><span class="line">        winStride = _winStride;</span><br><span class="line">        padding = _padding;</span><br><span class="line">        levelScale = _levelScale;</span><br><span class="line">        vec = _vec;</span><br><span class="line">        weights = _weights;</span><br><span class="line">        scales = _scales;</span><br><span class="line">        mtx = _mtx;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">( <span class="type">const</span> Range&amp; range )</span> <span class="type">const</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="type">int</span> i, i1 = range.start, i2 = range.end;</span><br><span class="line">        <span class="type">double</span> minScale = i1 &gt; <span class="number">0</span> ? levelScale[i1] : i2 &gt; <span class="number">1</span> ? levelScale[i1+<span class="number">1</span>] : std::<span class="built_in">max</span>(img.cols, img.rows);</span><br><span class="line">        <span class="function">Size <span class="title">maxSz</span><span class="params">(cvCeil(img.cols/minScale), cvCeil(img.rows/minScale))</span></span>;</span><br><span class="line">        <span class="function">Mat <span class="title">smallerImgBuf</span><span class="params">(maxSz, img.type())</span></span>;</span><br><span class="line">        std::vector&lt;Point&gt; locations;</span><br><span class="line">        std::vector&lt;<span class="type">double</span>&gt; hitsWeights;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>( i = i1; i &lt; i2; i++ )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">double</span> scale = levelScale[i];</span><br><span class="line">            <span class="function">Size <span class="title">sz</span><span class="params">(cvRound(img.cols/scale), cvRound(img.rows/scale))</span></span>;</span><br><span class="line">            <span class="function">Mat <span class="title">smallerImg</span><span class="params">(sz, img.type(), smallerImgBuf.ptr())</span></span>;</span><br><span class="line">            <span class="keyword">if</span>( sz == img.<span class="built_in">size</span>() )</span><br><span class="line">                smallerImg = <span class="built_in">Mat</span>(sz, img.<span class="built_in">type</span>(), img.data, img.step);</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">resize</span>(img, smallerImg, sz);</span><br><span class="line">            hog-&gt;<span class="built_in">detect</span>(smallerImg, locations, hitsWeights, hitThreshold, winStride, padding);</span><br><span class="line">            Size scaledWinSize = <span class="built_in">Size</span>(<span class="built_in">cvRound</span>(hog-&gt;winSize.width*scale), <span class="built_in">cvRound</span>(hog-&gt;winSize.height*scale));</span><br><span class="line"></span><br><span class="line">            mtx-&gt;<span class="built_in">lock</span>();</span><br><span class="line">            <span class="keyword">for</span>( <span class="type">size_t</span> j = <span class="number">0</span>; j &lt; locations.<span class="built_in">size</span>(); j++ )</span><br><span class="line">            &#123;</span><br><span class="line">                vec-&gt;<span class="built_in">push_back</span>(<span class="built_in">Rect</span>(<span class="built_in">cvRound</span>(locations[j].x*scale),</span><br><span class="line">                                    <span class="built_in">cvRound</span>(locations[j].y*scale),</span><br><span class="line">                                    scaledWinSize.width, scaledWinSize.height));</span><br><span class="line">                <span class="keyword">if</span> (scales)</span><br><span class="line">                    scales-&gt;<span class="built_in">push_back</span>(scale);</span><br><span class="line">            &#125;</span><br><span class="line">            mtx-&gt;<span class="built_in">unlock</span>();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (weights &amp;&amp; (!hitsWeights.<span class="built_in">empty</span>()))</span><br><span class="line">            &#123;</span><br><span class="line">                mtx-&gt;<span class="built_in">lock</span>();</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; locations.<span class="built_in">size</span>(); j++)</span><br><span class="line">                    weights-&gt;<span class="built_in">push_back</span>(hitsWeights[j]);</span><br><span class="line">                mtx-&gt;<span class="built_in">unlock</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">const</span> HOGDescriptor* hog;</span><br><span class="line">    Mat img;</span><br><span class="line">    <span class="type">double</span> hitThreshold;</span><br><span class="line">    Size winStride;</span><br><span class="line">    Size padding;</span><br><span class="line">    <span class="type">const</span> <span class="type">double</span>* levelScale;</span><br><span class="line">    std::vector&lt;Rect&gt;* vec;</span><br><span class="line">    std::vector&lt;<span class="type">double</span>&gt;* weights;</span><br><span class="line">    std::vector&lt;<span class="type">double</span>&gt;* scales;</span><br><span class="line">    Mutex* mtx;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::detectMultiScale</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    InputArray _img, std::vector&lt;Rect&gt;&amp; foundLocations, std::vector&lt;<span class="type">double</span>&gt;&amp; foundWeights,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">double</span> hitThreshold, Size winStride, Size padding,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">double</span> scale0, <span class="type">double</span> finalThreshold, <span class="type">bool</span> useMeanshiftGrouping)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_INSTRUMENT_REGION</span>()</span><br><span class="line"></span><br><span class="line">    <span class="type">double</span> scale = <span class="number">1.</span>;</span><br><span class="line">    <span class="type">int</span> levels = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    Size imgSize = _img.<span class="built_in">size</span>();</span><br><span class="line">    std::vector&lt;<span class="type">double</span>&gt; levelScale;</span><br><span class="line">    <span class="keyword">for</span>( levels = <span class="number">0</span>; levels &lt; nlevels; levels++ )</span><br><span class="line">    &#123;</span><br><span class="line">        levelScale.<span class="built_in">push_back</span>(scale);</span><br><span class="line">        <span class="keyword">if</span>( <span class="built_in">cvRound</span>(imgSize.width/scale) &lt; winSize.width ||</span><br><span class="line">            <span class="built_in">cvRound</span>(imgSize.height/scale) &lt; winSize.height ||</span><br><span class="line">                scale0 &lt;= <span class="number">1</span> )</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        scale *= scale0;</span><br><span class="line">    &#125;</span><br><span class="line">    levels = std::<span class="built_in">max</span>(levels, <span class="number">1</span>);</span><br><span class="line">    levelScale.<span class="built_in">resize</span>(levels);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(winStride == <span class="built_in">Size</span>())</span><br><span class="line">        winStride = blockStride;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CV_OCL_RUN</span>(_img.<span class="built_in">dims</span>() &lt;= <span class="number">2</span> &amp;&amp; _img.<span class="built_in">type</span>() == CV_8UC1 &amp;&amp; scale0 &gt; <span class="number">1</span> &amp;&amp; winStride.width % blockStride.width == <span class="number">0</span> &amp;&amp;</span><br><span class="line">        winStride.height % blockStride.height == <span class="number">0</span> &amp;&amp; padding == <span class="built_in">Size</span>(<span class="number">0</span>,<span class="number">0</span>) &amp;&amp; _img.<span class="built_in">isUMat</span>(),</span><br><span class="line">        <span class="built_in">ocl_detectMultiScale</span>(_img, foundLocations, levelScale, hitThreshold, winStride, finalThreshold, oclSvmDetector,</span><br><span class="line">        blockSize, cellSize, nbins, blockStride, winSize, gammaCorrection, L2HysThreshold, (<span class="type">float</span>)<span class="built_in">getWinSigma</span>(), free_coef, signedGradient));</span><br><span class="line"></span><br><span class="line">    std::vector&lt;Rect&gt; allCandidates;</span><br><span class="line">    std::vector&lt;<span class="type">double</span>&gt; tempScales;</span><br><span class="line">    std::vector&lt;<span class="type">double</span>&gt; tempWeights;</span><br><span class="line">    std::vector&lt;<span class="type">double</span>&gt; foundScales;</span><br><span class="line"></span><br><span class="line">    Mutex mtx;</span><br><span class="line">    Mat img = _img.<span class="built_in">getMat</span>();</span><br><span class="line">    <span class="function">Range <span class="title">range</span><span class="params">(<span class="number">0</span>, (<span class="type">int</span>)levelScale.size())</span></span>;</span><br><span class="line">    <span class="function">HOGInvoker <span class="title">invoker</span><span class="params">(<span class="keyword">this</span>, img, hitThreshold, winStride, padding, &amp;levelScale[<span class="number">0</span>], &amp;allCandidates, &amp;mtx, &amp;tempWeights, &amp;tempScales)</span></span>;</span><br><span class="line">    <span class="built_in">parallel_for_</span>(range, invoker);</span><br><span class="line"></span><br><span class="line">    std::<span class="built_in">copy</span>(tempScales.<span class="built_in">begin</span>(), tempScales.<span class="built_in">end</span>(), <span class="built_in">back_inserter</span>(foundScales));</span><br><span class="line">    foundLocations.<span class="built_in">clear</span>();</span><br><span class="line">    std::<span class="built_in">copy</span>(allCandidates.<span class="built_in">begin</span>(), allCandidates.<span class="built_in">end</span>(), <span class="built_in">back_inserter</span>(foundLocations));</span><br><span class="line">    foundWeights.<span class="built_in">clear</span>();</span><br><span class="line">    std::<span class="built_in">copy</span>(tempWeights.<span class="built_in">begin</span>(), tempWeights.<span class="built_in">end</span>(), <span class="built_in">back_inserter</span>(foundWeights));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ( useMeanshiftGrouping )</span><br><span class="line">        <span class="built_in">groupRectangles_meanshift</span>(foundLocations, foundWeights, foundScales, finalThreshold, winSize);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">groupRectangles</span>(foundLocations, foundWeights, (<span class="type">int</span>)finalThreshold, <span class="number">0.2</span>);</span><br><span class="line">    <span class="built_in">clipObjects</span>(imgSize, foundLocations, <span class="number">0</span>, &amp;foundWeights);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::detectMultiScale</span><span class="params">(InputArray img, std::vector&lt;Rect&gt;&amp; foundLocations,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">double</span> hitThreshold, Size winStride, Size padding,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">double</span> scale0, <span class="type">double</span> finalThreshold, <span class="type">bool</span> useMeanshiftGrouping)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_INSTRUMENT_REGION</span>()</span><br><span class="line"></span><br><span class="line">    std::vector&lt;<span class="type">double</span>&gt; foundWeights;</span><br><span class="line">    <span class="built_in">detectMultiScale</span>(img, foundLocations, foundWeights, hitThreshold, winStride,</span><br><span class="line">                padding, scale0, finalThreshold, useMeanshiftGrouping);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::detectROI</span><span class="params">(<span class="type">const</span> cv::Mat&amp; img, <span class="type">const</span> std::vector&lt;cv::Point&gt; &amp;locations,</span></span></span><br><span class="line"><span class="params"><span class="function">    CV_OUT std::vector&lt;cv::Point&gt;&amp; foundLocations, CV_OUT std::vector&lt;<span class="type">double</span>&gt;&amp; confidences,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">double</span> hitThreshold, cv::Size winStride, cv::Size padding)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_INSTRUMENT_REGION</span>()</span><br><span class="line"></span><br><span class="line">    foundLocations.<span class="built_in">clear</span>();</span><br><span class="line">    confidences.<span class="built_in">clear</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( svmDetector.<span class="built_in">empty</span>() || locations.<span class="built_in">empty</span>())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( winStride == <span class="built_in">Size</span>() )</span><br><span class="line">        winStride = cellSize;</span><br><span class="line">    <span class="function">Size <span class="title">cacheStride</span><span class="params">(gcd(winStride.width, blockStride.width),</span></span></span><br><span class="line"><span class="params"><span class="function">                     gcd(winStride.height, blockStride.height))</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> nwindows = locations.<span class="built_in">size</span>();</span><br><span class="line">    padding.width = (<span class="type">int</span>)<span class="built_in">alignSize</span>(std::<span class="built_in">max</span>(padding.width, <span class="number">0</span>), cacheStride.width);</span><br><span class="line">    padding.height = (<span class="type">int</span>)<span class="built_in">alignSize</span>(std::<span class="built_in">max</span>(padding.height, <span class="number">0</span>), cacheStride.height);</span><br><span class="line">    <span class="function">Size <span class="title">paddedImgSize</span><span class="params">(img.cols + padding.width*<span class="number">2</span>, img.rows + padding.height*<span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// HOGCache cache(this, img, padding, padding, nwindows == 0, cacheStride);</span></span><br><span class="line">    <span class="function">HOGCache <span class="title">cache</span><span class="params">(<span class="keyword">this</span>, img, padding, padding, <span class="literal">true</span>, cacheStride)</span></span>;</span><br><span class="line">    <span class="keyword">if</span>( !nwindows )</span><br><span class="line">        nwindows = cache.<span class="built_in">windowsInImage</span>(paddedImgSize, winStride).<span class="built_in">area</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> HOGCache::BlockData* blockData = &amp;cache.blockData[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nblocks = cache.nblocks.<span class="built_in">area</span>();</span><br><span class="line">    <span class="type">int</span> blockHistogramSize = cache.blockHistogramSize;</span><br><span class="line">    <span class="type">size_t</span> dsize = <span class="built_in">getDescriptorSize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="type">double</span> rho = svmDetector.<span class="built_in">size</span>() &gt; dsize ? svmDetector[dsize] : <span class="number">0</span>;</span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">blockHist</span><span class="params">(blockHistogramSize)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>( <span class="type">size_t</span> i = <span class="number">0</span>; i &lt; nwindows; i++ )</span><br><span class="line">    &#123;</span><br><span class="line">        Point pt0;</span><br><span class="line">        pt0 = locations[i];</span><br><span class="line">        <span class="keyword">if</span>( pt0.x &lt; -padding.width || pt0.x &gt; img.cols + padding.width - winSize.width ||</span><br><span class="line">                pt0.y &lt; -padding.height || pt0.y &gt; img.rows + padding.height - winSize.height )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// out of image</span></span><br><span class="line">            confidences.<span class="built_in">push_back</span>(<span class="number">-10.0</span>);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">double</span> s = rho;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* svmVec = &amp;svmDetector[<span class="number">0</span>];</span><br><span class="line">        <span class="type">int</span> j, k;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; nblocks; j++, svmVec += blockHistogramSize )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">const</span> HOGCache::BlockData&amp; bj = blockData[j];</span><br><span class="line">            Point pt = pt0 + bj.imgOffset;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// need to devide this into 4 parts!</span></span><br><span class="line">            <span class="type">const</span> <span class="type">float</span>* vec = cache.<span class="built_in">getBlock</span>(pt, &amp;blockHist[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span> ; k &lt; blockHistogramSize; k++ )</span><br><span class="line">                s += vec[k]*svmVec[k];</span><br><span class="line">        &#125;</span><br><span class="line">        confidences.<span class="built_in">push_back</span>(s);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>( s &gt;= hitThreshold )</span><br><span class="line">            foundLocations.<span class="built_in">push_back</span>(pt0);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HOGDescriptor::detectMultiScaleROI</span><span class="params">(<span class="type">const</span> cv::Mat&amp; img,</span></span></span><br><span class="line"><span class="params"><span class="function">    CV_OUT std::vector&lt;cv::Rect&gt;&amp; foundLocations, std::vector&lt;DetectionROI&gt;&amp; locations,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">double</span> hitThreshold, <span class="type">int</span> groupThreshold)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">CV_INSTRUMENT_REGION</span>()</span><br><span class="line"></span><br><span class="line">    std::vector&lt;Rect&gt; allCandidates;</span><br><span class="line">    Mutex mtx;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">parallel_for_</span>(<span class="built_in">Range</span>(<span class="number">0</span>, (<span class="type">int</span>)locations.<span class="built_in">size</span>()),</span><br><span class="line">                  <span class="built_in">HOGConfInvoker</span>(<span class="keyword">this</span>, img, hitThreshold, <span class="built_in">Size</span>(<span class="number">8</span>, <span class="number">8</span>),</span><br><span class="line">                                 &amp;locations, &amp;allCandidates, &amp;mtx));</span><br><span class="line"></span><br><span class="line">    foundLocations.<span class="built_in">resize</span>(allCandidates.<span class="built_in">size</span>());</span><br><span class="line">    std::<span class="built_in">copy</span>(allCandidates.<span class="built_in">begin</span>(), allCandidates.<span class="built_in">end</span>(), foundLocations.<span class="built_in">begin</span>());</span><br><span class="line">    cv::<span class="built_in">groupRectangles</span>(foundLocations, groupThreshold, <span class="number">0.2</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/notes.jpg"
alt="@我的手工笔记" /> <a
href="../../images/fhog/hog.cpp">源码下载</a></p>
<h2 id="fhog">FHOG</h2>
<p>源代码下载：<a
href="http://www.codeforge.com/read/465952/FHOG.cpp__html"
class="uri">http://www.codeforge.com/read/465952/FHOG.cpp__html</a>
FHOG是在HOG基础上，将冗余计算去除之后改进的算法。下面进行介绍 <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030318107.jpg"
alt="@31个向量" /></p>
<h1 id="参考资料">参考资料</h1>
<ol type="1">
<li><p>[hog中快速算法的三线插值将得很详细]<a
href="http://hi.baidu.com/susongzhi/item/3a3c758d7ff5cbdc5e0ec172"
class="uri">http://hi.baidu.com/susongzhi/item/3a3c758d7ff5cbdc5e0ec172</a></p></li>
<li><p>[HOG更加详细的解释]<a
href="http://blog.csdn.net/liulina603/article/details/8291093"
class="uri">http://blog.csdn.net/liulina603/article/details/8291093</a></p></li>
<li><p>[对行人检测任务进行了详细分析，此外还对OpenCV中的源代码进行了分析]<a
href="http://www.cnblogs.com/tornadomeet/archive/2012/08/15/2640754.html"
class="uri">http://www.cnblogs.com/tornadomeet/archive/2012/08/15/2640754.html</a></p></li>
</ol>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>CV算法</tag>
        <tag>detection</tag>
      </tags>
  </entry>
  <entry>
    <title>开发：C++开发面经</title>
    <url>/201708/20170830-cpp-learning/</url>
    <content><![CDATA[<h2 id="析构函数必须是虚函数为什么">析构函数必须是虚函数，为什么？</h2>
<p>在实现多态时，当用基类操作派生类，在析构时防止只析构基类而不析构派生类的状况发生。</p>
<ol type="1">
<li>第一段代码</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClxBase</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ClxBase</span>() &#123;&#125;;</span><br><span class="line">    ~<span class="built_in">ClxBase</span>() &#123;cout &lt;&lt; <span class="string">&quot;Output from the destructor of class ClxBase!&quot;</span> &lt;&lt; endl;&#125;;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">DoSomething</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Do something in class ClxBase!&quot;</span> &lt;&lt; endl; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClxDerived</span> : <span class="keyword">public</span> ClxBase&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ClxDerived</span>() &#123;&#125;;</span><br><span class="line">    ~<span class="built_in">ClxDerived</span>() &#123; cout &lt;&lt; <span class="string">&quot;Output from the destructor of class ClxDerived!&quot;</span> &lt;&lt; endl; &#125;;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">DoSomething</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Do something in class ClxDerived!&quot;</span> &lt;&lt; endl; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">  <span class="function"><span class="type">int</span>   <span class="title">main</span><span class="params">()</span></span>&#123;  </span><br><span class="line">  ClxDerived *p =  <span class="keyword">new</span> ClxDerived;</span><br><span class="line">  p-&gt;<span class="built_in">DoSomething</span>();</span><br><span class="line">  <span class="keyword">delete</span> p;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>运行结果： Do something in class ClxDerived!<br />
Output from the destructor of class ClxDerived! Output from the
destructor of class ClxBase!</p>
<p>这段代码中基类的析构函数不是虚函数,在<code>main</code>函数中用继承类的指针去操作继承类的成员,释放指针P的过程是:先释放继承类的资源,再释放基类资源.</p>
<ol start="2" type="1">
<li>第二段代码</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClxBase</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ClxBase</span>() &#123;&#125;;</span><br><span class="line">    ~<span class="built_in">ClxBase</span>() </span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;Output from the destructor of class ClxBase!&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">DoSomething</span><span class="params">()</span> </span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      cout &lt;&lt; <span class="string">&quot;Do something in class ClxBase!&quot;</span> &lt;&lt; endl; </span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClxDerived</span> : <span class="keyword">public</span> ClxBase&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ClxDerived</span>() &#123;&#125;;</span><br><span class="line">    ~<span class="built_in">ClxDerived</span>() &#123; cout &lt;&lt; <span class="string">&quot;Output from the destructor of class ClxDerived!&quot;</span> &lt;&lt; endl; &#125;;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">DoSomething</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Do something in class ClxDerived!&quot;</span> &lt;&lt; endl; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span>   <span class="title">main</span><span class="params">()</span></span>&#123;  </span><br><span class="line">  ClxBase *p =  <span class="keyword">new</span> ClxDerived;</span><br><span class="line">  p-&gt;<span class="built_in">DoSomething</span>();</span><br><span class="line">  <span class="keyword">delete</span> p;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<pre><code>输出结果：
Do something in class ClxBase!
Output from the destructor of class ClxBase!</code></pre>
<p>这段代码中基类的析构函数同样不是虚函数,不同的是在main函数中用基类的指针去操作继承类的成员,释放指针P的过程是:只是释放了基类的资源,而没有调用继承类的析构函数.调用<code>dosomething()</code>函数执行的也是基类定义的函数.
一般情况下,这样的删除只能够删除基类对象,而不能删除子类对象,形成了删除一半形象,造成内存泄漏.
在公有继承中,基类对派生类及其对象的操作,只能影响到那些从基类继承下来的成员.如果想要用基类对非继承成员进行操作,则要把基类的这个函数定义为虚函数.
析构函数自然也应该如此:如果它想析构子类中的重新定义或新的成员及对象,当然也应该声明为虚的.</p>
<ol start="3" type="1">
<li>第三段代码：</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClxBase</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ClxBase</span>() &#123;&#125;;</span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">ClxBase</span>() &#123;cout &lt;&lt; <span class="string">&quot;Output from the destructor of class ClxBase!&quot;</span> &lt;&lt; endl;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">DoSomething</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Do something in class ClxBase!&quot;</span> &lt;&lt; endl; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClxDerived</span> : <span class="keyword">public</span> ClxBase&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ClxDerived</span>() &#123;&#125;;</span><br><span class="line">    ~<span class="built_in">ClxDerived</span>() &#123; cout &lt;&lt; <span class="string">&quot;Output from the destructor of class ClxDerived!&quot;</span> &lt;&lt; endl; &#125;;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">DoSomething</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Do something in class ClxDerived!&quot;</span> &lt;&lt; endl; &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span>   <span class="title">main</span><span class="params">()</span></span>&#123;  </span><br><span class="line">  ClxBase *p =  <span class="keyword">new</span> ClxDerived;</span><br><span class="line">  p-&gt;<span class="built_in">DoSomething</span>();</span><br><span class="line">  <span class="keyword">delete</span> p;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code>运行结果：
Do something in class ClxDerived!
Output from the destructor of class ClxDerived!
Output from the destructor of class ClxBase!</code></pre>
<p>这段代码中基类的析构函数被定义为虚函数,在<code>main</code>函数中用基类的指针去操作继承类的成员,释放指针P的过程是:只是释放了继承类的资源,再调用基类的析构函数.调用<code>dosomething()</code>函数执行的也是继承类定义的函数.</p>
<p>如果不需要基类对派生类及对象进行操作,则不能定义虚函数,因为这样会增加内存开销。当类里面有定义虚函数的时候,编译器会给类添加一个虚函数表,里面来存放虚函数指针,这样就会增加类的存储空间.所以,只有当一个类被用来作为基类的时候,才把析构函数写成虚函数.</p>
<h2 id="虚函数表">虚函数表</h2>
<p><a
href="http://blog.csdn.net/haoel/article/details/1948051/">虚函数表专栏</a>
C++中的虚函数的作用主要是实现了多态的机制。关于多态，简而言之就是用父类型别的指针指向其子类的实例，然后通过父类的指针调用实际子类的成员函数。这种技术可以让父类的指针有“多种形态”，这是一种泛型技术。所谓泛型技术，说白了就是试图使用不变的代码来实现可变的算法。比如：模板技术，RTTI技术，虚函数技术，要么是试图做到在编译时决议，要么试图做到运行时决议</p>
<blockquote>
<p>模板技术是编译时产生对应的代码。
RTTI技术通过运行时类型信息程序能够使用基类的指针或引用来检查这些指针或引用所指的对象的实际派生类型。RTTI提供了以下两个非常有用的操作符：
- typeid操作符，返回指针和引用所指的实际类型。 -
dynamic_cast操作符，将基类类型的指针或引用安全地转换为派生类型的指针或引用。</p>
</blockquote>
<h2 id="多线程锁机制">多线程锁机制</h2>
<p><a
href="http://blog.csdn.net/redsuntim/article/details/8718487">linux多线程锁机制</a></p>
<h3 id="临界区访问">临界区访问</h3>
<ol type="1">
<li>访问共享资源的代码区域称为临界区。自旋锁(spinlock)和互斥体(mutex)是保护内核临界区的两种基本机制。</li>
<li><strong>互斥锁</strong>：<code>pthread_mutex</code>，属于sleep-waiting类型的锁。互斥量是实现最简单的锁类型，因此有一些教科书一般以互斥量为例对锁原语进行描述。<strong>互斥量的释放并不仅仅依赖于释放操作，还可以引入一个定时器属性</strong>。如果在释放操作执行前发生定时器超时，则互斥量也会释放代码块或共享存储区供其他线程访问。当有异常发生时，可使用try-finally语句来确保互斥量被释放。定时器状态或try-finally语句的使用可<strong>以避免产生死锁</strong>。</li>
<li><strong>自旋锁</strong>：pin lock，属于busy-wait类型的锁。
旋转锁是一种非阻塞锁，由某个线程独占。采用旋转锁时，等待线程并不静态地阻塞在同步点，而是必须“旋转”，不断尝试直到最终获得该锁。旋转锁多用于<strong>多处理器系统</strong>中。这是因为，如果在单核处理器中采用旋转锁，当一个线程正在“旋转”时，将没有执行资源可供另一释放锁的线程使用。<strong>旋转锁适合于任何锁持有时间少于将一个线程阻塞和唤醒所需时间的场合</strong>。<strong>线程控制的变更，包括线程上下文的切换和线程数据结构的更新，可能比旋转锁需要更多的指令周期。旋转锁的持有时间应该限制在线程上下文切换时间的50%到100%之间（Kleiman，1996年）</strong>。在线程调用其他子系统时，线程不应持有旋转锁。对旋转锁的不当使用可能会导致线程饿死，因此需谨慎使用这种锁机制。旋转锁导致的饿死问题可使用排队技术来解决，即每个等待线程按照先进先出的顺序或者队列结构在一个独立的局部标识上进行旋转。自旋锁有在内核可抢占式或SMP(对称多处理结构)的情况下才真正需要。</li>
<li><strong>互斥锁和自旋锁有各自的应用场景</strong>：</li>
</ol>
<ul>
<li>如果要等待的时间较长，互斥体比自旋锁更合适。</li>
<li>因为自旋锁不会引起调用者睡眠，所以自旋锁的效率远高于互斥锁。但自旋锁一直占用CPU，它在未获得锁的情况下，一直运行-自旋，所以占用着CPU，如果不能在很短的时间内获得锁，这无疑会使CPU效率降低。</li>
<li>如果临界区需要睡眠，只能使用互斥体，因为在获得自旋锁后进行调度、抢占以及在等待队列上睡眠都是非法的。</li>
<li>由于互斥体会在面临竞争的情况下将当前线程置于睡眠状态，因此，在中断处理函数中，只能使用自旋锁。</li>
</ul>
<ol start="5" type="1">
<li><strong>实例说明</strong>：两个项目中需要实现消息队列，一个消息队列只是简单的<code>queue.insert</code>和<code>queue.pop</code>，比较简单，没有什么业务逻辑，就使用了<em>自旋锁</em>；另外一个还需要进行队列的拼装和排序，业务逻辑比较复杂或耗时，就使用了<em>互斥锁</em></li>
</ol>
<h3 id="线程的同步">线程的同步</h3>
<p>线程的同步, 发生在多个线程<em>共享相同内存</em>的时候,
这时要保证每个线程在每个时刻看到的共享数据是一致的.
如果每个线程使用的变量都是其他线程不会使用的(<code>read &amp; write</code>),
或者变量是只读的, 就不存在一致性问题. 但是,
如果两个或两个以上的线程可以<code>read/write</code>一个变量时,
就需要对线程进行同步, 以确保它们在访问该变量时, 不会得到无效的值,
同时也可以唯一地修改该变量并使它生效. 以上就是我们所说的线程同步.
线程同步有三种常用的机制: <em>互斥量(mutex)</em>,
<em>读写锁(rwlock)</em>和<em>条件变量(cond)</em>.</p>
<pre><code>互斥量有两种状态: `lock`和`unlock`, 它确保同一时间只有一个线程访问数据;
读写锁有三种状态: 读加锁, 写加锁, 不加锁, 只有一个线程可以占有写模式的读写锁, 但是可以有多个线程同时占有读模式的读写锁.
条件变量则给多个线程提供了一个会合的场所, 与互斥量一起使用时, 允许线程以无竞争的方式等待特定条件的发生.</code></pre>
<h4 id="互斥量">互斥量</h4>
<p>互斥量从本质上说就是一把锁, 提供对共享资源的保护访问. 1. 初始化:
在Linux下, 线程的互斥量数据类型是<code>pthread_mutex_t</code>. 在使用前,
要对它进行初始化: 对于静态分配的互斥量,
可以把它设置为<code>PTHREAD_MUTEX_INITIALIZER</code>,
或者调用<code>pthread_mutex_init</code>. 对于动态分配的互斥量,
在申请内存(malloc)之后, 通过<code>pthread_mutex_init</code>进行初始化,
并且在释放内存(free)前需要调用<code>pthread_mutex_destroy</code>.
原型:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_mutex_init</span><span class="params">(<span class="type">pthread_mutex_t</span> *restrict mutex, <span class="type">const</span> <span class="type">pthread_mutexattr_t</span> *restric attr)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_mutex_destroy</span><span class="params">(<span class="type">pthread_mutex_t</span> *mutex)</span></span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>返回值: 成功则返回0, 出错则返回错误编号. 说明:
如果使用默认的属性初始化互斥量, 只需把attr设为NULL.
其他值在以后讲解.</p>
</blockquote>
<ol start="2" type="1">
<li>互斥操作: 对共享资源的访问, 要对互斥量进行加锁,
如果互斥量已经上了锁, 调用线程会阻塞, 直到互斥量被解锁.
在完成了对共享资源的访问后, 要对互斥量进行解锁. 首先说一下加锁函数:</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_mutex_lock</span><span class="params">(<span class="type">pthread_mutex_t</span> *mutex)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_mutex_trylock</span><span class="params">(<span class="type">pthread_mutex_t</span> *mutex)</span></span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>返回值: 成功则返回0, 出错则返回错误编号. 说 明:
具体说一下<code>trylock</code>函数,
这个函数是<strong>非阻塞</strong>调用模式, 也就是说, 如果互斥量没被锁住,
<code>trylock</code>函数将把互斥量加锁, 并获得对共享资源的访问权限;
如果互斥量被锁住了,
<code>trylock</code>函数将不会阻塞等待而直接返回EBUSY,
表示共享资源处于忙状态.</p>
</blockquote>
<p>再说一下解锁函数: 头文件: <code>&lt;pthread.h&gt;</code>
原型:<code>int pthread_mutex_unlock(pthread_mutex_t *mutex);</code>
返回值: 成功则返回0, 出错则返回错误编号.</p>
<ol start="3" type="1">
<li>死锁:
是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。
死锁主要发生在有<strong>多个依赖锁</strong>存在时,
会在一个线程试图以与另一个线程相反顺序锁住互斥量时发生.</li>
</ol>
<blockquote>
<p>如何避免死锁是使用互斥量应该格外注意的东西， 从以下原则入手： *
对共享资源操作前一定要获得锁. * 完成操作以后一定要释放锁. *
尽量短时间地占用锁. * 如果有多锁, 如获得顺序是ABC连环扣,
释放顺序也应该是ABC. * 线程错误返回时应该释放它所获得的锁.</p>
</blockquote>
<h4 id="读写锁">读写锁</h4>
<pre><code>在线程同步系列的第一篇文章里已经说过, 读写锁是因为有3种状态, 所以可以有更高的并行性.</code></pre>
<ol type="1">
<li>特性: 一次只有一个线程可以占有写模式的读写锁,
但是可以有多个线程同时占有读模式的读写锁. 正是因为这个特性,
当读写锁是写加锁状态时, 在这个锁被解锁之前,
所有试图对这个锁加锁的线程都会被阻塞. 当读写锁在读加锁状态时,
所有试图以读模式对它进行加锁的线程都可以得到访问权,
但是如果线程希望以写模式对此锁进行加锁, 它必须阻塞直到所有的线程释放锁.
通常, 当读写锁处于读模式锁住状态时, 如果有另外线程试图以写模式加锁,
读写锁通常会阻塞随后的读模式锁请求, 这样可以避免读模式锁长期占用,
而等待的写模式锁请求长期阻塞.</li>
<li>适用性: 读写锁适合于对数据结构的读次数比写次数多得多的情况. 因为,
读模式锁定时可以共享, 以写模式锁住时意味着独占,
所以读写锁又叫共享-独占锁.</li>
<li>初始化和销毁:</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_rwlock_init</span><span class="params">(<span class="type">pthread_rwlock_t</span> *restrict rwlock, <span class="type">const</span> <span class="type">pthread_rwlockattr_t</span> *restrict attr)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_rwlock_destroy</span><span class="params">(<span class="type">pthread_rwlock_t</span> *rwlock)</span></span>;</span><br></pre></td></tr></table></figure>
<p>成功则返回0, 出错则返回错误编号. 同互斥量以上,
在释放读写锁占用的内存之前,
需要先通过<code>pthread_rwlock_destroy</code>对读写锁进行清理工作,
释放由<code>init</code>分配的资源.</p>
<ol start="4" type="1">
<li>读和写:</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_rwlock_rdlock</span><span class="params">(<span class="type">pthread_rwlock_t</span> *rwlock)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_rwlock_wrlock</span><span class="params">(<span class="type">pthread_rwlock_t</span> *rwlock)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_rwlock_unlock</span><span class="params">(<span class="type">pthread_rwlock_t</span> *rwlock)</span></span>;</span><br></pre></td></tr></table></figure>
<p>成功则返回0, 出错则返回错误编号. 这3个函数分别实现获取读锁,
获取写锁和释放锁的操作. 获取锁的两个函数是阻塞操作, 同样,
非阻塞的函数为:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_rwlock_tryrdlock</span><span class="params">(<span class="type">pthread_rwlock_t</span> *rwlock)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_rwlock_trywrlock</span><span class="params">(<span class="type">pthread_rwlock_t</span> *rwlock)</span></span>;</span><br></pre></td></tr></table></figure>
<p>成功则返回0, 出错则返回错误编号. 非阻塞的获取锁操作,
如果可以获取则返回0, 否则返回错误的EBUSY.</p>
<h4 id="条件变量">条件变量</h4>
<pre><code> 条件变量分为两部分: 条件和变量. 条件本身是由互斥量保护的. 线程在改变条件状态前先要锁住互斥量.</code></pre>
<ol type="1">
<li>初始化: 条件变量采用的数据类型是<code>pthread_cond_t</code>,
在使用之前必须要进行初始化, 这包括两种方式: 静态:
可以把常量<code>PTHREAD_COND_INITIALIZER</code>给静态分配的条件变量.
动态: <code>pthread_cond_init</code>函数,
是释放动态条件变量的内存空间之前,
要用<code>pthread_cond_destroy</code>对其进行清理.</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_cond_init</span><span class="params">(<span class="type">pthread_cond_t</span> *restrict cond, <span class="type">pthread_condattr_t</span> *restrict attr)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_cond_destroy</span><span class="params">(<span class="type">pthread_cond_t</span> *cond)</span></span>;</span><br></pre></td></tr></table></figure>
<p>成功则返回0, 出错则返回错误编号. 当<code>pthread_cond_init</code>
的attr参数为NULL时, 会创建一个默认属性的条件变量;
非默认情况以后讨论.</p>
<ol start="2" type="1">
<li>等待条件:</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_cond_wait</span><span class="params">(<span class="type">pthread_cond_t</span> *restrict cond, <span class="type">pthread_mutex_t</span> *restric mutex)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_cond_timedwait</span><span class="params">(<span class="type">pthread_cond_t</span> *restrict cond, <span class="type">pthread_mutex_t</span> *restrict mutex,\</span></span></span><br><span class="line"><span class="params"><span class="function">                             <span class="type">const</span> <span class="keyword">struct</span> timespec *restrict timeout)</span></span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>成功则返回0, 出错则返回错误编号. 这两个函数分别是阻塞等待和超时等待.
等待条件函数等待条件变为真,
传递给<code>pthread_cond_wait</code>的互斥量对条件进行保护,
调用者把锁住的互斥量传递给函数. 函数把调用线程放到等待条件的线程列表上,
然后对互斥量解锁, 这两个操作是原子的. 这样便关闭了条件检查和线程进入
休眠状态等待条件改变这两个操作之间的时间通道,
这样线程就不会错过条件的任何变化.
当<code>pthread_cond_wait</code>返回时, 互斥量再次被锁住.</p>
</blockquote>
<ol start="3" type="1">
<li>通知条件:</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_cond_signal</span><span class="params">(<span class="type">pthread_cond_t</span> *cond)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_cond_broadcast</span><span class="params">(<span class="type">pthread_cond_t</span> *cond)</span></span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>成功则返回0, 出错则返回错误编号. 这两个函数用于通知线程条件已经满足.
调用这两个函数, 也称向线程或条件发送信号. <strong>必须注意,
一定要在改变条件状态以后再给线程发送信号.</strong></p>
</blockquote>
<h2 id="基础知识">基础知识</h2>
<h3 id="判断连个整数的和是否溢出">判断连个整数的和是否溢出</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 无符号类型</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">uadd_ok</span><span class="params">(<span class="type">unsigned</span> x, <span class="type">unsigned</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="type">unsigned</span> z = x + y;</span><br><span class="line">   <span class="keyword">if</span>(z &lt; x)</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 有符号类型只需要考虑一边即可</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">add_ok</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="type">int</span> z = x + y;</span><br><span class="line">   <span class="keyword">if</span>(x &gt; <span class="number">0</span> &amp;&amp; y &gt; <span class="number">0</span> &amp;&amp; z &lt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">   <span class="keyword">if</span>(x &lt; <span class="number">0</span> &amp;&amp; y &lt;  <span class="number">0</span> &amp;&amp; z &gt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>笔记：OpenCV中的算法--透视和仿射变换</title>
    <url>/201801/20180118-cv-transform/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>仿射变换保证物体形状的“平直性”和“平行性”。透视变换不能保证物体形状的“平行性”。仿射变换是透视变换的特殊形式。</p>
<p>仿射变换，又称仿射映射，是指在几何中，一个向量空间进行一次线性变换并接上一个平移，变换为另一个向量空间。仿射变换是在几何上定义为两个向量空间之间的一个仿射变换或者仿射映射（来自拉丁语，affine，“和…相关”）由一个非奇异的线性变换(运用一次函数进行的变换)接上一个平移变换组成。</p>
<h2
id="warpperspective-和-affinetransform的转换矩阵的区别">warpPerspective
和 affineTransform的转换矩阵的区别</h2>
<ol type="1">
<li>affineTransform保持平行性，而warpPerspective不能保证</li>
<li>warpPerspective至少4个点对，而 affineTransform至少三个点对
下面是opencv中关于这两个变换矩阵的求解过程。</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/* Calculates coefficients of perspective transformation</span></span><br><span class="line"><span class="comment"> * which maps (xi,yi) to (ui,vi), (i=1,2,3,4):</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *      c00*xi + c01*yi + c02</span></span><br><span class="line"><span class="comment"> * ui = ---------------------</span></span><br><span class="line"><span class="comment"> *      c20*xi + c21*yi + c22</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *      c10*xi + c11*yi + c12</span></span><br><span class="line"><span class="comment"> * vi = ---------------------</span></span><br><span class="line"><span class="comment"> *      c20*xi + c21*yi + c22</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Coefficients are calculated by solving linear system:</span></span><br><span class="line"><span class="comment"> * / x0 y0 1 0 0 0 -x0*u0 -y0*u0 \ /c00\ /u0\</span></span><br><span class="line"><span class="comment"> * | x1 y1 1 0 0 0 -x1*u1 -y1*u1 | |c01| |u1|</span></span><br><span class="line"><span class="comment"> * | x2 y2 1 0 0 0 -x2*u2 -y2*u2 | |c02| |u2|</span></span><br><span class="line"><span class="comment"> * | x3 y3 1 0 0 0 -x3*u3 -y3*u3 |.|c10|=|u3|,</span></span><br><span class="line"><span class="comment"> * | 0 0 0 x0 y0 1 -x0*v0 -y0*v0 | |c11| |v0|</span></span><br><span class="line"><span class="comment"> * | 0 0 0 x1 y1 1 -x1*v1 -y1*v1 | |c12| |v1|</span></span><br><span class="line"><span class="comment"> * | 0 0 0 x2 y2 1 -x2*v2 -y2*v2 | |c20| |v2|</span></span><br><span class="line"><span class="comment"> * \ 0 0 0 x3 y3 1 -x3*v3 -y3*v3 / \c21/ \v3/</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * where:</span></span><br><span class="line"><span class="comment"> * cij - matrix coefficients, c22 = 1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">cv::Mat <span class="title">cv::getPerspectiveTransform</span><span class="params">( <span class="type">const</span> Point2f src[], <span class="type">const</span> Point2f dst[] )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function">Mat <span class="title">M</span><span class="params">(<span class="number">3</span>, <span class="number">3</span>, CV_64F)</span>, <span class="title">X</span><span class="params">(<span class="number">8</span>, <span class="number">1</span>, CV_64F, M.data)</span></span>;</span><br><span class="line">  <span class="type">double</span> a[<span class="number">8</span>][<span class="number">8</span>], b[<span class="number">8</span>];</span><br><span class="line">  <span class="function">Mat <span class="title">A</span><span class="params">(<span class="number">8</span>, <span class="number">8</span>, CV_64F, a)</span>, <span class="title">B</span><span class="params">(<span class="number">8</span>, <span class="number">1</span>, CV_64F, b)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>( <span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i )</span><br><span class="line">  &#123;</span><br><span class="line">  a[i][<span class="number">0</span>] = a[i+<span class="number">4</span>][<span class="number">3</span>] = src[i].x;</span><br><span class="line">  a[i][<span class="number">1</span>] = a[i+<span class="number">4</span>][<span class="number">4</span>] = src[i].y;</span><br><span class="line">  a[i][<span class="number">2</span>] = a[i+<span class="number">4</span>][<span class="number">5</span>] = <span class="number">1</span>;</span><br><span class="line">  a[i][<span class="number">3</span>] = a[i][<span class="number">4</span>] = a[i][<span class="number">5</span>] =</span><br><span class="line">  a[i+<span class="number">4</span>][<span class="number">0</span>] = a[i+<span class="number">4</span>][<span class="number">1</span>] = a[i+<span class="number">4</span>][<span class="number">2</span>] = <span class="number">0</span>;</span><br><span class="line">  a[i][<span class="number">6</span>] = -src[i].x*dst[i].x;</span><br><span class="line">  a[i][<span class="number">7</span>] = -src[i].y*dst[i].x;</span><br><span class="line">  a[i+<span class="number">4</span>][<span class="number">6</span>] = -src[i].x*dst[i].y;</span><br><span class="line">  a[i+<span class="number">4</span>][<span class="number">7</span>] = -src[i].y*dst[i].y;</span><br><span class="line">  b[i] = dst[i].x;</span><br><span class="line">  b[i+<span class="number">4</span>] = dst[i].y;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">solve</span>( A, B, X, DECOMP_SVD );</span><br><span class="line">  ((<span class="type">double</span>*)M.data)[<span class="number">8</span>] = <span class="number">1.</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> M;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Calculates coefficients of affine transformation</span></span><br><span class="line"><span class="comment"> * which maps (xi,yi) to (ui,vi), (i=1,2,3):</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * ui = c00*xi + c01*yi + c02</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * vi = c10*xi + c11*yi + c12</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Coefficients are calculated by solving linear system:</span></span><br><span class="line"><span class="comment"> * / x0 y0 1 0 0 0 \ /c00\ /u0\</span></span><br><span class="line"><span class="comment"> * | x1 y1 1 0 0 0 | |c01| |u1|</span></span><br><span class="line"><span class="comment"> * | x2 y2 1 0 0 0 | |c02| |u2|</span></span><br><span class="line"><span class="comment"> * | 0 0 0 x0 y0 1 | |c10| |v0|</span></span><br><span class="line"><span class="comment"> * | 0 0 0 x1 y1 1 | |c11| |v1|</span></span><br><span class="line"><span class="comment"> * \ 0 0 0 x2 y2 1 / |c12| |v2|</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * where:</span></span><br><span class="line"><span class="comment"> * cij - matrix coefficients</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function">cv::Mat <span class="title">cv::getAffineTransform</span><span class="params">( <span class="type">const</span> Point2f src[], <span class="type">const</span> Point2f dst[] )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function">Mat <span class="title">M</span><span class="params">(<span class="number">2</span>, <span class="number">3</span>, CV_64F)</span>, <span class="title">X</span><span class="params">(<span class="number">6</span>, <span class="number">1</span>, CV_64F, M.data)</span></span>;</span><br><span class="line">  <span class="type">double</span> a[<span class="number">6</span>*<span class="number">6</span>], b[<span class="number">6</span>];</span><br><span class="line">  <span class="function">Mat <span class="title">A</span><span class="params">(<span class="number">6</span>, <span class="number">6</span>, CV_64F, a)</span>, <span class="title">B</span><span class="params">(<span class="number">6</span>, <span class="number">1</span>, CV_64F, b)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>( <span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++ )</span><br><span class="line">  &#123;</span><br><span class="line">  <span class="type">int</span> j = i*<span class="number">12</span>;</span><br><span class="line">  <span class="type">int</span> k = i*<span class="number">12</span>+<span class="number">6</span>;</span><br><span class="line">  a[j] = a[k+<span class="number">3</span>] = src[i].x;</span><br><span class="line">  a[j+<span class="number">1</span>] = a[k+<span class="number">4</span>] = src[i].y;</span><br><span class="line">  a[j+<span class="number">2</span>] = a[k+<span class="number">5</span>] = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  a[j+<span class="number">3</span>] = a[j+<span class="number">4</span>] = a[j+<span class="number">5</span>] = <span class="number">0</span>;</span><br><span class="line">  a[k] = a[k+<span class="number">1</span>] = a[k+<span class="number">2</span>] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  b[i*<span class="number">2</span>] = dst[i].x;</span><br><span class="line">  b[i*<span class="number">2</span>+<span class="number">1</span>] = dst[i].y;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">solve</span>( A, B, X );</span><br><span class="line">  <span class="keyword">return</span> M;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果我们要自己实现这个函数，其实关键就是在于如何求解AX=B的问题。当然，我们可以直接调用库函数，如<code>eigen</code>.</p>
<h3
id="问题这个函数如果要自己实现如何测试正确性">问题：这个函数如果要自己实现，如何测试正确性？</h3>
<ul>
<li><p>方案1：
采用引入opencv作为第三方库，然后相同的输入结果与opencv中进行对比。这种方法简单，但是需要引入庞大的第三方库opencv</p></li>
<li><p>方案2：
采用两次变换，例如测试<code>warp_perspective</code>其中第一次将<code>src_img</code>经过<code>warp_perspective</code>变换为<code>dst_img</code>，其中转换矩阵为M;
然后将<code>dst_img</code>经过<code>warp_perspective</code>变换为<code>dst_warp</code>，其中转换矩阵为<code>M‘</code>为<code>M</code>的逆矩阵;
最后比较<code>dst_warp</code>和<code>src</code>中进行逐个像素对照，统计diff的像素个数count，
return count &lt;= thresh_value.
这种方法的缺点就是需要设置thresh_value，同时需要求M的逆矩阵</p></li>
<li><p>方案3：
如果不能将opencv作为第三方库引入，那么我们可以这样，将opencv的输入参数和结果作为hard
code的方式，进行测试。这种方法尤其是 再嵌入式开发中很常见。</p></li>
</ul>
<h2 id="更多信息可以参考">更多信息可以参考</h2>
<p>[1]
https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.html</p>
<p>[2] gTest的原理： http://cwlseu.github.io/st-CMAKE-and-gTest/搜索</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux开发标准：Linux Standard Base</title>
    <url>/201711/20171128-Std-LSB/</url>
    <content><![CDATA[<h2 id="unixlinux-标准化历史">Unix/Linux 标准化历史</h2>
<p>标准化目前已经成为 Linux 系统上的一个热门话题。实际上，在 Linux
诞生之初，这个问题就得到了重视。当 Linus 在开发 0.01 版本的 Linux
内核时，就开始关注 <code>POSIX</code> 标准的发展，他在
<code>/include/unistd.h</code> 文件中定义了几个与 <code>POSIX</code>
有关的宏，以下内容就节选自 0.01 版本内核的
<code>/include/unistd.h</code> 文件： <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* ok, this may be a joke, but I&#x27;m working on it */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _POSIX_VERSION 198808L</span></span><br></pre></td></tr></table></figure> 下面我们就从
POSIX入手开始介绍 Unix/Linux 方面的标准化发展历程。</p>
<h3 id="posix">POSIX</h3>
<p>Unix 1969 年诞生于 AT&amp;T 贝尔实验室，并在 1973 年使用 C
语言进行了重写，从此就具有了很好的可移植性。但是当 AT&amp;T 在 1984
年由于分拆而得以进入计算机领域的市场之后，却引发了 Unix
业界的一场大战。当时最为主要的两个版本是 AT&amp;T 的 System V 和伯克利的
BSD。二者在技术方面（例如终端）和文化方面都存在很多分歧，导致应用程序很难在不同的系统上平滑地进行移植，为了解决这个问题，IEEE（Institute
of Electrical and Electronic Engineers）的 1003
委员会着手开发了一系列标准，这就是后来的 <code>POSIX</code>（Portable
Operating System Interface for UNIX）标准。其目的是为那些兼容各种 UNIX
变种的应用程序制定应用程序编程接口（API）规范，从而确保这些应用程序的兼容性。这些标准后来被
ISO/IEC 采纳，成为 ISO/IEC 9945 标准。</p>
<p><code>POSIX</code> 在 15
份不同的文档中对操作系统与用户软件的接口进行了规范，主要内容包括3个部分：
* POSIX 系统调用 * POSIX 命令和工具 * POSIX 兼容测试 同时还提供了一套
POSIX 兼容性测试工具，称为 PCTS（POSIX Conformance Test Suite）。</p>
<p>后来 <code>POSIX</code> 标准又进行了很多扩充，主要包括： 1.
POSIX.1，核心服务：主要集成了 ANSI C
标准，包括进程创建和控制、信号、浮点异常、段错误、非法指令、总线错误、定时器、文件和目录操作、管道、C
标准库、I/O 端口和控制 2.
POSIX.1b，实时扩展：包括优先级调度、实时信号、时钟和定时器、信号量、消息传递、共享内存、异步和同步
I/O、内存锁 3.
POSIX.1c，线程扩展：包括线程创建和控制、线程调度、线程同步、信号处理</p>
<p><code>POSIX</code> 最初的设计目标是为 Unix System V 和 BSD Unix 等
Unix
系统上的特性制定规范，使其可以实现更好的可移植性。但是很多其他系统都也兼容<code>POSIX</code>
标准。例如，微软的 Windows NT 就兼容 <code>POSIX</code>
标准的实时部分（POSIX.1b），而 RTOS（LynxOS real-time operating
system）也与 <code>POSIX</code> 标准兼容。Windows 上可以通过安装 Windows
的 Services for UNIX 或 Cygwin 来增强对 <code>POSIX</code>
标准的兼容度。</p>
<h3 id="open-group">Open Group</h3>
<p>Open Group 是现在 Unix 商标的拥有者，其前身是 X/Open。X/Open 是 Unix
厂商在 1984 年成立的一个联盟，它试图为众多 Unix
变种定义一个安全公共子集，因此即使在 Unix
混战的年代，也得到了比较好的发展。在 1993 年，包括主要 Unix 公司在内的75
家系统和软件供应商委托 X/Open 为 Unix
制定一个统一的规范。X/Open在现有标准基础上，增加了对终端进行处理的 API
和 X11 API，并全面兼容 1989 ANSI C 标准，最终诞生了第一版本的单一
Unix规范（Single Unix Specification，简称 SUS）。 X/Open在 1996 年与
OSF（开放软件基金会）进行合并，成立了 Open Group
组织，专门从事开放标准的制定和推广工作，并对很多领域提供了认证，包括
Unix 操作系统、Motif 和 CDE（Common Desktop Environment）用户界面。
Austin Group Austin Group 是在 1998
年成立的一个合作技术工作组，其使命是开发并维护 POSIX.1 和 SUS
规范。Austin Group 开发规范的方法是"write once, adopt everywhere"，即由
Austin Group 制定的规范既会成为 IEEE POSIX 规范，又会成为 Open Group 的
技术标准规范，以后又会被采纳为 ISO/IEC
的标准。新开发的规范后来就被标准化为 ISO/IEC 9945 和IEEE Std
1003.1，并成为 SUSV3 的核心部分。
这种独特的开发模式最大限度地利用了业界领先的工作成果，将正式的标准化工作转化成了一个唯一的行为，并且吸引了广泛的参与者。Austin
Group 目前有 500 多个参与者，工作组的主席是 Open Group 的 Andrew
Josey。</p>
<h3 id="lsb">LSB</h3>
<p>在90 年代中期，Linux 也开始了自己的标准化努力。实际上，Linux
一直都试图遵守 <code>POSIX</code>
标准，因此在源代码级上具有很好的兼容性，然而对于 Linux
来说，仅仅保证源码级的兼容性还不能完全满足要求：在 Unix
时代，大部分系统都使用的是专有的硬件，软件开发商必须负责将自己的应用程序从一个平台移植到其他平台上；每个系统的生命周期也很长，软件开发商可以投入足够的资源为各个平台发布二进制文件。然而
Linux 使用的最广泛的 x86
通用平台，其发行版是如此众多，而发展却如此之快，软件开发商不可能为每个发行版都发布一个二进制文件，因此就为
Linux
上的标准化提出了一个新的要求：二进制兼容性，即二进制程序不需要重新编译，就可以在其他发行版上运行。
实际上，在 Linux 社区中第一个标准化努力是文件系统层次标准（Filesystem
Hierarchy
Standard，FHS），用来规范系统文件、工具和程序的存放位置和系统中的目录层次结构，例如
ifconfig 命令应该放在 <code>/usr/bin</code> 还是 <code>/usr/sbin</code>
目录中，光驱应该挂载到 <code>/mnt/cdrom</code> 中还是
<code>/media/cdrom</code> 中。这些需求最终共同促进了 Linux Standard
Base（LSB）项目的诞生。 LSB目前是 FSG（Free Standards
Group）中最为活跃的一个工作组，其使命是开发一系列标准来增强 Linux
发行版的兼容性，使各种软件可以很好地在兼容 LSB
标准的系统上运行，从而可以帮助软件供应商更好地在 Linux
系统上开发产品，或将已有的产品移植到 Linux 系统上。</p>
<p>LSB 以 <code>POSIX</code> 和 SUS
标准为基础，并对其他领域（例如图形）中源代码的一些标准进行了扩充，还增加了对二进制可执行文件格式规范的定义，从而试图确保
Linux 上应用程序源码和二进制文件的兼容性。</p>
<h2 id="lsb简介">LSB简介</h2>
<p>LSB是Linux Standard
Base取首字母的缩写。LSB的目标是制定标准提高Linux系统与其他相似系统的兼容性。LSB标准定义了二进制环境，符合LSB的应用程序在其中可以可以在其中运行。LSB
是 Linux 标准化领域中事实上的标准，它的图标（请参看图
1）非常形象地阐述了自己的使命：对代表自由的企鹅（Linux）制定标准。给定企鹅的体形和三维标准之后，软件开发者就可以设计并裁减出各色花样的衣服（应用程序），这样不管穿在哪只企鹅身上，都会非常合身。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030306242.png"
alt="@图 1 LSB图标" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="图">@图</span> 1 LSB图标</figcaption>
</figure>
<p>在现有标准基础上，LSB
制定了应用程序与运行环境之间的二进制接口，这主要是基于以下标准： 1.
Single UNIX Specification（SUS） 2. System V Interface
Definition（SVID） 3. compilers for the Intel Itanium processor 4. C++
ABI 5. System V Application Binary Interface（ABI）</p>
<p>同时，LSB 充分吸取了 UNIX
标准化努力所取得经验和教训，回避了这些标准的一些问题。例如，<code>POSIX</code>
仅仅定义了编程接口的标准，但是它却无法保证二进制的兼容性。而诸如 OSF/1
之类的标准虽然试图解决二进制兼容性的问题，但是限制却太为严格。LSB
在二者之间达成了一个平衡，它包含了一个二进制兼容层，同时消除了
<code>POSIX</code> 与 OSF/1 之间存在分歧的地方。 LSB
对各个库提供的接口以及与每个接口相关的数据结构和常量进行了定义，图2给出了
LSB 3.1 环境中所包含的组件。这些组件包括开发者所需要的共享库（包括
C++），文件系统层次结构（FHS）、对象文件格式、命令和工具、应用程序包、用户和组、系统初始化等所采用的规范：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030306678.jpg"
alt="图 2 LSB 3.1规范包含的组件" />
<figcaption aria-hidden="true">图 2 LSB 3.1规范包含的组件</figcaption>
</figure>
<h2 id="lsb发展的路线图">LSB发展的路线图</h2>
<p>　 　LSB 项目最初发起于 1998 年 5 月，其项目启动宣言得到了 Linus
Torvalds、Bruce Perens、Eric Raymond
等人的签名支持，当时的目标是建立一系列构建 Linux
发行版所采用的源代码应该遵循的标准，并提供一个参考平台。 * 2000 年 5
月，LSB 成为 Free Standards Group（FSG）
的一个工作组，全面负责LSB计划。FSG
是一个独立的非盈利组织，专注于通过开发和促进标准来加速开源软件的发展。 *
2001年7月4日，LSB 1.0发布，迈出了Linux标准化道路上重要的一大步。LSB
1.0的规范仅包括了通用LSB（LSB Common）1.0.0。 *
2002年2月4日，在美国召开的LinuxWorld大会上，HP、IBM、拓林思、SuSE、Red
Hat、Caldera和Ximian公司联合发布了LSB 1.1。LSB
1.1对Linux核心功能和一些组件进行了标准化。它包括一组公共API、一个开发包和一些测试功能。LSB
1.1在1.0的基础上增加了对IA32架构处理器的支持，规范包括通用LSB
1.1.0和IA32处理器专用规范（LSB IA32）1.1.0。LSB 1.2 LSB
1.2包括了通用LSB规范及对IA32、IA64和PPC32架构处理器的专用规范。LSB 1.3
LSB 1.3在1.2的基础上又增加了对IBM S/390和S/390X的支持。规范包括通用LSB
1.3、LSB IA32 1.3、LSB IA64 1.3、LSB PPC32 1.3、LSB S390 1.3和LSB S390X
1.3。 * 2004年9月14日正式发布LSB
2.0。其最大特点是增加了对C++的二进制接口。2004年10月21日，LSB
2.0.1发布。 * 2005年7月1日， LSB 3.0发布。LSB
3.0更新了原来版本的一些基本规范和执行，特别是SUS（Single Unix
Specification，单一Unix规范）的升级。以SUS 3.0为基础。SUS
3.0同时也是IEEE 1003 1-2001标准（POSIX）和ISO/IEC 9945:2003标准。LSB
3.0中最重要的是文档的重构和LSB上层附加标准的发展。文档重构的目的是推动LSB未来的发展。LSB
3.0中另一个重要的新特点是引入了对POSIX线程和C++应用的支持，它增加了C++的应用二进制接口（ABI），用于改善代码互用性。
这一特点意义重大，因为现在的大多数应用都是用C++编写，通过在LSB中加入C++支持，使数以千计的软件开发商能以较低成本将他们的应用移植到
Linux上，由此带来Linux应用软件数量上的突飞猛进。LSB
3.0的文档结构是附加规范模块的根基，这些附加规范模块在核心LSB规范（Core
LSB
Specification）之上。这些新模块允许新功能的增加，其中一些功能甚至是被认为在LSB范围之外的。
新模块还允许LSB以外的组织通过使用 LSB确定的框架来添加新功能。LSB 3.0.0
标准文档，LSB标准发展到了3.0，结构与2.0一样。LSB 3.0 基于新的C++
二进制接口，还有其他的改进。另外还包括PAM和FHS
2.3。，以及包括加入gcc3.4，librt，一些新功能和新接口以及新命令等。 * LSB
3.1 版本的规范主要是增强了对桌面系统的标准化支持，增加了对 GTK 和 QT GUI
工具包的标准化。另外，LSB 还调整了自己的路线图，以便可以与主流的 Linux
发行商（Redhat、Novell、Asianux、Debian
等）的发行计划更好地吻合，并吸引了更多 Linux
发行商的参与，对开发工具和文档进行了改进，还与各个国家的组织（例如中国电子技术标准化研究所，CESI）进行认证方面的合作。截止到3.1版本，该规范可以支持
7 种体系结构： - IA32 - IA64 - X86_64 - PPC32 - PPC64 - S390 - S390x</p>
<ul>
<li>LSB 4.0 在 2008 年发布，它将实现更好的二进制兼容性，并增加对
Perl、Python、LAMP、Java
等语言的标准化支持。详细路线图及各个主要版本的特性如图 3 所示：</li>
</ul>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030306889.jpg"
alt="图 3 LSB 主要版本的路线图" />
<figcaption aria-hidden="true">图 3 LSB 主要版本的路线图</figcaption>
</figure>
<ul>
<li>LSB 5.0 was released June 3, 2015</li>
</ul>
<h2 id="在linux上的测试结果">在Linux上的测试结果</h2>
<h3 id="ubuntu-16.04">ubuntu 16.04</h3>
<ol type="1">
<li><p>下载<code>https://ftp.linuxbase.org/pub/lsb/bundles/released-5.0.0/app-testkit/lsb-app-checker-5.0.0-3.x86_64.tar.gz</code></p></li>
<li><p>运行<code>./lsb-app-checker/bin/app-check-start.pl</code></p></li>
</ol>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030307939.png"
alt="@LSB初始界面" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="LSB初始界面">@LSB初始界面</span></figcaption>
</figure>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030307159.png"
alt="@LSB报告界面" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="LSB报告界面">@LSB报告界面</span></figcaption>
</figure>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030307390.png"
alt="@LSB调用接口分析界面" /> 在ubuntu16.04上安装正常，使用正常。</p>
<h3
id="cdos上安装失败出现500-internal-server-error">CDOS上安装失败，出现500
Internal Server Error</h3>
<ol type="1">
<li>安装lsb和lsb-core <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030307364.png"
alt="@安装lsb过程中出现包依赖错误" /></li>
<li>lsb-app-checker访问错误1 <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030307354.png"
alt="@访问错误" /> 后面经过几番折腾，已经fix掉。开始使用进行application
LSB标准检测吧。结果出现如下问题： <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030307079.png"
alt="@数据分析错误" /></li>
</ol>
<h2 id="参考文献">参考文献</h2>
<p>[1]. LSB 5.0 Specifications Archive:
http://refspecs.linuxbase.org/LSB_5.0.0/allspecs.shtml</p>
<p>[2]. LSB 4.1 Release Notes
https://wiki.linuxfoundation.org/lsb/lsb-41-release-notes</p>
<p>[3]. LSB 下载：https://www.linuxbase.org/download/</p>
<p>[4]. ISO/IEC 23360 Spec文档下载链接，点击I accept:
http://standards.iso.org/ittf/PubliclyAvailableStandards/c043781_to_043788_ISO_IEC_23360_2006_LSB.zip</p>
<p>[5].
LSB简介：https://www.ibm.com/developerworks/cn/linux/l-lsb-intr/index.html</p>
<p>[6]. 有关 Open Group
以及相关标准的介绍，http://www.opengroup.org/</p>
<p>[7]. Free Standards
Group（FSG）及其主持的项目的信息：http://www.freestandards.org</p>
<p>[8]. Austin Group 的更多信息 http://www.opengroup.org/austin/</p>
<p>[9]. Unix 的发展历史和标准化努力，请参考Eric S. Raymond 撰写的"The
Art of Unix
Programming"一书（http://www.faqs.org/docs/artu/index.html</p>
<p>[10]. History and Timeline
（http://www.unix.org/what_is_unix/history_timeline.html</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux开发</tag>
        <tag>standard</tag>
      </tags>
  </entry>
  <entry>
    <title>开发笔记：Eigen开源库的应用</title>
    <url>/201802/20180203-Eigen-Open-Libs/</url>
    <content><![CDATA[<h2 id="eigen与c之间数据转换">Eigen与C之间数据转换</h2>
<h3 id="to-eigen">to Eigen</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span>* raw_data = <span class="built_in">malloc</span>(...);</span><br><span class="line"><span class="function">Map&lt;MatrixXd&gt; <span class="title">M</span><span class="params">(raw_data, rows, cols)</span></span>;</span><br><span class="line"><span class="comment">// use M as a MatrixXd</span></span><br><span class="line">M = M.<span class="built_in">inverse</span>();</span><br></pre></td></tr></table></figure>
<h3 id="from-eigen">from Eigen</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">MatrixXd M;</span><br><span class="line"><span class="type">float</span>* raw_data = M.<span class="built_in">data</span>();</span><br><span class="line"><span class="type">int</span> stride = M.<span class="built_in">outerStride</span>();</span><br><span class="line">raw_data[i+j*stride]</span><br></pre></td></tr></table></figure>
<h2 id="一些预备知识">一些预备知识</h2>
<h3 id="template-programming">template programming</h3>
<h3 id="levels-并行">4 levels 并行</h3>
<ul>
<li>cluster of PCs --MPI</li>
<li>multi/many-cores -- OpenMP</li>
<li>SIMD -- intrinsics for vector instructions</li>
<li>pipelining -- needs non dependent instructions</li>
</ul>
<h3 id="peak-performance">Peak Performance</h3>
<blockquote>
<p>Example： Intel Core2 Quad CPU Q9400 @ 2.66GHz (x86_64)</p>
</blockquote>
<pre><code>* pipelining → 1 mul + 1 add / cycle (ideal case)
* SSE → x 4 single precision ops at once
* frequency → x 2.66G
* peak performance: 21,790 Mflops (for 1 core)</code></pre>
<p>这就是我们优化的目标</p>
<h2 id="fused-operation-expression-template">Fused operation: Expression
Template</h2>
<p>Expression
Template是个好东西。通过编译融合嵌入的方式，减少了大量的读写和计算。</p>
<h2 id="curiously-recurring-template-pattern">Curiously Recurring
Template Pattern</h2>
<h2 id="eigen常见的坑"><a
href="https://zhuanlan.zhihu.com/p/32226967">Eigen常见的坑</a></h2>
<h3
id="编译的时候最好-deigen_mpl2_only详见-eigen">编译的时候最好-DEIGEN_MPL2_ONLY(详见:
Eigen)</h3>
<p>这是因为Eigen虽然大部分是MPL2 licensed的，但是还有少部分代码是LGPL
licensed的，如果修改了其代码，则必须开源。
这可能产生法律风险，而遭到法务部门的Complain</p>
<h3 id="要注意alignment的问题">要注意alignment的问题</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">my_program: path/to/eigen/Eigen/src/Core/DenseStorage.h:44:</span><br><span class="line">Eigen::internal::matrix_array&lt;T, Size, MatrixOptions, Align&gt;::internal::matrix_array()</span><br><span class="line">[with T = double, int Size = 2, int MatrixOptions = 2, bool Align = true]:</span><br><span class="line">Assertion `(reinterpret_cast&lt;size_t&gt;(array) &amp; (sizemask)) == 0 &amp;&amp; &quot;this assertion</span><br><span class="line">is explained here: http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html</span><br><span class="line">     READ THIS WEB PAGE !!! ****&quot;&#x27; failed.</span><br><span class="line">There are 4 known causes for this issue. Please read on to understand them and learn how to fix them.</span><br></pre></td></tr></table></figure>
<p>例如下面的代码都是有问题的，可能导致整个程序Crash。</p>
<ul>
<li>结构体含有Eigen类型的成员变量</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span> &#123;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  Eigen::Vector2d v; <span class="comment">// 这个类型只是一个例子，很多类型都有问题</span></span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line">Foo *foo = <span class="keyword">new</span> Foo;</span><br></pre></td></tr></table></figure>
<ul>
<li>Eigen类型的变量被放到STL容器中</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Eigen::Matrix2f这个类型只是一个例子，很多类型都有问题</span></span><br><span class="line">std::vector&lt;Eigen::Matrix2f&gt; my_vector;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">my_class</span> &#123; ... Eigen::Matrix2f m; ... &#125;; </span><br><span class="line">std::map&lt;<span class="type">int</span>, my_class&gt; my_map;</span><br></pre></td></tr></table></figure>
<ul>
<li>Eigen类型的变量被按值传入一个函数</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Eigen::Vector4d只是一个例子，很多类型都有这个问题</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(Eigen::Vector4d v)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>在栈上定义Eigen类型的变量(只有GCC4.4及以下版本 on
Windows被发现有这个问题，例如MinGW or TDM-GCC)</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Eigen::Quaternionf q; <span class="comment">// Eigen::Quaternionf只是一个例子，很多类型都有这个问题</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><a
href="http://eigen.tuxfamily.org/dox/group__TopicUnalignedArrayAssert.html">Explanation
of the assertion on unaligned arrays</a></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>HPC</tag>
        <tag>Template</tag>
      </tags>
  </entry>
  <entry>
    <title>开发：开源协议</title>
    <url>/201805/20180506-std-license-list/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>什么是许可，当你为你的产品签发许可，你是在出让自己的权利，不过，你仍然拥有版权和专利（如果申请了的话），许可的目的是，向使用你产品的人提供
一定的权限。</p>
<p>不管产品是免费向公众分发，还是出售，制定一份许可协议非常有用，否则，对于前者，你相当于放弃了自己所有的权利，任何人都没有义务表明你的原始作
者身份，对于后者，你将不得不花费比开发更多的精力用来逐个处理用户的授权问题。</p>
<p>而开源许可协议使这些事情变得简单，开发者很容易向一个项目贡献自己的代码，它还可以保护你原始作者的身份，使你
至少获得认可，开源许可协议还可以阻止其它人将某个产品据为己有。以下是开源界的
5 大许可协议。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030320927.jpeg"
alt="@ss" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="ss">@ss</span></figcaption>
</figure>
<h2 id="gnu-gpl">GNU GPL</h2>
<p>GNU General Public Licence (GPL) 有可能是开源界最常用的许可模式。GPL
保证了所有开发者的权利，同时为使用者提供了足够的复制，分发，修改的权利：</p>
<ul>
<li>可自由复制
你可以将软件复制到你的电脑，你客户的电脑，或者任何地方。复制份数没有任何限制。</li>
<li>可自由分发
在你的网站提供下载，拷贝到U盘送人，或者将源代码打印出来从窗户扔出去（环保起见，请别这样做）。</li>
<li>可以用来盈利
你可以在分发软件的时候收费，但你必须在收费前向你的客户提供该软件的 GNU
GPL
许可协议，以便让他们知道，他们可以从别的渠道免费得到这份软件，以及你收费的理由。</li>
<li>可自由修改
如果你想添加或删除某个功能，没问题，如果你想在别的项目中使用部分代码，也没问题，唯一的要求是，使用了这段代码的项目也必须使用
GPL 协议。</li>
</ul>
<p>需要注意的是，分发的时候，需要明确提供源代码和二进制文件，另外，用于某些程序的某些协议有一些问题和限制，你可以看一下
<span class="citation" data-cites="PierreJoye">@PierreJoye</span> 写的
Practical Guide to GPL Compliance 一文。使用 GPL
协议，你必须在源代码代码中包含相应信息，以及协议本身。</p>
<h2 id="gnu-lgpl">GNU LGPL</h2>
<p>GNU 还有另外一种协议，叫做 LGPL （Lesser General Public
Licence），它对产品所保留的权利比 GPL 少，
总的来说，LGPL适合那些用于非GPL或非开源产品的开源类库或框架。因为GPL要求，使用了GPL代码的产品必须也
使用GPL协议，开发者不允许将 GPL 代码用于商业产品。LGPL
绕过了这一限制。</p>
<h2 id="bsd">BSD</h2>
<p>BSD开源协议（original BSD license、FreeBSD license、Original BSD
license）一个给于使用者很大自由的协议。基本上使用者可以”为所欲为”,可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。
但”为所欲为”的前提当你发布使用了BSD协议的代码，或则以BSD协议代码为基础做二次开发自己的产品时，需要满足三个条件：
*
如果再发布的产品中包含源代码，则在源代码中必须带有原来代码中的BSD协议。
*
如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。
* 不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。</p>
<p>BSD
代码鼓励代码共享，但需要尊重代码作者的著作权。BSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销售，因此是对商业集成很友好的协议。而很多的公司企业在选用开源产品的时候都首选BSD协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者二次开发。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">Copyright 2008, Google Inc.</span><br><span class="line">All rights reserved.</span><br><span class="line"></span><br><span class="line">Redistribution and use in source and binary forms, with or without</span><br><span class="line">modification, are permitted provided that the following conditions are</span><br><span class="line">met:</span><br><span class="line"></span><br><span class="line"><span class="bullet">    *</span> Redistributions of source code must retain the above copyright</span><br><span class="line">notice, this list of conditions and the following disclaimer.</span><br><span class="line"><span class="bullet">    *</span> Redistributions in binary form must reproduce the above</span><br><span class="line">copyright notice, this list of conditions and the following disclaimer</span><br><span class="line">in the documentation and/or other materials provided with the</span><br><span class="line">Distribution.</span><br><span class="line"><span class="bullet">    *</span> Neither the name of Google Inc. nor the names of its</span><br><span class="line">contributors may be used to endorse or promote products derived from</span><br><span class="line">this software without specific prior written permission.</span><br><span class="line"></span><br><span class="line">THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS</span><br><span class="line">&quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT</span><br><span class="line">LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR</span><br><span class="line">A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT</span><br><span class="line">OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,</span><br><span class="line">SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT</span><br><span class="line">LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,</span><br><span class="line">DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY</span><br><span class="line">THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT</span><br><span class="line">(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE</span><br><span class="line">OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="mit">MIT</h2>
<p>MIT 协议可能是几大开源协议中最宽松的一个，核心条款是：
该软件及其相关文档对所有人免费，可以任意处置，包括使用，复制，修改，合并，发表，分发，再授权，或者销售。唯一的限制是，软件中必须包含上述版权和许可提示。</p>
<p>这意味着： * 你可以自由使用，复制，修改，可以用于自己的项目。 *
可以免费分发或用来盈利。 * 唯一的限制是必须包含许可声明。</p>
<p>MIT
协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">Copyright (c) <span class="language-xml"><span class="tag">&lt;<span class="name">year</span>&gt;</span></span> <span class="language-xml"><span class="tag">&lt;<span class="name">copyright</span> <span class="attr">holders</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line">Permission is hereby granted, free of charge, to any person obtaining a copy</span><br><span class="line">of this software and associated documentation files (the &quot;Software&quot;), to deal</span><br><span class="line">in the Software without restriction, including without limitation the rights</span><br><span class="line">to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span><br><span class="line">copies of the Software, and to permit persons to whom the Software is</span><br><span class="line">furnished to do so, subject to the following conditions:</span><br><span class="line"></span><br><span class="line">The above copyright notice and this permission notice shall be included in all</span><br><span class="line">copies or substantial portions of the Software.</span><br><span class="line"></span><br><span class="line">THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span><br><span class="line">IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span><br><span class="line">FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span><br><span class="line">AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span><br><span class="line">LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span><br><span class="line">OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span><br><span class="line">SOFTWARE.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="apache">Apache</h2>
<p>Apache协议2.0
和别的开源协议相比，除了为用户提供版权许可之外，还有专利许可，对于那些<strong>涉及专利内容</strong>
的开发者而言，该协议最适合（这里有 一篇文章阐述这个问题）。</p>
<p>Apache协议还有以下需要说明的地方:</p>
<ul>
<li>永久权利 一旦被授权，永久拥有。</li>
<li>全球范围的权利
在一个国家获得授权，适用于所有国家。假如你在美国，许可是从印度授权的，也没有问题。</li>
<li>授权免费，且无版税 前期，后期均无任何费用。</li>
<li>授权无排他性 任何人都可以获得授权</li>
<li>授权不可撤消
一旦获得授权，没有任何人可以取消。比如，你基于该产品代码开发了衍生产品，你不用担心会在某一天被禁止使用该代码。</li>
</ul>
<p>分发代码方面包含一些要求，主要是，要在声明中对参与开发的人给予认可并包含一份许可协议原文。</p>
<h2 id="mpl">MPL</h2>
<p>MPL是The Mozilla Public License的简写，是1998年初Netscape的
Mozilla小组为其开源软件项目设计的软件许可证。MPL许可证出现的最重要原因就是，Netscape公司认为GPL许可证没有很好地平衡开发者对源代码的需求和他们利用源代码获得的利益。同著名的GPL许可证和BSD许可证相比，MPL在许多权利与义务的约定方面与它们相同（因为都是符合OSIA
认定的开源软件许可证）。但是，相比而言MPL还有以下几个显著的不同之处:</p>
<ul>
<li>MPL虽然要求对于经MPL许可证发布的源代码的修改也要以MPL许可证的方式再许可出来，以保证其他人可以在MPL的条款下共享源代码。但是，在MPL许可证中对“发布”的定义是“以源代码方式发布的文件”，这就意味着MPL允许一个企业在自己已有的源代码库上加一个接口，除了接口程序的源代码以MPL许可证的形式对外许可外，源代码库中的源代码就可以不用MPL许可证的方式强制对外许可。这些，就为借鉴别人的源代码用做自己商业软件开发的行为留了一个豁口。</li>
<li>MPL许可证第三条第7款中允许被许可人将经过MPL许可证获得的源代码同自己其他类型的代码混合得到自己的软件程序。</li>
<li>对软件专利的态度，MPL许可证不像GPL许可证那样明确表示反对软件专利，但是却明确要求源代码的提供者不能提供已经受专利保护的源代码（除非他本人是专利权人，并书面向公众免费许可这些源代码），也不能在将这些源代码以开放源代码许可证形式许可后再去申请与这些源代码有关的专利。</li>
<li>对源代码的定义
而在MPL（1.1版本）许可证中，对源代码的定义是:“源代码指的是对作品进行修改最优先择取的形式，它包括:所有模块的所有源程序，加上有关的接口的定义，加上控制可执行作品的安装和编译的‘原本’（原文为‘Script’），或者不是与初始源代码显著不同的源代码就是被源代码贡献者选择的从公共领域可以得到的程序代码。”</li>
<li>MPL许可证第3条有专门的一款是关于对源代码修改进行描述的规定，就是要求所有再发布者都得有一个专门的文件就对源代码程序修改的时间和修改的方式有描述。</li>
</ul>
<h2 id="openldap">OpenLDAP</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">The OpenLDAP Public License</span><br><span class="line">  Version 2.8, 17 August 2003</span><br><span class="line"></span><br><span class="line">Redistribution and use of this software and associated documentation</span><br><span class="line">(&quot;Software&quot;), with or without modification, are permitted provided</span><br><span class="line">that the following conditions are met:</span><br><span class="line"></span><br><span class="line">1. Redistributions in source form must retain copyright statements</span><br><span class="line">   and notices,</span><br><span class="line"></span><br><span class="line">2. Redistributions in binary form must reproduce applicable copyright</span><br><span class="line">   statements and notices, this list of conditions, and the following</span><br><span class="line">   disclaimer in the documentation and/or other materials provided</span><br><span class="line">   with the distribution, and</span><br><span class="line"></span><br><span class="line">3. Redistributions must contain a verbatim copy of this document.</span><br><span class="line"></span><br><span class="line">The OpenLDAP Foundation may revise this license from time to time.</span><br><span class="line">Each revision is distinguished by a version number.  You may use</span><br><span class="line">this Software under terms of this license revision or under the</span><br><span class="line">terms of any subsequent revision of the license.</span><br><span class="line"></span><br><span class="line">THIS SOFTWARE IS PROVIDED BY THE OPENLDAP FOUNDATION AND ITS</span><br><span class="line">CONTRIBUTORS ``AS IS&#x27;&#x27; AND ANY EXPRESSED OR IMPLIED WARRANTIES,</span><br><span class="line">INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY</span><br><span class="line">AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT</span><br><span class="line">SHALL THE OPENLDAP FOUNDATION, ITS CONTRIBUTORS, OR THE AUTHOR(S)</span><br><span class="line">OR OWNER(S) OF THE SOFTWARE BE LIABLE FOR ANY DIRECT, INDIRECT,</span><br><span class="line">INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,</span><br><span class="line">BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;</span><br><span class="line">LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER</span><br><span class="line">CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT</span><br><span class="line">LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN</span><br><span class="line">ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE</span><br><span class="line">POSSIBILITY OF SUCH DAMAGE.</span><br><span class="line"></span><br><span class="line">The names of the authors and copyright holders must not be used in</span><br><span class="line">advertising or otherwise to promote the sale, use or other dealing</span><br><span class="line">in this Software without specific, written prior permission.  Title</span><br><span class="line">to copyright in this Software shall at all times remain with copyright</span><br><span class="line">holders.</span><br><span class="line"></span><br><span class="line">OpenLDAP is a registered trademark of the OpenLDAP Foundation.</span><br><span class="line"></span><br><span class="line">Copyright 1999-2003 The OpenLDAP Foundation, Redwood City,</span><br><span class="line">California, USA.  All Rights Reserved.  Permission to copy and</span><br><span class="line">distribute verbatim copies of this document is granted.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="creative-commons">Creative Commons</h2>
<p>Creative Commons (CC)
并非严格意义上的开源许可，它主要用于设计。Creative Commons
有多种协议，每种都提供了相应授权模式，CC 协议主要包含 4 种基本形式：</p>
<ul>
<li>署名权 必须为原始作者署名，然后才可以修改，分发，复制。</li>
<li>保持一致 作品同样可以在 CC 协议基础上修改，分发，复制。</li>
<li>非商业
作品可以被修改，分发，复制，但不能用于商业用途。但商业的定义有些模糊，比如，有的人认为非商业用途指的是不能销售，有的认为是甚至不能放在有广告的网
站，也有人认为非商业的意思是非盈利。</li>
<li>不能衍生新作品
你可以复制，分发，但不能修改，也不能以此为基础创作自己的作品。</li>
</ul>
<h2 id="总结">总结</h2>
<p>这些许可形式可以结合起来用，其中最严厉的组合是“署名，非商用，不能衍生新作品”，意味着，你可以分享作品，但不能改动或以此盈利，而且必须为原作者署名。在这种许可模式下，原始作者对作品还拥有完全的控制权，而最宽松的组合是“署名”，意味着，只要为原始作者署名了，就可以自由处置。</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux开发</tag>
        <tag>standard</tag>
      </tags>
  </entry>
  <entry>
    <title>《高质量的C++代码笔记》</title>
    <url>/201811/20181111-hight-property-codes/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>软件质量是被大多数程序员挂在嘴上而不是放在心上的东西！
除了完全外行和真正的编程高手外，初读本书，你最先的感受将是惊慌：“哇！我
以前捏造的 C++/C
程序怎么会有那么多的毛病？”有多少软件开发人员对正确性、健壮性、可靠性、效率、易用性、可读性（可理解性）、可扩展性、可复用性、兼容性、可移植性等质量属性了如指掌？并且能在实践中运用自如？。至少我现在还不是，我只能将平时遇到的一些值得记录的东西记录下来，以供下次翻阅。</p>
<h2 id="从小程序看问题">从小程序看问题</h2>
<p><code>strcpy</code>的实现可以看出一个人的 * 编程风格 * 出错处理 *
算法复杂度分析</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">char</span>* <span class="title">strcpy</span><span class="params">(<span class="type">char</span>* dest, <span class="type">const</span> <span class="type">char</span>* source)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> * destcopy = dest;</span><br><span class="line">    <span class="keyword">if</span>((dest == <span class="literal">NULL</span>) || (source == <span class="literal">NULL</span>))</span><br><span class="line">        <span class="keyword">throw</span> <span class="string">&quot;Invalid Arguments&quot;</span>;</span><br><span class="line">    <span class="keyword">while</span>((*dest++=*source++)!= <span class="string">&#x27;\0&#x27;</span>);</span><br><span class="line">    <span class="keyword">return</span> destcopy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="文件结构">文件结构</h2>
<ol type="1">
<li>声明在头文件.h，定义在源代码文件.cpp或者.c .cc</li>
<li>为了防止头文件被重复引用，应当用 ifndef/define/endif 结构产生预
处理块。</li>
<li>用 #include &lt;filename.h&gt; 格式来引用标准库的头文件（编译器将
从标准库目录开始搜索）。用 #include “filename.h”
格式来引用非标准库的头文件（编译器将从用户的工作目录开始搜索）。 4.
头文件中只存放“声明”而不存放“定义”</li>
<li>不提倡使用全局变量， 尽量不要在头文件中出现象 extern int value 这
类声明。</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* Copyright (c) 2001,上海贝尔有限公司网络应用事业部</span></span><br><span class="line"><span class="comment">* All rights reserved.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* 文件名称： filename.h</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">* 文件标识： 见配置管理计划书</span></span><br><span class="line"><span class="comment">* 摘 要： 简要描述本文件的内容</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* 当前版本： 1.1</span></span><br><span class="line"><span class="comment">* 作 者： 输入作者（或修改者）名字</span></span><br><span class="line"><span class="comment">* 完成日期： 2001年7月20日</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* 取代版本： 1.0</span></span><br><span class="line"><span class="comment">* 原作者 ： 输入原作者（或修改者）名字</span></span><br><span class="line"><span class="comment">* 完成日期： 2001年5月10日</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<h3 id="为什么要声明和定义分离">为什么要声明和定义分离：</h3>
<ol type="1">
<li>通过头文件来调用库功能。在很多场合，源代码不便（或不准）向用户公布，只
要向用户提供头文件和二进制的库即可。用户只需要按照头文件中的接口声明来调用库
功能，而不必关心接口怎么实现的。编译器会从库中提取相应的代码。</li>
<li>头文件能加强类型安全检查。如果某个接口被实现或被使用时，其方式与头文件
中的声明不一致，编译器就会指出错误，这一简单的规则能大大减轻程序员调试、改错
的负担。</li>
<li>便于管理。如果代码文件比较多，可以将头文件放到include目录下，源文件放到source目录下，方便分别管理</li>
</ol>
<h2 id="程序">程序</h2>
<ol type="1">
<li>在每个类声明之后、每个函数定义结束之后都要加空行</li>
<li>在一个函数体内，逻揖上密切相关的语句之间不加空行，其它地方应
加空行分隔。</li>
<li>一行代码只做一件事情，如只定义一个变量，或只写一条语句。</li>
<li>if、 for、 while、 do 等语句自占一行，执行语句不得紧跟其后。不论
执行语句有多少都要加{}。这样可以防止书写失误。</li>
<li>尽可能在定义变量的同时初始化该变量。如果变量的引用处和其定义处相隔比较远，变量的初始化很容易被忘记。如果引用了未被初始化的变量，可能会导致程序错误。本建议可以减少隐患。</li>
</ol>
<h3 id="指针声明">指针声明</h3>
<p>修饰符 * 和 ＆ 应该靠近数据类型还是该靠近变量名，是个有争议的活题。
若将修饰符 * 靠近数据类型，例如： int* x; 从语义上讲此写法比较直观，即 x
是 int 类型的指针。 上述写法的弊端是容易引起误解，例如： int* x, y; 此处
y 容易被误解为指针变 量。虽然将 x 和 y
分行定义可以避免误解，但并不是人人都愿意这样做。</p>
<h2 id="命名规则">命名规则</h2>
<p>unix系统中常常采用小写字母+_ 的方式 g_:全局变量 k_:static 变量
m_：class成员变量</p>
<h2
id="类的构造函数析构函数和赋值函数">类的构造函数、析构函数和赋值函数</h2>
<p>每个类只有一个析构函数和一个赋值函数，但可以有多个构造函数（包含一个拷贝
构造函数，其它的称为普通构造函数）。对于任意一个类
A，如果不想编写上述函数， C++编译器将自动为 A 产生四个缺省的函数，如
<code>A(void);</code> // 缺省的无参数构造函数
<code>A(const A &amp;a);</code> // 缺省的拷贝构造函数
<code>~A(void);</code> // 缺省的析构函数
<code>A &amp; operate =(const A &amp;a);</code> // 缺省的赋值函数</p>
<h2 id="经验">经验</h2>
<p>不少难以察觉的程序错误是由于变量没有被正确初始化或清除造成的，而初始化和清除工作很容易被人遗忘。</p>
<h2 id="调试经典">调试经典</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> stub  fprintf(stderr, <span class="string">&quot;error param in %s:%s:%d\n&quot;</span>,  __FUNCTION__, __FILE__, __LINE__);</span></span><br></pre></td></tr></table></figure>
<h2
id="mutable关键字用来解决常函数中不能修改对象的数据成员的问题">mutable关键字用来解决常函数中不能修改对象的数据成员的问题</h2>
<h2 id="内存对齐">内存对齐</h2>
<p>这是因为结构体内存分配有自己的对齐规则，结构体内存对齐默认的规则如下：
* 分配内存的顺序是按照声明的顺序。 *
每个变量相对于起始位置的偏移量必须是该变量类型大小的整数倍，不是整数倍空出内存，直到偏移量是整数倍为止。
* 最后整个结构体的大小必须是里面变量类型最大值的整数倍。</p>
<p>内存对齐<a href="https://www.cnblogs.com/suntp/p/MemAlignment.html"
class="uri">https://www.cnblogs.com/suntp/p/MemAlignment.html</a></p>
<p>OpenCV中16b对齐的内存申请和释放 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> CV_MALLOC_ALIGN 16</span></span><br><span class="line"><span class="comment">/*!</span></span><br><span class="line"><span class="comment">  Aligns pointer by the certain number of bytes</span></span><br><span class="line"><span class="comment">  This small inline function aligns the pointer by the certian number of bytes by shifting</span></span><br><span class="line"><span class="comment">  it forward by 0 or a positive offset.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> _Tp&gt; </span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> _Tp* <span class="title">alignPtr</span><span class="params">(_Tp* ptr, <span class="type">int</span> n=(<span class="type">int</span>)<span class="keyword">sizeof</span>(_Tp))</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (_Tp*)(((<span class="type">size_t</span>)ptr + n<span class="number">-1</span>) &amp; -n);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*!</span></span><br><span class="line"><span class="comment">  Aligns buffer size by the certain number of bytes</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  This small inline function aligns a buffer size by the certian number of bytes by enlarging it.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">size_t</span> <span class="title">alignSize</span><span class="params">(<span class="type">size_t</span> sz, <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>((n &amp; (n - <span class="number">1</span>)) == <span class="number">0</span>); <span class="comment">// n is a power of 2</span></span><br><span class="line">    <span class="keyword">return</span> (sz + n<span class="number">-1</span>) &amp; -n;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="title">fastMalloc</span><span class="params">( <span class="type">size_t</span> size )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    uchar* udata = (uchar*)<span class="built_in">malloc</span>(size + <span class="built_in">sizeof</span>(<span class="type">void</span>*) + CV_MALLOC_ALIGN);</span><br><span class="line">    <span class="keyword">if</span>(!udata)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">OutOfMemoryError</span>(size);</span><br><span class="line">    uchar** adata = <span class="built_in">alignPtr</span>((uchar**)udata + <span class="number">1</span>, CV_MALLOC_ALIGN);</span><br><span class="line">    adata[<span class="number">-1</span>] = udata;</span><br><span class="line">    <span class="keyword">return</span> adata;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">fastFree</span><span class="params">(<span class="type">void</span>* ptr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(ptr) &#123;</span><br><span class="line">        uchar* udata = ((uchar**)ptr)[<span class="number">-1</span>];</span><br><span class="line">        <span class="built_in">CV_DbgAssert</span>(udata &lt; (uchar*)ptr &amp;&amp;</span><br><span class="line">               ((uchar*)ptr - udata) &lt;= (<span class="type">ptrdiff_t</span>)(<span class="built_in">sizeof</span>(<span class="type">void</span>*)+CV_MALLOC_ALIGN));</span><br><span class="line">        <span class="built_in">free</span>(udata);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p><a
href="https://www.jianshu.com/p/9c58dd414e5f">NCNN中使用该code进行内存对齐</a></p>
<h2
id="内存的作用域不要在函数中创建临时对象返回">内存的作用域，不要在函数中创建临时对象返回</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="comment">///@brief 模型配置结构体</span></span><br><span class="line"><span class="comment">///@warning 该结构体在与did_model_set_config一起使用时，一定要先全部填充为0，再设置所需要的field。</span></span><br><span class="line"><span class="comment">/// set_model_config/get_model_config 是对该结构体的浅拷贝</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">net_config_t</span> &#123;</span><br><span class="line">	<span class="type">int</span>  engine;</span><br><span class="line"></span><br><span class="line">	<span class="comment">///@brief each engine specific data can be passed to here, such as snpe_runtime, tensorrt_batch_size, ocl_context and so on.</span></span><br><span class="line">	<span class="comment">///@note each engine implementation will cast it to the corresponding runtime type, such as snpe_context_t, ppl_context_t.</span></span><br><span class="line">	<span class="comment">/// The lifetime of this pointer should span until create_handle finished, and the memory is managed by users.</span></span><br><span class="line">	<span class="type">void</span>* engine_context;</span><br><span class="line">&#125; <span class="type">net_config_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">set_net_config_t</span><span class="params">(<span class="type">net_config_t</span>* config, <span class="type">int</span> engine_type)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(config, <span class="number">0</span>, <span class="built_in">sizeof</span>(<span class="type">net_config_t</span>));</span><br><span class="line">    <span class="type">int</span> otherc[] = &#123;<span class="number">1</span>, <span class="number">0</span>, <span class="number">5</span>&#125;;</span><br><span class="line">    config-&gt;engine = engine_type;</span><br><span class="line">    config-&gt;engine_context = (<span class="type">void</span>*)&amp;otherc;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span> </span>&#123;</span><br><span class="line">    <span class="type">net_config_t</span> config;</span><br><span class="line">    <span class="comment">// 设置模型加载配置项</span></span><br><span class="line">    <span class="built_in">set_net_config_t</span>(&amp;config, <span class="number">3</span>);</span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;config.engine %d\n&quot;</span>, config.engine);</span><br><span class="line">    <span class="type">int</span>* context = (<span class="type">int</span>*)config.engine_context;</span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;config.engine_context[0]=%d\n&quot;</span>, context[<span class="number">0</span>]);</span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;config.engine_context[1]=%d\n&quot;</span>, context[<span class="number">1</span>]);</span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;config.engine_context[2]=%d\n&quot;</span>, context[<span class="number">2</span>]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>第一次运行</p>
</blockquote>
<p>config.engine 3 config.engine_context[0]=1286489600
config.engine_context[1]=32624 config.engine_context[2]=1288667592</p>
<blockquote>
<p>第二次运行</p>
</blockquote>
<p>config.engine 3 config.engine_context[0]=-204200448
config.engine_context[1]=32695 config.engine_context[2]=-202022456</p>
<p>从结果中可以看出engine_context中的内存是一块未初始化的内存空间。这是因为返回的局部数组被释放导致的结果。
这情况可能导致你的程序有不期望的执行结果。尤其是如果采用context[1]作为分支判断条件，本来应该为0或者false，
现在可能是正数，也可能是负数，为0的概率非常小。因此我们要避免这种返回局部变量的情况。</p>
<h2
id="disable-copy和assign操作的方法-将赋值函数和拷贝构造函数显示作为private下">Disable
COPY和ASSIGN操作的方法， 将赋值函数和拷贝构造函数显示作为private下</h2>
<blockquote>
<p>方案 1</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A macro to disallow copy constructor and operator=</span></span><br><span class="line"><span class="comment">// This should be used in the private: declarations for a class.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GTEST_DISALLOW_COPY_AND_ASSIGN_(type)\</span></span><br><span class="line"><span class="meta">  type(type const &amp;);\</span></span><br><span class="line"><span class="meta">  void operator=(type const &amp;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestFactoryBase</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="built_in">GTEST_DISALLOW_COPY_AND_ASSIGN_</span>(TestFactoryBase);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>方案2</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">P</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">P</span>(<span class="type">const</span> P &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    P &amp;<span class="keyword">operator</span> =（<span class="type">const</span> P &amp;p) = <span class="keyword">delete</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>以上两个delete声明禁止复制
能够通过明确的方式显式限定这些特殊方法有助于增强代码的可读性和可维护性</p>
<h2 id="i和i的重载代码实现">++i和i++的重载代码实现</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ClassName&amp; <span class="keyword">operator</span>++()</span><br><span class="line">&#123;</span><br><span class="line">    ++cur;</span><br><span class="line">    <span class="keyword">if</span>(cur == last)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">set_node</span>(node + <span class="number">1</span>);</span><br><span class="line">      cur = first;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ClassName <span class="title">operator</span><span class="params">(<span class="type">int</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   ClassName tmp = *<span class="keyword">this</span>;</span><br><span class="line">   ++*<span class="keyword">this</span>;</span><br><span class="line">   <span class="keyword">return</span> tmp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2
id="unsigned类型的默认转化造成的苦恼">unsigned类型的默认转化造成的苦恼</h2>
<p>u32Width是unsigned
int类型的，在进行计算过程中如果<code>u32Width=2</code>，执行到<code>for (; j &lt;= u32Width - 4; j += 4)</code>的时候，会出现问题：
由于j是size_t类型的，
<code>u32Width-4</code>会被转化为<code>unsigned int</code>类型，从而造成该判断可通过，从直观上看来就发生了
<code>j &lt;= -2</code>(实际是<code>j &lt;= 4294967294</code>)是为<code>true</code>的事情了。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">unsigned</span> <span class="type">int</span> blob_len = u32Num * u32Chn * u32Height;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; blob_len; ++i) &#123;</span><br><span class="line">	<span class="type">size_t</span> j = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (; j &lt;= u32Width - <span class="number">4</span>; j += <span class="number">4</span>) &#123;</span><br><span class="line">		dataDstBlob[j] = (dst_type)(ps32Ptr[j] * NNIE_DATA_SCALE_INV);</span><br><span class="line">		dataDstBlob[j + <span class="number">1</span>] = (dst_type)(ps32Ptr[j + <span class="number">1</span>] * NNIE_DATA_SCALE_INV);</span><br><span class="line">		dataDstBlob[j + <span class="number">2</span>] = (dst_type)(ps32Ptr[j + <span class="number">2</span>] * NNIE_DATA_SCALE_INV);</span><br><span class="line">		dataDstBlob[j + <span class="number">3</span>] = (dst_type)(ps32Ptr[j + <span class="number">3</span>] * NNIE_DATA_SCALE_INV);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> (; j &lt; u32Width; ++j) &#123;</span><br><span class="line">		dataDstBlob[j] = (dst_type)(ps32Ptr[j] * NNIE_DATA_SCALE_INV);</span><br><span class="line">	&#125;</span><br><span class="line">	dataDstBlob += u32Width;</span><br><span class="line">	ps32Ptr += blob-&gt;u32Stride / <span class="built_in">getElemSize</span>(blob-&gt;enType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="c中容易忽略的库bitset">C++中容易忽略的库bitset</h2>
<p>bitset是处理<em>进制转换</em>，<em>基于bit的算法</em>中简单算法，虽然也可以使用raw的char
array替代，但是很多bitset自带的方法，可以让程序飞起来。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bitset&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">increment</span><span class="params">(std::bitset&lt;<span class="number">5</span>&gt;&amp; bset)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(bset[i] == <span class="number">1</span>)</span><br><span class="line">            bset[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            bset[i] = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">method_1</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i) &#123;</span><br><span class="line">        <span class="function">std::bitset&lt;5&gt; <span class="title">bset</span><span class="params">(i)</span></span>;</span><br><span class="line">        std::cout &lt;&lt; bset &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> <span class="type">const</span> *argv[])</span></span>&#123;</span><br><span class="line">    <span class="function">std::bitset&lt;5&gt; <span class="title">bset</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i) &#123;</span><br><span class="line">        std::cout &lt;&lt; bset &lt;&lt; std::endl;</span><br><span class="line">        <span class="built_in">increment</span>(bset);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="仿函数">仿函数</h2>
<p>仿函数(functor)，就是使一个类的使用看上去象一个函数。其实现就是类中实现一个
operator()，这个类就有了类似函数的行为，就是一个仿函数类了。C语言使用函数指针和回调函数来实现仿函数，例如一个用来排序的函数可以这样使用仿函数.在C++里，我们通过在一个类中重载括号运算符的方法使用一个函数对象而不是一个普通函数。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">xxx</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="function">returnType <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> T&amp; x)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> returnType;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">display</span>  </span><br><span class="line">&#123;  </span><br><span class="line"><span class="keyword">public</span>:  </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> T &amp;x)</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">        cout&lt;&lt;x&lt;&lt;<span class="string">&quot; &quot;</span>;   </span><br><span class="line">    &#125;   </span><br><span class="line">&#125;;   </span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span>  </span></span><br><span class="line"><span class="comment">//int sort_function( const void *a, const void *b);  </span></span><br><span class="line"><span class="type">int</span> <span class="title function_">sort_function</span><span class="params">( <span class="type">const</span> <span class="type">void</span> *a, <span class="type">const</span> <span class="type">void</span> *b)</span>  </span><br><span class="line">&#123;     </span><br><span class="line">    <span class="keyword">return</span> *(<span class="type">int</span>*)a-*(<span class="type">int</span>*)b;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>  </span><br><span class="line">&#123;  </span><br><span class="line">     </span><br><span class="line">   <span class="type">int</span> <span class="built_in">list</span>[<span class="number">5</span>] = &#123; <span class="number">54</span>, <span class="number">21</span>, <span class="number">11</span>, <span class="number">67</span>, <span class="number">22</span> &#125;;  </span><br><span class="line">   qsort((<span class="type">void</span> *)<span class="built_in">list</span>, <span class="number">5</span>, <span class="keyword">sizeof</span>(<span class="built_in">list</span>[<span class="number">0</span>]), sort_function);<span class="comment">//起始地址，个数，元素大小，回调函数   </span></span><br><span class="line">   <span class="type">int</span>  x;  </span><br><span class="line">   <span class="keyword">for</span> (x = <span class="number">0</span>; x &lt; <span class="number">5</span>; x++)  </span><br><span class="line">          <span class="built_in">printf</span>(<span class="string">&quot;%i\n&quot;</span>, <span class="built_in">list</span>[x]);  </span><br><span class="line">                    </span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<h3 id="仿函数在stl中的定义">仿函数在STL中的定义</h3>
<p>要使用STL内建的仿函数，必须包含<functional>头文件。而头文件中包含的仿函数分类包括</p>
<ol type="1">
<li>算术类仿函数 加：plus<T> 减：minus<T> 乘：multiplies<T>
除：divides<T> 模取：modulus<T> 否定：negate<T></li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;numeric&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span>   </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span>   </span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="type">int</span> ia[]=&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;  </span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">iv</span><span class="params">(ia,ia+<span class="number">5</span>)</span></span>;  </span><br><span class="line">    cout&lt;&lt;<span class="built_in">accumulate</span>(iv.<span class="built_in">begin</span>(),iv.<span class="built_in">end</span>(),<span class="number">1</span>,<span class="built_in">multiplies</span>&lt;<span class="type">int</span>&gt;())&lt;&lt;endl;   </span><br><span class="line">      </span><br><span class="line">    cout&lt;&lt;<span class="built_in">multiplies</span>&lt;<span class="type">int</span>&gt;()(<span class="number">3</span>,<span class="number">5</span>)&lt;&lt;endl;  </span><br><span class="line">      </span><br><span class="line">    modulus&lt;<span class="type">int</span>&gt;  modulusObj;  </span><br><span class="line">    cout&lt;&lt;<span class="built_in">modulusObj</span>(<span class="number">3</span>,<span class="number">5</span>)&lt;&lt;endl; <span class="comment">// 3   </span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;   </span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>关系运算类仿函数</li>
</ol>
<p>等于：equal_to<T> 不等于：not_equal_to<T> 大于：greater<T>
大于等于：greater_equal<T> 小于：less<T> 小于等于：less_equal<T></p>
<p>从大到小排序：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span>   </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;   </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">display</span>  </span><br><span class="line">&#123;  </span><br><span class="line"><span class="keyword">public</span>:  </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> T &amp;x)</span>  </span></span><br><span class="line"><span class="function">    </span>&#123;  </span><br><span class="line">        cout&lt;&lt;x&lt;&lt;<span class="string">&quot; &quot;</span>;   </span><br><span class="line">    &#125;   </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="type">int</span> ia[]=&#123;<span class="number">1</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>&#125;;  </span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">iv</span><span class="params">(ia,ia+<span class="number">5</span>)</span></span>;  </span><br><span class="line">    <span class="built_in">sort</span>(iv.<span class="built_in">begin</span>(),iv.<span class="built_in">end</span>(),<span class="built_in">greater</span>&lt;<span class="type">int</span>&gt;());  </span><br><span class="line">    for_each(iv.<span class="built_in">begin</span>(),iv.<span class="built_in">end</span>(),<span class="built_in">display</span>&lt;<span class="type">int</span>&gt;());   </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;   </span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>逻辑运算仿函数</li>
</ol>
<p>逻辑与：logical_and<T> 逻辑或：logical_or<T>
逻辑否：logical_no<T></p>
<h2 id="google-test的一些疑问test_f与test的区别">google
test的一些疑问：TEST_F与TEST的区别</h2>
<p>TEST_F与TEST的区别是，TEST_F提供了一个初始化函数（SetUp）和一个清理函数(TearDown)，在TEST_F中使用的变量可以在初始化函数SetUp中初始化，在TearDown中销毁，并且所有的TEST_F是互相独立的，都是在初始化以后的状态开始运行，一个TEST_F不会影响另一个TEST_F所使用的数据。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//A.h</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> A_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> A_H</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">　　<span class="type">int</span> _a;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">　　<span class="built_in">A</span>( <span class="type">int</span> a );</span><br><span class="line">　　~<span class="built_in">A</span>( );</span><br><span class="line">　　<span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">( <span class="type">int</span> a )</span></span>;</span><br><span class="line">　　<span class="function"><span class="type">int</span> <span class="title">getA</span><span class="params">( )</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">A.cpp</span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;A.h&quot;</span></span></span><br><span class="line">A::<span class="built_in">A</span>( <span class="type">int</span> a )&#123;</span><br><span class="line">　　<span class="keyword">this</span>-&gt;_a = a;</span><br><span class="line">&#125;</span><br><span class="line">A::~<span class="built_in">A</span>( )&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">A::add</span><span class="params">( <span class="type">int</span> a )</span></span>&#123;</span><br><span class="line">　　<span class="keyword">this</span>-&gt;_a += a;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">A::getA</span><span class="params">( )</span></span>&#123;</span><br><span class="line">　　<span class="keyword">return</span> <span class="keyword">this</span>-&gt;_a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>A_test.cpp</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 　A_test.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;A.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;gtest/gtest.h&gt;</span></span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A_test</span> : <span class="keyword">public</span> testing::Test &#123;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">　　A* _p_a;</span><br><span class="line">　　<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">SetUp</span><span class="params">( )</span></span>&#123;　　　<span class="comment">//初始化函数</span></span><br><span class="line">　　　　<span class="keyword">this</span>-&gt;_p_a = <span class="keyword">new</span> <span class="built_in">A</span>( <span class="number">1</span> );</span><br><span class="line">　　&#125;</span><br><span class="line">　　<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">TearDown</span><span class="params">( )</span></span>&#123;　 <span class="comment">//清理函数</span></span><br><span class="line">　　　　<span class="keyword">delete</span> <span class="keyword">this</span>-&gt;_p_a;</span><br><span class="line">　　&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//第一个测试，参数A_test是上面的那个类，第二个参数FirstAdd是测试名称</span></span><br><span class="line"><span class="built_in">TEST_F</span>( A_test,FirstAdd )&#123;　　　　</span><br><span class="line">　　<span class="built_in">EXPECT_EQ</span>( <span class="number">1</span>,_p_a-&gt;<span class="built_in">getA</span>( ) );</span><br><span class="line">　　_p_a-&gt;<span class="built_in">add</span>( <span class="number">3</span> );</span><br><span class="line">　　<span class="built_in">EXPECT_EQ</span>( <span class="number">4</span>,_p_a-&gt;<span class="built_in">getA</span>( ) );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//第二个测试</span></span><br><span class="line"><span class="built_in">TEST_F</span>( A_test,SecondAdd )&#123;</span><br><span class="line">　　<span class="built_in">EXPECT_EQ</span>( <span class="number">1</span>,_p_a-&gt;<span class="built_in">getA</span>( ) );</span><br><span class="line">　　_p_a-&gt;<span class="built_in">add</span>( <span class="number">5</span> );</span><br><span class="line">　　<span class="built_in">EXPECT_EQ</span>( <span class="number">6</span>,_p_a-&gt;<span class="built_in">getA</span>( ) );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">上面的两个测试都是在SetUp函数执行后的状态下执行，也就是说在执行任意一个TEST_F时 _p_a-&gt;_a 的值都是初始值1</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<ul>
<li>main.cpp</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;gtest/gtest.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> * argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">　　testing::<span class="built_in">InitGoogleTest</span>(&amp;argc, argv);</span><br><span class="line">　　<span class="keyword">return</span> <span class="built_in">RUN_ALL_TESTS</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __TIC__()                                    \</span></span><br><span class="line"><span class="meta">	struct timeval __timing_start, __timing_end; \</span></span><br><span class="line"><span class="meta">	gettimeofday(&amp;__timing_start, NULL);</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __TOC__()                                                        \</span></span><br><span class="line"><span class="meta">	do &#123;                                                             \</span></span><br><span class="line"><span class="meta">		gettimeofday(&amp;__timing_end, NULL);                       \</span></span><br><span class="line"><span class="meta">		double __timing_gap = (__timing_end.tv_sec -     \</span></span><br><span class="line"><span class="meta">					       __timing_start.tv_sec) *  \</span></span><br><span class="line"><span class="meta">					      1000.0 +                     \</span></span><br><span class="line"><span class="meta">				      (__timing_end.tv_usec -    \</span></span><br><span class="line"><span class="meta">					       __timing_start.tv_usec) / \</span></span><br><span class="line"><span class="meta">					      1000.0;                    \</span></span><br><span class="line"><span class="meta">		fprintf(stdout, <span class="string">&quot;TIME(ms): %lf\n&quot;</span>, __timing_gap);        \</span></span><br><span class="line"><span class="meta">	&#125; while (0)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="看看gtest的工作流程">看看gtest的工作流程</h2>
<ul>
<li>入口</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//第一个测试，参数A_test是上面的那个类，第二个参数FirstAdd是测试名称</span></span><br><span class="line"><span class="built_in">TEST</span>(A_test, FirstAdd)&#123;　　　　</span><br><span class="line">　　<span class="built_in">EXPECT_EQ</span>( <span class="number">1</span>,_p_a-&gt;<span class="built_in">getA</span>( ) );</span><br><span class="line">　　_p_a-&gt;<span class="built_in">add</span>( <span class="number">3</span> );</span><br><span class="line">　　<span class="built_in">EXPECT_EQ</span>( <span class="number">4</span>,_p_a-&gt;<span class="built_in">getA</span>( ) );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Define this macro to 1 to omit the definition of TEST(), which</span></span><br><span class="line"><span class="comment">// is a generic name and clashes with some other libraries.</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> !GTEST_DONT_DEFINE_TEST</span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> TEST(test_case_name, test_name) GTEST_TEST(test_case_name, test_name)</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GTEST_TEST(test_case_name, test_name)\</span></span><br><span class="line"><span class="meta">  GTEST_TEST_(test_case_name, test_name, \</span></span><br><span class="line"><span class="meta">              ::testing::Test, ::testing::internal::GetTestTypeId())</span></span><br></pre></td></tr></table></figure>
<ul>
<li>首先看看函数中调用的一个宏的实现</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Expands to the name of the class that implements the given test.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GTEST_TEST_CLASS_NAME_(test_case_name, test_name) \</span></span><br><span class="line"><span class="meta">  test_case_name##_##test_name##_Test</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Helper macro for defining tests.</span></span><br><span class="line"><span class="comment">// 这个宏声明了一个继承自parent_class ::testing::Test的类，然后对这个类的属性test_info_进行赋值</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GTEST_TEST_(test_case_name, test_name, parent_class, parent_id)\</span></span><br><span class="line"><span class="meta">class GTEST_TEST_CLASS_NAME_(test_case_name, test_name) : public parent_class &#123;\</span></span><br><span class="line"><span class="meta"> public:\</span></span><br><span class="line"><span class="meta">  GTEST_TEST_CLASS_NAME_(test_case_name, test_name)() &#123;&#125;\</span></span><br><span class="line"><span class="meta"> private:\</span></span><br><span class="line"><span class="meta">  virtual void TestBody();\</span></span><br><span class="line"><span class="meta">  static ::testing::TestInfo* const test_info_ GTEST_ATTRIBUTE_UNUSED_;\</span></span><br><span class="line"><span class="meta">  GTEST_DISALLOW_COPY_AND_ASSIGN_(\</span></span><br><span class="line"><span class="meta">      GTEST_TEST_CLASS_NAME_(test_case_name, test_name));\</span></span><br><span class="line"><span class="meta">&#125;;\</span></span><br><span class="line"><span class="meta"><span class="comment">/*这个宏声明了一个继承自parent_class ::testing::Test的类，然后对这个类的属性test_info_进行赋值*/</span>\</span></span><br><span class="line"><span class="meta">::testing::TestInfo* const GTEST_TEST_CLASS_NAME_(test_case_name, test_name)\</span></span><br><span class="line"><span class="meta">  ::test_info_ =\</span></span><br><span class="line"><span class="meta">    ::testing::internal::MakeAndRegisterTestInfo(\</span></span><br><span class="line"><span class="meta">        #test_case_name, #test_name, NULL, NULL, \</span></span><br><span class="line"><span class="meta">        (parent_id), \</span></span><br><span class="line"><span class="meta">        parent_class::SetUpTestCase, \</span></span><br><span class="line"><span class="meta">        parent_class::TearDownTestCase, \</span></span><br><span class="line"><span class="meta">        new ::testing::internal::TestFactoryImpl&lt;\</span></span><br><span class="line"><span class="meta">            GTEST_TEST_CLASS_NAME_(test_case_name, test_name)&gt;);\</span></span><br><span class="line"><span class="meta"><span class="comment">// 实现我们的这个TestBody\</span></span></span><br><span class="line"><span class="comment"><span class="meta">void GTEST_TEST_CLASS_NAME_(test_case_name, test_name)::TestBody()</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>看一下MakeAndRegisterTestInfo函数</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">TestInfo* <span class="title">MakeAndRegisterTestInfo</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">char</span>* test_case_name,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">char</span>* name,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">char</span>* type_param,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">char</span>* value_param,</span></span></span><br><span class="line"><span class="params"><span class="function">    TypeId fixture_class_id,</span></span></span><br><span class="line"><span class="params"><span class="function">    SetUpTestCaseFunc set_up_tc,</span></span></span><br><span class="line"><span class="params"><span class="function">    TearDownTestCaseFunc tear_down_tc,</span></span></span><br><span class="line"><span class="params"><span class="function">    TestFactoryBase* factory)</span> </span>&#123;</span><br><span class="line">  TestInfo* <span class="type">const</span> test_info =</span><br><span class="line">      <span class="keyword">new</span> <span class="built_in">TestInfo</span>(test_case_name, name, type_param, value_param,</span><br><span class="line">                   fixture_class_id, factory);</span><br><span class="line">  <span class="comment">// 添加测试用例信息到UnitTestImpl的testcase_中</span></span><br><span class="line">  <span class="built_in">GetUnitTestImpl</span>()-&gt;<span class="built_in">AddTestInfo</span>(set_up_tc, tear_down_tc, test_info);</span><br><span class="line">  <span class="keyword">return</span> test_info;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>AddTestInfo试图通过测试用例名等信息获取测试用例，然后调用测试用例对象去新增一个测试特例——test_info。
这样我们在此就将测试用例和测试特例的关系在代码中找到了关联。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Finds and returns a TestCase with the given name.  If one doesn&#x27;t</span></span><br><span class="line"><span class="comment">// exist, creates one and returns it.  It&#x27;s the CALLER&#x27;S</span></span><br><span class="line"><span class="comment">// RESPONSIBILITY to ensure that this function is only called WHEN THE</span></span><br><span class="line"><span class="comment">// TESTS ARE NOT SHUFFLED.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Arguments:</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//   test_case_name: name of the test case</span></span><br><span class="line"><span class="comment">//   type_param:     the name of the test case&#x27;s type parameter, or NULL if</span></span><br><span class="line"><span class="comment">//                   this is not a typed or a type-parameterized test case.</span></span><br><span class="line"><span class="comment">//   set_up_tc:      pointer to the function that sets up the test case</span></span><br><span class="line"><span class="comment">//   tear_down_tc:   pointer to the function that tears down the test case</span></span><br><span class="line"><span class="function">TestCase* <span class="title">UnitTestImpl::GetTestCase</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* test_case_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    <span class="type">const</span> <span class="type">char</span>* type_param,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    Test::SetUpTestCaseFunc set_up_tc,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    Test::TearDownTestCaseFunc tear_down_tc)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Can we find a TestCase with the given name?</span></span><br><span class="line">  <span class="type">const</span> std::vector&lt;TestCase*&gt;::const_iterator test_case =</span><br><span class="line">      std::<span class="built_in">find_if</span>(test_cases_.<span class="built_in">begin</span>(), test_cases_.<span class="built_in">end</span>(),</span><br><span class="line">                   <span class="built_in">TestCaseNameIs</span>(test_case_name));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (test_case != test_cases_.<span class="built_in">end</span>())</span><br><span class="line">    <span class="keyword">return</span> *test_case;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// No.  Let&#x27;s create one.</span></span><br><span class="line">  TestCase* <span class="type">const</span> new_test_case =</span><br><span class="line">      <span class="keyword">new</span> <span class="built_in">TestCase</span>(test_case_name, type_param, set_up_tc, tear_down_tc);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Is this a death test case?</span></span><br><span class="line">  <span class="keyword">if</span> (internal::UnitTestOptions::<span class="built_in">MatchesFilter</span>(test_case_name,</span><br><span class="line">                                               kDeathTestCaseFilter)) &#123;</span><br><span class="line">    <span class="comment">// Yes.  Inserts the test case after the last death test case</span></span><br><span class="line">    <span class="comment">// defined so far.  This only works when the test cases haven&#x27;t</span></span><br><span class="line">    <span class="comment">// been shuffled.  Otherwise we may end up running a death test</span></span><br><span class="line">    <span class="comment">// after a non-death test.</span></span><br><span class="line">    ++last_death_test_case_;</span><br><span class="line">    test_cases_.<span class="built_in">insert</span>(test_cases_.<span class="built_in">begin</span>() + last_death_test_case_,</span><br><span class="line">                       new_test_case);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// No.  Appends to the end of the list.</span></span><br><span class="line">    test_cases_.<span class="built_in">push_back</span>(new_test_case);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  test_case_indices_.<span class="built_in">push_back</span>(<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(test_case_indices_.<span class="built_in">size</span>()));</span><br><span class="line">  <span class="keyword">return</span> new_test_case;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="reference">Reference</h1>
<ul>
<li>[1]. gtest测试相关:
http://blog.csdn.net/breaksoftware/article/details/50948239</li>
<li>[2]. <a
href="https://wenku.baidu.com/view/11d8f46527d3240c8447efa8.html">Floating-Point
Arithmetic 浮点数结构</a></li>
</ul>
<h1
id="来自gtest文档中的内容方便后续查看">来自GTEST文档中的内容，方便后续查看</h1>
<h1 id="introduction-why-google-c-testing-framework">Introduction: Why
Google C++ Testing Framework?</h1>
<p><em>Google C++ Testing Framework</em> helps you write better C++
tests.</p>
<p>No matter whether you work on Linux, Windows, or a Mac, if you write
C++ code, Google Test can help you.</p>
<p>So what makes a good test, and how does Google C++ Testing Framework
fit in? We believe: 1. Tests should be <em>independent</em> and
<em>repeatable</em>. It's a pain to debug a test that succeeds or fails
as a result of other tests. Google C++ Testing Framework isolates the
tests by running each of them on a different object. When a test fails,
Google C++ Testing Framework allows you to run it in isolation for quick
debugging. 1. Tests should be well <em>organized</em> and reflect the
structure of the tested code. Google C++ Testing Framework groups
related tests into test cases that can share data and subroutines. This
common pattern is easy to recognize and makes tests easy to maintain.
Such consistency is especially helpful when people switch projects and
start to work on a new code base. 1. Tests should be <em>portable</em>
and <em>reusable</em>. The open-source community has a lot of code that
is platform-neutral, its tests should also be platform-neutral. Google
C++ Testing Framework works on different OSes, with different compilers
(gcc, MSVC, and others), with or without exceptions, so Google C++
Testing Framework tests can easily work with a variety of
configurations. (Note that the current release only contains build
scripts for Linux - we are actively working on scripts for other
platforms.) 1. When tests fail, they should provide as much
<em>information</em> about the problem as possible. Google C++ Testing
Framework doesn't stop at the first test failure. Instead, it only stops
the current test and continues with the next. You can also set up tests
that report non-fatal failures after which the current test continues.
Thus, you can detect and fix multiple bugs in a single run-edit-compile
cycle. 1. The testing framework should liberate test writers from
housekeeping chores and let them focus on the test <em>content</em>.
Google C++ Testing Framework automatically keeps track of all tests
defined, and doesn't require the user to enumerate them in order to run
them. 1. Tests should be <em>fast</em>. With Google C++ Testing
Framework, you can reuse shared resources across tests and pay for the
set-up/tear-down only once, without making tests depend on each
other.</p>
<p>Since Google C++ Testing Framework is based on the popular xUnit
architecture, you'll feel right at home if you've used JUnit or PyUnit
before. If not, it will take you about 10 minutes to learn the basics
and get started. So let's go!</p>
<p><em>Note:</em> We sometimes refer to Google C++ Testing Framework
informally as <em>Google Test</em>.</p>
<h1 id="setting-up-a-new-test-project">Setting up a New Test
Project</h1>
<p>To write a test program using Google Test, you need to compile Google
Test into a library and link your test with it. We provide build files
for some popular build systems: <code>msvc/</code> for Visual Studio,
<code>xcode/</code> for Mac Xcode, <code>make/</code> for GNU make,
<code>codegear/</code> for Borland C++ Builder, and the autotools script
(deprecated) and <code>CMakeLists.txt</code> for CMake (recommended) in
the Google Test root directory. If your build system is not on this
list, you can take a look at <code>make/Makefile</code> to learn how
Google Test should be compiled (basically you want to compile
<code>src/gtest-all.cc</code> with <code>GTEST_ROOT</code> and
<code>GTEST_ROOT/include</code> in the header search path, where
<code>GTEST_ROOT</code> is the Google Test root directory).</p>
<p>Once you are able to compile the Google Test library, you should
create a project or build target for your test program. Make sure you
have <code>GTEST_ROOT/include</code> in the header search path so that
the compiler can find <code>"gtest/gtest.h"</code> when compiling your
test. Set up your test project to link with the Google Test library (for
example, in Visual Studio, this is done by adding a dependency on
<code>gtest.vcproj</code>).</p>
<p>If you still have questions, take a look at how Google Test's own
tests are built and use them as examples.</p>
<h1 id="basic-concepts">Basic Concepts</h1>
<p>When using Google Test, you start by writing <em>assertions</em>,
which are statements that check whether a condition is true. An
assertion's result can be <em>success</em>, <em>nonfatal failure</em>,
or <em>fatal failure</em>. If a fatal failure occurs, it aborts the
current function; otherwise the program continues normally.</p>
<p><em>Tests</em> use assertions to verify the tested code's behavior.
If a test crashes or has a failed assertion, then it <em>fails</em>;
otherwise it <em>succeeds</em>.</p>
<p>A <em>test case</em> contains one or many tests. You should group
your tests into test cases that reflect the structure of the tested
code. When multiple tests in a test case need to share common objects
and subroutines, you can put them into a <em>test fixture</em>
class.</p>
<p>A <em>test program</em> can contain multiple test cases.</p>
<p>We'll now explain how to write a test program, starting at the
individual assertion level and building up to tests and test cases.</p>
<h1 id="assertions">Assertions</h1>
<p>Google Test assertions are macros that resemble function calls. You
test a class or function by making assertions about its behavior. When
an assertion fails, Google Test prints the assertion's source file and
line number location, along with a failure message. You may also supply
a custom failure message which will be appended to Google Test's
message.</p>
<p>The assertions come in pairs that test the same thing but have
different effects on the current function. <code>ASSERT_*</code>
versions generate fatal failures when they fail, and <strong>abort the
current function</strong>. <code>EXPECT_*</code> versions generate
nonfatal failures, which don't abort the current function. Usually
<code>EXPECT_*</code> are preferred, as they allow more than one
failures to be reported in a test. However, you should use
<code>ASSERT_*</code> if it doesn't make sense to continue when the
assertion in question fails.</p>
<p>Since a failed <code>ASSERT_*</code> returns from the current
function immediately, possibly skipping clean-up code that comes after
it, it may cause a space leak. Depending on the nature of the leak, it
may or may not be worth fixing - so keep this in mind if you get a heap
checker error in addition to assertion errors.</p>
<p>To provide a custom failure message, simply stream it into the macro
using the <code>&lt;&lt;</code> operator, or a sequence of such
operators. An example: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ASSERT_EQ(x.size(), y.size()) &lt;&lt; &quot;Vectors x and y are of unequal length&quot;;</span><br><span class="line"></span><br><span class="line">for (int i = 0; i &lt; x.size(); ++i) &#123;</span><br><span class="line">  EXPECT_EQ(x[i], y[i]) &lt;&lt; &quot;Vectors x and y differ at index &quot; &lt;&lt; i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Anything that can be streamed to an <code>ostream</code> can be
streamed to an assertion macro--in particular, C strings and
<code>string</code> objects. If a wide string (<code>wchar_t*</code>,
<code>TCHAR*</code> in <code>UNICODE</code> mode on Windows, or
<code>std::wstring</code>) is streamed to an assertion, it will be
translated to UTF-8 when printed.</p>
<h2 id="basic-assertions">Basic Assertions</h2>
<p>These assertions do basic true/false condition testing.</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_TRUE(</code><em>condition</em><code>)</code>;</td>
<td
style="text-align: left;"><code>EXPECT_TRUE(</code><em>condition</em><code>)</code>;</td>
<td style="text-align: left;"><em>condition</em> is true</td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_FALSE(</code><em>condition</em><code>)</code>;</td>
<td
style="text-align: left;"><code>EXPECT_FALSE(</code><em>condition</em><code>)</code>;</td>
<td style="text-align: left;"><em>condition</em> is false</td>
</tr>
</tbody>
</table>
<p>Remember, when they fail, <code>ASSERT_*</code> yields a fatal
failure and returns from the current function, while
<code>EXPECT_*</code> yields a nonfatal failure, allowing the function
to continue running. In either case, an assertion failure means its
containing test fails.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<h2 id="binary-comparison">Binary Comparison</h2>
<p>This section describes assertions that compare two values.</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_EQ(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_EQ(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td style="text-align: left;"><em>val1</em> <code>==</code>
<em>val2</em></td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_NE(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_NE(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td style="text-align: left;"><em>val1</em> <code>!=</code>
<em>val2</em></td>
</tr>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_LT(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_LT(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td style="text-align: left;"><em>val1</em> <code>&lt;</code>
<em>val2</em></td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_LE(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_LE(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td style="text-align: left;"><em>val1</em> <code>&lt;=</code>
<em>val2</em></td>
</tr>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_GT(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_GT(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td style="text-align: left;"><em>val1</em> <code>&gt;</code>
<em>val2</em></td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_GE(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_GE(</code><em>val1</em><code>,</code><em>val2</em><code>);</code></td>
<td style="text-align: left;"><em>val1</em> <code>&gt;=</code>
<em>val2</em></td>
</tr>
</tbody>
</table>
<p>In the event of a failure, Google Test prints both <em>val1</em> and
<em>val2</em>.</p>
<p>Value arguments must be comparable by the assertion's comparison
operator or you'll get a compiler error. We used to require the
arguments to support the <code>&lt;&lt;</code> operator for streaming to
an <code>ostream</code>, but it's no longer necessary since v1.6.0 (if
<code>&lt;&lt;</code> is supported, it will be called to print the
arguments when the assertion fails; otherwise Google Test will attempt
to print them in the best way it can. For more details and how to
customize the printing of the arguments, see this Google Mock <a
href="../../googlemock/docs/CookBook.md#teaching-google-mock-how-to-print-your-values">recipe</a>.).</p>
<p>These assertions can work with a user-defined type, but only if you
define the corresponding comparison operator (e.g. <code>==</code>,
<code>&lt;</code>, etc). If the corresponding operator is defined,
prefer using the <code>ASSERT_*()</code> macros because they will print
out not only the result of the comparison, but the two operands as
well.</p>
<p>Arguments are always evaluated exactly once. Therefore, it's OK for
the arguments to have side effects. However, as with any ordinary C/C++
function, the arguments' evaluation order is undefined (i.e. the
compiler is free to choose any order) and your code should not depend on
any particular argument evaluation order.</p>
<p><code>ASSERT_EQ()</code> does pointer equality on pointers. If used
on two C strings, it tests if they are in the same memory location, not
if they have the same value. Therefore, if you want to compare C strings
(e.g. <code>const char*</code>) by value, use
<code>ASSERT_STREQ()</code> , which will be described later on. In
particular, to assert that a C string is <code>NULL</code>, use
<code>ASSERT_STREQ(NULL, c_string)</code> . However, to compare two
<code>string</code> objects, you should use <code>ASSERT_EQ</code>.</p>
<p>Macros in this section work with both narrow and wide string objects
(<code>string</code> and <code>wstring</code>).</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<p><em>Historical note</em>: Before February 2016 <code>*_EQ</code> had
a convention of calling it as <code>ASSERT_EQ(expected, actual)</code>,
so lots of existing code uses this order. Now <code>*_EQ</code> treats
both parameters in the same way.</p>
<h2 id="string-comparison">String Comparison</h2>
<p>The assertions in this group compare two <strong>C strings</strong>.
If you want to compare two <code>string</code> objects, use
<code>EXPECT_EQ</code>, <code>EXPECT_NE</code>, and etc instead.</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_STREQ(</code><em>str1</em><code>,</code><em>str2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_STREQ(</code><em>str1</em><code>,</code>_str_2<code>);</code></td>
<td style="text-align: left;">the two C strings have the same
content</td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_STRNE(</code><em>str1</em><code>,</code><em>str2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_STRNE(</code><em>str1</em><code>,</code><em>str2</em><code>);</code></td>
<td style="text-align: left;">the two C strings have different
content</td>
</tr>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_STRCASEEQ(</code><em>str1</em><code>,</code><em>str2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_STRCASEEQ(</code><em>str1</em><code>,</code><em>str2</em><code>);</code></td>
<td style="text-align: left;">the two C strings have the same content,
ignoring case</td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_STRCASENE(</code><em>str1</em><code>,</code><em>str2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_STRCASENE(</code><em>str1</em><code>,</code><em>str2</em><code>);</code></td>
<td style="text-align: left;">the two C strings have different content,
ignoring case</td>
</tr>
</tbody>
</table>
<p>Note that "CASE" in an assertion name means that case is ignored.</p>
<p><code>*STREQ*</code> and <code>*STRNE*</code> also accept wide C
strings (<code>wchar_t*</code>). If a comparison of two wide strings
fails, their values will be printed as UTF-8 narrow strings.</p>
<p>A <code>NULL</code> pointer and an empty string are considered
<em>different</em>.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<p>See also: For more string comparison tricks (substring, prefix,
suffix, and regular expression matching, for example), see the <a
href="AdvancedGuide.md">Advanced Google Test Guide</a>.</p>
<h1 id="simple-tests">Simple Tests</h1>
<p>To create a test: 1. Use the <code>TEST()</code> macro to define and
name a test function, These are ordinary C++ functions that don't return
a value. 1. In this function, along with any valid C++ statements you
want to include, use the various Google Test assertions to check values.
1. The test's result is determined by the assertions; if any assertion
in the test fails (either fatally or non-fatally), or if the test
crashes, the entire test fails. Otherwise, it succeeds.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST(test_case_name, test_name) &#123;</span><br><span class="line"> ... test body ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>TEST()</code> arguments go from general to specific. The
<em>first</em> argument is the name of the test case, and the
<em>second</em> argument is the test's name within the test case. Both
names must be valid C++ identifiers, and they should not contain
underscore (<code>_</code>). A test's <em>full name</em> consists of its
containing test case and its individual name. Tests from different test
cases can have the same individual name.</p>
<p>For example, let's take a simple integer function: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int Factorial(int n); // Returns the factorial of n</span><br></pre></td></tr></table></figure></p>
<p>A test case for this function might look like: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Tests factorial of 0.</span><br><span class="line">TEST(FactorialTest, HandlesZeroInput) &#123;</span><br><span class="line">  EXPECT_EQ(1, Factorial(0));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Tests factorial of positive numbers.</span><br><span class="line">TEST(FactorialTest, HandlesPositiveInput) &#123;</span><br><span class="line">  EXPECT_EQ(1, Factorial(1));</span><br><span class="line">  EXPECT_EQ(2, Factorial(2));</span><br><span class="line">  EXPECT_EQ(6, Factorial(3));</span><br><span class="line">  EXPECT_EQ(40320, Factorial(8));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Google Test groups the test results by test cases, so
logically-related tests should be in the same test case; in other words,
the first argument to their <code>TEST()</code> should be the same. In
the above example, we have two tests, <code>HandlesZeroInput</code> and
<code>HandlesPositiveInput</code>, that belong to the same test case
<code>FactorialTest</code>.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<h1
id="test-fixtures-using-the-same-data-configuration-for-multiple-tests">Test
Fixtures: Using the Same Data Configuration for Multiple Tests</h1>
<p>If you find yourself writing two or more tests that operate on
similar data, you can use a <em>test fixture</em>. It allows you to
reuse the same configuration of objects for several different tests.</p>
<p>To create a fixture, just: 1. Derive a class from
<code>::testing::Test</code> . Start its body with
<code>protected:</code> or <code>public:</code> as we'll want to access
fixture members from sub-classes. 1. Inside the class, declare any
objects you plan to use. 1. If necessary, write a default constructor or
<code>SetUp()</code> function to prepare the objects for each test. A
common mistake is to spell <code>SetUp()</code> as <code>Setup()</code>
with a small <code>u</code> - don't let that happen to you. 1. If
necessary, write a destructor or <code>TearDown()</code> function to
release any resources you allocated in <code>SetUp()</code> . To learn
when you should use the constructor/destructor and when you should use
<code>SetUp()/TearDown()</code>, read this <a
href="FAQ.md#should-i-use-the-constructordestructor-of-the-test-fixture-or-the-set-uptear-down-function">FAQ
entry</a>. 1. If needed, define subroutines for your tests to share.</p>
<p>When using a fixture, use <code>TEST_F()</code> instead of
<code>TEST()</code> as it allows you to access objects and subroutines
in the test fixture: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST_F(test_case_name, test_name) &#123;</span><br><span class="line"> ... test body ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Like <code>TEST()</code>, the first argument is the test case name,
but for <code>TEST_F()</code> this must be the name of the test fixture
class. You've probably guessed: <code>_F</code> is for fixture.</p>
<p>Unfortunately, the C++ macro system does not allow us to create a
single macro that can handle both types of tests. Using the wrong macro
causes a compiler error.</p>
<p>Also, you must first define a test fixture class before using it in a
<code>TEST_F()</code>, or you'll get the compiler error
"<code>virtual outside class declaration</code>".</p>
<p>For each test defined with <code>TEST_F()</code>, Google Test will:
1. Create a <em>fresh</em> test fixture at runtime 1. Immediately
initialize it via <code>SetUp()</code> , 1. Run the test 1. Clean up by
calling <code>TearDown()</code> 1. Delete the test fixture. Note that
different tests in the same test case have different test fixture
objects, and Google Test always deletes a test fixture before it creates
the next one. Google Test does not reuse the same test fixture for
multiple tests. Any changes one test makes to the fixture do not affect
other tests.</p>
<p>As an example, let's write tests for a FIFO queue class named
<code>Queue</code>, which has the following interface:
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">template &lt;typename E&gt; // E is the element type.</span><br><span class="line">class Queue &#123;</span><br><span class="line"> public:</span><br><span class="line">  Queue();</span><br><span class="line">  void Enqueue(const E&amp; element);</span><br><span class="line">  E* Dequeue(); // Returns NULL if the queue is empty.</span><br><span class="line">  size_t size() const;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>First, define a fixture class. By convention, you should give it the
name <code>FooTest</code> where <code>Foo</code> is the class being
tested. <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class QueueTest : public ::testing::Test &#123;</span><br><span class="line"> protected:</span><br><span class="line">  virtual void SetUp() &#123;</span><br><span class="line">    q1_.Enqueue(1);</span><br><span class="line">    q2_.Enqueue(2);</span><br><span class="line">    q2_.Enqueue(3);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // virtual void TearDown() &#123;&#125;</span><br><span class="line"></span><br><span class="line">  Queue&lt;int&gt; q0_;</span><br><span class="line">  Queue&lt;int&gt; q1_;</span><br><span class="line">  Queue&lt;int&gt; q2_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>In this case, <code>TearDown()</code> is not needed since we don't
have to clean up after each test, other than what's already done by the
destructor.</p>
<p>Now we'll write tests using <code>TEST_F()</code> and this fixture.
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST_F(QueueTest, IsEmptyInitially) &#123;</span><br><span class="line">  EXPECT_EQ(0, q0_.size());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TEST_F(QueueTest, DequeueWorks) &#123;</span><br><span class="line">  int* n = q0_.Dequeue();</span><br><span class="line">  EXPECT_EQ(NULL, n);</span><br><span class="line"></span><br><span class="line">  n = q1_.Dequeue();</span><br><span class="line">  ASSERT_TRUE(n != NULL);</span><br><span class="line">  EXPECT_EQ(1, *n);</span><br><span class="line">  EXPECT_EQ(0, q1_.size());</span><br><span class="line">  delete n;</span><br><span class="line"></span><br><span class="line">  n = q2_.Dequeue();</span><br><span class="line">  ASSERT_TRUE(n != NULL);</span><br><span class="line">  EXPECT_EQ(2, *n);</span><br><span class="line">  EXPECT_EQ(1, q2_.size());</span><br><span class="line">  delete n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>The above uses both <code>ASSERT_*</code> and <code>EXPECT_*</code>
assertions. The rule of thumb is to use <code>EXPECT_*</code> when you
want the test to continue to reveal more errors after the assertion
failure, and use <code>ASSERT_*</code> when continuing after failure
doesn't make sense. For example, the second assertion in the
<code>Dequeue</code> test is <code>ASSERT_TRUE(n != NULL)</code>, as we
need to dereference the pointer <code>n</code> later, which would lead
to a segfault when <code>n</code> is <code>NULL</code>.</p>
<p>When these tests run, the following happens: 1. Google Test
constructs a <code>QueueTest</code> object (let's call it
<code>t1</code> ). 1. <code>t1.SetUp()</code> initializes
<code>t1</code> . 1. The first test ( <code>IsEmptyInitially</code> )
runs on <code>t1</code> . 1. <code>t1.TearDown()</code> cleans up after
the test finishes. 1. <code>t1</code> is destructed. 1. The above steps
are repeated on another <code>QueueTest</code> object, this time running
the <code>DequeueWorks</code> test.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<p><em>Note</em>: Google Test automatically saves all <em>Google
Test</em> flags when a test object is constructed, and restores them
when it is destructed.</p>
<h1 id="invoking-the-tests">Invoking the Tests</h1>
<p><code>TEST()</code> and <code>TEST_F()</code> implicitly register
their tests with Google Test. So, unlike with many other C++ testing
frameworks, you don't have to re-list all your defined tests in order to
run them.</p>
<p>After defining your tests, you can run them with
<code>RUN_ALL_TESTS()</code> , which returns <code>0</code> if all the
tests are successful, or <code>1</code> otherwise. Note that
<code>RUN_ALL_TESTS()</code> runs <em>all tests</em> in your link unit
-- they can be from different test cases, or even different source
files.</p>
<p>When invoked, the <code>RUN_ALL_TESTS()</code> macro: 1. Saves the
state of all Google Test flags. 1. Creates a test fixture object for the
first test. 1. Initializes it via <code>SetUp()</code>. 1. Runs the test
on the fixture object. 1. Cleans up the fixture via
<code>TearDown()</code>. 1. Deletes the fixture. 1. Restores the state
of all Google Test flags. 1. Repeats the above steps for the next test,
until all tests have run.</p>
<p>In addition, if the text fixture's constructor generates a fatal
failure in step 2, there is no point for step 3 - 5 and they are thus
skipped. Similarly, if step 3 generates a fatal failure, step 4 will be
skipped.</p>
<p><em>Important</em>: You must not ignore the return value of
<code>RUN_ALL_TESTS()</code>, or <code>gcc</code> will give you a
compiler error. The rationale for this design is that the automated
testing service determines whether a test has passed based on its exit
code, not on its stdout/stderr output; thus your <code>main()</code>
function must return the value of <code>RUN_ALL_TESTS()</code>.</p>
<p>Also, you should call <code>RUN_ALL_TESTS()</code> only
<strong>once</strong>. Calling it more than once conflicts with some
advanced Google Test features (e.g. thread-safe death tests) and thus is
not supported.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<h1 id="writing-the-main-function">Writing the main() Function</h1>
<p>You can start from this boilerplate: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &quot;this/package/foo.h&quot;</span><br><span class="line">#include &quot;gtest/gtest.h&quot;</span><br><span class="line"></span><br><span class="line">namespace &#123;</span><br><span class="line"></span><br><span class="line">// The fixture for testing class Foo.</span><br><span class="line">class FooTest : public ::testing::Test &#123;</span><br><span class="line"> protected:</span><br><span class="line">  // You can remove any or all of the following functions if its body</span><br><span class="line">  // is empty.</span><br><span class="line"></span><br><span class="line">  FooTest() &#123;</span><br><span class="line">    // You can do set-up work for each test here.</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  virtual ~FooTest() &#123;</span><br><span class="line">    // You can do clean-up work that doesn&#x27;t throw exceptions here.</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // If the constructor and destructor are not enough for setting up</span><br><span class="line">  // and cleaning up each test, you can define the following methods:</span><br><span class="line"></span><br><span class="line">  virtual void SetUp() &#123;</span><br><span class="line">    // Code here will be called immediately after the constructor (right</span><br><span class="line">    // before each test).</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  virtual void TearDown() &#123;</span><br><span class="line">    // Code here will be called immediately after each test (right</span><br><span class="line">    // before the destructor).</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // Objects declared here can be used by all tests in the test case for Foo.</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">// Tests that the Foo::Bar() method does Abc.</span><br><span class="line">TEST_F(FooTest, MethodBarDoesAbc) &#123;</span><br><span class="line">  const string input_filepath = &quot;this/package/testdata/myinputfile.dat&quot;;</span><br><span class="line">  const string output_filepath = &quot;this/package/testdata/myoutputfile.dat&quot;;</span><br><span class="line">  Foo f;</span><br><span class="line">  EXPECT_EQ(0, f.Bar(input_filepath, output_filepath));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Tests that Foo does Xyz.</span><br><span class="line">TEST_F(FooTest, DoesXyz) &#123;</span><br><span class="line">  // Exercises the Xyz feature of Foo.</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;  // namespace</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">  ::testing::InitGoogleTest(&amp;argc, argv);</span><br><span class="line">  return RUN_ALL_TESTS();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>The <code>::testing::InitGoogleTest()</code> function parses the
command line for Google Test flags, and removes all recognized flags.
This allows the user to control a test program's behavior via various
flags, which we'll cover in <a
href="AdvancedGuide.md">AdvancedGuide</a>. You must call this function
before calling <code>RUN_ALL_TESTS()</code>, or the flags won't be
properly initialized.</p>
<p>On Windows, <code>InitGoogleTest()</code> also works with wide
strings, so it can be used in programs compiled in <code>UNICODE</code>
mode as well.</p>
<p>But maybe you think that writing all those main() functions is too
much work? We agree with you completely and that's why Google Test
provides a basic implementation of main(). If it fits your needs, then
just link your test with gtest_main library and you are good to go.</p>
<h2 id="important-note-for-visual-c-users">Important note for Visual C++
users</h2>
<p>If you put your tests into a library and your <code>main()</code>
function is in a different library or in your .exe file, those tests
will not run. The reason is a <a
href="https://connect.microsoft.com/feedback/viewfeedback.aspx?FeedbackID=244410&amp;siteid=210">bug</a>
in Visual C++. When you define your tests, Google Test creates certain
static objects to register them. These objects are not referenced from
elsewhere but their constructors are still supposed to run. When Visual
C++ linker sees that nothing in the library is referenced from other
places it throws the library out. You have to reference your library
with tests from your main program to keep the linker from discarding it.
Here is how to do it. Somewhere in your library code declare a function:
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">__declspec(dllexport) int PullInMyLibrary() &#123; return 0; &#125;</span><br></pre></td></tr></table></figure> If you put your tests in a static library (not DLL) then
<code>__declspec(dllexport)</code> is not required. Now, in your main
program, write a code that invokes that function: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int PullInMyLibrary();</span><br><span class="line">static int dummy = PullInMyLibrary();</span><br></pre></td></tr></table></figure> This
will keep your tests referenced and will make them register themselves
at startup.</p>
<p>In addition, if you define your tests in a static library, add
<code>/OPT:NOREF</code> to your main program linker options. If you use
MSVC++ IDE, go to your .exe project properties/Configuration
Properties/Linker/Optimization and set References setting to
<code>Keep Unreferenced Data (/OPT:NOREF)</code>. This will keep Visual
C++ linker from discarding individual symbols generated by your tests
from the final executable.</p>
<p>There is one more pitfall, though. If you use Google Test as a static
library (that's how it is defined in gtest.vcproj) your tests must also
reside in a static library. If you have to have them in a DLL, you
<em>must</em> change Google Test to build into a DLL as well. Otherwise
your tests will not run correctly or will not run at all. The general
conclusion here is: make your life easier - do not write your tests in
libraries!</p>
<h1 id="where-to-go-from-here">Where to Go from Here</h1>
<p>Congratulations! You've learned the Google Test basics. You can start
writing and running Google Test tests, read some <a
href="Samples.md">samples</a>, or continue with <a
href="AdvancedGuide.md">AdvancedGuide</a>, which describes many more
useful Google Test features.</p>
<h1 id="known-limitations">Known Limitations</h1>
<p>Google Test is designed to be thread-safe. The implementation is
thread-safe on systems where the <code>pthreads</code> library is
available. It is currently <em>unsafe</em> to use Google Test assertions
from two threads concurrently on other systems (e.g. Windows). In most
tests this is not an issue as usually the assertions are done in the
main thread. If you want to help, you can volunteer to implement the
necessary synchronization primitives in <code>gtest-port.h</code> for
your platform.</p>
<p>Now that you have read <a href="Primer.md">Primer</a> and learned how
to write tests using Google Test, it's time to learn some new tricks.
This document will show you more assertions as well as how to construct
complex failure messages, propagate fatal failures, reuse and speed up
your test fixtures, and use various flags with your tests.</p>
<h1 id="more-assertions">More Assertions</h1>
<p>This section covers some less frequently used, but still significant,
assertions.</p>
<h2 id="explicit-success-and-failure">Explicit Success and Failure</h2>
<p>These three assertions do not actually test a value or expression.
Instead, they generate a success or failure directly. Like the macros
that actually perform a test, you may stream a custom failure message
into the them.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><code>SUCCEED();</code></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>Generates a success. This does NOT make the overall test succeed. A
test is considered successful only if none of its assertions fail during
its execution.</p>
<p>Note: <code>SUCCEED()</code> is purely documentary and currently
doesn't generate any user-visible output. However, we may add
<code>SUCCEED()</code> messages to Google Test's output in the
future.</p>
<table>
<colgroup>
<col style="width: 14%" />
<col style="width: 21%" />
<col style="width: 64%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><code>FAIL();</code></th>
<th style="text-align: left;"><code>ADD_FAILURE();</code></th>
<th
style="text-align: left;"><code>ADD_FAILURE_AT("</code><em>file_path</em><code>",</code><em>line_number</em><code>);</code></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p><code>FAIL()</code> generates a fatal failure, while
<code>ADD_FAILURE()</code> and <code>ADD_FAILURE_AT()</code> generate a
nonfatal failure. These are useful when control flow, rather than a
Boolean expression, deteremines the test's success or failure. For
example, you might want to write something like:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">switch(expression) &#123;</span><br><span class="line">  case 1: ... some checks ...</span><br><span class="line">  case 2: ... some other checks</span><br><span class="line">  ...</span><br><span class="line">  default: FAIL() &lt;&lt; &quot;We shouldn&#x27;t get here.&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Note: you can only use <code>FAIL()</code> in functions that return
<code>void</code>. See the <a href="#assertion-placement">Assertion
Placement section</a> for more information.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<h2 id="exception-assertions">Exception Assertions</h2>
<p>These are for verifying that a piece of code throws (or does not
throw) an exception of the given type:</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_THROW(</code><em>statement</em>,
<em>exception_type</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_THROW(</code><em>statement</em>,
<em>exception_type</em><code>);</code></td>
<td style="text-align: left;"><em>statement</em> throws an exception of
the given type</td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_ANY_THROW(</code><em>statement</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_ANY_THROW(</code><em>statement</em><code>);</code></td>
<td style="text-align: left;"><em>statement</em> throws an exception of
any type</td>
</tr>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_NO_THROW(</code><em>statement</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_NO_THROW(</code><em>statement</em><code>);</code></td>
<td style="text-align: left;"><em>statement</em> doesn't throw any
exception</td>
</tr>
</tbody>
</table>
<p>Examples:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ASSERT_THROW(Foo(5), bar_exception);</span><br><span class="line"></span><br><span class="line">EXPECT_NO_THROW(&#123;</span><br><span class="line">  int n = 5;</span><br><span class="line">  Bar(&amp;n);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p><em>Availability</em>: Linux, Windows, Mac; since version 1.1.0.</p>
<h2 id="predicate-assertions-for-better-error-messages">Predicate
Assertions for Better Error Messages</h2>
<p>Even though Google Test has a rich set of assertions, they can never
be complete, as it's impossible (nor a good idea) to anticipate all the
scenarios a user might run into. Therefore, sometimes a user has to use
<code>EXPECT_TRUE()</code> to check a complex expression, for lack of a
better macro. This has the problem of not showing you the values of the
parts of the expression, making it hard to understand what went wrong.
As a workaround, some users choose to construct the failure message by
themselves, streaming it into <code>EXPECT_TRUE()</code>. However, this
is awkward especially when the expression has side-effects or is
expensive to evaluate.</p>
<p>Google Test gives you three different options to solve this
problem:</p>
<h3 id="using-an-existing-boolean-function">Using an Existing Boolean
Function</h3>
<p>If you already have a function or a functor that returns
<code>bool</code> (or a type that can be implicitly converted to
<code>bool</code>), you can use it in a <em>predicate assertion</em> to
get the function arguments printed for free:</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>ASSERT_PRED1(</code><em>pred1,
val1</em><code>);</code></td>
<td style="text-align: left;"><code>EXPECT_PRED1(</code><em>pred1,
val1</em><code>);</code></td>
<td style="text-align: left;"><em>pred1(val1)</em> returns true</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>ASSERT_PRED2(</code><em>pred2, val1,
val2</em><code>);</code></td>
<td style="text-align: left;"><code>EXPECT_PRED2(</code><em>pred2, val1,
val2</em><code>);</code></td>
<td style="text-align: left;"><em>pred2(val1, val2)</em> returns
true</td>
</tr>
<tr class="odd">
<td style="text-align: left;">...</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">...</td>
</tr>
</tbody>
</table>
<p>In the above, <em>predn</em> is an <em>n</em>-ary predicate function
or functor, where <em>val1</em>, <em>val2</em>, ..., and <em>valn</em>
are its arguments. The assertion succeeds if the predicate returns
<code>true</code> when applied to the given arguments, and fails
otherwise. When the assertion fails, it prints the value of each
argument. In either case, the arguments are evaluated exactly once.</p>
<p>Here's an example. Given</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Returns true iff m and n have no common divisors except 1.</span><br><span class="line">bool MutuallyPrime(int m, int n) &#123; ... &#125;</span><br><span class="line">const int a = 3;</span><br><span class="line">const int b = 4;</span><br><span class="line">const int c = 10;</span><br></pre></td></tr></table></figure>
<p>the assertion <code>EXPECT_PRED2(MutuallyPrime, a, b);</code> will
succeed, while the assertion
<code>EXPECT_PRED2(MutuallyPrime, b, c);</code> will fail with the
message</p>
<pre>
!MutuallyPrime(b, c) is false, where<br>
b is 4<br>
c is 10<br>
</pre>
<p><strong>Notes:</strong></p>
<ol type="1">
<li>If you see a compiler error "no matching function to call" when
using <code>ASSERT_PRED*</code> or <code>EXPECT_PRED*</code>, please see
<a
href="FAQ.md#the-compiler-complains-no-matching-function-to-call-when-i-use-assert_predn-how-do-i-fix-it">this
FAQ</a> for how to resolve it.</li>
<li>Currently we only provide predicate assertions of arity &lt;= 5. If
you need a higher-arity assertion, let us know.</li>
</ol>
<p><em>Availability</em>: Linux, Windows, Mac</p>
<h3 id="using-a-function-that-returns-an-assertionresult">Using a
Function That Returns an AssertionResult</h3>
<p>While <code>EXPECT_PRED*()</code> and friends are handy for a quick
job, the syntax is not satisfactory: you have to use different macros
for different arities, and it feels more like Lisp than C++. The
<code>::testing::AssertionResult</code> class solves this problem.</p>
<p>An <code>AssertionResult</code> object represents the result of an
assertion (whether it's a success or a failure, and an associated
message). You can create an <code>AssertionResult</code> using one of
these factory functions:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">namespace testing &#123;</span><br><span class="line"></span><br><span class="line">// Returns an AssertionResult object to indicate that an assertion has</span><br><span class="line">// succeeded.</span><br><span class="line">AssertionResult AssertionSuccess();</span><br><span class="line"></span><br><span class="line">// Returns an AssertionResult object to indicate that an assertion has</span><br><span class="line">// failed.</span><br><span class="line">AssertionResult AssertionFailure();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>You can then use the <code>&lt;&lt;</code> operator to stream
messages to the <code>AssertionResult</code> object.</p>
<p>To provide more readable messages in Boolean assertions (e.g.
<code>EXPECT_TRUE()</code>), write a predicate function that returns
<code>AssertionResult</code> instead of <code>bool</code>. For example,
if you define <code>IsEven()</code> as:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">::testing::AssertionResult IsEven(int n) &#123;</span><br><span class="line">  if ((n % 2) == 0)</span><br><span class="line">    return ::testing::AssertionSuccess();</span><br><span class="line">  else</span><br><span class="line">    return ::testing::AssertionFailure() &lt;&lt; n &lt;&lt; &quot; is odd&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>instead of:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bool IsEven(int n) &#123;</span><br><span class="line">  return (n % 2) == 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>the failed assertion <code>EXPECT_TRUE(IsEven(Fib(4)))</code> will
print:</p>
<pre>
Value of: IsEven(Fib(4))<br>
Actual: false (*3 is odd*)<br>
Expected: true<br>
</pre>
<p>instead of a more opaque</p>
<pre>
Value of: IsEven(Fib(4))<br>
Actual: false<br>
Expected: true<br>
</pre>
<p>If you want informative messages in <code>EXPECT_FALSE</code> and
<code>ASSERT_FALSE</code> as well, and are fine with making the
predicate slower in the success case, you can supply a success
message:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">::testing::AssertionResult IsEven(int n) &#123;</span><br><span class="line">  if ((n % 2) == 0)</span><br><span class="line">    return ::testing::AssertionSuccess() &lt;&lt; n &lt;&lt; &quot; is even&quot;;</span><br><span class="line">  else</span><br><span class="line">    return ::testing::AssertionFailure() &lt;&lt; n &lt;&lt; &quot; is odd&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Then the statement <code>EXPECT_FALSE(IsEven(Fib(6)))</code> will
print</p>
<pre>
Value of: IsEven(Fib(6))<br>
Actual: true (8 is even)<br>
Expected: false<br>
</pre>
<p><em>Availability</em>: Linux, Windows, Mac; since version 1.4.1.</p>
<h3 id="using-a-predicate-formatter">Using a Predicate-Formatter</h3>
<p>If you find the default message generated by
<code>(ASSERT|EXPECT)_PRED*</code> and
<code>(ASSERT|EXPECT)_(TRUE|FALSE)</code> unsatisfactory, or some
arguments to your predicate do not support streaming to
<code>ostream</code>, you can instead use the following
<em>predicate-formatter assertions</em> to <em>fully</em> customize how
the message is formatted:</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_PRED_FORMAT1(</code><em>pred_format1,
val1</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_PRED_FORMAT1(</code><em>pred_format1,
val1</em><code>);</code></td>
<td style="text-align: left;"><em>pred_format1(val1)</em> is
successful</td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_PRED_FORMAT2(</code><em>pred_format2,
val1, val2</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_PRED_FORMAT2(</code><em>pred_format2,
val1, val2</em><code>);</code></td>
<td style="text-align: left;"><em>pred_format2(val1, val2)</em> is
successful</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>...</code></td>
<td style="text-align: left;"><code>...</code></td>
<td style="text-align: left;"><code>...</code></td>
</tr>
</tbody>
</table>
<p>The difference between this and the previous two groups of macros is
that instead of a predicate, <code>(ASSERT|EXPECT)_PRED_FORMAT*</code>
take a <em>predicate-formatter</em> (<em>pred_formatn</em>), which is a
function or functor with the signature:</p>
<p><code>::testing::AssertionResult PredicateFormattern(const char*</code><em>expr1</em><code>, const char*</code><em>expr2</em><code>, ... const char*</code><em>exprn</em><code>, T1</code><em>val1</em><code>, T2</code><em>val2</em><code>, ... Tn</code><em>valn</em><code>);</code></p>
<p>where <em>val1</em>, <em>val2</em>, ..., and <em>valn</em> are the
values of the predicate arguments, and <em>expr1</em>, <em>expr2</em>,
..., and <em>exprn</em> are the corresponding expressions as they appear
in the source code. The types <code>T1</code>, <code>T2</code>, ..., and
<code>Tn</code> can be either value types or reference types. For
example, if an argument has type <code>Foo</code>, you can declare it as
either <code>Foo</code> or <code>const Foo&amp;</code>, whichever is
appropriate.</p>
<p>A predicate-formatter returns a
<code>::testing::AssertionResult</code> object to indicate whether the
assertion has succeeded or not. The only way to create such an object is
to call one of these factory functions:</p>
<p>As an example, let's improve the failure message in the previous
example, which uses <code>EXPECT_PRED2()</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Returns the smallest prime common divisor of m and n,</span><br><span class="line">// or 1 when m and n are mutually prime.</span><br><span class="line">int SmallestPrimeCommonDivisor(int m, int n) &#123; ... &#125;</span><br><span class="line"></span><br><span class="line">// A predicate-formatter for asserting that two integers are mutually prime.</span><br><span class="line">::testing::AssertionResult AssertMutuallyPrime(const char* m_expr,</span><br><span class="line">                                               const char* n_expr,</span><br><span class="line">                                               int m,</span><br><span class="line">                                               int n) &#123;</span><br><span class="line">  if (MutuallyPrime(m, n))</span><br><span class="line">    return ::testing::AssertionSuccess();</span><br><span class="line"></span><br><span class="line">  return ::testing::AssertionFailure()</span><br><span class="line">      &lt;&lt; m_expr &lt;&lt; &quot; and &quot; &lt;&lt; n_expr &lt;&lt; &quot; (&quot; &lt;&lt; m &lt;&lt; &quot; and &quot; &lt;&lt; n</span><br><span class="line">      &lt;&lt; &quot;) are not mutually prime, &quot; &lt;&lt; &quot;as they have a common divisor &quot;</span><br><span class="line">      &lt;&lt; SmallestPrimeCommonDivisor(m, n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>With this predicate-formatter, we can use</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EXPECT_PRED_FORMAT2(AssertMutuallyPrime, b, c);</span><br></pre></td></tr></table></figure>
<p>to generate the message</p>
<pre>
b and c (4 and 10) are not mutually prime, as they have a common divisor 2.<br>
</pre>
<p>As you may have realized, many of the assertions we introduced
earlier are special cases of <code>(EXPECT|ASSERT)_PRED_FORMAT*</code>.
In fact, most of them are indeed defined using
<code>(EXPECT|ASSERT)_PRED_FORMAT*</code>.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<h2 id="floating-point-comparison">Floating-Point Comparison</h2>
<p>Comparing floating-point numbers is tricky. Due to round-off errors,
it is very unlikely that two floating-points will match exactly.
Therefore, <code>ASSERT_EQ</code> 's naive comparison usually doesn't
work. And since floating-points can have a wide value range, no single
fixed error bound works. It's better to compare by a fixed relative
error bound, except for values close to 0 due to the loss of precision
there.</p>
<p>In general, for floating-point comparison to make sense, the user
needs to carefully choose the error bound. If they don't want or care
to, comparing in terms of Units in the Last Place (ULPs) is a good
default, and Google Test provides assertions to do this. Full details
about ULPs are quite long; if you want to learn more, see <a
href="http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm">this
article on float comparison</a>.</p>
<h3 id="floating-point-macros">Floating-Point Macros</h3>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>ASSERT_FLOAT_EQ(</code><em>val1,
val2</em><code>);</code></td>
<td style="text-align: left;"><code>EXPECT_FLOAT_EQ(</code><em>val1,
val2</em><code>);</code></td>
<td style="text-align: left;">the two <code>float</code> values are
almost equal</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>ASSERT_DOUBLE_EQ(</code><em>val1,
val2</em><code>);</code></td>
<td style="text-align: left;"><code>EXPECT_DOUBLE_EQ(</code><em>val1,
val2</em><code>);</code></td>
<td style="text-align: left;">the two <code>double</code> values are
almost equal</td>
</tr>
</tbody>
</table>
<p>By "almost equal", we mean the two values are within 4 ULP's from
each other.</p>
<p>The following assertions allow you to choose the acceptable error
bound:</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>ASSERT_NEAR(</code><em>val1, val2,
abs_error</em><code>);</code></td>
<td style="text-align: left;"><code>EXPECT_NEAR</code><em>(val1, val2,
abs_error</em><code>);</code></td>
<td style="text-align: left;">the difference between <em>val1</em> and
<em>val2</em> doesn't exceed the given absolute error</td>
</tr>
</tbody>
</table>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<h3 id="floating-point-predicate-format-functions">Floating-Point
Predicate-Format Functions</h3>
<p>Some floating-point operations are useful, but not that often used.
In order to avoid an explosion of new macros, we provide them as
predicate-format functions that can be used in predicate assertion
macros (e.g. <code>EXPECT_PRED_FORMAT2</code>, etc).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EXPECT_PRED_FORMAT2(::testing::FloatLE, val1, val2);</span><br><span class="line">EXPECT_PRED_FORMAT2(::testing::DoubleLE, val1, val2);</span><br></pre></td></tr></table></figure>
<p>Verifies that <em>val1</em> is less than, or almost equal to,
<em>val2</em>. You can replace <code>EXPECT_PRED_FORMAT2</code> in the
above table with <code>ASSERT_PRED_FORMAT2</code>.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<h2 id="windows-hresult-assertions">Windows HRESULT assertions</h2>
<p>These assertions test for <code>HRESULT</code> success or
failure.</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_HRESULT_SUCCEEDED(</code><em>expression</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_HRESULT_SUCCEEDED(</code><em>expression</em><code>);</code></td>
<td style="text-align: left;"><em>expression</em> is a success
<code>HRESULT</code></td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_HRESULT_FAILED(</code><em>expression</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_HRESULT_FAILED(</code><em>expression</em><code>);</code></td>
<td style="text-align: left;"><em>expression</em> is a failure
<code>HRESULT</code></td>
</tr>
</tbody>
</table>
<p>The generated output contains the human-readable error message
associated with the <code>HRESULT</code> code returned by
<em>expression</em>.</p>
<p>You might use them like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CComPtr shell;</span><br><span class="line">ASSERT_HRESULT_SUCCEEDED(shell.CoCreateInstance(L&quot;Shell.Application&quot;));</span><br><span class="line">CComVariant empty;</span><br><span class="line">ASSERT_HRESULT_SUCCEEDED(shell-&gt;ShellExecute(CComBSTR(url), empty, empty, empty, empty));</span><br></pre></td></tr></table></figure>
<p><em>Availability</em>: Windows.</p>
<h2 id="type-assertions">Type Assertions</h2>
<p>You can call the function <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">::testing::StaticAssertTypeEq&lt;T1, T2&gt;();</span><br></pre></td></tr></table></figure> to assert that types
<code>T1</code> and <code>T2</code> are the same. The function does
nothing if the assertion is satisfied. If the types are different, the
function call will fail to compile, and the compiler error message will
likely (depending on the compiler) show you the actual values of
<code>T1</code> and <code>T2</code>. This is mainly useful inside
template code.</p>
<p><em>Caveat:</em> When used inside a member function of a class
template or a function template,
<code>StaticAssertTypeEq&lt;T1, T2&gt;()</code> is effective <em>only
if</em> the function is instantiated. For example, given: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">template &lt;typename T&gt; class Foo &#123;</span><br><span class="line"> public:</span><br><span class="line">  void Bar() &#123; ::testing::StaticAssertTypeEq&lt;int, T&gt;(); &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
the code: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void Test1() &#123; Foo&lt;bool&gt; foo; &#125;</span><br></pre></td></tr></table></figure> will <em>not</em> generate a compiler error, as
<code>Foo&lt;bool&gt;::Bar()</code> is never actually instantiated.
Instead, you need: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void Test2() &#123; Foo&lt;bool&gt; foo; foo.Bar(); &#125;</span><br></pre></td></tr></table></figure> to cause a compiler error.</p>
<p><em>Availability:</em> Linux, Windows, Mac; since version 1.3.0.</p>
<h2 id="assertion-placement">Assertion Placement</h2>
<p>You can use assertions in any C++ function. In particular, it doesn't
have to be a method of the test fixture class. The one constraint is
that assertions that generate a fatal failure (<code>FAIL*</code> and
<code>ASSERT_*</code>) can only be used in void-returning functions.
This is a consequence of Google Test not using exceptions. By placing it
in a non-void function you'll get a confusing compile error like
<code>"error: void value not ignored as it ought to be"</code>.</p>
<p>If you need to use assertions in a function that returns non-void,
one option is to make the function return the value in an out parameter
instead. For example, you can rewrite <code>T2 Foo(T1 x)</code> to
<code>void Foo(T1 x, T2* result)</code>. You need to make sure that
<code>*result</code> contains some sensible value even when the function
returns prematurely. As the function now returns <code>void</code>, you
can use any assertion inside of it.</p>
<p>If changing the function's type is not an option, you should just use
assertions that generate non-fatal failures, such as
<code>ADD_FAILURE*</code> and <code>EXPECT_*</code>.</p>
<p><em>Note</em>: Constructors and destructors are not considered
void-returning functions, according to the C++ language specification,
and so you may not use fatal assertions in them. You'll get a
compilation error if you try. A simple workaround is to transfer the
entire body of the constructor or destructor to a private void-returning
method. However, you should be aware that a fatal assertion failure in a
constructor does not terminate the current test, as your intuition might
suggest; it merely returns from the constructor early, possibly leaving
your object in a partially-constructed state. Likewise, a fatal
assertion failure in a destructor may leave your object in a
partially-destructed state. Use assertions carefully in these
situations!</p>
<h1 id="teaching-google-test-how-to-print-your-values">Teaching Google
Test How to Print Your Values</h1>
<p>When a test assertion such as <code>EXPECT_EQ</code> fails, Google
Test prints the argument values to help you debug. It does this using a
user-extensible value printer.</p>
<p>This printer knows how to print built-in C++ types, native arrays,
STL containers, and any type that supports the <code>&lt;&lt;</code>
operator. For other types, it prints the raw bytes in the value and
hopes that you the user can figure it out.</p>
<p>As mentioned earlier, the printer is <em>extensible</em>. That means
you can teach it to do a better job at printing your particular type
than to dump the bytes. To do that, define <code>&lt;&lt;</code> for
your type:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">namespace foo &#123;</span><br><span class="line"></span><br><span class="line">class Bar &#123; ... &#125;;  // We want Google Test to be able to print instances of this.</span><br><span class="line"></span><br><span class="line">// It&#x27;s important that the &lt;&lt; operator is defined in the SAME</span><br><span class="line">// namespace that defines Bar.  C++&#x27;s look-up rules rely on that.</span><br><span class="line">::std::ostream&amp; operator&lt;&lt;(::std::ostream&amp; os, const Bar&amp; bar) &#123;</span><br><span class="line">  return os &lt;&lt; bar.DebugString();  // whatever needed to print bar to os</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;  // namespace foo</span><br></pre></td></tr></table></figure>
<p>Sometimes, this might not be an option: your team may consider it bad
style to have a <code>&lt;&lt;</code> operator for <code>Bar</code>, or
<code>Bar</code> may already have a <code>&lt;&lt;</code> operator that
doesn't do what you want (and you cannot change it). If so, you can
instead define a <code>PrintTo()</code> function like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">namespace foo &#123;</span><br><span class="line"></span><br><span class="line">class Bar &#123; ... &#125;;</span><br><span class="line"></span><br><span class="line">// It&#x27;s important that PrintTo() is defined in the SAME</span><br><span class="line">// namespace that defines Bar.  C++&#x27;s look-up rules rely on that.</span><br><span class="line">void PrintTo(const Bar&amp; bar, ::std::ostream* os) &#123;</span><br><span class="line">  *os &lt;&lt; bar.DebugString();  // whatever needed to print bar to os</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;  // namespace foo</span><br></pre></td></tr></table></figure>
<p>If you have defined both <code>&lt;&lt;</code> and
<code>PrintTo()</code>, the latter will be used when Google Test is
concerned. This allows you to customize how the value appears in Google
Test's output without affecting code that relies on the behavior of its
<code>&lt;&lt;</code> operator.</p>
<p>If you want to print a value <code>x</code> using Google Test's value
printer yourself, just call
<code>::testing::PrintToString(</code><em>x</em><code>)</code>, which
returns an <code>std::string</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vector&lt;pair&lt;Bar, int&gt; &gt; bar_ints = GetBarIntVector();</span><br><span class="line"></span><br><span class="line">EXPECT_TRUE(IsCorrectBarIntVector(bar_ints))</span><br><span class="line">    &lt;&lt; &quot;bar_ints = &quot; &lt;&lt; ::testing::PrintToString(bar_ints);</span><br></pre></td></tr></table></figure>
<h1 id="death-tests">Death Tests</h1>
<p>In many applications, there are assertions that can cause application
failure if a condition is not met. These sanity checks, which ensure
that the program is in a known good state, are there to fail at the
earliest possible time after some program state is corrupted. If the
assertion checks the wrong condition, then the program may proceed in an
erroneous state, which could lead to memory corruption, security holes,
or worse. Hence it is vitally important to test that such assertion
statements work as expected.</p>
<p>Since these precondition checks cause the processes to die, we call
such tests <em>death tests</em>. More generally, any test that checks
that a program terminates (except by throwing an exception) in an
expected fashion is also a death test.</p>
<p>Note that if a piece of code throws an exception, we don't consider
it "death" for the purpose of death tests, as the caller of the code
could catch the exception and avoid the crash. If you want to verify
exceptions thrown by your code, see <a
href="#exception-assertions">Exception Assertions</a>.</p>
<p>If you want to test <code>EXPECT_*()/ASSERT_*()</code> failures in
your test code, see <a href="#catching-failures">Catching
Failures</a>.</p>
<h2 id="how-to-write-a-death-test">How to Write a Death Test</h2>
<p>Google Test has the following macros to support death tests:</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>ASSERT_DEATH(</code><em>statement,
regex</em><code>);</code></td>
<td style="text-align: left;"><code>EXPECT_DEATH(</code><em>statement,
regex</em><code>);</code></td>
<td style="text-align: left;"><em>statement</em> crashes with the given
error</td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>ASSERT_DEATH_IF_SUPPORTED(</code><em>statement,
regex</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_DEATH_IF_SUPPORTED(</code><em>statement,
regex</em><code>);</code></td>
<td style="text-align: left;">if death tests are supported, verifies
that <em>statement</em> crashes with the given error; otherwise verifies
nothing</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>ASSERT_EXIT(</code><em>statement,
predicate, regex</em><code>);</code></td>
<td style="text-align: left;"><code>EXPECT_EXIT(</code><em>statement,
predicate, regex</em><code>);</code></td>
<td style="text-align: left;"><em>statement</em> exits with the given
error and its exit code matches <em>predicate</em></td>
</tr>
</tbody>
</table>
<p>where <em>statement</em> is a statement that is expected to cause the
process to die, <em>predicate</em> is a function or function object that
evaluates an integer exit status, and <em>regex</em> is a regular
expression that the stderr output of <em>statement</em> is expected to
match. Note that <em>statement</em> can be <em>any valid statement</em>
(including <em>compound statement</em>) and doesn't have to be an
expression.</p>
<p>As usual, the <code>ASSERT</code> variants abort the current test
function, while the <code>EXPECT</code> variants do not.</p>
<p><strong>Note:</strong> We use the word "crash" here to mean that the
process terminates with a <em>non-zero</em> exit status code. There are
two possibilities: either the process has called <code>exit()</code> or
<code>_exit()</code> with a non-zero value, or it may be killed by a
signal.</p>
<p>This means that if <em>statement</em> terminates the process with a 0
exit code, it is <em>not</em> considered a crash by
<code>EXPECT_DEATH</code>. Use <code>EXPECT_EXIT</code> instead if this
is the case, or if you want to restrict the exit code more
precisely.</p>
<p>A predicate here must accept an <code>int</code> and return a
<code>bool</code>. The death test succeeds only if the predicate returns
<code>true</code>. Google Test defines a few predicates that handle the
most common cases:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">::testing::ExitedWithCode(exit_code)</span><br></pre></td></tr></table></figure>
<p>This expression is <code>true</code> if the program exited normally
with the given exit code.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">::testing::KilledBySignal(signal_number)  // Not available on Windows.</span><br></pre></td></tr></table></figure>
<p>This expression is <code>true</code> if the program was killed by the
given signal.</p>
<p>The <code>*_DEATH</code> macros are convenient wrappers for
<code>*_EXIT</code> that use a predicate that verifies the process' exit
code is non-zero.</p>
<p>Note that a death test only cares about three things:</p>
<ol type="1">
<li>does <em>statement</em> abort or exit the process?</li>
<li>(in the case of <code>ASSERT_EXIT</code> and
<code>EXPECT_EXIT</code>) does the exit status satisfy
<em>predicate</em>? Or (in the case of <code>ASSERT_DEATH</code> and
<code>EXPECT_DEATH</code>) is the exit status non-zero? And</li>
<li>does the stderr output match <em>regex</em>?</li>
</ol>
<p>In particular, if <em>statement</em> generates an
<code>ASSERT_*</code> or <code>EXPECT_*</code> failure, it will
<strong>not</strong> cause the death test to fail, as Google Test
assertions don't abort the process.</p>
<p>To write a death test, simply use one of the above macros inside your
test function. For example,</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST(MyDeathTest, Foo) &#123;</span><br><span class="line">  // This death test uses a compound statement.</span><br><span class="line">  ASSERT_DEATH(&#123; int n = 5; Foo(&amp;n); &#125;, &quot;Error on line .* of Foo()&quot;);</span><br><span class="line">&#125;</span><br><span class="line">TEST(MyDeathTest, NormalExit) &#123;</span><br><span class="line">  EXPECT_EXIT(NormalExit(), ::testing::ExitedWithCode(0), &quot;Success&quot;);</span><br><span class="line">&#125;</span><br><span class="line">TEST(MyDeathTest, KillMyself) &#123;</span><br><span class="line">  EXPECT_EXIT(KillMyself(), ::testing::KilledBySignal(SIGKILL), &quot;Sending myself unblockable signal&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>verifies that:</p>
<ul>
<li>calling <code>Foo(5)</code> causes the process to die with the given
error message,</li>
<li>calling <code>NormalExit()</code> causes the process to print
<code>"Success"</code> to stderr and exit with exit code 0, and</li>
<li>calling <code>KillMyself()</code> kills the process with signal
<code>SIGKILL</code>.</li>
</ul>
<p>The test function body may contain other assertions and statements as
well, if necessary.</p>
<p><em>Important:</em> We strongly recommend you to follow the
convention of naming your test case (not test) <code>*DeathTest</code>
when it contains a death test, as demonstrated in the above example. The
<code>Death Tests And Threads</code> section below explains why.</p>
<p>If a test fixture class is shared by normal tests and death tests,
you can use typedef to introduce an alias for the fixture class and
avoid duplicating its code: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class FooTest : public ::testing::Test &#123; ... &#125;;</span><br><span class="line"></span><br><span class="line">typedef FooTest FooDeathTest;</span><br><span class="line"></span><br><span class="line">TEST_F(FooTest, DoesThis) &#123;</span><br><span class="line">  // normal test</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TEST_F(FooDeathTest, DoesThat) &#123;</span><br><span class="line">  // death test</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><em>Availability:</em> Linux, Windows (requires MSVC 8.0 or above),
Cygwin, and Mac (the latter three are supported since v1.3.0).
<code>(ASSERT|EXPECT)_DEATH_IF_SUPPORTED</code> are new in v1.4.0.</p>
<h2 id="regular-expression-syntax">Regular Expression Syntax</h2>
<p>On POSIX systems (e.g. Linux, Cygwin, and Mac), Google Test uses the
<a
href="http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html#tag_09_04">POSIX
extended regular expression</a> syntax in death tests. To learn about
this syntax, you may want to read this <a
href="http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions">Wikipedia
entry</a>.</p>
<p>On Windows, Google Test uses its own simple regular expression
implementation. It lacks many features you can find in POSIX extended
regular expressions. For example, we don't support union
(<code>"x|y"</code>), grouping (<code>"(xy)"</code>), brackets
(<code>"[xy]"</code>), and repetition count (<code>"x&#123;5,7&#125;"</code>),
among others. Below is what we do support (Letter <code>A</code> denotes
a literal character, period (<code>.</code>), or a single
<code>\\</code> escape sequence; <code>x</code> and <code>y</code>
denote regular expressions.):</p>
<table>
<colgroup>
<col style="width: 12%" />
<col style="width: 87%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><code>c</code></th>
<th style="text-align: left;">matches any literal character
<code>c</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>\\d</code></td>
<td style="text-align: left;">matches any decimal digit</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>\\D</code></td>
<td style="text-align: left;">matches any character that's not a decimal
digit</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>\\f</code></td>
<td style="text-align: left;">matches <code>\f</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>\\n</code></td>
<td style="text-align: left;">matches <code>\n</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>\\r</code></td>
<td style="text-align: left;">matches <code>\r</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>\\s</code></td>
<td style="text-align: left;">matches any ASCII whitespace, including
<code>\n</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>\\S</code></td>
<td style="text-align: left;">matches any character that's not a
whitespace</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>\\t</code></td>
<td style="text-align: left;">matches <code>\t</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>\\v</code></td>
<td style="text-align: left;">matches <code>\v</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>\\w</code></td>
<td style="text-align: left;">matches any letter, <code>_</code>, or
decimal digit</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>\\W</code></td>
<td style="text-align: left;">matches any character that
<code>\\w</code> doesn't match</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>\\c</code></td>
<td style="text-align: left;">matches any literal character
<code>c</code>, which must be a punctuation</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>\\.</code></td>
<td style="text-align: left;">matches the <code>.</code> character</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>.</code></td>
<td style="text-align: left;">matches any single character except
<code>\n</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>A?</code></td>
<td style="text-align: left;">matches 0 or 1 occurrences of
<code>A</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>A*</code></td>
<td style="text-align: left;">matches 0 or many occurrences of
<code>A</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>A+</code></td>
<td style="text-align: left;">matches 1 or many occurrences of
<code>A</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>^</code></td>
<td style="text-align: left;">matches the beginning of a string (not
that of each line)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>$</code></td>
<td style="text-align: left;">matches the end of a string (not that of
each line)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xy</code></td>
<td style="text-align: left;">matches <code>x</code> followed by
<code>y</code></td>
</tr>
</tbody>
</table>
<p>To help you determine which capability is available on your system,
Google Test defines macro <code>GTEST_USES_POSIX_RE=1</code> when it
uses POSIX extended regular expressions, or
<code>GTEST_USES_SIMPLE_RE=1</code> when it uses the simple version. If
you want your death tests to work in both cases, you can either
<code>#if</code> on these macros or use the more limited syntax
only.</p>
<h2 id="how-it-works">How It Works</h2>
<p>Under the hood, <code>ASSERT_EXIT()</code> spawns a new process and
executes the death test statement in that process. The details of of how
precisely that happens depend on the platform and the variable
<code>::testing::GTEST_FLAG(death_test_style)</code> (which is
initialized from the command-line flag
<code>--gtest_death_test_style</code>).</p>
<ul>
<li>On POSIX systems, <code>fork()</code> (or <code>clone()</code> on
Linux) is used to spawn the child, after which:
<ul>
<li>If the variable's value is <code>"fast"</code>, the death test
statement is immediately executed.</li>
<li>If the variable's value is <code>"threadsafe"</code>, the child
process re-executes the unit test binary just as it was originally
invoked, but with some extra flags to cause just the single death test
under consideration to be run.</li>
</ul></li>
<li>On Windows, the child is spawned using the
<code>CreateProcess()</code> API, and re-executes the binary to cause
just the single death test under consideration to be run - much like the
<code>threadsafe</code> mode on POSIX.</li>
</ul>
<p>Other values for the variable are illegal and will cause the death
test to fail. Currently, the flag's default value is
<code>"fast"</code>. However, we reserve the right to change it in the
future. Therefore, your tests should not depend on this.</p>
<p>In either case, the parent process waits for the child process to
complete, and checks that</p>
<ol type="1">
<li>the child's exit status satisfies the predicate, and</li>
<li>the child's stderr matches the regular expression.</li>
</ol>
<p>If the death test statement runs to completion without dying, the
child process will nonetheless terminate, and the assertion fails.</p>
<h2 id="death-tests-and-threads">Death Tests And Threads</h2>
<p>The reason for the two death test styles has to do with thread
safety. Due to well-known problems with forking in the presence of
threads, death tests should be run in a single-threaded context.
Sometimes, however, it isn't feasible to arrange that kind of
environment. For example, statically-initialized modules may start
threads before main is ever reached. Once threads have been created, it
may be difficult or impossible to clean them up.</p>
<p>Google Test has three features intended to raise awareness of
threading issues.</p>
<ol type="1">
<li>A warning is emitted if multiple threads are running when a death
test is encountered.</li>
<li>Test cases with a name ending in "DeathTest" are run before all
other tests.</li>
<li>It uses <code>clone()</code> instead of <code>fork()</code> to spawn
the child process on Linux (<code>clone()</code> is not available on
Cygwin and Mac), as <code>fork()</code> is more likely to cause the
child to hang when the parent process has multiple threads.</li>
</ol>
<p>It's perfectly fine to create threads inside a death test statement;
they are executed in a separate process and cannot affect the
parent.</p>
<h2 id="death-test-styles">Death Test Styles</h2>
<p>The "threadsafe" death test style was introduced in order to help
mitigate the risks of testing in a possibly multithreaded environment.
It trades increased test execution time (potentially dramatically so)
for improved thread safety. We suggest using the faster, default "fast"
style unless your test has specific problems with it.</p>
<p>You can choose a particular style of death tests by setting the flag
programmatically:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">::testing::FLAGS_gtest_death_test_style = &quot;threadsafe&quot;;</span><br></pre></td></tr></table></figure>
<p>You can do this in <code>main()</code> to set the style for all death
tests in the binary, or in individual tests. Recall that flags are saved
before running each test and restored afterwards, so you need not do
that yourself. For example:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST(MyDeathTest, TestOne) &#123;</span><br><span class="line">  ::testing::FLAGS_gtest_death_test_style = &quot;threadsafe&quot;;</span><br><span class="line">  // This test is run in the &quot;threadsafe&quot; style:</span><br><span class="line">  ASSERT_DEATH(ThisShouldDie(), &quot;&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TEST(MyDeathTest, TestTwo) &#123;</span><br><span class="line">  // This test is run in the &quot;fast&quot; style:</span><br><span class="line">  ASSERT_DEATH(ThisShouldDie(), &quot;&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char** argv) &#123;</span><br><span class="line">  ::testing::InitGoogleTest(&amp;argc, argv);</span><br><span class="line">  ::testing::FLAGS_gtest_death_test_style = &quot;fast&quot;;</span><br><span class="line">  return RUN_ALL_TESTS();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="caveats">Caveats</h2>
<p>The <em>statement</em> argument of <code>ASSERT_EXIT()</code> can be
any valid C++ statement. If it leaves the current function via a
<code>return</code> statement or by throwing an exception, the death
test is considered to have failed. Some Google Test macros may return
from the current function (e.g. <code>ASSERT_TRUE()</code>), so be sure
to avoid them in <em>statement</em>.</p>
<p>Since <em>statement</em> runs in the child process, any in-memory
side effect (e.g. modifying a variable, releasing memory, etc) it causes
will <em>not</em> be observable in the parent process. In particular, if
you release memory in a death test, your program will fail the heap
check as the parent process will never see the memory reclaimed. To
solve this problem, you can</p>
<ol type="1">
<li>try not to free memory in a death test;</li>
<li>free the memory again in the parent process; or</li>
<li>do not use the heap checker in your program.</li>
</ol>
<p>Due to an implementation detail, you cannot place multiple death test
assertions on the same line; otherwise, compilation will fail with an
unobvious error message.</p>
<p>Despite the improved thread safety afforded by the "threadsafe" style
of death test, thread problems such as deadlock are still possible in
the presence of handlers registered with
<code>pthread_atfork(3)</code>.</p>
<h1 id="using-assertions-in-sub-routines">Using Assertions in
Sub-routines</h1>
<h2 id="adding-traces-to-assertions">Adding Traces to Assertions</h2>
<p>If a test sub-routine is called from several places, when an
assertion inside it fails, it can be hard to tell which invocation of
the sub-routine the failure is from. You can alleviate this problem
using extra logging or custom failure messages, but that usually
clutters up your tests. A better solution is to use the
<code>SCOPED_TRACE</code> macro:</p>
<table>
<thead>
<tr class="header">
<th
style="text-align: left;"><code>SCOPED_TRACE(</code><em>message</em><code>);</code></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>where <em>message</em> can be anything streamable to
<code>std::ostream</code>. This macro will cause the current file name,
line number, and the given message to be added in every failure message.
The effect will be undone when the control leaves the current lexical
scope.</p>
<p>For example,</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10: void Sub1(int n) &#123;</span><br><span class="line">11:   EXPECT_EQ(1, Bar(n));</span><br><span class="line">12:   EXPECT_EQ(2, Bar(n + 1));</span><br><span class="line">13: &#125;</span><br><span class="line">14:</span><br><span class="line">15: TEST(FooTest, Bar) &#123;</span><br><span class="line">16:   &#123;</span><br><span class="line">17:     SCOPED_TRACE(&quot;A&quot;);  // This trace point will be included in</span><br><span class="line">18:                         // every failure in this scope.</span><br><span class="line">19:     Sub1(1);</span><br><span class="line">20:   &#125;</span><br><span class="line">21:   // Now it won&#x27;t.</span><br><span class="line">22:   Sub1(9);</span><br><span class="line">23: &#125;</span><br></pre></td></tr></table></figure>
<p>could result in messages like these:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">path/to/foo_test.cc:11: Failure</span><br><span class="line">Value of: Bar(n)</span><br><span class="line">Expected: 1</span><br><span class="line">  Actual: 2</span><br><span class="line">   Trace:</span><br><span class="line">path/to/foo_test.cc:17: A</span><br><span class="line"></span><br><span class="line">path/to/foo_test.cc:12: Failure</span><br><span class="line">Value of: Bar(n + 1)</span><br><span class="line">Expected: 2</span><br><span class="line">  Actual: 3</span><br></pre></td></tr></table></figure>
<p>Without the trace, it would've been difficult to know which
invocation of <code>Sub1()</code> the two failures come from
respectively. (You could add an extra message to each assertion in
<code>Sub1()</code> to indicate the value of <code>n</code>, but that's
tedious.)</p>
<p>Some tips on using <code>SCOPED_TRACE</code>:</p>
<ol type="1">
<li>With a suitable message, it's often enough to use
<code>SCOPED_TRACE</code> at the beginning of a sub-routine, instead of
at each call site.</li>
<li>When calling sub-routines inside a loop, make the loop iterator part
of the message in <code>SCOPED_TRACE</code> such that you can know which
iteration the failure is from.</li>
<li>Sometimes the line number of the trace point is enough for
identifying the particular invocation of a sub-routine. In this case,
you don't have to choose a unique message for <code>SCOPED_TRACE</code>.
You can simply use <code>""</code>.</li>
<li>You can use <code>SCOPED_TRACE</code> in an inner scope when there
is one in the outer scope. In this case, all active trace points will be
included in the failure messages, in reverse order they are
encountered.</li>
<li>The trace dump is clickable in Emacs' compilation buffer - hit
return on a line number and you'll be taken to that line in the source
file!</li>
</ol>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h2 id="propagating-fatal-failures">Propagating Fatal Failures</h2>
<p>A common pitfall when using <code>ASSERT_*</code> and
<code>FAIL*</code> is not understanding that when they fail they only
abort the <em>current function</em>, not the entire test. For example,
the following test will segfault: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void Subroutine() &#123;</span><br><span class="line">  // Generates a fatal failure and aborts the current function.</span><br><span class="line">  ASSERT_EQ(1, 2);</span><br><span class="line">  // The following won&#x27;t be executed.</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TEST(FooTest, Bar) &#123;</span><br><span class="line">  Subroutine();</span><br><span class="line">  // The intended behavior is for the fatal failure</span><br><span class="line">  // in Subroutine() to abort the entire test.</span><br><span class="line">  // The actual behavior: the function goes on after Subroutine() returns.</span><br><span class="line">  int* p = NULL;</span><br><span class="line">  *p = 3; // Segfault!</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Since we don't use exceptions, it is technically impossible to
implement the intended behavior here. To alleviate this, Google Test
provides two solutions. You could use either the
<code>(ASSERT|EXPECT)_NO_FATAL_FAILURE</code> assertions or the
<code>HasFatalFailure()</code> function. They are described in the
following two subsections.</p>
<h3 id="asserting-on-subroutines">Asserting on Subroutines</h3>
<p>As shown above, if your test calls a subroutine that has an
<code>ASSERT_*</code> failure in it, the test will continue after the
subroutine returns. This may not be what you want.</p>
<p>Often people want fatal failures to propagate like exceptions. For
that Google Test offers the following macros:</p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Fatal assertion</strong></th>
<th style="text-align: left;"><strong>Nonfatal assertion</strong></th>
<th style="text-align: left;"><strong>Verifies</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>ASSERT_NO_FATAL_FAILURE(</code><em>statement</em><code>);</code></td>
<td
style="text-align: left;"><code>EXPECT_NO_FATAL_FAILURE(</code><em>statement</em><code>);</code></td>
<td style="text-align: left;"><em>statement</em> doesn't generate any
new fatal failures in the current thread.</td>
</tr>
</tbody>
</table>
<p>Only failures in the thread that executes the assertion are checked
to determine the result of this type of assertions. If
<em>statement</em> creates new threads, failures in these threads are
ignored.</p>
<p>Examples:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ASSERT_NO_FATAL_FAILURE(Foo());</span><br><span class="line"></span><br><span class="line">int i;</span><br><span class="line">EXPECT_NO_FATAL_FAILURE(&#123;</span><br><span class="line">  i = Bar();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p><em>Availability:</em> Linux, Windows, Mac. Assertions from multiple
threads are currently not supported.</p>
<h3 id="checking-for-failures-in-the-current-test">Checking for Failures
in the Current Test</h3>
<p><code>HasFatalFailure()</code> in the <code>::testing::Test</code>
class returns <code>true</code> if an assertion in the current test has
suffered a fatal failure. This allows functions to catch fatal failures
in a sub-routine and return early.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Test &#123;</span><br><span class="line"> public:</span><br><span class="line">  ...</span><br><span class="line">  static bool HasFatalFailure();</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>The typical usage, which basically simulates the behavior of a thrown
exception, is:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST(FooTest, Bar) &#123;</span><br><span class="line">  Subroutine();</span><br><span class="line">  // Aborts if Subroutine() had a fatal failure.</span><br><span class="line">  if (HasFatalFailure())</span><br><span class="line">    return;</span><br><span class="line">  // The following won&#x27;t be executed.</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>If <code>HasFatalFailure()</code> is used outside of
<code>TEST()</code> , <code>TEST_F()</code> , or a test fixture, you
must add the <code>::testing::Test::</code> prefix, as in:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (::testing::Test::HasFatalFailure())</span><br><span class="line">  return;</span><br></pre></td></tr></table></figure>
<p>Similarly, <code>HasNonfatalFailure()</code> returns
<code>true</code> if the current test has at least one non-fatal
failure, and <code>HasFailure()</code> returns <code>true</code> if the
current test has at least one failure of either kind.</p>
<p><em>Availability:</em> Linux, Windows, Mac.
<code>HasNonfatalFailure()</code> and <code>HasFailure()</code> are
available since version 1.4.0.</p>
<h1 id="logging-additional-information">Logging Additional
Information</h1>
<p>In your test code, you can call
<code>RecordProperty("key", value)</code> to log additional information,
where <code>value</code> can be either a string or an <code>int</code>.
The <em>last</em> value recorded for a key will be emitted to the XML
output if you specify one. For example, the test</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST_F(WidgetUsageTest, MinAndMaxWidgets) &#123;</span><br><span class="line">  RecordProperty(&quot;MaximumWidgets&quot;, ComputeMaxUsage());</span><br><span class="line">  RecordProperty(&quot;MinimumWidgets&quot;, ComputeMinUsage());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>will output XML like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">  &lt;testcase name=&quot;MinAndMaxWidgets&quot; status=&quot;run&quot; time=&quot;6&quot; classname=&quot;WidgetUsageTest&quot;</span><br><span class="line">            MaximumWidgets=&quot;12&quot;</span><br><span class="line">            MinimumWidgets=&quot;9&quot; /&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p><em>Note</em>: * <code>RecordProperty()</code> is a static member of
the <code>Test</code> class. Therefore it needs to be prefixed with
<code>::testing::Test::</code> if used outside of the <code>TEST</code>
body and the test fixture class. * <code>key</code> must be a valid XML
attribute name, and cannot conflict with the ones already used by Google
Test (<code>name</code>, <code>status</code>, <code>time</code>,
<code>classname</code>, <code>type_param</code>, and
<code>value_param</code>). * Calling <code>RecordProperty()</code>
outside of the lifespan of a test is allowed. If it's called outside of
a test but between a test case's <code>SetUpTestCase()</code> and
<code>TearDownTestCase()</code> methods, it will be attributed to the
XML element for the test case. If it's called outside of all test cases
(e.g. in a test environment), it will be attributed to the top-level XML
element.</p>
<p><em>Availability</em>: Linux, Windows, Mac.</p>
<h1 id="sharing-resources-between-tests-in-the-same-test-case">Sharing
Resources Between Tests in the Same Test Case</h1>
<p>Google Test creates a new test fixture object for each test in order
to make tests independent and easier to debug. However, sometimes tests
use resources that are expensive to set up, making the one-copy-per-test
model prohibitively expensive.</p>
<p>If the tests don't change the resource, there's no harm in them
sharing a single resource copy. So, in addition to per-test
set-up/tear-down, Google Test also supports per-test-case
set-up/tear-down. To use it:</p>
<ol type="1">
<li>In your test fixture class (say <code>FooTest</code> ), define as
<code>static</code> some member variables to hold the shared
resources.</li>
<li>In the same test fixture class, define a
<code>static void SetUpTestCase()</code> function (remember not to spell
it as <strong><code>SetupTestCase</code></strong> with a small
<code>u</code>!) to set up the shared resources and a
<code>static void TearDownTestCase()</code> function to tear them
down.</li>
</ol>
<p>That's it! Google Test automatically calls
<code>SetUpTestCase()</code> before running the <em>first test</em> in
the <code>FooTest</code> test case (i.e. before creating the first
<code>FooTest</code> object), and calls <code>TearDownTestCase()</code>
after running the <em>last test</em> in it (i.e. after deleting the last
<code>FooTest</code> object). In between, the tests can use the shared
resources.</p>
<p>Remember that the test order is undefined, so your code can't depend
on a test preceding or following another. Also, the tests must either
not modify the state of any shared resource, or, if they do modify the
state, they must restore the state to its original value before passing
control to the next test.</p>
<p>Here's an example of per-test-case set-up and tear-down:
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class FooTest : public ::testing::Test &#123;</span><br><span class="line"> protected:</span><br><span class="line">  // Per-test-case set-up.</span><br><span class="line">  // Called before the first test in this test case.</span><br><span class="line">  // Can be omitted if not needed.</span><br><span class="line">  static void SetUpTestCase() &#123;</span><br><span class="line">    shared_resource_ = new ...;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // Per-test-case tear-down.</span><br><span class="line">  // Called after the last test in this test case.</span><br><span class="line">  // Can be omitted if not needed.</span><br><span class="line">  static void TearDownTestCase() &#123;</span><br><span class="line">    delete shared_resource_;</span><br><span class="line">    shared_resource_ = NULL;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // You can define per-test set-up and tear-down logic as usual.</span><br><span class="line">  virtual void SetUp() &#123; ... &#125;</span><br><span class="line">  virtual void TearDown() &#123; ... &#125;</span><br><span class="line"></span><br><span class="line">  // Some expensive resource shared by all tests.</span><br><span class="line">  static T* shared_resource_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">T* FooTest::shared_resource_ = NULL;</span><br><span class="line"></span><br><span class="line">TEST_F(FooTest, Test1) &#123;</span><br><span class="line">  ... you can refer to shared_resource here ...</span><br><span class="line">&#125;</span><br><span class="line">TEST_F(FooTest, Test2) &#123;</span><br><span class="line">  ... you can refer to shared_resource here ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h1 id="global-set-up-and-tear-down">Global Set-Up and Tear-Down</h1>
<p>Just as you can do set-up and tear-down at the test level and the
test case level, you can also do it at the test program level. Here's
how.</p>
<p>First, you subclass the <code>::testing::Environment</code> class to
define a test environment, which knows how to set-up and tear-down:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Environment &#123;</span><br><span class="line"> public:</span><br><span class="line">  virtual ~Environment() &#123;&#125;</span><br><span class="line">  // Override this to define how to set up the environment.</span><br><span class="line">  virtual void SetUp() &#123;&#125;</span><br><span class="line">  // Override this to define how to tear down the environment.</span><br><span class="line">  virtual void TearDown() &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>Then, you register an instance of your environment class with Google
Test by calling the <code>::testing::AddGlobalTestEnvironment()</code>
function:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Environment* AddGlobalTestEnvironment(Environment* env);</span><br></pre></td></tr></table></figure>
<p>Now, when <code>RUN_ALL_TESTS()</code> is called, it first calls the
<code>SetUp()</code> method of the environment object, then runs the
tests if there was no fatal failures, and finally calls
<code>TearDown()</code> of the environment object.</p>
<p>It's OK to register multiple environment objects. In this case, their
<code>SetUp()</code> will be called in the order they are registered,
and their <code>TearDown()</code> will be called in the reverse
order.</p>
<p>Note that Google Test takes ownership of the registered environment
objects. Therefore <strong>do not delete them</strong> by yourself.</p>
<p>You should call <code>AddGlobalTestEnvironment()</code> before
<code>RUN_ALL_TESTS()</code> is called, probably in <code>main()</code>.
If you use <code>gtest_main</code>, you need to call this before
<code>main()</code> starts for it to take effect. One way to do this is
to define a global variable like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">::testing::Environment* const foo_env = ::testing::AddGlobalTestEnvironment(new FooEnvironment);</span><br></pre></td></tr></table></figure>
<p>However, we strongly recommend you to write your own
<code>main()</code> and call <code>AddGlobalTestEnvironment()</code>
there, as relying on initialization of global variables makes the code
harder to read and may cause problems when you register multiple
environments from different translation units and the environments have
dependencies among them (remember that the compiler doesn't guarantee
the order in which global variables from different translation units are
initialized).</p>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h1 id="value-parameterized-tests">Value Parameterized Tests</h1>
<p><em>Value-parameterized tests</em> allow you to test your code with
different parameters without writing multiple copies of the same
test.</p>
<p>Suppose you write a test for your code and then realize that your
code is affected by a presence of a Boolean command line flag.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST(MyCodeTest, TestFoo) &#123;</span><br><span class="line">  // A code to test foo().</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Usually people factor their test code into a function with a Boolean
parameter in such situations. The function sets the flag, then executes
the testing code.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void TestFooHelper(bool flag_value) &#123;</span><br><span class="line">  flag = flag_value;</span><br><span class="line">  // A code to test foo().</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TEST(MyCodeTest, TestFoo) &#123;</span><br><span class="line">  TestFooHelper(false);</span><br><span class="line">  TestFooHelper(true);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>But this setup has serious drawbacks. First, when a test assertion
fails in your tests, it becomes unclear what value of the parameter
caused it to fail. You can stream a clarifying message into your
<code>EXPECT</code>/<code>ASSERT</code> statements, but it you'll have
to do it with all of them. Second, you have to add one such helper
function per test. What if you have ten tests? Twenty? A hundred?</p>
<p>Value-parameterized tests will let you write your test only once and
then easily instantiate and run it with an arbitrary number of parameter
values.</p>
<p>Here are some other situations when value-parameterized tests come
handy:</p>
<ul>
<li>You want to test different implementations of an OO interface.</li>
<li>You want to test your code over various inputs (a.k.a. data-driven
testing). This feature is easy to abuse, so please exercise your good
sense when doing it!</li>
</ul>
<h2 id="how-to-write-value-parameterized-tests">How to Write
Value-Parameterized Tests</h2>
<p>To write value-parameterized tests, first you should define a fixture
class. It must be derived from both <code>::testing::Test</code> and
<code>::testing::WithParamInterface&lt;T&gt;</code> (the latter is a
pure interface), where <code>T</code> is the type of your parameter
values. For convenience, you can just derive the fixture class from
<code>::testing::TestWithParam&lt;T&gt;</code>, which itself is derived
from both <code>::testing::Test</code> and
<code>::testing::WithParamInterface&lt;T&gt;</code>. <code>T</code> can
be any copyable type. If it's a raw pointer, you are responsible for
managing the lifespan of the pointed values.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class FooTest : public ::testing::TestWithParam&lt;const char*&gt; &#123;</span><br><span class="line">  // You can implement all the usual fixture class members here.</span><br><span class="line">  // To access the test parameter, call GetParam() from class</span><br><span class="line">  // TestWithParam&lt;T&gt;.</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">// Or, when you want to add parameters to a pre-existing fixture class:</span><br><span class="line">class BaseTest : public ::testing::Test &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br><span class="line">class BarTest : public BaseTest,</span><br><span class="line">                public ::testing::WithParamInterface&lt;const char*&gt; &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>Then, use the <code>TEST_P</code> macro to define as many test
patterns using this fixture as you want. The <code>_P</code> suffix is
for "parameterized" or "pattern", whichever you prefer to think.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST_P(FooTest, DoesBlah) &#123;</span><br><span class="line">  // Inside a test, access the test parameter with the GetParam() method</span><br><span class="line">  // of the TestWithParam&lt;T&gt; class:</span><br><span class="line">  EXPECT_TRUE(foo.Blah(GetParam()));</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TEST_P(FooTest, HasBlahBlah) &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Finally, you can use <code>INSTANTIATE_TEST_CASE_P</code> to
instantiate the test case with any set of parameters you want. Google
Test defines a number of functions for generating test parameters. They
return what we call (surprise!) <em>parameter generators</em>. Here is a
summary of them, which are all in the <code>testing</code>
namespace:</p>
<table>
<colgroup>
<col style="width: 20%" />
<col style="width: 79%" />
</colgroup>
<thead>
<tr class="header">
<th
style="text-align: left;"><code>Range(begin, end[, step])</code></th>
<th style="text-align: left;">Yields values
<code>&#123;begin, begin+step, begin+step+step, ...&#125;</code>. The values do
not include <code>end</code>. <code>step</code> defaults to 1.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>Values(v1, v2, ..., vN)</code></td>
<td style="text-align: left;">Yields values
<code>&#123;v1, v2, ..., vN&#125;</code>.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>ValuesIn(container)</code> and
<code>ValuesIn(begin, end)</code></td>
<td style="text-align: left;">Yields values from a C-style array, an
STL-style container, or an iterator range <code>[begin, end)</code>.
<code>container</code>, <code>begin</code>, and <code>end</code> can be
expressions whose values are determined at run time.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>Bool()</code></td>
<td style="text-align: left;">Yields sequence
<code>&#123;false, true&#125;</code>.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Combine(g1, g2, ..., gN)</code></td>
<td style="text-align: left;">Yields all combinations (the Cartesian
product for the math savvy) of the values generated by the
<code>N</code> generators. This is only available if your system
provides the <code>&lt;tr1/tuple&gt;</code> header. If you are sure your
system does, and Google Test disagrees, you can override it by defining
<code>GTEST_HAS_TR1_TUPLE=1</code>. See comments in <a
href="../include/gtest/internal/gtest-port.h">include/gtest/internal/gtest-port.h</a>
for more information.</td>
</tr>
</tbody>
</table>
<p>For more details, see the comments at the definitions of these
functions in the <a href="../include/gtest/gtest-param-test.h">source
code</a>.</p>
<p>The following statement will instantiate tests from the
<code>FooTest</code> test case each with parameter values
<code>"meeny"</code>, <code>"miny"</code>, and <code>"moe"</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INSTANTIATE_TEST_CASE_P(InstantiationName,</span><br><span class="line">                        FooTest,</span><br><span class="line">                        ::testing::Values(&quot;meeny&quot;, &quot;miny&quot;, &quot;moe&quot;));</span><br></pre></td></tr></table></figure>
<p>To distinguish different instances of the pattern (yes, you can
instantiate it more than once), the first argument to
<code>INSTANTIATE_TEST_CASE_P</code> is a prefix that will be added to
the actual test case name. Remember to pick unique prefixes for
different instantiations. The tests from the instantiation above will
have these names:</p>
<ul>
<li><code>InstantiationName/FooTest.DoesBlah/0</code> for
<code>"meeny"</code></li>
<li><code>InstantiationName/FooTest.DoesBlah/1</code> for
<code>"miny"</code></li>
<li><code>InstantiationName/FooTest.DoesBlah/2</code> for
<code>"moe"</code></li>
<li><code>InstantiationName/FooTest.HasBlahBlah/0</code> for
<code>"meeny"</code></li>
<li><code>InstantiationName/FooTest.HasBlahBlah/1</code> for
<code>"miny"</code></li>
<li><code>InstantiationName/FooTest.HasBlahBlah/2</code> for
<code>"moe"</code></li>
</ul>
<p>You can use these names in <a
href="#running-a-subset-of-the-tests">--gtest_filter</a>.</p>
<p>This statement will instantiate all tests from <code>FooTest</code>
again, each with parameter values <code>"cat"</code> and
<code>"dog"</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const char* pets[] = &#123;&quot;cat&quot;, &quot;dog&quot;&#125;;</span><br><span class="line">INSTANTIATE_TEST_CASE_P(AnotherInstantiationName, FooTest,</span><br><span class="line">                        ::testing::ValuesIn(pets));</span><br></pre></td></tr></table></figure>
<p>The tests from the instantiation above will have these names:</p>
<ul>
<li><code>AnotherInstantiationName/FooTest.DoesBlah/0</code> for
<code>"cat"</code></li>
<li><code>AnotherInstantiationName/FooTest.DoesBlah/1</code> for
<code>"dog"</code></li>
<li><code>AnotherInstantiationName/FooTest.HasBlahBlah/0</code> for
<code>"cat"</code></li>
<li><code>AnotherInstantiationName/FooTest.HasBlahBlah/1</code> for
<code>"dog"</code></li>
</ul>
<p>Please note that <code>INSTANTIATE_TEST_CASE_P</code> will
instantiate <em>all</em> tests in the given test case, whether their
definitions come before or <em>after</em> the
<code>INSTANTIATE_TEST_CASE_P</code> statement.</p>
<p>You can see <a href="../samples/sample7_unittest.cc">these</a> <a
href="../samples/sample8_unittest.cc">files</a> for more examples.</p>
<p><em>Availability</em>: Linux, Windows (requires MSVC 8.0 or above),
Mac; since version 1.2.0.</p>
<h2 id="creating-value-parameterized-abstract-tests">Creating
Value-Parameterized Abstract Tests</h2>
<p>In the above, we define and instantiate <code>FooTest</code> in the
same source file. Sometimes you may want to define value-parameterized
tests in a library and let other people instantiate them later. This
pattern is known as <i>abstract tests</i>. As an example of its
application, when you are designing an interface you can write a
standard suite of abstract tests (perhaps using a factory function as
the test parameter) that all implementations of the interface are
expected to pass. When someone implements the interface, he can
instantiate your suite to get all the interface-conformance tests for
free.</p>
<p>To define abstract tests, you should organize your code like
this:</p>
<ol type="1">
<li>Put the definition of the parameterized test fixture class (e.g.
<code>FooTest</code>) in a header file, say
<code>foo_param_test.h</code>. Think of this as <em>declaring</em> your
abstract tests.</li>
<li>Put the <code>TEST_P</code> definitions in
<code>foo_param_test.cc</code>, which includes
<code>foo_param_test.h</code>. Think of this as <em>implementing</em>
your abstract tests.</li>
</ol>
<p>Once they are defined, you can instantiate them by including
<code>foo_param_test.h</code>, invoking
<code>INSTANTIATE_TEST_CASE_P()</code>, and linking with
<code>foo_param_test.cc</code>. You can instantiate the same abstract
test case multiple times, possibly in different source files.</p>
<h1 id="typed-tests">Typed Tests</h1>
<p>Suppose you have multiple implementations of the same interface and
want to make sure that all of them satisfy some common requirements. Or,
you may have defined several types that are supposed to conform to the
same "concept" and you want to verify it. In both cases, you want the
same test logic repeated for different types.</p>
<p>While you can write one <code>TEST</code> or <code>TEST_F</code> for
each type you want to test (and you may even factor the test logic into
a function template that you invoke from the <code>TEST</code>), it's
tedious and doesn't scale: if you want <em>m</em> tests over <em>n</em>
types, you'll end up writing <em>m*n</em> <code>TEST</code>s.</p>
<p><em>Typed tests</em> allow you to repeat the same test logic over a
list of types. You only need to write the test logic once, although you
must know the type list when writing typed tests. Here's how you do
it:</p>
<p>First, define a fixture class template. It should be parameterized by
a type. Remember to derive it from <code>::testing::Test</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">template &lt;typename T&gt;</span><br><span class="line">class FooTest : public ::testing::Test &#123;</span><br><span class="line"> public:</span><br><span class="line">  ...</span><br><span class="line">  typedef std::list&lt;T&gt; List;</span><br><span class="line">  static T shared_;</span><br><span class="line">  T value_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>Next, associate a list of types with the test case, which will be
repeated for each type in the list:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">typedef ::testing::Types&lt;char, int, unsigned int&gt; MyTypes;</span><br><span class="line">TYPED_TEST_CASE(FooTest, MyTypes);</span><br></pre></td></tr></table></figure>
<p>The <code>typedef</code> is necessary for the
<code>TYPED_TEST_CASE</code> macro to parse correctly. Otherwise the
compiler will think that each comma in the type list introduces a new
macro argument.</p>
<p>Then, use <code>TYPED_TEST()</code> instead of <code>TEST_F()</code>
to define a typed test for this test case. You can repeat this as many
times as you want:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TYPED_TEST(FooTest, DoesBlah) &#123;</span><br><span class="line">  // Inside a test, refer to the special name TypeParam to get the type</span><br><span class="line">  // parameter.  Since we are inside a derived class template, C++ requires</span><br><span class="line">  // us to visit the members of FooTest via &#x27;this&#x27;.</span><br><span class="line">  TypeParam n = this-&gt;value_;</span><br><span class="line"></span><br><span class="line">  // To visit static members of the fixture, add the &#x27;TestFixture::&#x27;</span><br><span class="line">  // prefix.</span><br><span class="line">  n += TestFixture::shared_;</span><br><span class="line"></span><br><span class="line">  // To refer to typedefs in the fixture, add the &#x27;typename TestFixture::&#x27;</span><br><span class="line">  // prefix.  The &#x27;typename&#x27; is required to satisfy the compiler.</span><br><span class="line">  typename TestFixture::List values;</span><br><span class="line">  values.push_back(n);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TYPED_TEST(FooTest, HasPropertyA) &#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>You can see <code>samples/sample6_unittest.cc</code> for a complete
example.</p>
<p><em>Availability:</em> Linux, Windows (requires MSVC 8.0 or above),
Mac; since version 1.1.0.</p>
<h1 id="type-parameterized-tests">Type-Parameterized Tests</h1>
<p><em>Type-parameterized tests</em> are like typed tests, except that
they don't require you to know the list of types ahead of time. Instead,
you can define the test logic first and instantiate it with different
type lists later. You can even instantiate it more than once in the same
program.</p>
<p>If you are designing an interface or concept, you can define a suite
of type-parameterized tests to verify properties that any valid
implementation of the interface/concept should have. Then, the author of
each implementation can just instantiate the test suite with his type to
verify that it conforms to the requirements, without having to write
similar tests repeatedly. Here's an example:</p>
<p>First, define a fixture class template, as we did with typed
tests:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">template &lt;typename T&gt;</span><br><span class="line">class FooTest : public ::testing::Test &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>Next, declare that you will define a type-parameterized test
case:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TYPED_TEST_CASE_P(FooTest);</span><br></pre></td></tr></table></figure>
<p>The <code>_P</code> suffix is for "parameterized" or "pattern",
whichever you prefer to think.</p>
<p>Then, use <code>TYPED_TEST_P()</code> to define a type-parameterized
test. You can repeat this as many times as you want:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TYPED_TEST_P(FooTest, DoesBlah) &#123;</span><br><span class="line">  // Inside a test, refer to TypeParam to get the type parameter.</span><br><span class="line">  TypeParam n = 0;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TYPED_TEST_P(FooTest, HasPropertyA) &#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>Now the tricky part: you need to register all test patterns using the
<code>REGISTER_TYPED_TEST_CASE_P</code> macro before you can instantiate
them. The first argument of the macro is the test case name; the rest
are the names of the tests in this test case:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">REGISTER_TYPED_TEST_CASE_P(FooTest,</span><br><span class="line">                           DoesBlah, HasPropertyA);</span><br></pre></td></tr></table></figure>
<p>Finally, you are free to instantiate the pattern with the types you
want. If you put the above code in a header file, you can
<code>#include</code> it in multiple C++ source files and instantiate it
multiple times.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">typedef ::testing::Types&lt;char, int, unsigned int&gt; MyTypes;</span><br><span class="line">INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, MyTypes);</span><br></pre></td></tr></table></figure>
<p>To distinguish different instances of the pattern, the first argument
to the <code>INSTANTIATE_TYPED_TEST_CASE_P</code> macro is a prefix that
will be added to the actual test case name. Remember to pick unique
prefixes for different instances.</p>
<p>In the special case where the type list contains only one type, you
can write that type directly without
<code>::testing::Types&lt;...&gt;</code>, like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, int);</span><br></pre></td></tr></table></figure>
<p>You can see <code>samples/sample6_unittest.cc</code> for a complete
example.</p>
<p><em>Availability:</em> Linux, Windows (requires MSVC 8.0 or above),
Mac; since version 1.1.0.</p>
<h1 id="testing-private-code">Testing Private Code</h1>
<p>If you change your software's internal implementation, your tests
should not break as long as the change is not observable by users.
Therefore, per the <em>black-box testing principle</em>, most of the
time you should test your code through its public interfaces.</p>
<p>If you still find yourself needing to test internal implementation
code, consider if there's a better design that wouldn't require you to
do so. If you absolutely have to test non-public interface code though,
you can. There are two cases to consider:</p>
<ul>
<li>Static functions (<em>not</em> the same as static member functions!)
or unnamed namespaces, and</li>
<li>Private or protected class members</li>
</ul>
<h2 id="static-functions">Static Functions</h2>
<p>Both static functions and definitions/declarations in an unnamed
namespace are only visible within the same translation unit. To test
them, you can <code>#include</code> the entire <code>.cc</code> file
being tested in your <code>*_test.cc</code> file.
(<code>#include</code>ing <code>.cc</code> files is not a good way to
reuse code - you should not do this in production code!)</p>
<p>However, a better approach is to move the private code into the
<code>foo::internal</code> namespace, where <code>foo</code> is the
namespace your project normally uses, and put the private declarations
in a <code>*-internal.h</code> file. Your production <code>.cc</code>
files and your tests are allowed to include this internal header, but
your clients are not. This way, you can fully test your internal
implementation without leaking it to your clients.</p>
<h2 id="private-class-members">Private Class Members</h2>
<p>Private class members are only accessible from within the class or by
friends. To access a class' private members, you can declare your test
fixture as a friend to the class and define accessors in your fixture.
Tests using the fixture can then access the private members of your
production class via the accessors in the fixture. Note that even though
your fixture is a friend to your production class, your tests are not
automatically friends to it, as they are technically defined in
sub-classes of the fixture.</p>
<p>Another way to test private members is to refactor them into an
implementation class, which is then declared in a
<code>*-internal.h</code> file. Your clients aren't allowed to include
this header but your tests can. Such is called the Pimpl (Private
Implementation) idiom.</p>
<p>Or, you can declare an individual test as a friend of your class by
adding this line in the class body:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FRIEND_TEST(TestCaseName, TestName);</span><br></pre></td></tr></table></figure>
<p>For example, <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// foo.h</span><br><span class="line">#include &quot;gtest/gtest_prod.h&quot;</span><br><span class="line"></span><br><span class="line">// Defines FRIEND_TEST.</span><br><span class="line">class Foo &#123;</span><br><span class="line">  ...</span><br><span class="line"> private:</span><br><span class="line">  FRIEND_TEST(FooTest, BarReturnsZeroOnNull);</span><br><span class="line">  int Bar(void* x);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">// foo_test.cc</span><br><span class="line">...</span><br><span class="line">TEST(FooTest, BarReturnsZeroOnNull) &#123;</span><br><span class="line">  Foo foo;</span><br><span class="line">  EXPECT_EQ(0, foo.Bar(NULL));</span><br><span class="line">  // Uses Foo&#x27;s private member Bar().</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Pay special attention when your class is defined in a namespace, as
you should define your test fixtures and tests in the same namespace if
you want them to be friends of your class. For example, if the code to
be tested looks like:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">namespace my_namespace &#123;</span><br><span class="line"></span><br><span class="line">class Foo &#123;</span><br><span class="line">  friend class FooTest;</span><br><span class="line">  FRIEND_TEST(FooTest, Bar);</span><br><span class="line">  FRIEND_TEST(FooTest, Baz);</span><br><span class="line">  ...</span><br><span class="line">  definition of the class Foo</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  // namespace my_namespace</span><br></pre></td></tr></table></figure>
<p>Your test code should be something like:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">namespace my_namespace &#123;</span><br><span class="line">class FooTest : public ::testing::Test &#123;</span><br><span class="line"> protected:</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">TEST_F(FooTest, Bar) &#123; ... &#125;</span><br><span class="line">TEST_F(FooTest, Baz) &#123; ... &#125;</span><br><span class="line"></span><br><span class="line">&#125;  // namespace my_namespace</span><br></pre></td></tr></table></figure>
<h1 id="catching-failures">Catching Failures</h1>
<p>If you are building a testing utility on top of Google Test, you'll
want to test your utility. What framework would you use to test it?
Google Test, of course.</p>
<p>The challenge is to verify that your testing utility reports failures
correctly. In frameworks that report a failure by throwing an exception,
you could catch the exception and assert on it. But Google Test doesn't
use exceptions, so how do we test that a piece of code generates an
expected failure?</p>
<p><code>"gtest/gtest-spi.h"</code> contains some constructs to do this.
After <code>#include</code>ing this header, you can use</p>
<table>
<thead>
<tr class="header">
<th
style="text-align: left;"><code>EXPECT_FATAL_FAILURE(</code><em>statement,
substring</em><code>);</code></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>to assert that <em>statement</em> generates a fatal (e.g.
<code>ASSERT_*</code>) failure whose message contains the given
<em>substring</em>, or use</p>
<table>
<thead>
<tr class="header">
<th
style="text-align: left;"><code>EXPECT_NONFATAL_FAILURE(</code><em>statement,
substring</em><code>);</code></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>if you are expecting a non-fatal (e.g. <code>EXPECT_*</code>)
failure.</p>
<p>For technical reasons, there are some caveats:</p>
<ol type="1">
<li>You cannot stream a failure message to either macro.</li>
<li><em>statement</em> in <code>EXPECT_FATAL_FAILURE()</code> cannot
reference local non-static variables or non-static members of
<code>this</code> object.</li>
<li><em>statement</em> in <code>EXPECT_FATAL_FAILURE()</code> cannot
return a value.</li>
</ol>
<p><em>Note:</em> Google Test is designed with threads in mind. Once the
synchronization primitives in <code>"gtest/internal/gtest-port.h"</code>
have been implemented, Google Test will become thread-safe, meaning that
you can then use assertions in multiple threads concurrently. Before
that, however, Google Test only supports single-threaded usage. Once
thread-safe, <code>EXPECT_FATAL_FAILURE()</code> and
<code>EXPECT_NONFATAL_FAILURE()</code> will capture failures in the
current thread only. If <em>statement</em> creates new threads, failures
in these threads will be ignored. If you want to capture failures from
all threads instead, you should use the following macros:</p>
<table>
<thead>
<tr class="header">
<th
style="text-align: left;"><code>EXPECT_FATAL_FAILURE_ON_ALL_THREADS(</code><em>statement,
substring</em><code>);</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>EXPECT_NONFATAL_FAILURE_ON_ALL_THREADS(</code><em>statement,
substring</em><code>);</code></td>
</tr>
</tbody>
</table>
<h1 id="getting-the-current-tests-name">Getting the Current Test's
Name</h1>
<p>Sometimes a function may need to know the name of the currently
running test. For example, you may be using the <code>SetUp()</code>
method of your test fixture to set the golden file name based on which
test is running. The <code>::testing::TestInfo</code> class has this
information:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">namespace testing &#123;</span><br><span class="line"></span><br><span class="line">class TestInfo &#123;</span><br><span class="line"> public:</span><br><span class="line">  // Returns the test case name and the test name, respectively.</span><br><span class="line">  //</span><br><span class="line">  // Do NOT delete or free the return value - it&#x27;s managed by the</span><br><span class="line">  // TestInfo class.</span><br><span class="line">  const char* test_case_name() const;</span><br><span class="line">  const char* name() const;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  // namespace testing</span><br></pre></td></tr></table></figure>
<blockquote>
<p>To obtain a <code>TestInfo</code> object for the currently running
test, call <code>current_test_info()</code> on the <code>UnitTest</code>
singleton object:</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Gets information about the currently running test.</span><br><span class="line">// Do NOT delete the returned object - it&#x27;s managed by the UnitTest class.</span><br><span class="line">const ::testing::TestInfo* const test_info =</span><br><span class="line">  ::testing::UnitTest::GetInstance()-&gt;current_test_info();</span><br><span class="line">printf(&quot;We are in test %s of test case %s.\n&quot;,</span><br><span class="line">       test_info-&gt;name(), test_info-&gt;test_case_name());</span><br></pre></td></tr></table></figure>
<p><code>current_test_info()</code> returns a null pointer if no test is
running. In particular, you cannot find the test case name in
<code>TestCaseSetUp()</code>, <code>TestCaseTearDown()</code> (where you
know the test case name implicitly), or functions called from them.</p>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h1 id="extending-google-test-by-handling-test-events">Extending Google
Test by Handling Test Events</h1>
<p>Google Test provides an <b>event listener API</b> to let you receive
notifications about the progress of a test program and test failures.
The events you can listen to include the start and end of the test
program, a test case, or a test method, among others. You may use this
API to augment or replace the standard console output, replace the XML
output, or provide a completely different form of output, such as a GUI
or a database. You can also use test events as checkpoints to implement
a resource leak checker, for example.</p>
<p><em>Availability:</em> Linux, Windows, Mac; since v1.4.0.</p>
<h2 id="defining-event-listeners">Defining Event Listeners</h2>
<p>To define a event listener, you subclass either <a
href="../include/gtest/gtest.h#L991">testing::TestEventListener</a> or
<a
href="../include/gtest/gtest.h#L1044">testing::EmptyTestEventListener</a>.
The former is an (abstract) interface, where <i>each pure virtual
method<br> can be overridden to handle a test event</i> (For example,
when a test starts, the <code>OnTestStart()</code> method will be
called.). The latter provides an empty implementation of all methods in
the interface, such that a subclass only needs to override the methods
it cares about.</p>
<p>When an event is fired, its context is passed to the handler function
as an argument. The following argument types are used: * <a
href="../include/gtest/gtest.h#L1151">UnitTest</a> reflects the state of
the entire test program, * <a
href="../include/gtest/gtest.h#L778">TestCase</a> has information about
a test case, which can contain one or more tests, * <a
href="../include/gtest/gtest.h#L644">TestInfo</a> contains the state of
a test, and * <a
href="../include/gtest/gtest-test-part.h#L47">TestPartResult</a>
represents the result of a test assertion.</p>
<p>An event handler function can examine the argument it receives to
find out interesting information about the event and the test program's
state. Here's an example:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class MinimalistPrinter : public ::testing::EmptyTestEventListener &#123;</span><br><span class="line">  // Called before a test starts.</span><br><span class="line">  virtual void OnTestStart(const ::testing::TestInfo&amp; test_info) &#123;</span><br><span class="line">    printf(&quot;*** Test %s.%s starting.\n&quot;,</span><br><span class="line">           test_info.test_case_name(), test_info.name());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // Called after a failed assertion or a SUCCEED() invocation.</span><br><span class="line">  virtual void OnTestPartResult(</span><br><span class="line">      const ::testing::TestPartResult&amp; test_part_result) &#123;</span><br><span class="line">    printf(&quot;%s in %s:%d\n%s\n&quot;,</span><br><span class="line">           test_part_result.failed() ? &quot;*** Failure&quot; : &quot;Success&quot;,</span><br><span class="line">           test_part_result.file_name(),</span><br><span class="line">           test_part_result.line_number(),</span><br><span class="line">           test_part_result.summary());</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  // Called after a test ends.</span><br><span class="line">  virtual void OnTestEnd(const ::testing::TestInfo&amp; test_info) &#123;</span><br><span class="line">    printf(&quot;*** Test %s.%s ending.\n&quot;,</span><br><span class="line">           test_info.test_case_name(), test_info.name());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="using-event-listeners">Using Event Listeners</h2>
<p>To use the event listener you have defined, add an instance of it to
the Google Test event listener list (represented by class <a
href="../include/gtest/gtest.h#L1064">TestEventListeners</a> - note the
"s" at the end of the name) in your <code>main()</code> function, before
calling <code>RUN_ALL_TESTS()</code>: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int main(int argc, char** argv) &#123;</span><br><span class="line">  ::testing::InitGoogleTest(&amp;argc, argv);</span><br><span class="line">  // Gets hold of the event listener list.</span><br><span class="line">  ::testing::TestEventListeners&amp; listeners =</span><br><span class="line">      ::testing::UnitTest::GetInstance()-&gt;listeners();</span><br><span class="line">  // Adds a listener to the end.  Google Test takes the ownership.</span><br><span class="line">  listeners.Append(new MinimalistPrinter);</span><br><span class="line">  return RUN_ALL_TESTS();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>There's only one problem: the default test result printer is still in
effect, so its output will mingle with the output from your minimalist
printer. To suppress the default printer, just release it from the event
listener list and delete it. You can do so by adding one line:
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">delete listeners.Release(listeners.default_result_printer());</span><br><span class="line">listeners.Append(new MinimalistPrinter);</span><br><span class="line">return RUN_ALL_TESTS();</span><br></pre></td></tr></table></figure></p>
<p>Now, sit back and enjoy a completely different output from your
tests. For more details, you can read this <a
href="../samples/sample9_unittest.cc">sample</a>.</p>
<p>You may append more than one listener to the list. When an
<code>On*Start()</code> or <code>OnTestPartResult()</code> event is
fired, the listeners will receive it in the order they appear in the
list (since new listeners are added to the end of the list, the default
text printer and the default XML generator will receive the event
first). An <code>On*End()</code> event will be received by the listeners
in the <em>reverse</em> order. This allows output by listeners added
later to be framed by output from listeners added earlier.</p>
<h2 id="generating-failures-in-listeners">Generating Failures in
Listeners</h2>
<p>You may use failure-raising macros (<code>EXPECT_*()</code>,
<code>ASSERT_*()</code>, <code>FAIL()</code>, etc) when processing an
event. There are some restrictions:</p>
<ol type="1">
<li>You cannot generate any failure in <code>OnTestPartResult()</code>
(otherwise it will cause <code>OnTestPartResult()</code> to be called
recursively).</li>
<li>A listener that handles <code>OnTestPartResult()</code> is not
allowed to generate any failure.</li>
</ol>
<p>When you add listeners to the listener list, you should put listeners
that handle <code>OnTestPartResult()</code> <em>before</em> listeners
that can generate failures. This ensures that failures generated by the
latter are attributed to the right test by the former.</p>
<p>We have a sample of failure-raising listener <a
href="../samples/sample10_unittest.cc">here</a>.</p>
<h1 id="running-test-programs-advanced-options">Running Test Programs:
Advanced Options</h1>
<p>Google Test test programs are ordinary executables. Once built, you
can run them directly and affect their behavior via the following
environment variables and/or command line flags. For the flags to work,
your programs must call <code>::testing::InitGoogleTest()</code> before
calling <code>RUN_ALL_TESTS()</code>.</p>
<p>To see a list of supported flags and their usage, please run your
test program with the <code>--help</code> flag. You can also use
<code>-h</code>, <code>-?</code>, or <code>/?</code> for short. This
feature is added in version 1.3.0.</p>
<p>If an option is specified both by an environment variable and by a
flag, the latter takes precedence. Most of the options can also be
set/read in code: to access the value of command line flag
<code>--gtest_foo</code>, write <code>::testing::GTEST_FLAG(foo)</code>.
A common pattern is to set the value of a flag before calling
<code>::testing::InitGoogleTest()</code> to change the default value of
the flag: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int main(int argc, char** argv) &#123;</span><br><span class="line">  // Disables elapsed time by default.</span><br><span class="line">  ::testing::GTEST_FLAG(print_time) = false;</span><br><span class="line"></span><br><span class="line">  // This allows the user to override the flag on the command line.</span><br><span class="line">  ::testing::InitGoogleTest(&amp;argc, argv);</span><br><span class="line"></span><br><span class="line">  return RUN_ALL_TESTS();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="selecting-tests">Selecting Tests</h2>
<p>This section shows various options for choosing which tests to
run.</p>
<h3 id="listing-test-names">Listing Test Names</h3>
<p>Sometimes it is necessary to list the available tests in a program
before running them so that a filter may be applied if needed. Including
the flag <code>--gtest_list_tests</code> overrides all other flags and
lists tests in the following format: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TestCase1.</span><br><span class="line">  TestName1</span><br><span class="line">  TestName2</span><br><span class="line">TestCase2.</span><br><span class="line">  TestName</span><br></pre></td></tr></table></figure></p>
<p>None of the tests listed are actually run if the flag is provided.
There is no corresponding environment variable for this flag.</p>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h3 id="running-a-subset-of-the-tests">Running a Subset of the
Tests</h3>
<p>By default, a Google Test program runs all tests the user has
defined. Sometimes, you want to run only a subset of the tests (e.g. for
debugging or quickly verifying a change). If you set the
<code>GTEST_FILTER</code> environment variable or the
<code>--gtest_filter</code> flag to a filter string, Google Test will
only run the tests whose full names (in the form of
<code>TestCaseName.TestName</code>) match the filter.</p>
<p>The format of a filter is a '<code>:</code>'-separated list of
wildcard patterns (called the positive patterns) optionally followed by
a '<code>-</code>' and another '<code>:</code>'-separated pattern list
(called the negative patterns). A test matches the filter if and only if
it matches any of the positive patterns but does not match any of the
negative patterns.</p>
<p>A pattern may contain <code>'*'</code> (matches any string) or
<code>'?'</code> (matches any single character). For convenience, the
filter <code>'*-NegativePatterns'</code> can be also written as
<code>'-NegativePatterns'</code>.</p>
<p>For example:</p>
<ul>
<li><code>./foo_test</code> Has no flag, and thus runs all its
tests.</li>
<li><code>./foo_test --gtest_filter=*</code> Also runs everything, due
to the single match-everything <code>*</code> value.</li>
<li><code>./foo_test --gtest_filter=FooTest.*</code> Runs everything in
test case <code>FooTest</code>.</li>
<li><code>./foo_test --gtest_filter=*Null*:*Constructor*</code> Runs any
test whose full name contains either <code>"Null"</code> or
<code>"Constructor"</code>.</li>
<li><code>./foo_test --gtest_filter=-*DeathTest.*</code> Runs all
non-death tests.</li>
<li><code>./foo_test --gtest_filter=FooTest.*-FooTest.Bar</code> Runs
everything in test case <code>FooTest</code> except
<code>FooTest.Bar</code>.</li>
</ul>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h3 id="temporarily-disabling-tests">Temporarily Disabling Tests</h3>
<p>If you have a broken test that you cannot fix right away, you can add
the <code>DISABLED_</code> prefix to its name. This will exclude it from
execution. This is better than commenting out the code or using
<code>#if 0</code>, as disabled tests are still compiled (and thus won't
rot).</p>
<p>If you need to disable all tests in a test case, you can either add
<code>DISABLED_</code> to the front of the name of each test, or
alternatively add it to the front of the test case name.</p>
<p>For example, the following tests won't be run by Google Test, even
though they will still be compiled:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Tests that Foo does Abc.</span><br><span class="line">TEST(FooTest, DISABLED_DoesAbc) &#123; ... &#125;</span><br><span class="line"></span><br><span class="line">class DISABLED_BarTest : public ::testing::Test &#123; ... &#125;;</span><br><span class="line"></span><br><span class="line">// Tests that Bar does Xyz.</span><br><span class="line">TEST_F(DISABLED_BarTest, DoesXyz) &#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p><em>Note:</em> This feature should only be used for temporary
pain-relief. You still have to fix the disabled tests at a later date.
As a reminder, Google Test will print a banner warning you if a test
program contains any disabled tests.</p>
<p><em>Tip:</em> You can easily count the number of disabled tests you
have using <code>grep</code>. This number can be used as a metric for
improving your test quality.</p>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h3 id="temporarily-enabling-disabled-tests">Temporarily Enabling
Disabled Tests</h3>
<p>To include <a href="#temporarily-disabling-tests">disabled tests</a>
in test execution, just invoke the test program with the
<code>--gtest_also_run_disabled_tests</code> flag or set the
<code>GTEST_ALSO_RUN_DISABLED_TESTS</code> environment variable to a
value other than <code>0</code>. You can combine this with the <a
href="#running-a-subset-of-the-tests">--gtest_filter</a> flag to further
select which disabled tests to run.</p>
<p><em>Availability:</em> Linux, Windows, Mac; since version 1.3.0.</p>
<h2 id="repeating-the-tests">Repeating the Tests</h2>
<p>Once in a while you'll run into a test whose result is hit-or-miss.
Perhaps it will fail only 1% of the time, making it rather hard to
reproduce the bug under a debugger. This can be a major source of
frustration.</p>
<p>The <code>--gtest_repeat</code> flag allows you to repeat all (or
selected) test methods in a program many times. Hopefully, a flaky test
will eventually fail and give you a chance to debug. Here's how to use
it:</p>
<table>
<colgroup>
<col style="width: 37%" />
<col style="width: 62%" />
</colgroup>
<thead>
<tr class="header">
<th
style="text-align: left;"><code>$ foo_test --gtest_repeat=1000</code></th>
<th style="text-align: left;">Repeat foo_test 1000 times and don't stop
at failures.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td
style="text-align: left;"><code>$ foo_test --gtest_repeat=-1</code></td>
<td style="text-align: left;">A negative count means repeating
forever.</td>
</tr>
<tr class="even">
<td
style="text-align: left;"><code>$ foo_test --gtest_repeat=1000 --gtest_break_on_failure</code></td>
<td style="text-align: left;">Repeat foo_test 1000 times, stopping at
the first failure. This is especially useful when running under a
debugger: when the testfails, it will drop into the debugger and you can
then inspect variables and stacks.</td>
</tr>
<tr class="odd">
<td
style="text-align: left;"><code>$ foo_test --gtest_repeat=1000 --gtest_filter=FooBar</code></td>
<td style="text-align: left;">Repeat the tests whose name matches the
filter 1000 times.</td>
</tr>
</tbody>
</table>
<p>If your test program contains global set-up/tear-down code registered
using <code>AddGlobalTestEnvironment()</code>, it will be repeated in
each iteration as well, as the flakiness may be in it. You can also
specify the repeat count by setting the <code>GTEST_REPEAT</code>
environment variable.</p>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h2 id="shuffling-the-tests">Shuffling the Tests</h2>
<p>You can specify the <code>--gtest_shuffle</code> flag (or set the
<code>GTEST_SHUFFLE</code> environment variable to <code>1</code>) to
run the tests in a program in a random order. This helps to reveal bad
dependencies between tests.</p>
<p>By default, Google Test uses a random seed calculated from the
current time. Therefore you'll get a different order every time. The
console output includes the random seed value, such that you can
reproduce an order-related test failure later. To specify the random
seed explicitly, use the <code>--gtest_random_seed=SEED</code> flag (or
set the <code>GTEST_RANDOM_SEED</code> environment variable), where
<code>SEED</code> is an integer between 0 and 99999. The seed value 0 is
special: it tells Google Test to do the default behavior of calculating
the seed from the current time.</p>
<p>If you combine this with <code>--gtest_repeat=N</code>, Google Test
will pick a different random seed and re-shuffle the tests in each
iteration.</p>
<p><em>Availability:</em> Linux, Windows, Mac; since v1.4.0.</p>
<h2 id="controlling-test-output">Controlling Test Output</h2>
<p>This section teaches how to tweak the way test results are
reported.</p>
<h3 id="colored-terminal-output">Colored Terminal Output</h3>
<p>Google Test can use colors in its terminal output to make it easier
to spot the separation between tests, and whether tests passed.</p>
<p>You can set the GTEST_COLOR environment variable or set the
<code>--gtest_color</code> command line flag to <code>yes</code>,
<code>no</code>, or <code>auto</code> (the default) to enable colors,
disable colors, or let Google Test decide. When the value is
<code>auto</code>, Google Test will use colors if and only if the output
goes to a terminal and (on non-Windows platforms) the <code>TERM</code>
environment variable is set to <code>xterm</code> or
<code>xterm-color</code>.</p>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h3 id="suppressing-the-elapsed-time">Suppressing the Elapsed Time</h3>
<p>By default, Google Test prints the time it takes to run each test. To
suppress that, run the test program with the
<code>--gtest_print_time=0</code> command line flag. Setting the
<code>GTEST_PRINT_TIME</code> environment variable to <code>0</code> has
the same effect.</p>
<p><em>Availability:</em> Linux, Windows, Mac. (In Google Test 1.3.0 and
lower, the default behavior is that the elapsed time is
<strong>not</strong> printed.)</p>
<h3 id="generating-an-xml-report">Generating an XML Report</h3>
<p>Google Test can emit a detailed XML report to a file in addition to
its normal textual output. The report contains the duration of each
test, and thus can help you identify slow tests.</p>
<p>To generate the XML report, set the <code>GTEST_OUTPUT</code>
environment variable or the <code>--gtest_output</code> flag to the
string <code>"xml:_path_to_output_file_"</code>, which will create the
file at the given location. You can also just use the string
<code>"xml"</code>, in which case the output can be found in the
<code>test_detail.xml</code> file in the current directory.</p>
<p>If you specify a directory (for example,
<code>"xml:output/directory/"</code> on Linux or
<code>"xml:output\directory\"</code> on Windows), Google Test will
create the XML file in that directory, named after the test executable
(e.g. <code>foo_test.xml</code> for test program <code>foo_test</code>
or <code>foo_test.exe</code>). If the file already exists (perhaps left
over from a previous run), Google Test will pick a different name (e.g.
<code>foo_test_1.xml</code>) to avoid overwriting it.</p>
<p>The report uses the format described here. It is based on the
<code>junitreport</code> Ant task and can be parsed by popular
continuous build systems like <a
href="https://hudson.dev.java.net/">Hudson</a>. Since that format was
originally intended for Java, a little interpretation is required to
make it apply to Google Test tests, as shown here:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;testsuites name=&quot;AllTests&quot; ...&gt;</span><br><span class="line">  &lt;testsuite name=&quot;test_case_name&quot; ...&gt;</span><br><span class="line">    &lt;testcase name=&quot;test_name&quot; ...&gt;</span><br><span class="line">      &lt;failure message=&quot;...&quot;/&gt;</span><br><span class="line">      &lt;failure message=&quot;...&quot;/&gt;</span><br><span class="line">      &lt;failure message=&quot;...&quot;/&gt;</span><br><span class="line">    &lt;/testcase&gt;</span><br><span class="line">  &lt;/testsuite&gt;</span><br><span class="line">&lt;/testsuites&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>The root <code>&lt;testsuites&gt;</code> element corresponds to the
entire test program.</li>
<li><code>&lt;testsuite&gt;</code> elements correspond to Google Test
test cases.</li>
<li><code>&lt;testcase&gt;</code> elements correspond to Google Test
test functions.</li>
</ul>
<p>For instance, the following program</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST(MathTest, Addition) &#123; ... &#125;</span><br><span class="line">TEST(MathTest, Subtraction) &#123; ... &#125;</span><br><span class="line">TEST(LogicTest, NonContradiction) &#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>could generate this report:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;testsuites tests=&quot;3&quot; failures=&quot;1&quot; errors=&quot;0&quot; time=&quot;35&quot; name=&quot;AllTests&quot;&gt;</span><br><span class="line">  &lt;testsuite name=&quot;MathTest&quot; tests=&quot;2&quot; failures=&quot;1&quot; errors=&quot;0&quot; time=&quot;15&quot;&gt;</span><br><span class="line">    &lt;testcase name=&quot;Addition&quot; status=&quot;run&quot; time=&quot;7&quot; classname=&quot;&quot;&gt;</span><br><span class="line">      &lt;failure message=&quot;Value of: add(1, 1)&amp;#x0A; Actual: 3&amp;#x0A;Expected: 2&quot; type=&quot;&quot;/&gt;</span><br><span class="line">      &lt;failure message=&quot;Value of: add(1, -1)&amp;#x0A; Actual: 1&amp;#x0A;Expected: 0&quot; type=&quot;&quot;/&gt;</span><br><span class="line">    &lt;/testcase&gt;</span><br><span class="line">    &lt;testcase name=&quot;Subtraction&quot; status=&quot;run&quot; time=&quot;5&quot; classname=&quot;&quot;&gt;</span><br><span class="line">    &lt;/testcase&gt;</span><br><span class="line">  &lt;/testsuite&gt;</span><br><span class="line">  &lt;testsuite name=&quot;LogicTest&quot; tests=&quot;1&quot; failures=&quot;0&quot; errors=&quot;0&quot; time=&quot;5&quot;&gt;</span><br><span class="line">    &lt;testcase name=&quot;NonContradiction&quot; status=&quot;run&quot; time=&quot;5&quot; classname=&quot;&quot;&gt;</span><br><span class="line">    &lt;/testcase&gt;</span><br><span class="line">  &lt;/testsuite&gt;</span><br><span class="line">&lt;/testsuites&gt;</span><br></pre></td></tr></table></figure>
<p>Things to note:</p>
<ul>
<li>The <code>tests</code> attribute of a
<code>&lt;testsuites&gt;</code> or <code>&lt;testsuite&gt;</code>
element tells how many test functions the Google Test program or test
case contains, while the <code>failures</code> attribute tells how many
of them failed.</li>
<li>The <code>time</code> attribute expresses the duration of the test,
test case, or entire test program in milliseconds.</li>
<li>Each <code>&lt;failure&gt;</code> element corresponds to a single
failed Google Test assertion.</li>
<li>Some JUnit concepts don't apply to Google Test, yet we have to
conform to the DTD. Therefore you'll see some dummy elements and
attributes in the report. You can safely ignore these parts.</li>
</ul>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h2 id="controlling-how-failures-are-reported">Controlling How Failures
Are Reported</h2>
<h3 id="turning-assertion-failures-into-break-points">Turning Assertion
Failures into Break-Points</h3>
<p>When running test programs under a debugger, it's very convenient if
the debugger can catch an assertion failure and automatically drop into
interactive mode. Google Test's <em>break-on-failure</em> mode supports
this behavior.</p>
<p>To enable it, set the <code>GTEST_BREAK_ON_FAILURE</code> environment
variable to a value other than <code>0</code> . Alternatively, you can
use the <code>--gtest_break_on_failure</code> command line flag.</p>
<p><em>Availability:</em> Linux, Windows, Mac.</p>
<h3 id="disabling-catching-test-thrown-exceptions">Disabling Catching
Test-Thrown Exceptions</h3>
<p>Google Test can be used either with or without exceptions enabled. If
a test throws a C++ exception or (on Windows) a structured exception
(SEH), by default Google Test catches it, reports it as a test failure,
and continues with the next test method. This maximizes the coverage of
a test run. Also, on Windows an uncaught exception will cause a pop-up
window, so catching the exceptions allows you to run the tests
automatically.</p>
<p>When debugging the test failures, however, you may instead want the
exceptions to be handled by the debugger, such that you can examine the
call stack when an exception is thrown. To achieve that, set the
<code>GTEST_CATCH_EXCEPTIONS</code> environment variable to
<code>0</code>, or use the <code>--gtest_catch_exceptions=0</code> flag
when running the tests.</p>
<p><strong>Availability</strong>: Linux, Windows, Mac.</p>
<h3 id="letting-another-testing-framework-drive">Letting Another Testing
Framework Drive</h3>
<p>If you work on a project that has already been using another testing
framework and is not ready to completely switch to Google Test yet, you
can get much of Google Test's benefit by using its assertions in your
existing tests. Just change your <code>main()</code> function to look
like:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &quot;gtest/gtest.h&quot;</span><br><span class="line"></span><br><span class="line">int main(int argc, char** argv) &#123;</span><br><span class="line">  ::testing::GTEST_FLAG(throw_on_failure) = true;</span><br><span class="line">  // Important: Google Test must be initialized.</span><br><span class="line">  ::testing::InitGoogleTest(&amp;argc, argv);</span><br><span class="line"></span><br><span class="line">  ... whatever your existing testing framework requires ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>With that, you can use Google Test assertions in addition to the
native assertions your testing framework provides, for example:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void TestFooDoesBar() &#123;</span><br><span class="line">  Foo foo;</span><br><span class="line">  EXPECT_LE(foo.Bar(1), 100);     // A Google Test assertion.</span><br><span class="line">  CPPUNIT_ASSERT(foo.IsEmpty());  // A native assertion.</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>If a Google Test assertion fails, it will print an error message and
throw an exception, which will be treated as a failure by your host
testing framework. If you compile your code with exceptions disabled, a
failed Google Test assertion will instead exit your program with a
non-zero code, which will also signal a test failure to your test
runner.</p>
<p>If you don't write
<code>::testing::GTEST_FLAG(throw_on_failure) = true;</code> in your
<code>main()</code>, you can alternatively enable this feature by
specifying the <code>--gtest_throw_on_failure</code> flag on the
command-line or setting the <code>GTEST_THROW_ON_FAILURE</code>
environment variable to a non-zero value.</p>
<p>Death tests are <em>not</em> supported when other test framework is
used to organize tests.</p>
<p><em>Availability:</em> Linux, Windows, Mac; since v1.3.0.</p>
<h2 id="distributing-test-functions-to-multiple-machines">Distributing
Test Functions to Multiple Machines</h2>
<p>If you have more than one machine you can use to run a test program,
you might want to run the test functions in parallel and get the result
faster. We call this technique <em>sharding</em>, where each machine is
called a <em>shard</em>.</p>
<p>Google Test is compatible with test sharding. To take advantage of
this feature, your test runner (not part of Google Test) needs to do the
following:</p>
<ol type="1">
<li>Allocate a number of machines (shards) to run the tests.</li>
<li>On each shard, set the <code>GTEST_TOTAL_SHARDS</code> environment
variable to the total number of shards. It must be the same for all
shards.</li>
<li>On each shard, set the <code>GTEST_SHARD_INDEX</code> environment
variable to the index of the shard. Different shards must be assigned
different indices, which must be in the range
<code>[0, GTEST_TOTAL_SHARDS - 1]</code>.</li>
<li>Run the same test program on all shards. When Google Test sees the
above two environment variables, it will select a subset of the test
functions to run. Across all shards, each test function in the program
will be run exactly once.</li>
<li>Wait for all shards to finish, then collect and report the
results.</li>
</ol>
<p>Your project may have tests that were written without Google Test and
thus don't understand this protocol. In order for your test runner to
figure out which test supports sharding, it can set the environment
variable <code>GTEST_SHARD_STATUS_FILE</code> to a non-existent file
path. If a test program supports sharding, it will create this file to
acknowledge the fact (the actual contents of the file are not important
at this time; although we may stick some useful information in it in the
future.); otherwise it will not create it.</p>
<p>Here's an example to make it clear. Suppose you have a test program
<code>foo_test</code> that contains the following 5 test functions:
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TEST(A, V)</span><br><span class="line">TEST(A, W)</span><br><span class="line">TEST(B, X)</span><br><span class="line">TEST(B, Y)</span><br><span class="line">TEST(B, Z)</span><br></pre></td></tr></table></figure> and you have 3 machines at your disposal. To run the
test functions in parallel, you would set
<code>GTEST_TOTAL_SHARDS</code> to 3 on all machines, and set
<code>GTEST_SHARD_INDEX</code> to 0, 1, and 2 on the machines
respectively. Then you would run the same <code>foo_test</code> on each
machine.</p>
<p>Google Test reserves the right to change how the work is distributed
across the shards, but here's one possible scenario:</p>
<ul>
<li>Machine #0 runs <code>A.V</code> and <code>B.X</code>.</li>
<li>Machine #1 runs <code>A.W</code> and <code>B.Y</code>.</li>
<li>Machine #2 runs <code>B.Z</code>.</li>
</ul>
<p><em>Availability:</em> Linux, Windows, Mac; since version 1.3.0.</p>
<h1 id="fusing-google-test-source-files">Fusing Google Test Source
Files</h1>
<p>Google Test's implementation consists of ~30 files (excluding its own
tests). Sometimes you may want them to be packaged up in two files (a
<code>.h</code> and a <code>.cc</code>) instead, such that you can
easily copy them to a new machine and start hacking there. For this we
provide an experimental Python script <code>fuse_gtest_files.py</code>
in the <code>scripts/</code> directory (since release 1.3.0). Assuming
you have Python 2.4 or above installed on your machine, just go to that
directory and run <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python fuse_gtest_files.py OUTPUT_DIR</span><br></pre></td></tr></table></figure></p>
<p>and you should see an <code>OUTPUT_DIR</code> directory being created
with files <code>gtest/gtest.h</code> and
<code>gtest/gtest-all.cc</code> in it. These files contain everything
you need to use Google Test. Just copy them to anywhere you want and you
are ready to write tests. You can use the <a
href="../scripts/test/Makefile">scripts/test/Makefile</a> file as an
example on how to compile your tests against them.</p>
<h1 id="where-to-go-from-here-1">Where to Go from Here</h1>
<p>Congratulations! You've now learned more advanced Google Test tools
and are ready to tackle more complex testing tasks. If you want to dive
even deeper, you can read the <a href="FAQ.md">Frequently-Asked
Questions</a>.</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>开发</tag>
      </tags>
  </entry>
  <entry>
    <title>android开发中奇怪crash问题</title>
    <url>/201812/20181204-dev-problem-android-string-crash/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>实际开发过程中，会遇到千奇百怪的问题。有的是因为库与系统不匹配，有时是因为标准库存在不兼容问题，当然也有内存申请释放访问的问题。
大部分奇怪的问题并不是必现，有的跟机器相关，偶的甚至跟人品有关系。总之，我们经常要与千奇百怪的问题打交道。今天就说说产品落地中遇到的一个关于字符串赋值导致crash的问题。</p>
<h2 id="问题来源">问题来源</h2>
<p>在<strong>android</strong>系统中，测试一个C++动态库时，出现segment
fault或者Invalid Address free
等问题，最终定位crash的位置时在一个<strong>字符串赋值</strong>的位置。例如：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">O</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">allfunction</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AO</span> : <span class="keyword">public</span> O &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">otherFunc</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">setName</span><span class="params">(<span class="type">const</span> std::string&amp; name)</span></span>&#123;</span><br><span class="line">		<span class="built_in">LOG</span>(<span class="string">&quot;Before setName&quot;</span>);</span><br><span class="line">		<span class="keyword">this</span>-&gt;_name = name;</span><br><span class="line">		<span class="built_in">LOG</span>(<span class="string">&quot;Finished setName&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	string _name;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BAO</span>: <span class="keyword">public</span> AO &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">otherFunc</span><span class="params">()</span> <span class="keyword">override</span></span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	type _value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CBAO</span>: <span class="keyword">public</span> BAO &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">otherFunc</span><span class="params">()</span> <span class="keyword">override</span></span>;</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">otherFunc2</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	type2 other_value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">AO* cbao = <span class="keyword">new</span> CBAO;</span><br><span class="line">cbao-&gt;<span class="built_in">setName</span>(<span class="string">&quot;a name&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>其中输出的信息中含有"Before setName"的信息，但是没有"Finished
setName"。
然后如果将<code>this-&gt;_name = name</code>这行代码注释，那么这个问题就可以不出现。此外，采用如下的时候
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">AO* bao = <span class="keyword">new</span> BAO;</span><br><span class="line">bao-&gt;<span class="built_in">setName</span>(<span class="string">&quot;a name&quot;</span>);</span><br></pre></td></tr></table></figure> 竟然没有问题。好苦恼呀~~</p>
<h2 id="探索1">探索1：</h2>
<blockquote>
<p>是不是因为<code>std::string</code>采用引用的方式，导致内存释放的时候出现多次释放。</p>
</blockquote>
<p>这是不应该的，因为我们采用的是标准库，而且string会自己管理内存的，不应该导致这种问题的。而且我们通过对<code>setName</code>中<code>_name</code>赋值常量字符串，该问题仍然存在。</p>
<h2 id="探索2">探索2：</h2>
<blockquote>
<p>如果不采用set函数方式进行赋值，而是将<code>_name</code>变为<code>public</code>类型，从而直接对对象成员进行赋值。</p>
</blockquote>
<p>这样操作并没有什么实质性的变化，仍然存在存在这种现象，也就是说与对象的存储方式是与成员的可见性是没有关系的。</p>
<h2 id="探索3">探索3：</h2>
<blockquote>
<p>采用<code>char _name[256]</code>代替<code>std::string _name</code>
，我们自己负责内存的管理，而不是由C++管理内存分配。</p>
</blockquote>
<p>虽然这个问题绕过去了，但是后面仍然出现了类似的问题，因为我们的对象中还有其他string类型的成员变量。如果全部改用C类型的数组进行替换，代价太大。</p>
<h2 id="探索4">探索4：</h2>
<blockquote>
<p>采用静态库进行测试，问题没有问题</p>
</blockquote>
<p>为什么动态库就有问题，静态库没有问题呢？
<del>因为静态库中是直接将所有需要的文件都包含到静态库中。而动态库中拥有的是所有<strong>需要库的链接</strong></del>我们的动态库中是将所有需要的符号，库等等都编译进行去了的。而我们的软件库依赖其他软件库。</p>
<h2 id="最终结论">最终结论</h2>
<h3 id="问题原因">问题原因</h3>
<p>不同编译环境，以及编译配置导致依赖的静态库和target
动态库依赖了不同的c++标准库，由于两个标准库中的string实现是不同的，导致string对象在释放的时候出现crash。</p>
<h3 id="fix方案">fix方案</h3>
<p>android项目中添加
<code>-DANDROID_STL=gnustl_shared</code>或者编译链接中添加<code>TARGET_LINK_LIBRARIES(test_sdk_common gnustl_shared)</code>用来显示声明链接的库为gnustl_shared库，从而使得多个动态库链接同一个标准库即可。</p>
<h2 id="附录-android-对c库的支持">附录： Android 对C++库的支持</h2>
<table>
<colgroup>
<col style="width: 32%" />
<col style="width: 37%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">名称</th>
<th style="text-align: center;">说明</th>
<th style="text-align: center;">功能</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">libstdc++（默认）</td>
<td style="text-align: center;">默认最小系统 C++ 运行时库。</td>
<td style="text-align: center;">不适用</td>
</tr>
<tr class="even">
<td style="text-align: center;">gabi++_static</td>
<td style="text-align: center;">GAbi++ 运行时（静态）。</td>
<td style="text-align: center;">C++ 异常和 RTTI</td>
</tr>
<tr class="odd">
<td style="text-align: center;">gabi++_shared</td>
<td style="text-align: center;">GAbi++ 运行时（共享）。</td>
<td style="text-align: center;">C++ 异常和 RTTI</td>
</tr>
<tr class="even">
<td style="text-align: center;">stlport_static</td>
<td style="text-align: center;">STLport 运行时（静态）。</td>
<td style="text-align: center;">C++ 异常和 RTTI；标准库</td>
</tr>
<tr class="odd">
<td style="text-align: center;">stlport_shared</td>
<td style="text-align: center;">STLport 运行时（共享）。</td>
<td style="text-align: center;">C++ 异常和 RTTI；标准库</td>
</tr>
<tr class="even">
<td style="text-align: center;">gnustl_static</td>
<td style="text-align: center;">GNU STL（静态）。</td>
<td style="text-align: center;">C++ 异常和 RTTI；标准库</td>
</tr>
<tr class="odd">
<td style="text-align: center;">gnustl_shared</td>
<td style="text-align: center;">GNU STL（共享）。</td>
<td style="text-align: center;">C++ 异常和 RTTI；标准库</td>
</tr>
<tr class="even">
<td style="text-align: center;">c++_static</td>
<td style="text-align: center;">LLVM libc++ 运行时（静态）。</td>
<td style="text-align: center;">C++ 异常和 RTTI；标准库</td>
</tr>
<tr class="odd">
<td style="text-align: center;">c++_shared</td>
<td style="text-align: center;">LLVM libc++ 运行时（共享）。</td>
<td style="text-align: center;">C++ 异常和 RTTI；标准库</td>
</tr>
</tbody>
</table>
<p>https://developer.android.google.cn/ndk/guides/cpp-support</p>
<h3 id="兼容性">兼容性</h3>
<p>NDK 的 libc++
不稳定。并非所有测试都能通过，而且测试套件并不全面。一些已知的问题包括：
如果在 ARM 上使用<code>c++_shared</code>，引发异常时可能会崩溃。
对<code>wchar_t</code>和语言区域 API 的支持受到限制。</p>
<h3 id="c-异常">C++ 异常</h3>
<p>在高于 NDKr5 的所有 NDK 版本中，NDK 工具链可让您使用支持异常处理的
C++ 运行时。 但为确保与早期版本兼容，默认情况下它会编译所有支持
-fno-exceptions 的 C++ 来源。 您可以为整个应用或个别模块启用 C++
异常。</p>
<p>要为整个应用启用异常处理支持，请将以下行添加到 Application.mk
文件中。要为个别模块启用异常处理支持，请将以下行添加到其各自的
Android.mk 文件中。</p>
<p><code>APP_CPPFLAGS += -fexceptions</code></p>
<h3 id="rtti">RTTI</h3>
<p>在高于 NDKr5 的所有 NDK 版本中，NDK 工具链可让您使用支持 RTTI 的 C++
运行时。 但为确保与早期版本兼容，默认情况下它会编译所有支持
<code>-fno-rtti</code> 的 C++ 来源。</p>
<p>要为整个应用启用 RTTI 支持，请将以下行添加到
<code>Application.mk</code>文件中： <code>APP_CPPFLAGS += -frtti</code>
要为个别模块启用 RTTI 支持，请将以下行添加到其各自的 Android.mk 文件中：
<code>LOCAL_CPP_FEATURES += rtti</code> 或者，您也可以使用：
<code>LOCAL_CPPFLAGS += -frtti</code></p>
<h3 id="静态运行时">静态运行时</h3>
<p>将 C++ 运行时的静态库变体添加到多个二进制文件可能导致意外行为。
例如，您可能会遇到：</p>
<p>内存在一个库中分配，在另一个库中释放，从而导致内存泄漏或堆损坏。
libfoo.so 中引发的异常在 libbar.so 中未被捕获，从而导致您的应用崩溃。
<code>std::cout</code> 的缓冲未正常运行 此外，如果您将两个共享库 –
或者一个共享库和一个可执行文件 –
链接到同一个静态运行时，每个共享库的最终二进制映像包含运行时代码的副本。
运行时代码有多个实例是表明有问题，因为运行时内部使用或提供的某些全局变量会重复。</p>
<p>此问题不适用于只包含一个共享库的项目。例如，您可以链接
stlport_static，并预期您的应用正确运行。
如果您的项目需要多个共享库模块，建议使用 C++ 运行时的共享库变体。</p>
<h3 id="共享运行时">共享运行时</h3>
<p>如果您的应用针对早于 Android 4.3（Android API 级别 18）的 Android
版本，并且您使用指定 C++
运行时的共享库变体，则必须先加载共享库，再加载依赖它的任何其他库。</p>
<p>例如，应用可能具有以下模块: - libfoo.so - libfoo.so 使用的 libbar.so
- libfoo 和 libbar 使用的 libstlport_shared.so
必须以相反的依赖顺序加载库：</p>
<pre><code>static &#123;
  System.loadLibrary(&quot;stlport_shared&quot;);
  System.loadLibrary(&quot;bar&quot;);
  System.loadLibrary(&quot;foo&quot;);
&#125;</code></pre>
<p>注：调用<code>System.loadLibrary()</code>时不要使用 lib 前缀。</p>
<h3 id="android-c系统库">Android C++系统库</h3>
<p>从上到下依次分为六层： * 应用框架层 * 进程通信层 * 系统服务层 *
Android运行时层 * 硬件抽象层 * Linux内核层</p>
<p>Android包含一个C/C++库的集合，供Android系统的各个组件使用。这些功能通过Android的应用程序框架（application
framework）暴露给开发者。系统库包括九个子系统，分别是图层管理、媒体库、SQLite、OpenGLEState、FreeType、WebKit、SGL、SSL和libc。Android运行时包括核心库和Dalvik虚拟机，前者既兼容了大多数Java语言所需要调用的功能函数，又包括了Android的核心库，比如android.os、android.net、android.media等等。后者是一种基于寄存器的java虚拟机，<code>Dalvik虚拟机</code>主要是完成对生命周期的管理、堆栈的管理、线程的管理、安全和异常的管理以及垃圾回收等重要功能。下面列出一些核心库：
* 系统C库——标准C系统库（libc）的BSD衍生，调整为基于嵌入式Linux设备 *
媒体库——基于PacketVideo的OpenCORE。这些库支持播放和录制许多流行的音频和视频格式，以及静态图像文件，包括MPEG4、
H.264、 MP3、 AAC、 AMR、JPG、 PNG<br />
* LibWebCore——新式的Web浏览器引擎,驱动Android 浏览器和内嵌的web视图 *
FreeType ——位图和矢量字体渲染 * OpenGL——开放图形库（英语：Open Graphics
Library，缩写为
OpenGL）是个定义了一个跨编程语言、跨平台的应用程序接口（API）的规范，它用于生成二维、三维图像。
* SQLite
——所有应用程序都可以使用的强大而轻量级的关系数据库引擎，SQLite是遵守ACID的关系数据库管理系统，它包含在一个相对小的C程序库中;</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030322925.png"
alt="官方Android架构图" />
<figcaption aria-hidden="true">官方Android架构图</figcaption>
</figure>
<h3 id="参考链接">参考链接</h3>
<p>[1]. <a
href="https://blog.csdn.net/matrix_laboratory/article/details/79217973">Android
gnustl_static VS gnustl_share</a></p>
<p>[2].<a
href="https://developer.android.com/ndk/guides/cpp-support">C++支持</a></p>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>android</tag>
        <tag>sdk</tag>
      </tags>
  </entry>
  <entry>
    <title>Make &amp; CMake 进阶</title>
    <url>/201901/20190110-CMake-Makefile/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>当下流行的IDE，将源代码生成可执行文件的过程都封装起来，对于开发着来说方便使用。
但是对于初学者来说，蒙蔽了源代码到可执行文件过程。源代码预处理，编译，打包，链接等步骤，
才能形成IDE中的一步到位的可执行文件target。而Makefile是直白的描述一个源代码如何被操作
才能成为target的一种文件格式。而CMake是一种可以通过配置的方式生成Makefile的脚本.
如果只是简单的开发一个.cpp进行测试，Makefile是首选。
本文中不对Makefile的基本语法进行介绍，要学习基本语法可以参看陈皓老师的Makefile中文教程进行学习。</p>
<h2 id="makefile">Makefile</h2>
<h3
id="ifeq和ifneq之后要有个空格否则不识别"><code>ifeq</code>和<code>ifneq</code>之后要有个空格，否则不识别</h3>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">ifeq ($(UNAME), linux)</span><br><span class="line">     $(info <span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">      $(warning <span class="string">&quot;&quot;</span>)</span><br><span class="line">     $(error $(HAVE_SSHSERVER))</span><br><span class="line"><span class="keyword">endif</span> </span><br></pre></td></tr></table></figure>
<h3 id="定义变量">定义变量</h3>
<p><code>HAVE_THE_VALUE :=</code> # 新定义一个变量
<code>HAVE_THE_VALUE ?=</code> # 如果没有定义，则定义一个新变量
<code>HAVE_THE_VALUE +=</code> # 往变量中append数据</p>
<p>这个地方有点像pascal，不要与shell中混淆了</p>
<h3 id="变量赋值">变量赋值</h3>
<p><strong>后面一定不要有空格，回车之类的空白符号</strong>，否则可能会将你整疯了的。
就拿caffe中的Makefile.config中</p>
<p><code>USE_LEVELDB := 1</code></p>
<p><code>USE_LEVELDB := 1</code></p>
<p>这两行的区别在于，第二行赋值操作后面有一个空格。在Makefile中通过如下代码进行添加编译需要的宏。</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">ifeq</span> (<span class="variable">$(USE_LEVELDB)</span>, 1)</span><br><span class="line">  CXX_FLAGS += -DUSE_LEVELDB</span><br><span class="line"><span class="keyword">endif</span></span><br></pre></td></tr></table></figure>
<p>结果编译的时候打开的开关会与设想的不一样。</p>
<h3 id="makefile案例">Makefile案例</h3>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment">#! Makefile</span></span><br><span class="line"></span><br><span class="line">SRCS := PAPI_flops.c</span><br><span class="line">OBJECTS := <span class="variable">$(<span class="built_in">patsubst</span> %.c, %.o, <span class="variable">$(SRCS)</span>)</span></span><br><span class="line">STATIC_LIB := /usr/local/lib/libpapi.a</span><br><span class="line">INCLUDE_DIR := -I/usr/local/<span class="keyword">include</span></span><br><span class="line">CC := gcc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="section">all: PAPI_flops</span></span><br><span class="line"></span><br><span class="line"><span class="section">PAPI_flops: <span class="variable">$(OBJECTS)</span></span></span><br><span class="line">     <span class="variable">$(CC)</span> -O0 <span class="variable">$&lt;</span> <span class="variable">$(STATIC_LIB)</span> -o <span class="variable">$@</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$(OBJECTS)</span>: <span class="variable">$(SRCS)</span></span><br><span class="line">     <span class="variable">$(CC)</span> <span class="variable">$(INCLUDE_DIR)</span> -O0 -c <span class="variable">$&lt;</span></span><br><span class="line"></span><br><span class="line"><span class="section">test:</span></span><br><span class="line">     echo <span class="string">&quot;----Running the PAPI_flops-----&quot;</span></span><br><span class="line">     @./PAPI_flops</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">     rm -rf PAPI_flops</span><br><span class="line">     rm -rf *.o</span><br></pre></td></tr></table></figure>
<h3 id="makefile中调用.a库的编写">makefile中调用.a库的编写</h3>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!Makefile</span></span><br><span class="line">CC = g++</span><br><span class="line"></span><br><span class="line">TINYCV_DIR = /home/cwl/TinyCV</span><br><span class="line">TINYCV_INCLUDE_DIR = <span class="variable">$(TINYCV_DIR)</span>/<span class="keyword">include</span></span><br><span class="line">LIB_DIR = <span class="variable">$(TINYCV_DIR)</span>/build</span><br><span class="line"></span><br><span class="line">CXX_FLAG = -O3 -std=c++11 -Wall -Werror -fPIC</span><br><span class="line"></span><br><span class="line"><span class="section">all: main</span></span><br><span class="line"></span><br><span class="line"><span class="section">main: main.o</span></span><br><span class="line">  <span class="variable">$(CC)</span> <span class="variable">$&lt;</span> <span class="variable">$(CXX_FLAG)</span> -I<span class="variable">$(TINYCV_INCLUDE_DIR)</span> -L<span class="variable">$(LIB_DIR)</span> -ltinycv -o <span class="variable">$@</span></span><br><span class="line"></span><br><span class="line"><span class="section">main.o: main.cpp</span></span><br><span class="line">  <span class="variable">$(CC)</span> <span class="variable">$(CXX_FLAG)</span> -I<span class="variable">$(TINYCV_INCLUDE_DIR)</span> -c <span class="variable">$&lt;</span></span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">  rm -f *.o main</span><br></pre></td></tr></table></figure>
<p>需要注意的是下面这句中<code>$&lt;</code>是指输入文件main.o，此处紧跟gcc
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">main: main.o</span><br><span class="line">  $(CC) $&lt; $(CXX_FLAG) -I$(TINYCV_INCLUDE_DIR) -L$(LIB_DIR) -ltinycv -o $@</span><br></pre></td></tr></table></figure> 但是如果变为如下情形，就会出现后面中的错误 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">main: main.o</span><br><span class="line">  $(CC) $(CXX_FLAG) -I$(TINYCV_INCLUDE_DIR) -L$(LIB_DIR) -ltinycv -o $@  $&lt;</span><br></pre></td></tr></table></figure>
错误： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">caowenlong@Server-NF5280M3:~/Test$ make</span><br><span class="line">g++ -O3 -std=c++11 -Wall -Werror -fPIC -I/home/cwl/TinyCV/include -c main.cpp</span><br><span class="line">g++ -O3 -std=c++11 -Wall -Werror -fPIC -I/home/cwl/TinyCV/include -L/home/cwl/TinyCV/build -ltinycv -o main main.o</span><br><span class="line">main.o：在函数‘main’中：</span><br><span class="line">main.cpp:(.text.startup+0x3b)：对‘tinycv::imread(std::string const&amp;, int)’未定义的引用</span><br><span class="line">main.cpp:(.text.startup+0x43)：对‘tinycv::Mat&lt;unsigned char&gt;::Mat()’未定义的引用</span><br><span class="line">main.cpp:(.text.startup+0x63)：对‘double tinycv::threshold&lt;unsigned char&gt;(tinycv::Mat&lt;unsigned char&gt; const&amp;, tinycv::Mat&lt;unsigned char&gt;&amp;, double, double, int)’未定义的引用</span><br><span class="line">collect2: error: ld returned 1 exit status</span><br><span class="line">make: *** [main] 错误 1</span><br></pre></td></tr></table></figure></p>
<h3 id="makefile中的全局自变量">makefile中的全局自变量</h3>
<p><code>$@</code>目标文件名 <code>@^</code>所有前提名，除副本
<code>@＋</code>所有前提名，含副本 <code>@＜</code>一个前提名
<code>@？</code>所有新于目标文件的前提名
<code>@*</code>目标文件的基名称</p>
<h3 id="是否输出执行过程">是否输出执行过程</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#! Makefile</span><br><span class="line">SAMPLE_ENABLE ?= 1</span><br><span class="line"></span><br><span class="line">ifeq ($(SAMPLE_ENABLE), 1)</span><br><span class="line">	EXEC ?= @echo &quot;[@]&quot;</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">target: target2</span><br><span class="line">	echo &quot;hehe, this is target&quot;</span><br><span class="line"></span><br><span class="line">target2:</span><br><span class="line">	echo &quot;this is target2&quot;</span><br><span class="line">clean:</span><br><span class="line">	rm -rf out.o</span><br></pre></td></tr></table></figure>
<ul>
<li><a
href="https://github.com/cwlseu/recipes/tree/master/makepractise">more
samples</a></li>
</ul>
<h2 id="cmake">CMake</h2>
<h3 id="cmake-入门案例">CMake 入门案例</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">PROJECT(sdk_common_samples)</span><br><span class="line">cmake_minimum_required(VERSION <span class="number">3.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找已经安装的包</span></span><br><span class="line">FIND_PACKAGE(OpenCV <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SET 指令的语法是:</span></span><br><span class="line"><span class="comment"># SET(VAR [VALUE] [CACHE TYPE DOCSTRING [FORCE]])</span></span><br><span class="line"></span><br><span class="line">SET(</span><br><span class="line">	SDK_COMMON_INCLUDE_DIR</span><br><span class="line">	$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/../../include</span><br><span class="line">	CACHE PATH</span><br><span class="line">	<span class="string">&quot;SDK_COMMON HEADER FILE PATH&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MESSAGE 指令的语法是:</span></span><br><span class="line"><span class="comment"># MESSAGE([SEND_ERROR | STATUS | FATAL_ERROR] &quot;message to display&quot; ...)</span></span><br><span class="line"><span class="comment"># 这个指令用于向终端输出用户定义的信息,包含了三种类型:</span></span><br><span class="line"><span class="comment"># SEND_ERROR,产生错误,生成过程被跳过。</span></span><br><span class="line"><span class="comment"># SATUS ,输出前缀为 — 的信息。</span></span><br><span class="line"><span class="comment"># FATAL_ERROR,立即终止所有 cmake 过程.</span></span><br><span class="line"></span><br><span class="line">MESSAGE(<span class="string">&quot;Find libs in $&#123;SDK_COMMON_LIB_DIR&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># INCLUDE_DIRECTORIES,其完整语法为:</span></span><br><span class="line"><span class="comment"># INCLUDE_DIRECTORIES([AFTER|BEFORE] [SYSTEM] dir1 dir2 ...)</span></span><br><span class="line"><span class="comment"># 这条指令可以用来向工程添加多个特定的头文件搜索路径,路径之间用空格分割,如果路径</span></span><br><span class="line"><span class="comment"># 中包含了空格,可以使用双引号将它括起来,默认的行为是追加到当前的头文件搜索路径的</span></span><br><span class="line"><span class="comment"># 后面,你可以通过两种方式来进行控制搜索路径添加的方式:</span></span><br><span class="line"><span class="comment"># 1,CMAKE_INCLUDE_DIRECTORIES_BEFORE,通过 SET 这个 cmake 变量为 on,可以</span></span><br><span class="line"><span class="comment"># 将添加的头文件搜索路径放在已有路径的前面。</span></span><br><span class="line"><span class="comment"># 2,通过 AFTER 或者 BEFORE 参数,也可以控制是追加还是置前。</span></span><br><span class="line">INCLUDE_DIRECTORIES(</span><br><span class="line">	$&#123;PROJECT_SOURCE_DIR&#125;</span><br><span class="line">	$&#123;SDK_COMMON_INCLUDE_DIR&#125;</span><br><span class="line">	$&#123;OpenCV_INCLUDE_DIRS&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加链接库的文件夹路径</span></span><br><span class="line">LINK_DIRECTORIES($&#123;SDK_COMMON_LIB_DIR&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set最长用的方法，就像shell中export一个变量一样</span></span><br><span class="line">SET(CMAKE_C_FLAGS <span class="string">&quot;$&#123;CMAKE_C_FLAGS&#125; -g -Wall -O2 -std=gnu++0x&quot;</span>)</span><br><span class="line">SET(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -g -Wall -O2 -std=gnu++0x&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找在相对路径下与*.cpp所匹配的模式的所有文件，保存到变量samples中</span></span><br><span class="line">FILE(GLOB samples $&#123;PROJECT_SOURCE_DIR&#125;/*.cpp)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 针对samples中的所有元素进行操作</span></span><br><span class="line">FOREACH (sample $&#123;samples&#125;)</span><br><span class="line">	STRING(REGEX MATCH <span class="string">&quot;[^/]+$&quot;</span> sample_file $&#123;sample&#125;)</span><br><span class="line">	STRING(REPLACE <span class="string">&quot;.cpp&quot;</span> <span class="string">&quot;&quot;</span> sample_basename $&#123;sample_file&#125;)</span><br><span class="line">	ADD_EXECUTABLE(test_$&#123;sample_basename&#125; $&#123;sample&#125;)</span><br><span class="line">	<span class="comment"># 添加执行时的需要链接的lib： common OpenCV_Libs</span></span><br><span class="line">	TARGET_LINK_LIBRARIES(test_$&#123;sample_basename&#125;</span><br><span class="line">	sdk_common $&#123;OpenCV_LIBS&#125;)</span><br><span class="line">	<span class="comment"># 另外，如果不是再window下的话需要添加线程库 -lpthread</span></span><br><span class="line">	<span class="keyword">if</span> (NOT WIN32)</span><br><span class="line">		TARGET_LINK_LIBRARIES(test_$&#123;sample_basename&#125; pthread)</span><br><span class="line">	endif()</span><br><span class="line">	</span><br><span class="line">	INSTALL(TARGETS test_$&#123;sample_basename&#125; DESTINATION $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/<span class="built_in">bin</span>)</span><br><span class="line">ENDFOREACH() <span class="comment"># foreach 结束</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="windows指定编译器">windows指定编译器</h2>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">cmake \</span><br><span class="line">-DCMAKE_MODULE_PATH:PATH=Y:\\cmake  -DCMAKE_CONFIGURATION_TYPES=release \</span><br><span class="line">-DCMAKE_INSTALL_PREFIX=C:\\cygwin\\data\\windows-x86_64\\<span class="keyword">test</span> \</span><br><span class="line">-G <span class="string">&quot;Visual Studio 12 Win64&quot;</span> -T <span class="string">&quot;v120_xp&quot;</span> ..</span><br><span class="line"></span><br><span class="line">cmake -G<span class="string">&quot;Visual Studio 12 2013&quot;</span> -A x64 -DCMAKE_BUILD_TYPE=RELEASE ..</span><br><span class="line">cmake -G<span class="string">&quot;Visual Studio 12 2013&quot;</span> -A Win32 -DCMAKE_BUILD_TYPE=RELEASE ..</span><br></pre></td></tr></table></figure>
<p>有的时候在windows下，buildtype为debug和release表现不同，而且概率还是比较高的。</p>
<h3 id="官网提供的入门教程中的案例">官网提供的入门教程中的案例</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required (VERSION <span class="number">2.6</span>)</span><br><span class="line">project (Tutorial)</span><br><span class="line"></span><br><span class="line"><span class="comment"># should we use our own math functions?</span></span><br><span class="line">option (USE_MYMATH </span><br><span class="line">  <span class="string">&quot;Use tutorial provided math implementation&quot;</span> ON) </span><br><span class="line"></span><br><span class="line"><span class="comment"># The version number.</span></span><br><span class="line"><span class="built_in">set</span> (Tutorial_VERSION_MAJOR <span class="number">1</span>)</span><br><span class="line"><span class="built_in">set</span> (Tutorial_VERSION_MINOR <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># configure a header file to pass some of the CMake settings</span></span><br><span class="line"><span class="comment"># to the source code</span></span><br><span class="line">configure_file (</span><br><span class="line">  <span class="string">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/TutorialConfig.h.in&quot;</span></span><br><span class="line">  <span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;/TutorialConfig.h&quot;</span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the binary tree to the search path for include files</span></span><br><span class="line"><span class="comment"># so that we will find TutorialConfig.h</span></span><br><span class="line">include_directories(<span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (USE_MYMATH)</span><br><span class="line">  include_directories (<span class="string">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/MathFunctions&quot;</span>)</span><br><span class="line">  add_subdirectory (MathFunctions)</span><br><span class="line">  <span class="built_in">set</span> (EXTRA_LIBS $&#123;EXTRA_LIBS&#125; MathFunctions)</span><br><span class="line">endif (USE_MYMATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the executable</span></span><br><span class="line">add_executable(Tutorial main.cpp)</span><br><span class="line">target_link_libraries (Tutorial $&#123;EXTRA_LIBS&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the install targets</span></span><br><span class="line">install (TARGETS Tutorial DESTINATION <span class="built_in">bin</span>)</span><br><span class="line">install (FILES <span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;/TutorialConfig.h&quot;</span>        </span><br><span class="line">  DESTINATION include)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">include(CTest)</span><br><span class="line"><span class="comment"># does it sqrt of 25</span></span><br><span class="line">add_test (TutorialComp25 Tutorial <span class="number">25</span>)</span><br><span class="line">set_tests_properties (TutorialComp25 PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;25 is 5&quot;</span>)</span><br><span class="line"><span class="comment"># does it handle negative numbers</span></span><br><span class="line"><span class="comment">#add_test (TutorialNegative Tutorial -25)</span></span><br><span class="line"><span class="comment">#set_tests_properties (TutorialNegative PROPERTIES PASS_REGULAR_EXPRESSION &quot;-25 is 0&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># does it handle small numbers</span></span><br><span class="line">add_test (TutorialSmall Tutorial <span class="number">0.0001</span>)</span><br><span class="line">set_tests_properties (TutorialSmall PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;0.0001 is 0.01&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># does the usage message work?</span></span><br><span class="line">add_test (TutorialUsage Tutorial)</span><br><span class="line">set_tests_properties (TutorialUsage PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;Usage:.*number&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#define a macro to simplify adding tests, then use it</span></span><br><span class="line">macro (do_test arg result)</span><br><span class="line">  add_test (TutorialComp$&#123;arg&#125; Tutorial $&#123;arg&#125;)</span><br><span class="line">  set_tests_properties (TutorialComp$&#123;arg&#125;</span><br><span class="line">  PROPERTIES PASS_REGULAR_EXPRESSION $&#123;result&#125;)</span><br><span class="line">endmacro (do_test)</span><br><span class="line"></span><br><span class="line">do_test (<span class="number">81</span> <span class="string">&quot;81 is 9&quot;</span>)</span><br><span class="line"><span class="comment"># do a bunch of result based tests</span></span><br><span class="line">do_test (<span class="number">25</span> <span class="string">&quot;25 is 5&quot;</span>)</span><br><span class="line">do_test (-<span class="number">25</span> <span class="string">&quot;-25 is 0&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="cmake-特点">CMake 特点</h3>
<ul>
<li>跨平台，并且可以生成响应的编译配置文件，如在linux平台下生成makefile,在苹果下生成xcode,在windows下可以生成MSVC的工程文件</li>
<li>开源，使用类BSD许可发布</li>
<li>简化管理大型项目</li>
<li>简化编译构建过程和编译过程cmake + make</li>
<li>可拓展，可以编写特定功能的模块</li>
</ul>
<h3 id="cmake问题">CMake问题</h3>
<ul>
<li>cmake编写的过程实际上是编程，每个目录一个CMakeLists.txt，使用cmake语言和语法</li>
<li>一些拓展可以使用，但是配合起来可能不是很理想</li>
<li>针对大型项目，如果项目比较小，还是直接编写makefile比较好</li>
</ul>
<h3 id="定义变量-1">定义变量</h3>
<ol type="1">
<li>命令行中 <code>cmake -DCUDA_USE_STATIC_CUDA_RUNTIME=1 ..</code></li>
<li><a
href="https://cmake.org/cmake/help/v3.10/command/set.html?highlight=set">cmake
中set的使用</a></li>
</ol>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 普通变量定义</span></span><br><span class="line"><span class="keyword">SET</span>(DIDBUILD_TARGET_OS LINUX)</span><br><span class="line"><span class="comment"># 强制覆盖</span></span><br><span class="line"><span class="keyword">SET</span>(CUDA_USE_STATIC_CUDA_RUNTIME <span class="keyword">OFF</span> CACHE BOOL <span class="string">&quot;fix cuda compiling error&quot;</span> FORCE)</span><br><span class="line"><span class="comment"># 有则忽略，否则定义变量</span></span><br><span class="line"><span class="keyword">SET</span>(DIDBUILD_TARGET_ARCH X86_64 CACHE <span class="keyword">STRING</span> <span class="string">&quot;default arch is x86_64&quot;</span>)</span><br><span class="line"><span class="comment"># 设置环境变量</span></span><br><span class="line"><span class="keyword">SET</span>(ENV&#123;LD_LIBRARY_PATH&#125; /usr/local/lib64)</span><br></pre></td></tr></table></figure>
<h3 id="字符串处理"><a
href="https://cmake.org/cmake/help/v3.10/command/string.html?highlight=string#command:string">字符串处理</a></h3>
<p><code>STRING(FIND $Origin_str $substr $target_str)</code></p>
<p>此外，<code>FIND</code>,<code>REPLACE</code>,<code>REGEX MATCH</code>，<code>APPEND</code>
<code>string(CONCAT &lt;output variable&gt; [&lt;input&gt;...])</code></p>
<p>Concatenate all the input arguments together and store the result in
the named output variable.</p>
<p><code>string(TOLOWER &lt;string1&gt; &lt;output variable&gt;)</code></p>
<p>Convert string to lower characters.</p>
<p><code>string(LENGTH &lt;string&gt; &lt;output variable&gt;)</code></p>
<p>Store in an output variable a given string’s length.</p>
<p><code>string(SUBSTRING &lt;string&gt; &lt;begin&gt; &lt;length&gt; &lt;output variable&gt;)</code></p>
<p>Store in an output variable a substring of a given string. If length
is -1 the remainder of the string starting at begin will be returned. If
string is shorter than length then end of string is used instead.</p>
<p><code>string(STRIP &lt;string&gt; &lt;output variable&gt;)</code></p>
<p>Store in an output variable a substring of a given string with
leading and trailing spaces removed. <figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">string</span>(COMPARE <span class="keyword">LESS</span> &lt;string1&gt; &lt;string2&gt; &lt;output variable&gt;)</span><br><span class="line"><span class="keyword">string</span>(COMPARE <span class="keyword">EQUAL</span> &lt;string1&gt; &lt;string2&gt; &lt;output variable&gt;)</span><br><span class="line"><span class="keyword">string</span>(&lt;HASH&gt; &lt;output variable&gt; &lt;input&gt;)</span><br></pre></td></tr></table></figure> Compute a
cryptographic hash of the input string. The supported
<code>&lt;HASH&gt;</code> algorithm names are: 很多</p>
<h3 id="strequal"><code>STREQUAL</code></h3>
<h3 id="make-verbose1"><code>make VERBOSE=1</code></h3>
<p>可以将cmake中定义的变量打印</p>
<h3 id="object-libraries">Object Libraries</h3>
<p>The OBJECT library type is also not linked to. It defines a
non-archival collection of object files resulting from compiling the
given source files. The object files collection can be used as source
inputs to other targets:</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">add_library</span>(archive OBJECT archive.cpp zip.cpp lzma.cpp)</span><br><span class="line"><span class="keyword">add_library</span>(archiveExtras STATIC $&lt;TARGET_OBJECTS:archive&gt; extras.cpp)</span><br><span class="line"><span class="keyword">add_executable</span>(test_exe $&lt;TARGET_OBJECTS:archive&gt; <span class="keyword">test</span>.cpp)</span><br></pre></td></tr></table></figure>
<p>OBJECT libraries may only be used locally as sources in a buildsystem
– they may not be installed, exported, or used in the right hand side of
<code>target_link_libraries()</code>. They also may not be used as the
<code>TARGET</code> in a use of the
<code>add_custom_command(TARGET)</code> command signature.</p>
<p>Although object libraries may not be named directly in calls to the
<code>target_link_libraries()</code> command, they can be “linked”
indirectly by using an Interface Library whose
<code>INTERFACE_SOURCES</code> target property is set to name
<code>$&lt;TARGET_OBJECTS:objlib&gt;</code>.</p>
<h3
id="externalproject通过url配置依赖第三方库">ExternalProject，通过url配置依赖第三方库</h3>
<blockquote>
<p>cmake/DownloadGoogleBenchmark.cmake</p>
</blockquote>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INCLUDE</span>(ExternalProject)</span><br><span class="line">ExternalProject_Add(googletest</span><br><span class="line">	URL https://github.com/google/googletest/archive/release-<span class="number">1.8</span>.<span class="number">0</span>.zip</span><br><span class="line">	URL_HASH SHA256=f3ed3b58511efd272eb074a3a6d6fb79d7c2e6a0e374323d1e6bcbcc1ef141bf</span><br><span class="line">	SOURCE_DIR <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_SOURCE_DIR&#125;/googletest&quot;</span></span><br><span class="line">	BINARY_DIR <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/googletest&quot;</span></span><br><span class="line">	CONFIGURE_COMMAND <span class="string">&quot;&quot;</span></span><br><span class="line">	<span class="keyword">BUILD_COMMAND</span> <span class="string">&quot;&quot;</span></span><br><span class="line">	INSTALL_COMMAND <span class="string">&quot;&quot;</span></span><br><span class="line">	TEST_COMMAND <span class="string">&quot;&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>主CMakeLists.txt中的使用</p>
</blockquote>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">IF</span>(PTHREADPOOL_BUILD_BENCHMARKS <span class="keyword">AND</span> <span class="keyword">NOT</span> <span class="keyword">DEFINED</span> GOOGLEBENCHMARK_SOURCE_DIR)</span><br><span class="line">     <span class="keyword">MESSAGE</span>(STATUS <span class="string">&quot;Downloading Google Benchmark to     $&#123;CONFU_DEPENDENCIES_SOURCE_DIR&#125;/googlebenchmark (define GOOGLEBENCHMARK_SOURCE_DIR to avoid it)&quot;</span>)</span><br><span class="line">     <span class="comment"># 添加其他依赖路径</span></span><br><span class="line">     <span class="keyword">CONFIGURE_FILE</span>(cmake/DownloadGoogleBenchmark.cmake <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/googlebenchmark-download/CMakeLists.txt&quot;</span>)</span><br><span class="line">     <span class="keyword">EXECUTE_PROCESS</span>(<span class="keyword">COMMAND</span> <span class="string">&quot;$&#123;CMAKE_COMMAND&#125;&quot;</span> -G <span class="string">&quot;$&#123;CMAKE_GENERATOR&#125;&quot;</span> .</span><br><span class="line">     WORKING_DIRECTORY <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/googlebenchmark-download&quot;</span>)</span><br><span class="line">     <span class="keyword">EXECUTE_PROCESS</span>(<span class="keyword">COMMAND</span> <span class="string">&quot;$&#123;CMAKE_COMMAND&#125;&quot;</span> --build .</span><br><span class="line">     WORKING_DIRECTORY <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/googlebenchmark-download&quot;</span>)</span><br><span class="line">     <span class="keyword">SET</span>(GOOGLEBENCHMARK_SOURCE_DIR <span class="string">&quot;$&#123;CONFU_DEPENDENCIES_SOURCE_DIR&#125;/googlebenchmark&quot;</span> CACHE <span class="keyword">STRING</span> <span class="string">&quot;Google Benchmark source directory&quot;</span>)</span><br><span class="line"><span class="keyword">ENDIF</span>()</span><br></pre></td></tr></table></figure>
<h2 id="cmakelists中的高级用法">CMakeLists中的高级用法</h2>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSTALL</span>(TARGETS libdeepindeed</span><br><span class="line">  LIBRARY DESTINATION lib</span><br><span class="line">  RUNTIME DESTINATION bin</span><br><span class="line">  ARCHIVE DESTINATION lib)</span><br></pre></td></tr></table></figure>
<ul>
<li><p><a
href="https://cmake.org/cmake/help/v3.1/command/install.html#installing-targets">cmake
install target</a></p></li>
<li><p>库之间的符号继承等</p></li>
</ul>
<h2 id="参考资料">参考资料</h2>
<ul>
<li>[1] <a
href="https://cmake.org/cmake/help/v3.10/manual/cmake-buildsystem.7.html">cmake
buildsystem文档，主要关于target_property,
target_include_directories,target_link_libraries,set_target_properties</a></li>
<li>[2] <a
href="https://cmake.org/cmake/help/v3.0/module/ExternalProject.html">ExternalProject文档</a></li>
<li>[3] <a
href="https://app.yinxiang.com/shard/s40/res/ecb203bd-889b-4eb3-8ee6-d0b0e88765f6/CMake%20Practice.pdf?search=Cmake">CMake
Practice</a></li>
<li>[4] <a
href="https://app.yinxiang.com/shard/s40/res/67a665d8-3622-49d1-ac10-2b21c8f29277/Makefile%E4%B8%AD%E6%96%87%E6%95%99%E7%A8%8B.pdf?search=Cmake">Makefile中文简明教程(陈皓)</a></li>
<li>[5] <a
href="https://blog.csdn.net/u011092188/article/details/61425924">CMake如何查找链接库---find_package的使用方法</a></li>
<li>[6]. 练习CMake的项目: https://github.com/cwlseu/brick</li>
</ul>
<h2 id="cmake-manual">CMake manual</h2>
<ul>
<li><a
href="https://cmake.org/cmake/help/v3.12/manual/cmake-buildsystem.7.html">cmake
buildsystem</a></li>
<li>cmake packages
<ul>
<li><a
href="https://cmake.org/cmake/help/v3.12/manual/cmake-packages.7.html#creating-packages">creating-packages</a></li>
<li><a
href="https://github.com/cwlseu/codefeeling/tree/master/cmaketest/createpackage">cmaketest
sample</a></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux开发</tag>
      </tags>
  </entry>
  <entry>
    <title>Python中的一些奇淫技巧</title>
    <url>/201812/20181214-python-tips/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>最近觉得 Python 太“简单了”，于是在师父川爷面前放肆了一把：“我觉得
Python 是世界上最简单的语言！”。于是川爷嘴角闪过了一丝轻蔑的微笑（内心
OS：Naive！，作为一个 Python
开发者，我必须要给你一点人生经验，不然你不知道天高地厚！）于是川爷给我了一份满分100分的题，然后这篇文章就是记录下做这套题所踩过的坑。</p>
<h2 id="变量类型">变量类型</h2>
<p>这是关于list的数据类型的理解。觉得如下程序会输出怎么样的结果？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x, L = []</span>):</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x):</span><br><span class="line">		L.append(i*i)</span><br><span class="line">	<span class="built_in">print</span>(L)</span><br><span class="line">	<span class="built_in">print</span>(<span class="built_in">id</span>(L))</span><br><span class="line"></span><br><span class="line">f(<span class="number">2</span>)</span><br><span class="line">f(<span class="number">2</span>, [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">f(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果如下 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[0, 1]</span><br><span class="line">139664725541736</span><br><span class="line">[1, 2, 3, 0, 1]</span><br><span class="line">139664725491584</span><br><span class="line">[0, 1, 0, 1, 4]</span><br><span class="line">139664725541736</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>在python中的数据可以分为可变数据类型和不变数据类型。
可变数据类型：像tuple,list,dict之类的变量就是可变数据类型，变量名存储的是一个地址，
该地址指向一个具体的对象，并且不管对变量的值即对象做怎么样的操作，都不会改变变量名存储的地址。
我们把列表作为参数传入一个函数时，在函数内我们对该列表进行了一些改变，由于变量存储的地址没有变
，所以就算我们没有故意通过return语句把该列表传递出来，该列表还是会在函数执行结束后跟着改变的。</p></li>
<li><p>函数的默认值为可变数据类型的话，会申请一个变量，这个变量地址是固定的，但是值在函数可被改变，
而且还会影响下次调用。</p></li>
</ul>
<p>同样的道理, 如果对不可变数据类型作为输入参数的话，会有什么结果？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">g</span>(<span class="params">x, s=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x):</span><br><span class="line">		s += <span class="built_in">str</span>(<span class="string">&quot;&#123;&#125; &quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">	<span class="built_in">print</span>(s)</span><br><span class="line">	<span class="built_in">print</span>(<span class="built_in">id</span>(x), <span class="built_in">id</span>(s))</span><br><span class="line">g(<span class="number">2</span>)</span><br><span class="line">ss = <span class="string">&quot;hello&quot;</span></span><br><span class="line">g(<span class="number">3</span>, ss)</span><br><span class="line">g(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0 1 </span><br><span class="line">(42414400, 140100353397648)</span><br><span class="line">140100353385936</span><br><span class="line">hello0 1 2 </span><br><span class="line">(42414376, 140100353397648)</span><br><span class="line">0 1 </span><br><span class="line">(42414400, 140100353397648)</span><br></pre></td></tr></table></figure>
从中可以看出，不可变数据类型的情况下，其中的 *
默认值是空没有随着函数调用被改变,与函数是绑定的关系，不信你可以测试一下相对位置是不变的；
* 而且在python语言的世界里，数字类型也是一个引用哦；</p>
<h2 id="列表生成器">列表生成器</h2>
<blockquote>
<p>描述:</p>
</blockquote>
<pre><code>下面的代码会报错，为什么？</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classA(<span class="built_in">object</span>):</span><br><span class="line">    x = <span class="number">1</span></span><br><span class="line">    gen = (xfor_inxrange(<span class="number">10</span>))<span class="comment"># gen=(x for _ in range(10))</span></span><br><span class="line">    if__name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(A.gen))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>答案</p>
</blockquote>
<p>这个问题是变量作用域问题，在 gen=(x for _ in xrange(10)) 中 gen
是一个 generator ,在
generator中变量有自己的一套作用域，与其余作用域空间相互隔离。因此，将会出现这样的
NameError: name 'x' is not defined
的问题，那么解决方案是什么呢？答案是：用 lambda 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classA(<span class="built_in">object</span>):</span><br><span class="line">    x = <span class="number">1</span></span><br><span class="line">    gen = (lambdax: (xfor_inxrange(<span class="number">10</span>)))(x)<span class="comment"># gen=(x for _ in range(10))</span></span><br><span class="line">    if__name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(A.gen))</span><br></pre></td></tr></table></figure>
<h2 id="装饰器">装饰器</h2>
<blockquote>
<p>描述</p>
</blockquote>
<p>我想写一个类装饰器用来度量函数/方法运行时间</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Timeit</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, func</span>):</span><br><span class="line">        self._wrapped = func</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, *args, **kws</span>):</span><br><span class="line">        start_time = time.time()</span><br><span class="line">        result = self._wrapped(*args, **kws)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;elapsed time is %s &quot;</span> % (time.time() - start_time))</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>这个装饰器能够运行在普通函数上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Timeit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span><span class="string">&quot;invoking function func&quot;</span></span><br><span class="line"></span><br><span class="line">if__name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    func()<span class="comment"># output: elapsed time is 1.00044410133</span></span><br></pre></td></tr></table></figure>
<p>但是运行在方法上会报错，为什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Timeit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span><span class="string">&quot;invoking function func&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">    @Timeit</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">self</span>):</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span><span class="string">&#x27;invoking method func&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    a = A()</span><br><span class="line">    a.func()<span class="comment"># Boom!</span></span><br></pre></td></tr></table></figure>
<p>如果我坚持使用类装饰器，应该如何修改？</p>
<blockquote>
<p>答案</p>
</blockquote>
<p>使用类装饰器后，在调用 <code>func</code> 函数的过程中其对应的
instance 并不会传递给 <code>__call__</code>方法，造成其 mehtod unbound
,那么解决方法是什么呢？描述符</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Timeit</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,func</span>):</span><br><span class="line">        self.func = func</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;invoking Timer&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__get__</span>(<span class="params">self, instance, owner</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">lambda</span> *args, **kwargs: self.func(instance, *args, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="meta">@Timeit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span><span class="string">&quot;invoking function func&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">    @Timeit</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">self</span>):</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span><span class="string">&#x27;invoking method func&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    a = A()</span><br><span class="line">    <span class="built_in">print</span> a.func()</span><br></pre></td></tr></table></figure>
<h2 id="python-调用机制">Python 调用机制</h2>
<blockquote>
<p>描述</p>
</blockquote>
<p>我们知道
<code>__call__</code>方法可以用来重载圆括号调用，好的，以为问题就这么简单？Naive！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;invoking __call__ from A!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    a = A()</span><br><span class="line">    a()<span class="comment">## output: invoking __call__ from A</span></span><br></pre></td></tr></table></figure>
<p>现在我们可以看到 a() 似乎等价于 <code>a.__call__()</code> ,看起来很
Easy 对吧，好的，我现在想作死，又写出了如下的代码，</p>
<p><code>a.__call__ = lambda: "invoking __call__ from lambda"</code>
<code>a.__call__()</code></p>
<p># output:invoking <strong>call</strong> from lambda</p>
<p><code>a()</code></p>
<p># output:invoking <strong>call</strong> from A!</p>
<p>请大佬们解释下，为什么 a() 没有调用出 <code>a.__call__()</code>
(此题由 USTC 王子博前辈提出) &gt; 答案</p>
<p>原因在于，在 Python 中，新式类（ new class
)的内建特殊方法，和实例的属性字典是相互隔离的，具体可以看看 Python
官方文档对于这一情况的说明</p>
<pre><code>For new-style classes, implicit invocations of special methods are only guaranteed to work correctly if defined on an object’s type, not in the object’s instance dictionary. That behaviour is the reason why the following code raises an exception (unlike the equivalent example with old-style classes):</code></pre>
<p>同时官方也给出了一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">C</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># def __len__(self):</span></span><br><span class="line">    <span class="comment">#   return 5</span></span><br><span class="line"></span><br><span class="line">c = C()</span><br><span class="line">c.__len__ = <span class="keyword">lambda</span>: <span class="number">5</span></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(c)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Traceback (most recent call last):</span><br><span class="line">#  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line"># TypeError: object of type &#x27;C&#x27; has no len()</span><br></pre></td></tr></table></figure>
<p>回到我们的例子上来，当我们在执行
<code>a.__call__=lambda: "invoking __call__ from lambda"</code>
时，的确在我们在 <code>a.__dict__</code> 中新增加了一个 key 为
<code>__call__</code> 的 item，但是当我们执行 a()
时，因为涉及特殊方法的调用，因此我们的调用过程不会从
<code>a.__dict__</code> 中寻找属性，而是从
<code>type(a).__dict__</code>中寻找属性。因此，就会出现如上所述的情况。</p>
<h2 id="描述符">描述符</h2>
<blockquote>
<p>描述</p>
</blockquote>
<p>我想写一个 Exam 类，其属性 math 为 [0,100]
的整数，若赋值时不在此范围内则抛出异常，我决定用描述符来实现这个需求。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Grade</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self._score = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__get__</span>(<span class="params">self, instance, owner</span>):</span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__set__</span>(<span class="params">self, instance, value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt;= value &lt;= <span class="number">100</span>:</span><br><span class="line">            self._score = value</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;grade must be between 0 and 100&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Exam</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    math = Grade()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, math</span>):</span><br><span class="line">        self.math = math</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    niche = Exam(math = <span class="number">90</span>)</span><br><span class="line">    <span class="built_in">print</span>(niche.math)</span><br><span class="line">    <span class="comment"># output : 90</span></span><br><span class="line">    snake = Exam(math = <span class="number">75</span>)</span><br><span class="line">    <span class="built_in">print</span>(snake.math)</span><br><span class="line">    <span class="comment"># output : 75</span></span><br><span class="line">    snake.math = <span class="number">120</span></span><br><span class="line">    <span class="comment"># output: ValueError:grade must be between 0 and 100!</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>看起来一切正常。不过这里面有个巨大的问题，尝试说明是什么问题。为了解决这个问题，我改写了
Grade 描述符如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Grade</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self._grade_pool = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__get__</span>(<span class="params">self, instance, owner</span>):</span><br><span class="line">        <span class="keyword">return</span> self._grade_pool.get(instance, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__set__</span>(<span class="params">self, instance, value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt;= value &lt;= <span class="number">100</span>:</span><br><span class="line">            _grade_pool = self.__dict__.setdefault(<span class="string">&#x27;_grade_pool&#x27;</span>,&#123;&#125;)</span><br><span class="line">            _grade_pool[instance] = value</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Ooh, Value Error&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>不过这样会导致更大的问题，请问该怎么解决这个问题？</p>
<blockquote>
<p>答案</p>
</blockquote>
<ol type="1">
<li>第一个问题的其实很简单，如果你再运行一次 print(niche.math)
你就会发现，输出值是 75 ，那么这是为什么呢？这就要先从
Python的调用机制说起了。我们如果调用一个属性，那么其顺序是优先从实例的
<code>__dict__</code>
里查找，然后如果没有查找到的话，那么依次查询类字典，父类字典，直到彻底查不到为止。好的，现在回到我们的问题，我们发现，在我们的类
Exam
中，其<code>self.math</code>的调用过程是，首先在实例化后的实例的<code>__dict__</code>中进行查找，没有找到，接着往上一级，在我们的类
Exam 中进行查找，好的找到了，返回。那么这意味着，我们对于 self.math
的所有操作都是对于类变量
math的操作。因此造成变量污染的问题。那么该则怎么解决呢？很多同志可能会说，恩，在
<code>__set__</code> 函数中将值设置到具体的实例字典不就行了。</li>
</ol>
<p>那么这样可不可以呢？答案是，很明显不得行啊，至于为什么，就涉及到我们
Python 描述符的机制了，</p>
<blockquote>
<p>描述符指的是实现了描述符协议的特殊的类，三个描述符协议指的是
<code>__get__</code>, <code>__set__</code> , <code>__delete__</code>以及
Python 3.6 中新增的 <code>__set_name__</code>
方法，其中实现了<code>__get__</code> 以及
<code>__set__ / __delete__ / __set_name__</code> 的是 Data descriptors
，而只实现了 <code>__get__</code> 的是 Non-Data descriptor</p>
</blockquote>
<p>那么有什么区别呢，前面说了，
我们如果调用一个属性，那么其顺序是优先从实例的 <code>__dict__</code>
里查找，然后如果没有查找到的话，那么一次查询类字典，父类字典，直到彻底查不到为止。
但是，这里没有考虑描述符的因素进去，如果将描述符因素考虑进去，那么正确的表述应该是我们如果调用一个属性，那么其顺序是优先从实例的
<code>__dict__</code>
里查找，然后如果没有查找到的话，那么依次查询类字典，父类字典，直到彻底查不到为止。其中如果在<em>类实例字典</em>中的该属性是一个
Data descriptors
，那么无论实例字典中存在该属性与否，无条件走描述符协议进行调用，在类实例字典中的该属性是一个Non-Data
descriptors
，那么优先调用实例字典中的属性值而不触发描述符协议，如果实例字典中不存在该属性值，那么触发
Non-Data descriptor的描述符协议。回到之前的问题，我们即使在
<code>__set__</code>将具体的属性写入实例字典中，但是由于类字典中存在着
Data descriptors ，因此，我们在调用 math
属性时，依旧会触发描述符协议。</p>
<ol start="2" type="1">
<li>经过改良的做法，利用dict的key唯一性，将具体的值与实例进行绑定，但是同时带来了内存泄露的问题。那么为什么会造成内存泄露呢，首先复习下我们的
dict 的特性:</li>
</ol>
<ul>
<li>dict 最重要的一个特性，凡可 hash 的对象皆可为 key ，dict 通过利用的
hash 值的唯一性(严格意义上来讲并不是唯一，而是其 hash
值碰撞几率极小，近似认定其唯一)来保证 key 的不重复；</li>
<li>同时,
dict中的key引用是<em>强引用类型</em>,会造成对应对象的引用计数的增加，可能造成对象无法被GC,从而产生内存泄露。</li>
</ul>
<ol start="3" type="1">
<li>那么这里该怎么解决呢？两种方法</li>
</ol>
<ul>
<li>第一种：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Grade</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">import</span> weakref</span><br><span class="line">        self._grade_pool = weakref.WeakKeyDictionary()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__get__</span>(<span class="params">self,instance,owner</span>):</span><br><span class="line">        <span class="keyword">return</span> self._grade_pool.get(instance,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__set__</span>(<span class="params">self,instance,value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt;= value &lt;= <span class="number">100</span>:</span><br><span class="line">            _grade_pool = self.__dict__.setdefault(<span class="string">&#x27;_grade_pool&#x27;</span>,&#123;&#125;)</span><br><span class="line">            _grade_pool[instance] = value</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;fuck&quot;</span>)</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Exam</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    math = Grade()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, math</span>):</span><br><span class="line">        self.math = math</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    niche = Exam(math = <span class="number">90</span>)</span><br><span class="line">    <span class="built_in">print</span>(niche.math)</span><br><span class="line">    <span class="comment"># output : 90</span></span><br><span class="line">    snake = Exam(math = <span class="number">75</span>)</span><br><span class="line">    <span class="built_in">print</span>(snake.math)</span><br><span class="line">    <span class="comment"># output : 75</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        snake.math = <span class="number">120</span></span><br><span class="line">    <span class="keyword">except</span> ValueError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span> e</span><br><span class="line">    <span class="built_in">print</span> niche.math</span><br></pre></td></tr></table></figure>
<p>weakref 库中的 WeakKeyDictionary 所产生的字典的 key
对于<em>对象的引用是弱引用类型</em>，其不会造成内存引用计数的增加，因此不会造成内存泄露。同理，如果我们为了避免
value 对于对象的强引用，我们可以使用 WeakValueDictionary 。</p>
<ul>
<li>第二种：在<strong>Python 3.6 </strong>中，实现的PEP 487
提案，为描述符新增加了一个协议<code>__set_name__</code>，我们可以用其来绑定对应的对象：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Grade</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__get__</span>(<span class="params">self, instance, owner</span>):</span><br><span class="line">        <span class="keyword">return</span> instance.__dict__[self.key]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__set__</span>(<span class="params">self, instance, value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt;= value &lt;= <span class="number">100</span>:</span><br><span class="line">            instance.__dict__[self.key] = value</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;fuck&quot;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__set_name__</span>(<span class="params">self, owner, name</span>):</span><br><span class="line">        self.key = name</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这道题涉及的东西比较多，这里给出一点参考链接 -
invoking-descriptors(https://docs.python.org/2/reference/datamodel.html#invoking-descriptors)<br />
- Descriptor HowTo
Guide(https://docs.python.org/3/howto/descriptor.html)<br />
- PEP
487(https://www.python.org/dev/peps/pep-0487/#adding-a-class-attribute-with-the-attribute-order)
- what`s new in Python
3.6(https://docs.python.org/3.6/whatsnew/3.6.html)</p>
<h2 id="python-继承机制">Python 继承机制</h2>
<blockquote>
<p>描述</p>
</blockquote>
<p>试求出以下代码的输出结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Init</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.val = value</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;init&quot;</span>, self.val</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Add2</span>(<span class="title class_ inherited__">Init</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, val</span>):</span><br><span class="line">        <span class="built_in">super</span>(Add2, self).__init__(val)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Add2 Before:&quot;</span>, self.val</span><br><span class="line">        self.val += <span class="number">2</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Add2&quot;</span>, self.val</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mul5</span>(<span class="title class_ inherited__">Init</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, val</span>):</span><br><span class="line">        <span class="built_in">super</span>(Mul5, self).__init__(val)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Mul5 Before:&quot;</span>, self.val</span><br><span class="line">        self.val *= <span class="number">5</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Mul5&quot;</span>, self.val</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pro</span>(Mul5, Add2):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Incr</span>(<span class="title class_ inherited__">Pro</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, val</span>):</span><br><span class="line">        <span class="built_in">super</span>(Pro, self).__init__(val)</span><br><span class="line">        self.val += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Incr&quot;</span>, self.val</span><br><span class="line"></span><br><span class="line">p = Incr(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(p.val)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>答案</p>
</blockquote>
<pre><code>输出是 36 ，具体可以参考 New-style Classes , multiple-inheritance</code></pre>
<h2 id="python-特殊方法">Python 特殊方法</h2>
<pre><code>描述
我写了一个通过重载 new 方法来实现单例模式的类。</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    _instance = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__new__</span>(<span class="params">self, *args, **kwargs</span>):</span><br><span class="line">        <span class="keyword">if</span> self._instance:</span><br><span class="line">            <span class="keyword">return</span> self._instance</span><br><span class="line">        self._instance = cv = <span class="built_in">object</span>.__new__(self, *args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> cv</span><br><span class="line"></span><br><span class="line">sin1 = Singleton()</span><br><span class="line">sin2 = Singleton()</span><br><span class="line"><span class="built_in">print</span>(sin1 <span class="keyword">is</span> sin2)</span><br><span class="line"><span class="built_in">print</span> Singleton() <span class="keyword">is</span> sin2</span><br><span class="line"></span><br><span class="line"><span class="comment"># output: True</span></span><br></pre></td></tr></table></figure>
<p>现在我有一堆类要实现为单例模式，所以我打算照葫芦画瓢写一个元类，这样可以让代码复用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SingleMeta</span>(<span class="title class_ inherited__">type</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, bases, <span class="built_in">dict</span></span>):</span><br><span class="line">        self._instance = <span class="literal">None</span></span><br><span class="line">        __new__o = self.__new__</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__new__</span>(<span class="params">self, *args, **kwargs</span>):</span><br><span class="line">            <span class="keyword">if</span> self._instance:</span><br><span class="line">                <span class="keyword">return</span> self._instance</span><br><span class="line">            self._instance = cv = __new__o(self, *args, **kwargs)</span><br><span class="line">            <span class="keyword">return</span> cv</span><br><span class="line">        self.__new__ = __new__</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    __metaclass__ = SingleMeta</span><br><span class="line"></span><br><span class="line">a1 = A() <span class="comment"># what`s the fuck</span></span><br></pre></td></tr></table></figure>
<p>哎，为啥这会报错啊，我明明之前用这种方法给
<code>__getattribute__</code>打补丁的，下面这段代码能够捕获一切属性调用并打印参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TraceAttribute</span>(<span class="title class_ inherited__">type</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">cls, name, bases, <span class="built_in">dict</span></span>):</span><br><span class="line">        __getattribute__o = cls.__getattribute__</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__getattribute__</span>(<span class="params">self, *args, **kwargs</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;__getattribute__:&#x27;</span>, args, kwargs)</span><br><span class="line">            <span class="keyword">return</span> __getattribute__o(self, *args, **kwargs)</span><br><span class="line">        cls.__getattribute__ = __getattribute__</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):  <span class="comment"># Python 3 是 class A(object,metaclass=TraceAttribute):</span></span><br><span class="line">    __metaclass__ = TraceAttribute</span><br><span class="line">    a = <span class="number">1</span></span><br><span class="line">    b = <span class="number">2</span></span><br><span class="line">a = A()</span><br><span class="line">a.a</span><br><span class="line">a.b</span><br></pre></td></tr></table></figure>
<p>a.b</p>
<p>试解释为什么给 getattribute 打补丁成功，而 new 打补丁失败。
如果我坚持使用元类给 new 打补丁来实现单例模式，应该怎么修改？</p>
<blockquote>
<p>答案</p>
</blockquote>
<p>其实这是最气人的一点，类里的<code>__new__</code>是一个
<strong>staticmethod</strong> 因此替换的时候必须以
<strong>staticmethod</strong> 进行替换。答案如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SingleMeta</span>(<span class="title class_ inherited__">type</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, bases, <span class="built_in">dict</span></span>):</span><br><span class="line">        self._instance = <span class="literal">None</span></span><br><span class="line">        __new__o = self.__new__</span><br><span class="line"></span><br><span class="line"><span class="meta">        @staticmethod</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__new__</span>(<span class="params">self, *args, **kwargs</span>):</span><br><span class="line">            <span class="keyword">if</span> self._instance:</span><br><span class="line">                <span class="keyword">return</span> self._instance</span><br><span class="line">            self._instance = cv = __new__o(self, *args, **kwargs)</span><br><span class="line">            <span class="keyword">return</span> cv</span><br><span class="line">        self.__new__ = __new__</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    __metaclass__ = SingleMeta</span><br><span class="line"></span><br><span class="line">a1 = A() <span class="comment"># what`s the fuck</span></span><br></pre></td></tr></table></figure>
<h2 id="多线程是真的多线程吗">多线程是真的多线程吗？</h2>
<blockquote>
<p>Effective Python
第37条：可以使用线程来执行阻塞式IO，但是不要用它做平行计算。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python2.7</span></span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep, ctime</span><br><span class="line"></span><br><span class="line">loops = [<span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ThreadFunc</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, func, args, name=<span class="string">&#x27;&#x27;</span></span>):</span><br><span class="line">        self.name = name </span><br><span class="line">        self.func = func</span><br><span class="line">        self.args = args </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self</span>):</span><br><span class="line">        apply(self.func, self.args)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loop</span>(<span class="params">nloop, nsec</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;start loop &quot;</span>, nloop, <span class="string">&quot;at:&quot;</span>, ctime()</span><br><span class="line">    a = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">30000000</span>):</span><br><span class="line">        a += i</span><br><span class="line">    <span class="built_in">print</span> a</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;loop &quot;</span>, nloop, <span class="string">&quot;done at:&quot;</span>, ctime()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main_with_muilt_thread</span>():</span><br><span class="line">    threads = []</span><br><span class="line">    nloops = <span class="built_in">range</span>(<span class="built_in">len</span>(loops))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nloops:</span><br><span class="line">        t = threading.Thread(target=ThreadFunc(loop,(i, loops[i]),loop.__name__))</span><br><span class="line">        threads.append(t)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;starting at:&quot;</span>, ctime()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nloops:</span><br><span class="line">        threads[i].start()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nloops:</span><br><span class="line">        threads[i].join()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;all DONE at:&quot;</span>, ctime()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main_with_one_thread</span>():</span><br><span class="line">    threads = []</span><br><span class="line">    nloops = <span class="built_in">range</span>(<span class="built_in">len</span>(loops))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nloops:</span><br><span class="line">        t = threading.Thread(target=ThreadFunc(loop,(i, loops[i]),loop.__name__))</span><br><span class="line">        threads.append(t)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;starting at:&quot;</span>,ctime()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nloops:</span><br><span class="line">        loop(i, loops[i])</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;all DONE at:&quot;</span>,ctime()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main_with_one_thread()</span><br><span class="line">    main_with_muilt_thread()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>output</p>
</blockquote>
<pre><code>starting at: Sun Jul 30 20:05:28 2017
start loop  0 at: Sun Jul 30 20:05:28 2017
449999985000000
loop  0 done at: Sun Jul 30 20:05:30 2017
start loop  1 at: Sun Jul 30 20:05:30 2017
449999985000000
loop  1 done at: Sun Jul 30 20:05:32 2017
all DONE at: Sun Jul 30 20:05:32 2017
starting at: Sun Jul 30 20:05:32 2017
start loop  0 at: Sun Jul 30 20:05:32 2017start loop 
1 at: Sun Jul 30 20:05:32 2017
449999985000000
loop  0 done at: Sun Jul 30 20:05:40 2017
449999985000000
loop  1 done at: Sun Jul 30 20:05:40 2017
all DONE at: Sun Jul 30 20:05:40 2017</code></pre>
<p>从中看出，使用单线程顺序执行时使用了4s，但是使用多线程执行了8s。本来使用多线程应该是原的两倍才对啊，但是现在多线程竟然比但想成还慢。因为<strong>标准CPython解释器中的多线程受到了GIL的影响，同一时刻只能有一个线程得到执行</strong>。但是为啥还要支持多线程呢？
1. 程序看上去可以同时执行很多个事情，免去了手工管理任务的切换操作 2.
处理阻塞式IO操作。Python执行某些系统调用时，会触发阻塞式操作。读写文件，在网络间通讯，显示器与设计之间交互都属于阻塞式IO。为了响应阻塞式请求，开发者可以借助线程，把python程序与这些耗时IO操作隔离开来。</p>
<h2 id="python中一些忽视的性质">Python中一些忽视的性质</h2>
<ol type="1">
<li><p><code>eval</code> 与<code>ast.literal_eval</code>:
literal_eval相对来说比较安全，只有字符串中包含表达式的时候才会评估。</p></li>
<li><p>实现一组字符串分组分开：<code>itertools.groupby</code>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from itertools import groupby</span><br><span class="line">s = &quot;1123433364433&quot;</span><br><span class="line">print([&#x27;&#x27;.join(i) for _, i in groupby(s)])</span><br></pre></td></tr></table></figure></p></li>
<li><p>判断list是否为空 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if not l:</span><br><span class="line">	pass</span><br></pre></td></tr></table></figure> 就是最好的选择 <a
href="https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty?rq=1">how-do-i-check-if-a-list-is-empty</a></p></li>
<li><p>从json文件中读取参数 <a
href="https://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file?noredirect=1&amp;lq=1">parse
values from a json file</a></p></li>
<li><p>各种<code>@property</code>的实现 <a
href="https://stackoverflow.com/questions/17330160/how-does-the-property-decorator-work">python
property的作用</a> <a
href="https://stackoverflow.com/questions/3012421/python-memoising-deferred-lookup-property-decorator">python
property的重定义</a></p></li>
</ol>
<h2 id="常见问题">常见问题</h2>
<h2 id="pip安装package出现read-timed-out.">pip安装package出现Read timed
out.</h2>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">xxx@xxxx:~/Repo/engine/online_index/webpy-master$ pip install cheroot-6.0.0-py2.py3-none-any.whl </span><br><span class="line">Processing ./cheroot-6.0.0-py2.py3-none-any.whl</span><br><span class="line">Requirement already satisfied: six&gt;=1.11.0 <span class="keyword">in</span> /opt/anaconda2/lib/python2.7/site-packages (from cheroot==6.0.0)</span><br><span class="line">Collecting more-itertools&gt;=2.6 (from cheroot==6.0.0)</span><br><span class="line">Retrying (Retry(total=4, connect=None, <span class="built_in">read</span>=None, redirect=None)) after connection broken by <span class="string">&#x27;ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#x27;</span>pypi.python.org<span class="string">&#x27;, port=443): Read timed out. (read timeout=15)&quot;,)&#x27;</span>: /simple/more-itertools/</span><br><span class="line">Retrying (Retry(total=3, connect=None, <span class="built_in">read</span>=None, redirect=None)) after connection broken by <span class="string">&#x27;ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#x27;</span>pypi.python.org<span class="string">&#x27;, port=443): Read timed out. (read timeout=15)&quot;,)&#x27;</span>: /simple/more-itertools/</span><br><span class="line">Retrying (Retry(total=2, connect=None, <span class="built_in">read</span>=None, redirect=None)) after connection broken by <span class="string">&#x27;ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#x27;</span>pypi.python.org<span class="string">&#x27;, port=443): Read timed out. (read timeout=15)&quot;,)&#x27;</span>: /simple/more-itertools/</span><br><span class="line">Retrying (Retry(total=1, connect=None, <span class="built_in">read</span>=None, redirect=None)) after connection broken by <span class="string">&#x27;ReadTimeoutError(&quot;HTTPSConnectionPool(host=&#x27;</span>pypi.python.org<span class="string">&#x27;, port=443): Read timed out. (read timeout=15)&quot;,)&#x27;</span>: /simple/more-itertools/</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="解决方案">解决方案</h3>
<p>安装过程中添加信赖的地址，尤其是在某些互联网公司中，由于安全，防火墙等等安全考虑，会将pip默认的host地址作为不信任。
xxx@xxxx:~/Repo/engine/online_index/webpy-master$ pip install web.py -i
http://pypi.douban.com/simple --trusted-host pypi.douban.com</p>
<p>在pip.conf中加入trusted-host选项，该方法是一劳永逸 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure></p>
<h2 id="参考文献">参考文献</h2>
<p>[1]. [Someone-tell-me-that-you-think-Python-is-simple]<a
href="https://manjusaka.itscoder.com/2016/11/18/Someone-tell-me-that-you-think-Python-is-simple/"
class="uri">https://manjusaka.itscoder.com/2016/11/18/Someone-tell-me-that-you-think-Python-is-simple/</a></p>
<p>[2].[invoking-descriptors]<a
href="https://docs.python.org/2/reference/datamodel.html#invoking-descriptors"
class="uri">https://docs.python.org/2/reference/datamodel.html#invoking-descriptors</a></p>
<p>[3].[Descriptor HowTo Guide]<a
href="https://docs.python.org/3/howto/descriptor.html"
class="uri">https://docs.python.org/3/howto/descriptor.html</a></p>
<p>[4].[Python代码规范PEP 487]<a
href="https://www.python.org/dev/peps/pep-0487/#adding-a-class-attribute-with-the-attribute-order"
class="uri">https://www.python.org/dev/peps/pep-0487/#adding-a-class-attribute-with-the-attribute-order</a></p>
<p>[5].[what`s new in Python 3.6]<a
href="https://docs.python.org/3.6/whatsnew/3.6.html"
class="uri">https://docs.python.org/3.6/whatsnew/3.6.html</a></p>
<p>[6].[Python相见恨晚的库]<a
href="https://www.zhihu.com/question/24590883"
class="uri">https://www.zhihu.com/question/24590883</a></p>
<p>[7]. [python recipes]<a
href="https://github.com/cwlseu/pyrecipes.git"
class="uri">https://github.com/cwlseu/pyrecipes.git</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Object Detection Metrics</title>
    <url>/201903/20190311-object-detection-metrics/</url>
    <content><![CDATA[<h2 id="物体检测效果评估相关的定义-1">物体检测效果评估相关的定义 <a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h2>
<h3 id="intersection-over-union-iou">Intersection Over Union (IOU)</h3>
<p>Intersection Over Union (IOU) is measure based on Jaccard Index that
evaluates the overlap between two bounding boxes. It requires a ground
truth bounding box <span class="math inline">\(B_{gt}\)</span>and a
predicted bounding box <span class="math inline">\(B_p\)</span> By
applying the IOU we can tell if a detection is valid (True Positive) or
not (False Positive).<br />
IOU is given by the overlapping area between the predicted bounding box
and the ground truth bounding box divided by the area of union between
them:</p>
<p><span class="math display">\[IOU = \frac{\text{area of
overlap}}{\text{area of union}} = \frac{area(B_p \cap B_{gt})}{area(B_p
\cup B_{gt})}\]</span></p>
<p>The image below illustrates the IOU between a ground truth bounding
box (in green) and a detected bounding box (in red).</p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030323414.png" alt="iou" style="zoom:150%;" align="center" /></p>
<h3
id="true-positive-false-positive-false-negative-and-true-negative4">True
Positive, False Positive, False Negative and True Negative<a href="#fn2"
class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></h3>
<p>Some basic concepts used by the metrics:</p>
<ul>
<li><strong>True Positive (TP)</strong>: A correct detection. Detection
with <code>IOU ≥ _threshold_</code></li>
<li><strong>False Positive (FP)</strong>: A wrong detection. Detection
with <code>IOU &lt; _threshold_</code></li>
<li><strong>False Negative (FN)</strong>: A ground truth not
detected</li>
<li><strong>True Negative (TN)</strong>: Does not apply. It would
represent a corrected misdetection. In the object detection task there
are many possible bounding boxes that should not be detected within an
image. Thus, TN would be all possible bounding boxes that were
corrrectly not detected (so many possible boxes within an image). That's
why it is not used by the metrics.</li>
</ul>
<p><code>_threshold_</code>: depending on the metric, it is usually set
to 50%, 75% or 95%.</p>
<h3 id="precision">Precision</h3>
<p>Precision is the ability of a model to identify <strong>only</strong>
the relevant objects. It is the percentage of correct positive
predictions and is given by: <span class="math display">\[Precision =
\frac{TP}{TP + FP} = \frac{TP}{all-detections}\]</span></p>
<h3 id="recall">Recall</h3>
<p>Recall is the ability of a model to find all the relevant cases (all
ground truth bounding boxes). It is the percentage of true positive
detected among all relevant ground truths and is given by: <span
class="math display">\[Recall = \frac{TP}{TP + FN} =
\frac{TP}{all-groundtruths}\]</span> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030324390.png"
alt="@混淆矩阵" /></p>
<h2 id="评估方法metrics235">评估方法Metrics<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a><a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a><a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a></h2>
<ul>
<li>Receiver operating characteristics (ROC) curve</li>
<li>Precision x Recall curve</li>
<li>Average Precision
<ul>
<li>11-point interpolation</li>
<li>Interpolating all points</li>
</ul></li>
</ul>
<h2 id="物体检测中的损失函数">物体检测中的损失函数</h2>
<p><a
href="https://yq.aliyun.com/articles/602858?utm_content=m_1000002415">【机器学习者都应该知道的五种损失函数！】</a>
我们假设有<span class="math inline">\(n\)</span>个样本, 其中<span
class="math inline">\(x_i\)</span>的gt值为<span
class="math inline">\(y_i\)</span>, 算法<span
class="math inline">\(f(x)\)</span>的预测结果为<span
class="math inline">\(y_i^p\)</span></p>
<h4 id="均方误差-l2损失">均方误差 —— L2损失</h4>
<p>均方误差（MSE）是回归损失函数中最常用的误差，它是预测值与目标值之间差值的平方和，公式如下</p>
<p><span class="math display">\[MSE = \frac{\sum_{i=1}^{n}(y_i -
y_i^p)^2}{n}\]</span></p>
<h4 id="平均绝对误差l1损失函数">平均绝对误差——L1损失函数</h4>
<p>平均绝对误差（MAE）是另一种常用的回归损失函数，它是目标值与预测值之差绝对值的和，表示了预测值的平均误差幅度，而不需要考虑误差的方向（注：平均偏差误差MBE则是考虑的方向的误差，是残差的和），范围是0到<span
class="math inline">\(\infin\)</span></p>
<p><span class="math display">\[MAE = \frac{\sum_{i=1}^{n}|y_i -
y_i^p|}{n}\]</span></p>
<h4 id="l1-v.s-l2损失函数7">L1 v.s L2损失函数<a href="#fn6"
class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a></h4>
<p>通常，利用均方差更容易求解，但平方绝对误差则对于异常值更稳健。</p>
<p>下面让我们对这两种损失函数进行具体的分析。无论哪一种机器学习模型，目标都是找到能使目标函数最小的点。在最小值处每一种损失函数都会得到最小值。</p>
<p><a
href="http://nbviewer.ipython.org/github/rishy/rishy.github.io/blob/master/ipy_notebooks/L1%20vs.%20L2%20Loss.ipynb">可以运行相关代码进行分析</a><a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p>
<p>由于均方误差（MSE）在误差较大点时的损失远大于平均绝对误差（MAE），它会给异常值赋予更大的权重，模型会全力减小异常值造成的误差，从而使得模型的整体表现下降。所以当训练数据中含有较多的异常值时，平均绝对误差（MAE）更为有效。当我们对所有观测值进行处理时，如果利用MSE进行优化则我们会得到所有观测的均值，而使用MAE则能得到所有观测的中值。与均值相比，中值对于异常值的鲁棒性更好，这就意味着平均绝对误差对于异常值有着比均方误差更好的鲁棒性。</p>
<p>但MAE也存在一个问题，特别是对于神经网络来说，它的<strong>梯度在极值点处会有很大的跃变</strong>，及时很小的损失值也会长生很大的误差，这很不利于学习过程。<strong>为了解决这个问题，需要在解决极值点的过程中动态减小学习率</strong>。MSE在极值点却有着良好的特性，及时在固定学习率下也能收敛。MSE的梯度随着损失函数的减小而减小，这一特性使得它在最后的训练过程中能得到更精确的结果。</p>
<p>在实际训练过程中，如果异常值对于实际业务十分重要需要进行检测，MSE是更好的选择，而如果在异常值极有可能是坏点的情况下MAE则会带来更好的结果。</p>
<p>总结：L1损失对于异常值更鲁棒，但它的导数不连续使得寻找最优解的过程低效；L2损失对于异常值敏感，但在优化过程中更为稳定和准确。更详细的L1和L2不同比较可以参考这篇文章。</p>
<blockquote>
<p>但现实中还存在两种损失都很难处理的问题。例如某个任务中90%的数据都符合目标值——150，而其余的10%数据取值则在0-30之间。那么利用MAE优化的模型将会得到150的预测值而忽略的剩下的10%（倾向于中值）；而对于MSE来说由于异常值会带来很大的损失，将使得模型倾向于在0-30的方向取值。这两种结果在实际的业务场景中都是我们不希望看到的。</p>
</blockquote>
<h4 id="huber损失平滑平均绝对误差">Huber损失——平滑平均绝对误差</h4>
<p>Huber损失相比于平方损失来说对于异常值不敏感，但它同样保持了可微的特性。它基于绝对误差但在误差很小的时候变成了平方误差。我们可以使用超参数<span
class="math inline">\(\delta\)</span>来调节这一误差的阈值。当<span
class="math inline">\(\delta\)</span>趋向于0时它就退化成了MAE，而当<span
class="math inline">\(\delta\)</span>趋向于无穷时则退化为了MSE，其表达式如下，是一个连续可微的分段函数：</p>
<p><span class="math display">\[ L_\delta(y, f(x)) =
   \begin{cases}
    \frac{1}{2}(y - f(x))^2       &amp; \quad \text{if } |y - f(x)| \le
\delta\\
    \delta{|y - f(x)|} - \frac{1}{2}\delta^2  &amp; \quad
\text{otherwise }\\
  \end{cases} \]</span></p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030325495.png"
alt="@HuberLoss with delta change" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="HuberLoss">@HuberLoss</span> with delta change</figcaption>
</figure>
<p>对于Huber损失来说，<span
class="math inline">\(\delta\)</span>的选择十分重要，它决定了模型处理异常值的行为。当残差大于<span
class="math inline">\(\delta\)</span>时使用L1损失，很小时则使用更为合适的L2损失来进行优化。</p>
<p>Huber损失函数克服了MAE和MSE的缺点，不仅可以保持损失函数具有连续的导数，同时可以利用MSE梯度随误差减小的特性来得到更精确的最小值，也对异常值具有更好的鲁棒性。</p>
<p>而Huber损失函数的良好表现得益于精心训练的超参数<span
class="math inline">\(\delta\)</span>.</p>
<h2 id="参考文献">参考文献</h2>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://github.com/cwlseu/Object-Detection-Metrics
"评估标准"<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"
role="doc-endnote"><p>https://acutecaretesting.org/en/articles/precision-recall-curves-what-are-they-and-how-are-they-used
"Precision-recall curves – what are they and how are they used"<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>https://www.jianshu.com/p/c61ae11cc5f6
"机器学习之分类性能度量指标 : ROC曲线、AUC值、正确率、召回率"<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/
"How and When to Use ROC Curves and Precision-Recall Curves for
Classification in Python"<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>https://www.zhihu.com/question/30643044
"精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？"<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://yq.aliyun.com/articles/602858?utm_content=m_1000002415
"机器学习者都应该知道的五种损失函数！"<a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"
role="doc-endnote"><p>http://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/?spm=a2c4e.10696291.0.0.170b19a44a9JnP<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>detection</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习: 一起来看数据增强</title>
    <url>/201902/20190225-Data-Argumentation/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>从AlexNet夺取ImageNet的冠军，到RCNN的出现，再到后来的SSD算法，数据增强仿佛像是一位功成名就的老者，虽然数据增强对于算法性能的提升起到重要的作用，但是他从来不居功，默默在背后付出"众里寻他千百度"，只为让你"蓦然回首，她在灯火阑珊处"。</p>
<h2 id="数据增强data-augmentation的目的与作用">数据增强(Data
Augmentation)的目的与作用</h2>
<p>卷积神经网络能够鲁棒地将物体分类，即便物体放置在不同的方向上，这也就是所说不变性的性质，即使卷积神经网络被放在不同方向上，它也能进行对象分类。更具体的说，卷积神经网络对平移、视角、尺寸或照度（或以上组合）保持不变性。
这就是数据增强的本质前提。在现实世界中，我们可能会有一组在有限的条件下拍摄的图像
。但是，我们的目标应用可能是在多变的环境中，例如，不同的方向、位置、比例、亮度等。我们通过使用经综合修改过的数据来训练神经网络，以应对这些情形。</p>
<blockquote>
<p>数据少的负面影响： 1.
模型训练的时候可能无法收敛，少量训练数据难以提供足够的信息给模型学习 2.
过拟合，模型容易将训练数据的完全不相关信息学习进去，如噪声 3.
容易陷入局部最优值 4.
难以衡量模型好坏，除了训练数据，测试数据也非常少，少量数据整的与否可能对结果产生较大影响。</p>
</blockquote>
<blockquote>
<p>数据不平衡的负面影响：
最常见的就是模型的权值更新被数据多的一个方向带跑偏了。</p>
</blockquote>
<blockquote>
<p>数据增强的作用 1. 补充数据样本不足 2.
减少网络的过拟合现象，通过对训练图片进行变换可以得到泛化能力更强的网络，更好的适应应用场景。</p>
</blockquote>
<h2 id="基本方法">基本方法</h2>
<p>现在最常用的数据方案是
数据增强的基本方法无非就是图像的基本操作进行排列组合，生成千万种数据增强的可能性：
* 旋转/反射变换(Rotation/reflection): 随机旋转图像一定角度;
改变图像内容的朝向; * 翻转变换(flip): 沿着水平或者垂直方向翻转图像; *
缩放变换(zoom): 按照一定的比例放大或者缩小图像; * 平移变换(shift):
在图像平面上对图像以一定方式进行平移; *
可以采用随机或人为定义的方式指定平移范围和平移步长,
沿水平或竖直方向进行平移. 改变图像内容的位置; * 尺度变换(scale):
对图像按照指定的尺度因子, 进行放大或缩小; 或者参照SIFT特征提取思想,
利用指定的尺度因子对图像滤波构造尺度空间. 改变图像内容的大小或模糊程度;
* 对比度变换(contrast):
在图像的HSV颜色空间，改变饱和度S和V亮度分量，保持色调H不变.
对每个像素的S和V分量进行指数运算(指数因子在0.25到4之间), 增加光照变化; *
噪声扰动(noise): 对图像的每个像素RGB进行随机扰动,
常用的噪声模式是椒盐噪声和高斯噪声; *
颜色变化：在图像通道上添加随机扰动。 * PCA Jittering 首先，按照 RGB
三个颜色通道计算均值和方差，规范网络输入数据；
然后，计算整个训练数据集的协方差矩阵，进行特征分解，得到特征向量和特征值，以作
PCA Jittering.</p>
<h2 id="caffe中的数据增强">caffe中的数据增强</h2>
<p><code>caffe/src/caffe/data_transformer.cpp</code>
只发现mirror、scale、crop三种。
其中Data_Transformer被调用的时候，会采用1/2的随机镜像，以及对应输入参数的scale和crop进行生成新的样本，输出到下一层网络中。因此，我们使用caffe训练的时候，只训练一个epoch就可以的情况是万万不能的。即使是同一个图片，同一套参数，也要进行多次采样才行。每个epoch进行shuffle一次，每次的batch中的分布就会发生变化，同样一张图片，虽然是同一套参数，也可能会出现不同的结果。在训练过程中的数据采样，随机性让样本不至于将噪声过度的学习。</p>
<h2 id="ssd中的数据增强">SSD中的数据增强</h2>
<p>SSD中的数据采样，在caffe中数据采样的基础上，进行了充分扩充，增强方式包括<code>resize</code>，<code>crop</code>，<code>distort</code>，...
更重要的是引入BatchSampler,
以Batch中的数据基础，达到真正的增加不同overlap的数据的目的，使得检测能力极大增强。因此，我一度认为，SSD的成功不是One-Stage在Detection的突破，而是数据增强方法的提升。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Sample a batch of bboxes with provided constraints.</span><br><span class="line">message BatchSampler &#123;</span><br><span class="line">  // 是否使用原来的图片</span><br><span class="line">  optional bool use_original_image = 1 [default = true];</span><br><span class="line">  // sampler的参数</span><br><span class="line">  optional Sampler sampler = 2;</span><br><span class="line">  // 对于采样box的限制条件，决定一个采样数据positive or negative</span><br><span class="line">  optional SampleConstraint sample_constraint = 3;</span><br><span class="line">  // 当采样总数满足条件时，直接结束</span><br><span class="line">  optional uint32 max_sample = 4;</span><br><span class="line">  // 为了避免死循环，采样最大try的次数.</span><br><span class="line">  optional uint32 max_trials = 5 [default = 100];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>更多内容，参考博客：http://deepindeed.cn/2017/04/05/SSD-Data-Augmentation/</p>
<h2
id="海康威视mscoco比赛中的数据增强">海康威视MSCOCO比赛中的数据增强</h2>
<ul>
<li>第一，对颜色的数据增强，包括色彩的饱和度、亮度和对比度等方面，主要从Facebook的代码里改过来的。</li>
<li>第二，PCA
Jittering，最早是由Alex在他2012年赢得ImageNet竞赛的那篇NIPS中提出来的.
我们首先按照RGB三个颜色通道计算了均值和标准差，对网络的输入数据进行规范化，随后我们在整个训练集上计算了协方差矩阵，进行特征分解，得到特征向量和特征值，用来做PCA
Jittering。</li>
<li>第三，在图像进行裁剪和缩放的时候，我们采用了随机的图像差值方式。</li>
<li>第四， Crop
Sampling，就是怎么从原始图像中进行缩放裁剪获得网络的输入。比较常用的有2种方法：
<ul>
<li>一是使用Scale Jittering，VGG和ResNet模型的训练都用了这种方法。</li>
<li>二是尺度和长宽比增强变换，最早是Google提出来训练他们的Inception网络的。我们对其进行了改进，提出Supervised
Data Augmentation方法。</li>
</ul></li>
</ul>
<h2 id="学习的数据增强策略">学习的数据增强策略</h2>
<p>在分类模型中，常见的数据增广策略有尺度、平移、旋转。在目标检测任务中，较多使用镜像和多尺度训练进行数据增广。除此以外，一些方法在图像上随机增加噪声、遮挡等，或者在训练图像上增加新物体。当前大多数图像分类器使用人工数据增广方法，目前有一些工作<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>不再使用人工数据增广方法，而是使用从数据中学习到的策略以提升图像分类模型的性能。学习到的数据增广策略对小数据有较大帮助，避免过拟合。对于一个增广策略，将其分解成K个子策略，在训练过程中随机选择每个子策略，将该策略应用到当前图像上。其中，每个子策略包括N个图像变换。将搜寻最佳数据增广策略的问题就转换成在搜索空间中的离散优化问题。当前存在许多解决离散优化问题的方法，包括强化学习，基于序列模型的优化等。<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>将离散优化问题构建为RNN的输出空间，并采用强化学习来更新模型的权重。<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></p>
<h2 id="启发点">启发点</h2>
<ul>
<li>并不是越多越好，要在多的基础上保持随机性，因为应用场景的不是固定的输入</li>
<li>结合新的方法，例如GAN进行生成图片等技术，进一步扩充训练集合</li>
<li>合理性采样降低样本不均衡的影响</li>
</ul>
<h2 id="小结">小结</h2>
<p>同样的算法，数据增强能够显著提升算法的性能。不仅仅是因为我们采集的数据不够全面，而是我们专注的这个CV领域就是一个受多种因素影响的领域，光照，人物姿势，拍照角度，旋转角度等等。想要我们的CNN算子将所有这些影响因素都考虑进去，这是几乎不可能的。只有可能让它多学一点，多看一点，少犯一点错罢了。而数据增强就是能够让它可以多学一点不一样的东西，少一点死板在里面。
https://github.com/mdbloice/Augmentor</p>
<h2 id="可参考链接">可参考链接</h2>
<ul>
<li><a href="https://arxiv.org/pdf/1406.6909.pdf">Discriminative
Unsupervised Feature Learning with Exemplar Convolutional Neural
Networks</a></li>
<li><a
href="https://arxiv.org/pdf/1511.05635.pdf">输入图像随机选择一块区域涂黑，《Random
Erasing Data Augmentation》</a></li>
<li><a href="https://arxiv.org/pdf/1902.04103.pdf">Bag of Freebies for
Training Object Detection Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1805.09501v1">AutoAugment: Learning
Augmentation Policies from Data</a></li>
<li><a
href="https://zhuanlan.zhihu.com/p/23249000">海康威视研究院ImageNet2016竞赛经验分享</a></li>
<li><a
href="https://github.com/kevinlin311tw/caffe-augmentation">https://github.com/kevinlin311tw/caffe-augmentation</a></li>
<li><a
href="https://github.com/codebox/image_augmentor">https://github.com/codebox/image_augmentor</a></li>
<li><a
href="https://github.com/aleju/imgaug.git">https://github.com/aleju/imgaug.git</a></li>
<li><a
href="http://lib.stat.cmu.edu/~brian/905-2009/all-papers/01-jcgs-art.pdf">The
art of Data Augmentation</a></li>
<li><a href="https://arxiv.org/abs/1902.07296">Augmentation for small
object detection</a></li>
<li><a
href="https://www.zhihu.com/question/35339639">使用深度学习(CNN)算法进行图像识别工作时，有哪些data
augmentation 的奇技淫巧？</a></li>
</ul>
<h2 id="案例-医学图像分割的数据增广">案例-医学图像分割的数据增广</h2>
<p><a href="http://arxiv.org/abs/1902.09383">Data augmentation using
learned transforms for one-shot medical image segmentation</a></p>
<p>github: https://github.com/xamyzhao/brainstorm</p>
<pre><code>Biomedical image segmentation is an important task in many medical applications. Segmentation methods based on convolutional neural networks attain state-of-the-art accuracy; however, they typically rely on supervised training with large labeled datasets. Labeling datasets of medical images requires significant expertise and time, and is infeasible at large scales. To tackle the lack of labeled data, researchers use techniques such as hand-engineered preprocessing steps, hand-tuned architectures, and data augmentation. However, these techniques involve costly engineering efforts, and are typically dataset-specific. We present an automated data augmentation method for medical images. We demonstrate our method on the task of segmenting magnetic resonance imaging (MRI) brain scans, focusing on the one-shot segmentation scenario -- a practical challenge in many medical applications. Our method requires only a single segmented scan, and leverages other unlabeled scans in a semi-supervised approach. We learn a model of transforms from the images, and use the model along with the labeled example to synthesize additional labeled training examples for supervised segmentation. Each transform is comprised of a spatial deformation field and an intensity change, enabling the synthesis of complex effects such as variations in anatomy and image acquisition procedures. Augmenting the training of a supervised segmenter with these new examples provides significant improvements over state-of-the-art methods for one-shot biomedical image segmentation.</code></pre>
<h3 id="医学图像segment中u-net">医学图像segment中U-Net</h3>
<ul>
<li>paper: <a
href="https://lmb.informatik.uni-freiburg.de/Publications/2019/FMBCAMBBR19/paper-U-Net.pdf">U-net:
Convolutional networks for biomedical image segmentation</a></li>
<li>作者： Olaf Ronneberger, Philipp Fischer, and Thomas Brox</li>
<li><a
href="https://lmb.informatik.uni-freiburg.de/resources/opensource/unet/">project</a>
其中使用的数据增强方案为论文 <a
href="https://arxiv.org/pdf/1406.6909.pdf">Discriminative Unsupervised
Feature Learning with Exemplar Convolutional Neural
Networks</a>中的方法：</li>
</ul>
<blockquote>
<p>we train the network to discriminate between a set of surrogate
classes. Each surrogate class is formed by applying a variety of
transformations to a randomly sampled ’seed’ image patch. In contrast to
supervised network training, the resulting feature representation is not
class specific. It rather provides robustness to the transformations
that have been applied during training. This generic feature
representation allows for classification results that outperform the
state of the art for unsupervised learning on several popular datasets
(STL-10, CIFAR-10, Caltech-101, Caltech-256). While such generic
features cannot compete with class specific features from supervised
training on a classification task, we show that they are advantageous on
geometric matching problems, where they also outperform the SIFT
descriptor.</p>
</blockquote>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>https://arxiv.org/pdf/1805.09501.pdf
"AutoAugment:Learning Augmentation Strategies from Data"<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>https://arxiv.org/pdf/1906.11172.pdf
"Learning Data Augmentation Strategies for Object Detection"<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>https://zhuanlan.zhihu.com/p/76446741
"目标检测之Data Augmentation"<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>detection</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>笔记：混合精度训练技术报告</title>
    <url>/201904/20190407-cuda9-mixed-precision/</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<p>CUDA在推出7.5的时候提出了
可以计算16位浮点数据的新特性。定义了两种新的数据类型<code>half</code>和<code>half2</code>.
NVIDIA GPUs implement the IEEE 754 floating point standard (2008), which
defines half-precision numbers as follows (see Figure 1).</p>
<ul>
<li>Sign: 1 bit</li>
<li>Exponent width: 5 bits</li>
<li>Significand precision: 11 bits (10 explicitly stored) The range of
half-precision numbers is approximately <span class="math inline">\(5.96
\times 10^{-8} \ldots 6.55 \times 10^4\)</span>. <code>half2</code>
structures store two half values in the space of a single 32-bit word,
as the bottom of Figure 1 shows.</li>
</ul>
<figure>
<img
src="https://devblogs.nvidia.com/wp-content/uploads/2015/07/fp16_format-624x146.png"
alt="@Figure 1:16-bit half-precision data formats. Top: single half value. Bottom: half2 vector representation." />
<figcaption aria-hidden="true"><span class="citation"
data-cites="Figure">@Figure</span> 1:16-bit half-precision data formats.
Top: single <code>half</code> value. Bottom: <code>half2</code> vector
representation.</figcaption>
</figure>
<p>CUDA-9中已经开始支持混合精度训练<a href="#fn1" class="footnote-ref"
id="fnref1"
role="doc-noteref"><sup>1</sup></a>，TensorRT作为NVIDIA的inference引擎，同样支持混合精度的神经网络inference计算.
之前在网上看到半精度memory
copy与计算，发现copy的代价会减少一半，而计算的提升并不是很理想。后来看到了《<a
href="https://devtalk.nvidia.com/default/topic/972337/gpu-accelerated-libraries/why-cublashgemm-is-slower-more-than-cublassgemm-when-i-use-/"><code>why cublasHgemm is slower more than cublasSgemm when I use?</code></a>》这个帖子，终于发现其中的一点规律。</p>
<p>问题的提出者问，为什么在GTX1070上运行<code>cublasHgemm</code>（半精度计算）
比
<code>cublasSgemm</code>（单精度计算）计算的慢呢？NVIDIA官方的回答说，当前Pascal架构的GPU只有的P100的FP16计算快于FP32。并且给出了编程手册的吞吐量的表<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>。</p>
<h1 id="alibaba-pai-auto-mixed-precision-training-techniques">Alibaba
PAI: Auto-Mixed Precision Training Techniques</h1>
<p>随着NVIDIA release的APEX<a href="#fn3" class="footnote-ref"
id="fnref3"
role="doc-noteref"><sup>3</sup></a>，利用Volta架构和混合精度在Pytorch上进行拓展，实现了训练的精度混合。腾讯<a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>和百度<a href="#fn5"
class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>分别发表关于混合精度训练的文章.PAI-TAO是alibaba内部一个关于混合精度训练的一个研究项目。
在整个AI模型的生命周期中的位置如下：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030325913.png"
alt="@PAI-TAO" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="PAI-TAO">@PAI-TAO</span></figcaption>
</figure>
<p>从中可以看出，自动混合精度主要是在训练过程中，为了加快计算节点之间的数据交换和层之间的数据交换与计算，采用FP16来替换FP32，这样在计算结果精度几乎不损失的情况下，带了数据交换和计算速度方面的性能提升，从而加快模型训练速度。</p>
<p>而这项任务的成功，与CUDA9中支持TensorCore的特性是息息相关的。下面对TensorCode进行简单介绍。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030325950.png"
alt="@tensor core" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="tensor">@tensor</span> core</figcaption>
</figure>
<p>TensorCore是NVIDIA在Volta
architecture下引入的，专门针对计算4x4矩阵的计算模块。
以前NVIDIA的GPU中只有FP32和FP64计算单元，在TensorCore中，特别针对FP16做了相应的补充，
来补充在半精度浮点方面的不足。TensorCore相比较直接进行FP32的计算，速度有了很大的提升。</p>
<h3 id="为什么采用ampauto-mixed-precision">为什么采用AMP（Auto
mixed-precision）</h3>
<h4 id="mixed-precision的优势">Mixed-precision的优势</h4>
<ul>
<li>充分发挥Volta架构引入的TensorCore计算性能
(<code>15</code>-&gt;<code>120TFLOPs</code>, 8X)</li>
<li>减少了访存带宽</li>
</ul>
<h4 id="no-free-lunch">No free-lunch</h4>
<ul>
<li>用户模型改写的人力负担</li>
<li>精度调优问题</li>
<li>充分利用TensorCore的技术tricks
<ul>
<li>数据尺寸对齐问题</li>
<li>Layout问题</li>
</ul></li>
<li>TensorCore将计算密集部分比例降低以后的进一步优化空间挖掘</li>
</ul>
<h3 id="如何ampdesign-philosophy">如何AMP：Design Philosophy</h3>
<ul>
<li>精度问题
<ul>
<li>模型以FP32进行保存</li>
<li>不同算子的区别处理
<ul>
<li>计算密集型算子（MatMul/Conv）
输入为FP16，FP32累加中间结果，输出为FP32，计算基于TensorCore</li>
<li>访存密集型算法（Add/Reduce/…) 输入输出均为FP16，计算为FP16/FP32,
不使用TensorCore，访存量减少</li>
</ul></li>
<li>Loss scaling策略解决gradient underflow问题</li>
<li>表达精度问题： FP32-&gt;FP16
<ul>
<li>尾数位减少: precision gap in sum (Solution: 模型以FP32进行保存)</li>
<li>指数位减少: gradient underflow</li>
</ul></li>
</ul></li>
</ul>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030325565.png"
alt="@scale在训练过程中的作用" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="scale在训练过程中的作用">@scale在训练过程中的作用</span></figcaption>
</figure>
<ul>
<li>速度及易用性问题
<ul>
<li>通过图优化pass自动完成混合精度所需的图转换工作</li>
</ul></li>
</ul>
<h3 id="结果">结果</h3>
<ul>
<li>No laborious FP32/FP16 casting work anymore</li>
<li>Already supporting diversified internal workloads:
NLP/CNN/Bert/Graph Embedding</li>
<li><code>1.3~3x</code> time-to-accuracy speed-up 与PAI-TAO
Compiler联合使用可以达到1+1&gt;2的加速收益</li>
</ul>
<h1 id="题外思考">题外思考</h1>
<p>现在我们的训练应该是没有引入混合精度训练的，而且inference框架中没有混合精度的苗头。
我们的inference应该可以先支持起混合精度的，然后后面慢慢地在训练框架中添加相关功能。
然后重构节点之间的数据交换代码，加大对混合精度训练的时候并行度，进一步降低训练模型的成本。
尤其是弱计算能力的芯片上，通过添加混合计算功能，能够在加速的同时，追求更高的精度。
现在很多AI推理芯片如华为himix200中，支持int8和int16的计算，而且同一个模型可以混合int8和int16的精度类型。</p>
<h1 id="参考文献">参考文献</h1>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://docs.nvidia.com/deeplearning/sdk/pdf/Training-Mixed-Precision-User-Guide.pdf
"Training-Mixed-Precision-User-Guide"
<!-- [^7]: http://m.elecfans.com/article/640489.html "英伟达发布全新AI芯片Jetson Xavier" --><a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"
role="doc-endnote"><p>https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#arithmetic-instructions
"throughputs of the arithmetic instructions"<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>https://cloud.tencent.com/developer/news/254121
"混合精度训练之APEX"<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>http://m.elecfans.com/article/721085.html
"一种具有混合精度的高度可扩展的深度学习训练系统"<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>https://arxiv.org/pdf/1710.03740.pdf
"百度和NVIDIA联合出品：MIXED PRECISION TRAINING"<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>HPC</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>开发中常见的编译器技巧</title>
    <url>/201904/20190411-cpp-compiler/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>编译器是我们开发人员与机器指令之间的翻译,现在编译器越来越优化,而且基于一些开源的编译器项目(gcc,clang)等,相继出现不同platform下的编译器。
此外，各种芯片、开发板层出不穷，各个商业公司都针对自己出产的开发板定制特定的编译链条。例如华为hisi系列的himix100中提供的编译链中，包括编译器，链接器，打包器之外，还提供了nm，gdb，gcov，gprof等等开发工具。
这篇文章将主要将开发工作中与编译器（这篇文章中不作特殊说明，指的是gnu
gcc编译器）相关的一些options和配置参数进行总结,方便在后面的项目遇到相似的问题进行查阅与借鉴。</p>
<h2 id="编译常见问题">编译常见问题</h2>
<h3
id="包含静态库中所有符号的option">1、包含静态库中所有符号的option</h3>
<p><span class="math display">\[A -&gt; B -&gt; C\]</span></p>
<p>编译shared target
B库的时候，gcc编译器默认是用什么区什么的原则，也就是说，依赖了库A中哪个.o文件中的东西，就会把相应的.o文件
打包到最终的库中。但是，有的时候在这个库中我们并没有引用全部的符号，但是当其他库C依赖我们这个B库的时候，如果引用了B中未引用的A中的符号，这个时候会出现"undefined
reference"的编译错误。<code>-Wl,--whole-archive</code>可以实现将所有库中的符号打包进去。</p>
<p>编译器编译动态库或者运行程序的时候，会对依赖的静态库中进行基于<code>.o</code>的选择，但是有的时候我们希望我们编译的动态库能够包含所有的函数实现给用户使用。gcc中的链接控制选项<code>-Wl,--whole-archive xxxxx_lib -Wl,--no-whole-archive</code>就可以实现类似功能。</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">target_link_libraries</span>(xxxx_export </span><br><span class="line">            PRIVATE <span class="string">&quot;-Wl,--whole-archive&quot;</span> $&lt;TARGET_FILE:xxxxx_lib&gt;</span><br><span class="line">                    <span class="string">&quot;-Wl,--no-whole-archive -Wl,--exclude-libs,ALL&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="其他可能问题">2、其他可能问题</h3>
<p><code>--exclude-libs</code> does not work for static libraries
affected by the <code>--whole-archive</code> option.</p>
<ul>
<li><code>--exclude-libs</code> creates a list of static library paths
and does library lookups in this list.</li>
<li><code>--whole-archive</code> splits the static libraries that follow
it into separate objects. As a result, lld no longer sees static
libraries among linked files and does no <code>--exclude-libs</code>
lookups.</li>
</ul>
<h4 id="solution">Solution</h4>
<p>The proposed solution is to make <code>--exclude-libs</code> consider
object files too. When lld finds an object file it checks whether this
file originates from an archive and, if so, looks the archive up in the
<code>--exclude-libs</code> list.</p>
<p><strong>Reference</strong>: https://reviews.llvm.org/D39353</p>
<h3
id="编译运行查找头文件和库的顺序">3、编译运行查找头文件和库的顺序</h3>
<blockquote>
<p>gcc 在编译时如何去寻找所需要的头文件:</p>
</blockquote>
<ul>
<li>所以header file的搜寻会从-I开始</li>
<li>然后找gcc的环境变量
<code>C_INCLUDE_PATH</code>，<code>CPLUS_INCLUDE_PATH</code>，<code>OBJC_INCLUDE_PATH</code></li>
<li>再找内定目录
<ul>
<li><code>/usr/include</code></li>
<li><code>/usr/local/include</code></li>
</ul></li>
</ul>
<p>gcc的一系列自带目录
<code>CPLUS_INCLUDE_PATH=/usr/lib/gcc/x86_64-linux-gnu/4.9.4/include:/usr/include/c++/4.9.4</code></p>
<blockquote>
<p>库文件</p>
</blockquote>
<p>编译的时候： * gcc会去找-L * 再找gcc的环境变量LIBRARY_PATH *
再找内定目录 * <code>/lib</code>和<code>/lib64</code> *
<code>/usr/lib</code> 和<code>/usr/lib64</code> *
<code>/usr/local/lib</code>和<code>/usr/local/lib64</code></p>
<p>这是当初compile gcc时写在程序内的</p>
<h3 id="运行时动态库的搜索路径">4、运行时动态库的搜索路径</h3>
<p>动态库的搜索路径搜索的先后顺序是： 1.
编译目标代码时指定的动态库搜索路径； 2.
环境变量<code>LD_LIBRARY_PATH</code>指定的动态库搜索路径； 3.
配置文件<code>/etc/ld.so.conf</code>中指定的动态库搜索路径； 4.
默认的动态库搜索路径<code>/lib</code>； 5.
默认的动态库搜索路径<code>/usr/lib</code>。</p>
<h3 id="动态库中的static变量">5、动态库中的static变量</h3>
<blockquote>
<p>In all cases, static global variables (or functions) are never
visible from outside a module (dll/so or executable). The C++ standard
requires that these have internal linkage, meaning that they are not
visible outside the translation unit (which becomes an object file) in
which they are defined.</p>
</blockquote>
<h2 id="windows编译">windows编译</h2>
<p>在windows常用的编译器是VS里面的cl编译器。我们要实现上述
cmake使用<code>cmake -DCMAKE_WINDOWS_EXPORT_ALL_SYMBOLS=TRUE -DBUILD_SHARED_LIBS=TRUE</code></p>
<pre><code>Enable this boolean property to automatically create a module definition (.def) file with all global symbols found in the input .obj files for a SHARED library on Windows. The module definition file will be passed to the linker causing all symbols to be exported from the .dll. For global data symbols, __declspec(dllimport) must still be used when compiling against the code in the .dll. All other function symbols will be automatically exported and imported by callers. This simplifies porting projects to Windows by reducing the need for explicit dllexport markup, even in C++ classes.

This property is initialized by the value of the CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS variable if it is set when a target is created.</code></pre>
<p><strong>Reference</strong>: <a
href="https://cmake.org/cmake/help/v3.4/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html"><code>WINDOWS_EXPORT_ALL_SYMBOLS</code></a></p>
<h3 id="windows下路径长度不能太长">windows下路径长度不能太长</h3>
<p><strong>error MSB3491: Could n ot write lines to file</strong>
https://stackoverflow.com/questions/31765909/node-socket-io-client-windows-path-too-long-to-install</p>
<h3 id="msvc中预定义宏5">MSVC中预定义宏<a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h3>
<ul>
<li><p><code>_M_IX86</code> Defined as the integer literal value 600 for
compilations that target x86 processors. This macro isn't defined for
x64 or ARM compilation targets.</p></li>
<li><p><code>_M_IX86_FP</code> Defined as an integer literal value that
indicates the <code>/arch</code> compiler option that was set, or the
default. This macro is always defined when the compilation target is an
x86 processor. Otherwise, undefined. When defined, the value is:</p>
<ul>
<li>0 if the <code>/arch:IA32</code> compiler option was set.</li>
<li>1 if the <code>/arch:SSE</code> compiler option was set.</li>
<li>2 if the <code>/arch:SSE2</code>, <code>/arch:AVX</code>,
<code>/arch:AVX2</code>, or <code>/arch:AVX512</code> compiler option
was set. This value is the default if an /arch compiler option wasn't
specified. When <code>/arch:AVX</code> is specified, the macro
<code>__AVX__</code> is also defined. When <code>/arch:AVX2</code> is
specified, both <code>__AVX__</code> and <code>__AVX2__</code> are also
defined. When /arch:AVX512 is specified, <code>__AVX__</code>,
<code>__AVX2__</code>, <code>__AVX512BW__</code>,
<code>__AVX512CD__</code>, <code>__AVX512DQ__</code>,
<code>__AVX512F__</code> and <code>__AVX512VL__</code> are also
defined.</li>
</ul>
<p>For more information, see /arch (x86).</p></li>
<li><p><code>_M_X64</code> Defined as the integer literal value 100 for
compilations that target x64 processors. Otherwise, undefined.</p></li>
<li><p><code>_MSC_VER</code> Defined as an integer literal that encodes
the major and minor number elements of the compiler's version number.
The major number is the first element of the period-delimited version
number and the minor number is the second element. For example, if the
version number of the Microsoft C/C++ compiler is 17.00.51106.1, the
<code>_MSC_VER</code> macro evaluates to 1700. Enter <code>cl /?</code>
at the command line to view the compiler's version number. This macro is
always defined.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Visual Studio version</th>
<th style="text-align: center;"><code>_MSC_VER</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Visual Studio 6.0</td>
<td style="text-align: center;">1200</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio .NET 2002 (7.0)</td>
<td style="text-align: center;">1300</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio .NET 2003 (7.1)</td>
<td style="text-align: center;">1310</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2005 (8.0)</td>
<td style="text-align: center;">1400</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2008 (9.0)</td>
<td style="text-align: center;">1500</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2010 (10.0)</td>
<td style="text-align: center;">1600</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2012 (11.0)</td>
<td style="text-align: center;">1700</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2013 (12.0)</td>
<td style="text-align: center;">1800</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2015 (14.0)</td>
<td style="text-align: center;">1900</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2017 RTW (15.0)</td>
<td style="text-align: center;">1910</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2017 version 15.3</td>
<td style="text-align: center;">1911</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2017 version 15.5</td>
<td style="text-align: center;">1912</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2017 version 15.6</td>
<td style="text-align: center;">1913</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2017 version 15.7</td>
<td style="text-align: center;">1914</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2017 version 15.8</td>
<td style="text-align: center;">1915</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2017 version 15.9</td>
<td style="text-align: center;">1916</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2019 RTW (16.0)</td>
<td style="text-align: center;">1920</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2019 version 16.1</td>
<td style="text-align: center;">1921</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Visual Studio 2019 version 16.2</td>
<td style="text-align: center;">1922</td>
</tr>
<tr class="even">
<td style="text-align: center;">Visual Studio 2019 version 16.3</td>
<td style="text-align: center;">1923</td>
</tr>
</tbody>
</table></li>
<li><p><code>_MSVC_LANG</code> Defined as an integer literal that
specifies the C++ language standard targeted by the compiler. It's set
only in code compiled as C++. The macro is the integer literal value
201402L by default, or when the <code>/std:c++14</code> compiler option
is specified. The macro is set to 201703L if the <code>/std:c++17</code>
compiler option is specified. It's set to a higher, unspecified value
when the <code>/std:c++latest</code> option is specified. Otherwise, the
macro is undefined. The <code>_MSVC_LANG</code> macro and
<code>/std (Specify Language Standard Version)</code> compiler options
are available beginning in Visual Studio 2015 Update 3.</p></li>
<li><p><code>_MT</code> Defined as 1 when /MD or /MDd (Multithreaded
DLL) or /MT or /MTd (Multithreaded) is specified. Otherwise,
undefined.</p></li>
<li><p><code>_WIN32</code> Defined as 1 when the compilation target is
32-bit ARM, 64-bit ARM, x86, or x64. Otherwise, undefined.</p></li>
<li><p><code>_WIN64</code> Defined as 1 when the compilation target is
64-bit ARM or x64. Otherwise, undefined.</p></li>
</ul>
<h2 id="gnu-编译器">GNU 编译器</h2>
<h3 id="gccg的--as-needed">1、gcc/g++的<code>--as-needed</code></h3>
<p>gcc/g++提供了<code>-Wl,--as-needed</code>和
<code>-Wl,--no-as-needed</code>两个选项，这两个选项一个是开启特性，一个是取消该特性。</p>
<p>在生成可执行文件的时候，通过 -lxxx
选项指定需要链接的库文件。以动态库为例，如果我们指定了一个需要链接的库，则连接器会在可执行文件的文件头中会记录下该库的信息。而后，在可执行文件运行的时候，动态加载器会读取文件头信息，并加载所有的链接库。在这个过程中，如果用户指定链接了一个毫不相关的库，则这个库在最终的可执行程序运行时也会被加载，如果类似这样的不相关库很多，会明显拖慢程序启动过程。</p>
<p>这时，通过指定<code>-Wl,--as-needed</code>选项，链接过程中，链接器会检查所有的依赖库，没有实际被引用的库，不再写入可执行文件头。最终生成的可执行文件头中包含的都是必要的链接库信息。<code>-Wl,--no-as-needed</code>选项不会做这样的检查，会把用户指定的链接库完全写入可执行文件中。</p>
<p><strong>Reference</strong>: <a
href="https://my.oschina.net/yepanl/blog/2222870">GCC/G++选项
-Wl,--as-needed</a></p>
<h3 id="rdynamic">2、-rdynamic</h3>
<pre><code>Pass the flag `-export-dynamic` to the ELF linker, on targets that support
it. This instructs the linker to add all symbols, not only used ones, to the dynamic symbol table. This option is needed for some uses of `dlopen` or to allow obtaining backtraces from within a program.</code></pre>
<p>关键的不同是：<code>-Wl,--export-dynamic -pthread</code>
<code>-Wl</code>:指示后面的选项是给链接器的 <code>-pthread</code>:
链接程序的时包含libpthread.so
<code>--export-dynamic</code>：就是这个选项让主程序内定义的全局函数对库函数可见。</p>
<p><strong>Reference</strong>: <a
href="https://blog.csdn.net/u011644231/article/details/88880362">gcc链接选项--export-dynamic的一次问题记录</a></p>
<h3
id="glibcxx_use_cxx11_abi">3、<code>_GLIBCXX_USE_CXX11_ABI</code></h3>
<p>在GCC
5.1版本中，libstdc++引入了一个新的ABI，其中包括std::string和std::list的新实现。为了符合2011年c++标准，这些更改是必要的，该标准禁止复制即写字符串，并要求列表跟踪字符串的大小。
为了保持与libstdc++链接的现有代码的向后兼容性，库的soname没有更改，并且仍然支持与新实现并行的旧实现。这是通过在内联命名空间中定义新的实现来实现的，因此它们具有不同的用于链接目的的名称，例如，<code>std::list</code>的新版本实际上定义为<code>std:: _cxx11::list</code>。因为新实现的符号有不同的名称，所以两个版本的定义可以出现在同一个库中。
<code>_GLIBCXX_USE_CXX11_ABI</code>宏控制库头中的声明是使用旧ABI还是新ABI。因此，可以为正在编译的每个源文件分别决定使用哪个ABI。使用GCC的默认配置选项，宏的默认值为1，这将导致新的ABI处于活动状态，因此要使用旧的ABI，必须在包含任何库头之前显式地将宏定义为0。(<strong>注意，一些GNU/Linux发行版对GCC
5的配置不同，因此宏的默认值是0，用户必须将它定义为1才能启用新的ABI</strong>)。</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">IF</span>(CMAKE_CXX_COMPILER_VERSION <span class="keyword">VERSION_LESS</span> <span class="string">&quot;5.1&quot;</span>)</span><br><span class="line">	<span class="keyword">ADD_DEFINITIONS</span>(-D_GLIBCXX_USE_CXX11_ABI=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">ENDIF</span>()</span><br></pre></td></tr></table></figure>
<h3 id="wl--allow-shlib-undefined">4、-Wl,--allow-shlib-undefined</h3>
<p>在交叉编译程序过程中，往往会有这样的情况，依赖的target系统上的动态库（例如android上的OpenCL.so）又依赖其他的许多动态库，这个时候，我们希望链接target系统上的这个动态库的时候，我们可以不要去找OpenCL相关的依赖符号。</p>
<p><code>SET(CMAKE_CXX_FLAGS "$&#123;CMAKE_CXX_FLAGS&#125; -Wl,--allow-shlib-undefined")</code></p>
<blockquote>
<p>Linking errors with “-Wl,--no-undefined
-Wl,--no-allow-shlib-undefined”</p>
</blockquote>
<p>第二个参数的默认值是<code>--allow-shlib-undefined</code>。如果您选择该选项，代码可能会生成。
第二个参数处理构建时检查，启用它意味着检查您所链接的库是否在构建时连接了其依赖项。</p>
<p>第一个参数确保您没有忘记声明对运行时库的依赖项(也可能是运行时库对另一个运行时库的依赖项)。
例如，如果您调用的函数的实现位于示例运行时库“libfunc”中。然后这个库会调用另一个运行时库中的函数libext。然后通过声明对libfunc的“func”和“ext”的依赖关系。因此，将在内部生成一个对libext的依赖引用。
如果您省略<code>--no undefined</code>并忘记添加依赖项声明，那么构建仍然会成功，因为您相信运行时链接器将在运行时解析依赖项。
由于构建成功了，您可能会相信一切都会好起来，而不知道构建已经将责任推迟到运行时链接器。
但大多数情况下，运行时链接器的设计目的不是搜索未解析的引用，而是希望找到运行时库中声明的此类依赖项。如果没有这样的引用，您将得到一个运行时错误。
运行时错误通常比解决编译时错误要昂贵得多。</p>
<h3
id="target_link_library-link_library">5、<code>TARGET_LINK_LIBRARY</code>
&amp; <code>LINK_LIBRARY</code></h3>
<p>target_link_libraries 会将需要链接的库作为属性挂在目标库上，
后面用户用到这个库的时候可以通过<code>get_target_property(interface_link_libs $&#123;&#125; TARGET_LINK_LIBRARIES)</code>进行获取相应的值。</p>
<h2 id="gcc不同版本中一些东西">GCC不同版本中一些东西</h2>
<h3 id="gcc4.9.4">1、GCC4.9.4</h3>
<blockquote>
<p>The <code>-Wdate-time</code> option has been added for the C, C++ and
Fortran compilers, which warns when the <code>__DATE__</code>,
<code>__TIME__</code> or <code>__TIMESTAMP__</code> macros are used.
Those macros might prevent bit-wise-identical reproducible
compilations.</p>
</blockquote>
<blockquote>
<p>With the new <code>#pragma GCC ivdep</code>, the user can assert that
there are no loop-carried dependencies which would prevent concurrent
execution of consecutive iterations using SIMD (single instruction
multiple data) instructions.</p>
</blockquote>
<h4 id="inter-procedural-optimization-improvements">Inter-procedural
optimization improvements:</h4>
<ul>
<li>New type inheritance analysis module improving devirtualization.
Devirtualization now takes into account anonymous name-spaces and the
C++11 final keyword.</li>
<li>New speculative devirtualization pass (controlled by
<code>-fdevirtualize-speculatively</code>.</li>
<li>Calls that were speculatively made direct are turned back to
indirect where direct call is not cheaper.</li>
<li>Local aliases are introduced for symbols that are known to be
semantically equivalent across shared libraries improving dynamic
linking times.</li>
</ul>
<h4 id="feedback-directed-optimization-improvements">Feedback directed
optimization improvements:</h4>
<ul>
<li>Profiling of programs using C++ inline functions is now more
reliable.</li>
<li>New time profiling determines typical order in which functions are
executed.</li>
<li>A new function reordering pass (controlled by -freorder-functions)
significantly reduces startup time of large applications. Until binutils
support is completed, it is effective only with link-time
optimization.</li>
<li>Feedback driven indirect call removal and devirtualization now
handle cross-module calls when link-time optimization is enabled.</li>
</ul>
<p>https://gcc.gnu.org/gcc-4.9/porting_to.html</p>
<h3 id="gcc-5.4">2、GCC 5.4</h3>
<ul>
<li><p>The default mode for C is now -std=gnu11 instead of
-std=gnu89.</p></li>
<li><p>The C++ runtime library (libstdc++) uses a new ABI by default
(see below).</p></li>
<li><p>The non-standard C++0x type traits
<code>has_trivial_default_constructor</code>,
<code>has_trivial_copy_constructor</code> and
<code>has_trivial_copy_assign</code> have been deprecated and will be
removed in a future version. The standard C++11 traits
<code>is_trivially_default_constructible</code>,
<code>is_trivially_copy_constructible</code> and
<code>is_trivially_copy_assignable</code> should be used
instead.</p></li>
<li><p>添加<code>-fipa-icf</code>的配置项目 &gt; An Identical Code
Folding (ICF) pass (controlled via -fipa-icf) has been added. Compared
to the identical code folding performed by the Gold linker this pass
does not require function sections. It also performs merging before
inlining, so inter-procedural optimizations are aware of the code
re-use. On the other hand not all unifications performed by a linker are
doable by GCC which must honor aliasing information.</p></li>
<li><p>The devirtualization pass was significantly improved by adding
better support for speculative devirtualization and dynamic type
detection.</p></li>
<li><p>虚表进行了优化以减少动态链接时间 Virtual tables are now
optimized. Local aliases are used to reduce dynamic linking time of C++
virtual tables on ELF targets and data alignment has been reduced to
limit data segment bloat.</p></li>
<li><p>添加针对不允许插入导出符号的shared库，添加了控制项目以提高代码质量
&gt; A new -fno-semantic-interposition option can be used to improve
code quality of shared libraries where interposition of exported symbols
is not allowed.</p></li>
<li><p>内联可以控制 &gt; With profile feedback the function inliner can
now bypass --param inline-insns-auto and --param inline-insns-single
limits for hot calls.</p></li>
<li><p>常量的过程间传播现在也传播指针参数的对齐。 &gt; The
interprocedural propagation of constants now also propagates alignments
of pointer parameters. This for example means that the vectorizer often
does not need to generate loop prologues and epilogues to make up for
potential misalignments.</p></li>
<li><p>内存使用上一些优化 &gt; Memory usage and link times were
improved. Tree merging was sped up, memory usage of GIMPLE declarations
and types was reduced, and, support for on-demand streaming of variable
constructors was added.</p></li>
</ul>
<h4 id="libstd上的优化">libstd++上的优化</h4>
<ul>
<li>Dual ABI</li>
<li>A new implementation of std::string is enabled by default, using the
small string optimization(SSO) instead of copy-on-write(COW) reference
counting.</li>
<li>A new implementation of std::list is enabled by default, with an
O(1) size() function;</li>
</ul>
<h3 id="gcc-dump-preprocessor-defines">3、GCC dump preprocessor
defines</h3>
<ul>
<li>最常用的输出编译器预定义的宏</li>
</ul>
<p><code>gcc -dM -E - &lt; /dev/null</code></p>
<p><code>g++ -dM -E -x c++ - &lt; /dev/null</code></p>
<ul>
<li>How do I dump preprocessor macros coming from a particular header
file?</li>
</ul>
<p><code>echo "#include &lt;sys/socket.h&gt;" | gcc -E -dM -</code></p>
<ul>
<li>添加某些options之后的</li>
</ul>
<p><code>gcc -dM -E -msse4 - &lt; /dev/null | grep SSE[34]</code> &gt;
#define <strong>SSE3</strong> 1<br />
&gt; #define <strong>SSE4_1</strong> 1<br />
&gt; #define <strong>SSE4_2</strong> 1<br />
&gt; #define <strong>SSSE3</strong> 1</p>
<h3 id="todo">4、TODO</h3>
<ul>
<li>常用的交叉编译的选项</li>
<li>-O3和-O2之间的差别</li>
<li>不同平台之间之间的差别</li>
<li>如何给不同版本的gcc打补丁</li>
</ul>
<p>在文章[Algorithm-Optimization]<a href="#fn2" class="footnote-ref"
id="fnref2"
role="doc-noteref"><sup>2</sup></a>中介绍了一些有利于优化性能的函数，感兴趣可以结合不同平台的优化指令一起学习使用。</p>
<h2 id="gcc-different-platform的配置项">GCC different
platform的配置项</h2>
<p>[Using static and shared libraries across platforms]<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030359040.png"
alt="@" /> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030358337.png"
alt="@" /></p>
<h2 id="更多c内容">更多C++内容</h2>
<ul>
<li>http://deepindeed.cn/2018/11/28/gnu-cpp-Relearn/</li>
<li>http://deepindeed.cn/2019/03/18/cpp-program-trick/</li>
<li>libstdc++关于dual ABI文档:
https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html</li>
</ul>
<h2 id="其他">其他</h2>
<ul>
<li>[gcc与g++的区别]<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></li>
<li>[ARM？华为？]<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></li>
<li>himix100的交叉编译链 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">➜  arm-himix100-linux tree -L 2 ./host_bin </span><br><span class="line">./host_bin</span><br><span class="line">├── arm-linux-androideabi-addr2line</span><br><span class="line">├── arm-linux-androideabi-ar</span><br><span class="line">├── arm-linux-androideabi-as</span><br><span class="line">├── arm-linux-androideabi-c++</span><br><span class="line">├── arm-linux-androideabi-c++filt</span><br><span class="line">├── arm-linux-androideabi-cpp</span><br><span class="line">├── arm-linux-androideabi-elfedit</span><br><span class="line">├── arm-linux-androideabi-g++</span><br><span class="line">├── arm-linux-androideabi-gcc</span><br><span class="line">├── arm-linux-androideabi-gcc-6.3.0</span><br><span class="line">├── arm-linux-androideabi-gcc-ar</span><br><span class="line">├── arm-linux-androideabi-gcc-nm</span><br><span class="line">├── arm-linux-androideabi-gcc-ranlib</span><br><span class="line">├── arm-linux-androideabi-gcov</span><br><span class="line">├── arm-linux-androideabi-gcov-tool</span><br><span class="line">├── arm-linux-androideabi-gdb</span><br><span class="line">├── arm-linux-androideabi-gprof</span><br><span class="line">├── arm-linux-androideabi-ld</span><br><span class="line">├── arm-linux-androideabi-ld.bfd</span><br><span class="line">├── arm-linux-androideabi-nm</span><br><span class="line">├── arm-linux-androideabi-objcopy</span><br><span class="line">├── arm-linux-androideabi-objdump</span><br><span class="line">├── arm-linux-androideabi-ranlib</span><br><span class="line">├── arm-linux-androideabi-readelf</span><br><span class="line">├── arm-linux-androideabi-run</span><br><span class="line">├── arm-linux-androideabi-size</span><br><span class="line">├── arm-linux-androideabi-strings</span><br><span class="line">├── arm-linux-androideabi-strip</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="参考文献">参考文献</h2>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://docs.microsoft.com/en-us/cpp/preprocessor/predefined-macros?view=vs-2017
"Predefined macros"<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"
role="doc-endnote"><p>http://deepindeed.cn/2017/03/17/Algorithm-Optimization/<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>http://www.fortran-2000.com/ArnaudRecipes/sharedlib.html
"Using static and shared libraries across platforms"<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://www.cnblogs.com/liushui-sky/p/7729838.html
"gcc和g++的区别"<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>https://news.mydrivers.com/1/628/628308.htm<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Complier</tag>
      </tags>
  </entry>
  <entry>
    <title>Android手机上GDB调试</title>
    <url>/201901/20190115-dev-android-gdb/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>在android开发C++过程，除了使用logcat进行追踪程序之外，更加便捷的方式便是像在linux上开发使用gdb程序进行调试一样调试android程序，只不过程序不是运行在linux机器上，而是在某个android手机上。
常见的android手机上程序调试有： 1.
通过打印log，这种方式对于比较庞大的项目有利于迅速定位问题的模块，但是，如果引用第三方库，某些程序调试起来会很无力。而且打印log的程序往往比较大，不利于部署发布，因此release版本往往都没有log
2. 通过ssh连接，使用gdb进行调试，这种便于团队开发。 3.
直接将手机usb连接在电脑上进行调试，这种情况适合个人开发</p>
<h2 id="ssh连接进行调试">SSH连接进行调试</h2>
<ol type="1">
<li><p>将相关运行程序和依赖库拷贝到手机某个目录下，例如我将sdk_xxx拷贝到<code>root@10.1.42.15:/data/data/berserker.android.apps.sshdroid/home/cwl/sdk_xxx</code></p></li>
<li><p>从本地机器中交叉编译链中查找gdb
例如我的机器上是在<code>$NDK_DIR/prebuilt/android-arm64/gdbserver</code>
到手机某个位置下，例如我放在跟项目相同目录下</p></li>
<li><p>andorid手机上运行 <code>gdbserver [port] [exe file]</code>
运行该程序之前，先确认该[exe
file]是否需要动态链接其他库，如果需要添加动态库路径到<code>LD_LIBRARY_PATH</code>
执行<code>export LD_LIBRARY_PATH=./target/android-aarch64/test</code>
然后再执行如下程序
<code>./gdbserver :5039 target/android-aarch64/test_sdk_xxx</code>
将test_sdk_xxx与端口5039绑定</p></li>
<li><p>在本地查找对应的gdb程序进行调试例如
<code>$NDK_DIR/android-aarch64/bin/aarch64-linux-android-gdb ./target/android-aarch64/test/test_sdk_xxx</code>
如果ndk14b找不该程序，可以使用ndk10里面的gdb进行调试
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) help target</span><br><span class="line">target core -- Use a core file as a target</span><br><span class="line">target exec -- Use an executable file as a target</span><br><span class="line">target extended-remote -- Use a remote computer via a serial line</span><br><span class="line">target record -- Log program while executing and replay execution from log</span><br><span class="line">target record-btrace -- Collect control-flow trace and provide the execution history</span><br><span class="line">target record-core -- Log program while executing and replay execution from log</span><br><span class="line">target record-full -- Log program while executing and replay execution from log</span><br><span class="line">target remote -- Use a remote computer via a serial line</span><br><span class="line">target tfile -- Use a trace file as a target</span><br><span class="line"></span><br><span class="line">Type &quot;help target&quot; followed by target subcommand name for full documentation.</span><br><span class="line">Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;.</span><br><span class="line">Command name abbreviations are allowed if unambiguous.</span><br></pre></td></tr></table></figure></p></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) target remote 10.1.42.15:5039</span><br><span class="line">(gdb) continue</span><br><span class="line">(gdb) bt</span><br></pre></td></tr></table></figure>
<h2 id="连接真机gdb">连接真机gdb</h2>
<h3 id="查看手机usb">查看手机usb</h3>
<pre><code>cwl@ubuntu:~$ lsusb 
Bus 002 Device 004: ID 18c3:6255  
Bus 002 Device 002: ID 8087:0020 Intel Corp. Integrated Rate Matching Hub
Bus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
Bus 001 Device 005: ID 22b8:41db Motorola PCS Motorola Droid (USB Debug)
Bus 001 Device 004: ID 04d9:a06b Holtek Semiconductor, Inc. </code></pre>
<h3 id="添加udev规则">添加udev规则</h3>
<p>udev就是一个动态硬件管理服务</p>
<pre><code>cwl@ubuntu:/etc/udev/rules.d$ cd /etc/udev/rules.d/
cwl@ubuntu:/etc/udev/rules.d$ sudo vi 50-android-usb.rules
 </code></pre>
<p>编辑规则文件并保存
<code>SUBSYSTEM=="usb", SYSFS("Motorola PCS Motorola Droid (USB Debug)")=="22b8",MODE="0666"</code>
其中，<code>sysfs</code>括号内是自己android手机的实际描述信息，==后面的是id号，<code>mode</code>是读取模式，<code>0666</code>是所有人可以访问，以上的信息都是<code>lsusb</code>查处来的。</p>
<h3
id="设置规则文件权限并重启udev">设置规则文件权限并重启<code>udev</code></h3>
<pre><code>cwl@ubuntu:/etc/udev/rules.d$ sudo chmod a+rx /etc/udev/rules.d/50-android-usb.rules 
cwl@ubuntu:/etc/udev/rules.d$ sudo /etc/init.d/udev restart </code></pre>
<p>会看到udev相关的提示信息
<code>adb push target/android-aarch64/test/test_sdk_xxx /data/local/tmp/sdk_xxx</code></p>
<h2 id="其他可能问题">其他可能问题</h2>
<p>在手机里面执行文件的时候提示<code>can't execute: Permission denied</code>
一开始以为是没有root权限，自己傻逼了，错误意思是，不能执行，权限定义，</p>
<h3 id="解决办法">解决办法</h3>
<p><code>chmod +x filename</code>给文件可执行就可以。 一般把文件放到
<code>/data/local/tmp/</code>目录下 然后 <code>chmod +x file</code></p>
<h2 id="小结">小结</h2>
<p>交叉编译和开源项目，使得交叉编译、跨平台开发等问题越来容易，才能够有这种在android
调试程序和在linux上调试程序毫无间隙地切换。</p>
<h2 id="参考链接">参考链接</h2>
<ul>
<li><a
href="https://www.cnblogs.com/hangxin1940/archive/2011/07/10/2101552.html">https://www.cnblogs.com/hangxin1940/archive/2011/07/10/2101552.html</a></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>高通芯片笔记</title>
    <url>/201903/20190301-Hexagon-DSP/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>从2011年甚至更早开始，智能手机，智能终端，车载芯片等等智能终端中，高通芯片无处不在。相比较Intel，高通抓住了移动处理器中续航的问题，不断推出低功耗移动处理器，从而抓住移动处理器的市场。日常工作中接触到很多冠以高通之名的产品，记录以习之。</p>
<h2 id="性能排行榜">性能排行榜</h2>
<p>收集了一下<a
href="https://www.xianshua.net/top/5534.html">2018年高通骁龙CPU处理器排行榜</a>和<a
href="http://mobile.zol.com.cn/soc/">各种手机品牌的处理器性能对比</a>，从中可以看出，骁龙系列
处理器也是分为高中低端处理器的，其中去年最常见的845系列，占据较大的市场份额。与之争锋麒麟
980虽然在HUWEI Meta 20
Pro的跑分汇总获得更高名次，性能前10中高通独占8席。</p>
<h2 id="骁龙">骁龙</h2>
<p>为什么要选择骁龙处理器？
骁龙移动处理器是Qualcomm开发的完整片上系统解决方案系列产品，该系列适应用户需求而提供卓越的用户体验和更长的电池寿命。利用骁龙处理器先进的处理能力和并发性能，您可以同时运行多个高级应用，而对电池的消耗却可以降到最少。</p>
<p>骁龙处理器经过发展，早已不再仅仅支持先进的手机，还可在各种智能产品和互连设备上看到它的身影，包括可穿戴设备、智能家电、智能电话亭和数字标识系统等。我们的一系列软硬件解决方案专门提供您所需要的，以帮助您最大限度地利用采用骁龙处理器的设备。我们的SDK、Profiler分析器和调试器能帮助您分析和提升应用性能、打造创新特性和创造新的互连体验。我们甚至能帮助您开始按照您自身的设计打造设备（从原型设计到生产的全过程）。如果您要打造下一代设备，采用骁龙处理器的开发设备，您便已经可以将未来握在手中了。</p>
<p><a
href="https://developer.qualcomm.com/">高通公司官网开发文档</a></p>
<h3 id="cpu">CPU</h3>
<p>有了高品质的处理内核，骁龙处理器中经优化的CPU是专为让您的应用运行得更快、更流畅而设计。我们所有CPU的目标是将世界级的移动体验带进生活，同时智能地控制电池寿命。但是如果没有能完全发挥其特性的软件，即使是最高性能的CPU也不能开发出自身的全部潜力。采用骁龙LLVM编译器编译的代码在骁龙处理器上会执行的更好，因为它具有独特的优化处理和漏洞修复。</p>
<h3 id="gpu">GPU</h3>
<p>图形性能对于现代移动体验是一个重要部分，这就是为什么我们的Qualcomm骁龙处理器要内置开拓性的Adreno™图形处理器的原因。Adreno是目前最先进的移动图形处理背后的发电站，它能加速游戏、用户界面和网络浏览器中复杂几何体的渲染。快来下载Adreno
SDK，优化您针对Adreno
GPU的应用，该SDK含打造沉浸式手机游戏体验所需的工具、库、示例、文档和辅导资料。您还可利用Adreno
Profiler分析器来分析和优化您应用的图形性能。该分析器具有的特性包括：基于硬件的性能监视器、渲染调用指标、Shader原型设计等。</p>
<h3 id="dsp">DSP</h3>
<p>在最适合的处理引擎上运行适当的任务能为开发者带来性能优势。这就是为什么开发Hexagon
DSP的原因，该产品专为优化调制解调器和多媒体应用而设计，具有的特性包括<strong>硬件辅助多线程</strong>。Hexagon
SDK使您能最大化发挥DSP的性能，提供一个用于生成动态Hexagon
DSP代码模块的环境，并且使您能访问Hexagon
DSP上的内置计算资源。该SDK是专为帮助确保处理效率而设计，这意味着它具备更高的流动性、更低的延迟和卓越的应用性能。</p>
<h2 id="csdn中高通专栏"><a
href="https://qualcomm.csdn.net/">CSDN中高通专栏</a></h2>
<h2 id="中科创达-王庆民关于hexagon-dsp功能介绍"><a
href="https://blog.csdn.net/awangqm/article/details/49333385">【中科创达-王庆民】关于Hexagon
DSP功能介绍</a></h2>
<p>Qualcomm的晓龙芯片从创立之几乎一直内置Hexagon
DSP芯片，它是移动异构计算必需的处理引擎。Hexagon架构设计的核心在于如何在低功耗的情况下能够高性能的处理各种各样的应用，它具有的特性包括多线程，特权级，VLIW，SIMD以及专门适应于信号处理的指令。该CPU可以在单个时间周期中依序快速的将四个指令（已打包好）处理为执行单元。硬件多线程则由
TMT（TemporalMultiThreading，时间多线程）来实现，在这种模式下，频率600MHz的物理核心可以被抽象成三个频率200MHz的核心。许多体验如声音和图像增强功能以及高级摄像头和传感器功能都包括信号处理任务，而DSP尤其擅长在低功耗下处理这些任务。起初，Hexagon
DSP作为处理引擎，主要用于语音和简单的音频播放。现在，Hexagon
DSP的作用已经扩展至多种用途，如图像增强、计算机视觉、扩增实境、视频处理和传感器处理。随着智能手机使用需求的不断加大，现在包括摄像头和传感器功能都包括信号处理任务都需要借助DSP来完成，相比强大的CPU，DSP尤其擅长在低功耗下处理这些任务。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030322238.png"
alt="@Qualcomm最新发布的Hexagon 680 DSP版本新特性" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="Qualcomm最新发布的Hexagon">@Qualcomm最新发布的Hexagon</span>
680 DSP版本新特性</figcaption>
</figure>
<h2 id="高清图像处理低功耗qualcomm-hexagon-vector-extensions-hvx"><a
href="https://www.csdn.net/article/a/2015-09-15/15828177">高清图像处理，低功耗——Qualcomm®
Hexagon™ Vector eXtensions (HVX)</a></h2>
<p>摘要：过去几年，开发人员一直在利用 Hexagon SDK，量身定制
DSP，处理音频、图像与计算 。在 HotChips
半导体会议上，我们揭开了即将上市的 Snapdragon 820 处理器中全新 Hexagon
DSP 的部分面纱。这款 Hexagon 680 DSP ，集成宽幅向量处理 Hexagon
向量扩展（HVX）核心，充分利用新的DSP 应用实例。 英文原版<a
href="https://developer.qualcomm.com/blog/high-res-image-processing-low-power-consumption-qualcomm-hexagon-vector-extensions-vx">High-Res
Image Processing, Low Power Consumption – Qualcomm® Hexagon™ Vector
eXtensions (VX)</a> 关于HVX技术，可以参考如下介绍
https://www.hotchips.org/wp-content/uploads/hc_archives/hc27/HC27.24-Monday-Epub/HC27.24.20-Multimedia-Epub/HC27.24.211-Hexagon680-Codrescu-Qualcomm.pdf</p>
<p>高通向量拓展技术的概括 与NEON编程模型相类似，在计算机视觉应用领域
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030322748.png"
alt="Alt text" /></p>
<p>指令和CPU的NEON指令相比，指令简单，更低功耗 <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030322662.png"
alt="Alt text" /></p>
<p>性能方面,CPU使用NEON优化虽然能够提升1<sub>3的速度，但是单pixel功耗方面大约是DSP的4</sub>18倍。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030323827.png"
alt="@Benchmark" /></p>
<h2 id="snapdragon-neural-processing-engine-snpe">Snapdragon Neural
Processing Engine (SNPE)</h2>
<h3 id="capabilities">Capabilities</h3>
<p>The Snapdragon Neural Processing Engine (SNPE) is a Qualcomm
Snapdragon software accelerated runtime for the execution of deep neural
networks. With SNPE, users can:</p>
<ul>
<li>Execute an arbitrarily deep neural network</li>
<li>Execute the network on the SnapdragonTM CPU, the AdrenoTM GPU or the
HexagonTM DSP.</li>
<li>Debug the network execution on x86 Ubuntu Linux</li>
<li>Convert Caffe, Caffe2, ONNXTM and TensorFlowTM models to a SNPE Deep
Learning Container (DLC) file</li>
<li>Quantize DLC files to 8 bit fixed point for running on the Hexagon
DSP</li>
<li>Debug and analyze the performance of the network with SNPE
tools</li>
<li>Integrate a network into applications and other code via C++ or
Java</li>
</ul>
<h3 id="workflow">Workflow</h3>
<p>Model training is performed on a popular deep learning framework
(Caffe, Caffe2, ONNX and TensorFlow models are supported by SNPE.) After
training is complete the trained model is converted into a DLC file that
can be loaded into the SNPE runtime. This DLC file can then be used to
perform forward inference passes using one of the Snapdragon accelerated
compute cores. The basic SNPE workflow consists of only a few steps:</p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030323080.png"
alt="@SNPE运行模型的工作流" /> * Convert the network model to a DLC file
that can be loaded by SNPE. * Optionally quantize the DLC file for
running on the Hexagon DSP. * Prepare input data for the model. * Load
and execute the model using SNPE runtime.</p>
<h3 id="测试模型">测试模型</h3>
<ol type="1">
<li>添加环境变量 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(__linux__) || defined(__ANDROID__)</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">SetAdspLibraryPath</span><span class="params">(std::string nativeLibPath)</span> </span>&#123;</span><br><span class="line">    std::stringstream path;</span><br><span class="line">    path &lt;&lt; nativeLibPath &lt;&lt; <span class="string">&quot;;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">setenv</span>(<span class="string">&quot;ADSP_LIBRARY_PATH&quot;</span>, path.<span class="built_in">str</span>().<span class="built_in">c_str</span>(), <span class="number">1</span> <span class="comment">/*override*/</span>) == <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">error</span> <span class="string">&quot;the platform not support dsp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure></li>
</ol>
<p><code>./snpe-net-run --container ./modelname.dlc --input_list list.one --use_dsp</code></p>
<ul>
<li><a
href="https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk">SNPE
sdk download</a></li>
<li><a
href="https://developer.qualcomm.com/docs/snpe/overview.html">SNPE
document</a></li>
<li><a
href="https://developer.qualcomm.com/docs/snpe/network_layers.html">SNPE支持的网络层</a></li>
<li><a
href="https://blog.csdn.net/guvcolie/article/details/77937786">SNPE用户自定义层JNI实现</a></li>
</ul>
<h2 id="参考链接">参考链接</h2>
<ul>
<li><a
href="http://mobile.zol.com.cn/soc/">手机处理器性能排行榜</a></li>
<li><a
href="http://www.mydrivers.com/zhuanti/tianti/01/">手机CPU性能天梯图</a></li>
<li><a
href="https://www.xianshua.net/top/5534.html">2018年高通骁龙CPU处理器排行榜</a></li>
<li><a
href="http://www.ti.com.cn/general/cn/docs/gencontent.tsp?contentId=61574">【德州仪器DSP技术应用工程师
冯华亮】影响高性能DSP功耗的因素及其优化方法</a></li>
<li><a
href="https://blog.csdn.net/yuanlulu/article/details/80857211">移动端深度学习框架小结</a></li>
</ul>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>HPC</tag>
        <tag>SNPE</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ Programming Tricks</title>
    <url>/201811/20181128-gnu-cpp-programming-tricks/</url>
    <content><![CDATA[<h2 id="pragma-warning"><code>pragma warning</code></h2>
<p><a
href="https://stackoverflow.com/questions/3350852/how-to-correctly-fix-zero-sized-array-in-struct-union-warning-c4200-without">关于warning的一个问题：
warning C4200: nonstandard extension used : zero-sized array in
struct/union Cannot generate copy-ctor or copy-assignment operator when
UDT contains a zero-sized array</a></p>
<h4 id="常用去警告">常用去警告：</h4>
<ul>
<li><code>#pragma warning(disable:4035)</code> //no return value</li>
<li><code>#pragma warning(disable:4068)</code> //unknown pragma</li>
<li><code>#pragma warning(disable:4201)</code> //nonstandard extension
used : nameless struct/union</li>
<li><code>#pragma warning(disable:4267)</code></li>
<li><code>#pragma warning(disable:4018)</code> //signed/unsigned
mismatch</li>
<li><code>#pragma warning(disable:4127)</code> //conditional expression
is constant</li>
<li><code>#pragma warning(disable:4146)</code></li>
<li><code>#pragma warning(disable:4244)</code> //conversion from
'LONG_PTR' to 'LONG', possible loss of data</li>
<li><code>#pragma warning(disable:4311)</code> //'type cast' : pointer
truncation from 'BYTE *' to 'ULONG'</li>
<li><code>#pragma warning(disable:4312)</code> //'type cast' :
conversion from 'LONG' to 'WNDPROC' of greater size</li>
<li><code>#pragma warning(disable:4346)</code> //_It::iterator_category'
: dependent name is not a type</li>
<li><code>#pragma warning(disable:4786)</code></li>
<li><code>#pragma warning(disable:4541)</code> //'dynamic_cast' used on
polymorphic type</li>
<li><code>#pragma warning(disable:4996)</code> //declared deprecated
?</li>
<li><code>#pragma warning(disable:4200)</code> //zero-sized array in
struct/union</li>
<li><code>#pragma warning(disable:4800)</code> //forcing value to bool
'true' or 'false' (performance warning)</li>
</ul>
<h4 id="常用用法">常用用法:</h4>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(push) </span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(disable:XXXX)    <span class="comment">// 需要消除警告的代码</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(pop)</span></span><br></pre></td></tr></table></figure>
<p>or: <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(disable:XXXX) <span class="comment">// 需要消除警告的代码</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span>   <span class="keyword">warning</span>(enable:XXXX)  <span class="comment">// 如果出现：&#x27;enable&#x27;not valid specifier 用 </span></span></span><br><span class="line">                                <span class="comment">// #pragma   warning(default:XXXX)  代替试试</span></span><br></pre></td></tr></table></figure></p>
<h4 id="pragma-支持"><code>#pragma</code> 支持</h4>
<p>开发人员可以使用 <code>#pragma</code>
指令将警告作为错误处理；还可以启用或禁用警告，如下面的示例所示：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span> (<span class="keyword">error</span>: 6260) </span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span> (disable: 6011) </span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span> (enable: 6056)</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><code>Q: #pragma warning (disable : 4996)和#pragma warning (default : 4996) 是干啥用的呢？</code></p>
</blockquote>
<ol type="1">
<li><code>#pragma warning(disable: n)</code> 将某个警报置为失效</li>
<li><code>#pragma warning(default: n)</code> 将报警置为默认
使用VS2005,编译提示"xxxxxx被声明为否决的
这是MS新的C库提供的带有检查的函数,有内存溢出检测。可以防止一部分程序bug,
抵制缓冲区溢出攻击(buffer overflow attack). 但是应该速度上有牺牲。</li>
</ol>
<blockquote>
<p>解决办法 - 所以在你确信安全的情况下,可以用#pragma warning(disable:
4996)消除这个警告 -
建议使用_s的缓冲区安全的版本，而不是简单的屏蔽警告。</p>
</blockquote>
<h3 id="关于pragma-warning">关于#pragma warning</h3>
<ol type="1">
<li><p><code>#pragma warning</code>只对当前文件有效（对于.h，对包含它的cpp也是有效的），
而不是是对整个工程的所有文件有效。当该文件编译结束，设置也就失去作用。</p></li>
<li><p><code>#pragma warning(push)</code> 存储当前报警设置。
<code>#pragma warning(push, n)</code>
存储当前报警设置，并设置报警级别为n。n为从1到4的自然数。</p></li>
<li><p><code>#pragma warning(pop)</code>
恢复之前压入堆栈的报警设置。在一对push和pop之间作的任何报警相关设置都将失效。</p></li>
<li><p><code>#pragma warning(disable: n)</code>
将某个警报置为失效</p></li>
<li><p><code>#pragma warning(default: n)</code> 将报警置为默认</p></li>
<li><p>某些警告如C4309是从上到下生效的。即文件内<code>#pragma warning</code>从上到下遍历，依次生效。</p>
<p>例如： <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(disable: 4189)</span></span><br><span class="line">      <span class="type">char</span> s;</span><br><span class="line">      s = <span class="number">128</span>;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(default: 4189)</span></span><br><span class="line">      <span class="type">char</span> c;</span><br><span class="line">      c = <span class="number">128</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 则s =
128不会产生C4309报警，而C4309会产生报警。</p></li>
<li><p>某些警告例如C4189是以函数中最后出现的#pragma
warning设置为准的，其余针对该报警的设置都是无效的。 例如：</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(disable: 4189)</span></span><br><span class="line">      <span class="type">int</span> x = <span class="number">1</span>;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(default: 4189)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
则C4189仍然会出现，因为default指令是函数的最后一条。在该文件内的其他函数中，如果没有重新设置，C4189也是以<code>#pragma warning(default: 4189)</code>为准。如果重新设置，同样是按照其函数中的最后一个<code>#pragma warning</code>为准。</p></li>
<li><p>某些警告（MSDN认为是大于等于C4700的警告）是在函数结束后才能生效。
例如：</p>
<p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(disable:4700)</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="type">int</span> x;</span><br><span class="line">      <span class="type">int</span> y = x;</span><br><span class="line">      <span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span>(default:4700)</span></span><br><span class="line">      <span class="type">int</span> z= x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>则y = x和z =
x都不会产生C4700报警。只有在函数结束后的后的另外一个函数中，<code>#pragma warning(default:4700)</code>才能生效。</p></li>
</ol>
<h2 id="cc-宏定义define中-的含义">C++/C 宏定义（define）中# ##
的含义</h2>
<p>define 中的# ##
一般是用来拼接字符串的，但是实际使用过程中，有哪些细微的差别呢，我们通过几个例子来看看。</p>
<p>#是字符串化的意思，出现在宏定义中的#是把跟在后面的参数转成一个字符串；</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A simple registry for caffe commands.</span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">int</span> <span class="params">(*BrewFunction)</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">typedef</span> std::map&lt;caffe::string, BrewFunction&gt; BrewMap;</span><br><span class="line">BrewMap g_brew_map;</span><br><span class="line"></span><br><span class="line">\<span class="meta">#<span class="keyword">define</span> RegisterBrewFunction(func) \</span></span><br><span class="line"><span class="meta">namespace &#123; \</span></span><br><span class="line"><span class="meta">class __Registerer_##func &#123; \</span></span><br><span class="line"><span class="meta"> public: <span class="comment">/* NOLINT */</span> \</span></span><br><span class="line"><span class="meta">  __Registerer_##func() &#123; \</span></span><br><span class="line"><span class="meta">  g_brew_map[#func] = &amp;func; \</span></span><br><span class="line"><span class="meta">  &#125; \</span></span><br><span class="line"><span class="meta">&#125;; \</span></span><br><span class="line"><span class="meta">__Registerer_##func g_registerer_##func; \</span></span><br><span class="line"><span class="meta">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> BrewFunction <span class="title">GetBrewFunction</span><span class="params">(<span class="type">const</span> caffe::string&amp; name)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (g_brew_map.<span class="built_in">count</span>(name)) &#123;</span><br><span class="line">  <span class="keyword">return</span> g_brew_map[name];</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;Available caffe actions:&quot;</span>;</span><br><span class="line">  <span class="keyword">for</span> (BrewMap::iterator it = g_brew_map.<span class="built_in">begin</span>();</span><br><span class="line">  it != g_brew_map.<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">  <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;\t&quot;</span> &lt;&lt; it-&gt;first;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknown action: &quot;</span> &lt;&lt; name;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">NULL</span>; <span class="comment">// not reachable, just to suppress old compiler warnings.</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面这段代码是Caffe源码tools/caffe.cpp中的一段程序，主要完成了caffe不同工作阶段的注册工作。如caffe可以在
<code>train, test</code>
等不同环境下工作。每个环境对应着响应的处理函数。这些函数是如何通过main函数统一管理的。就是通过这个<code>GetBrewFunction</code>函数统一调用的。那么这个函数如何获取具体的调用函数，就得知道函数指针和宏替换的相关知识了。具体参考<a
href="https://github.com/BVLC/caffe/blob/master/tools/caffe.cpp">caffe.cpp</a></p>
<h2 id="gnu-c中不为人知的特色__attribute__机制">GNU
C中不为人知的特色：<code>__attribute__</code>机制</h2>
<p>偶然碰到了<code>__attribute__</code>，虽然之前在看Linux内核代码时见过很多次，但还是对它熟视无睹，罪过啊，下面的文章是从源码网上转载的，原文在这里:http://www.yuanma.org/data/2006/0625/article_948.htm，此处只是做简单阐述，共同进步。</p>
<ol type="1">
<li><p>GNU
C的一大特色（却不被初学者所知）就是<code>__attribute__</code>机制。<code>__attribute__</code>可以设置函数属性（Function
Attribute）、变量属性（Variable Attribute）和类型属性（Type
Attribute）。它的书写特征是：<code>__attribute__</code>前后都有两个下划线，并切后面会紧跟一对原括弧，括弧里面是相应的<code>__attribute__</code>参数，语法格式如下：
<code>__attribute__ ((attribute-list))</code></p></li>
<li><p>另外，它必须放于声明的尾部“；”之前。</p></li>
</ol>
<p>函数属性可以帮助开发者把一些特性添加到函数声明中，从而可以使编译器在错误检查方面的功能更强大。<code>__attribute__</code>机制也很容易同非GNU应用程序做到兼容之功效。</p>
<p><strong>GNU CC需要使用
–Wall编译器来击活该功能</strong>，这是控制警告信息的一个很好的方式。下面介绍几个常见的属性参数。</p>
<p><code>__attribute__ format</code>。该<code>__attribute__</code>属性可以给被声明的函数加上类似<code>printf</code>或者<code>scanf</code>的特征，它可以使编译器检查函数声明和函数实际调用参数之间的格式化字符串是否匹配。该功能十分有用，尤其是处理一些很难发现的bug。<code>format</code>的语法格式为：</p>
<p><code>format (archetype, string-index, first-to-check)</code></p>
<p>format属性告诉编译器，按照printf, scanf,
strftime或strfmon的参数表格式规则对该函数的参数进行检查。“archetype”指定是哪种风格；“string-index”指定传入函数的第几个参数是格式化字符串；“first-to-check”指定从函数的第几个参数开始按上述规则进行检查。</p>
<ol start="3" type="1">
<li>具体使用格式如下： <code>__attribute__((format(printf,m,n)))</code>
<code>__attribute__((format(scanf,m,n)))</code></li>
</ol>
<p>其中参数m与n的含义为： * m：第几个参数为格式化字符串（format
string）； *
n：参数集合中的第一个，即参数“…”里的第一个参数在函数参数总数排在第几，注意，有时函数参数里还有“隐身”的呢，后面会提到；</p>
<p>在使用上，<code>__attribute__((format(printf,m,n)))</code>是常用的，而另一种却很少见到。下面举例说明，其中myprint为自己定义的一个带有可变参数的函数，其功能类似于printf：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//m=1；n=2</span></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myprint</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *format,...)</span> __<span class="title">attribute__</span><span class="params">((format(printf,<span class="number">1</span>,<span class="number">2</span>)))</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//m=2；n=3</span></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myprint</span><span class="params">(<span class="type">int</span> l，<span class="type">const</span> <span class="type">char</span> *format,...)</span> __<span class="title">attribute__</span><span class="params">((format(printf,<span class="number">2</span>,<span class="number">3</span>)))</span></span>;</span><br></pre></td></tr></table></figure>
<p>需要特别注意的是，如果myprint是一个函数的成员函数，那么m和n的值可有点“悬乎”了，例如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//m=3；n=4</span></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myprint</span><span class="params">(<span class="type">int</span> l，<span class="type">const</span> <span class="type">char</span> *format,...)</span> __<span class="title">attribute__</span><span class="params">((format(printf,<span class="number">3</span>,<span class="number">4</span>)))</span></span>;</span><br></pre></td></tr></table></figure>
<p>其原因是，类成员函数的第一个参数实际上一个“隐身”的“this”指针。（有点C++基础的都知道点this指针，不知道你在这里还知道吗？）</p>
<p>这里给出测试用例：attribute.c，代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">extern</span> <span class="title">myprint</span><span class="params">(<span class="type">const</span> *format,...)</span> <span class="title">attribute__</span><span class="params">((format(printf,<span class="number">1</span>,<span class="number">2</span>)))</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">test</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%d\n&quot;</span>, <span class="number">1</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%s\n&quot;</span>, <span class="number">2</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%s\n&quot;</span>,<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;%s,%d,%d\n&quot;</span>,<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myprint</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *format,...)</span> __<span class="title">attribute__</span><span class="params">((format(printf,<span class="number">1</span>,<span class="number">2</span>)))</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">test</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%d\n&quot;</span>,<span class="number">6</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%s\n&quot;</span>,<span class="number">6</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;i=%s\n&quot;</span>,<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">  <span class="built_in">myprint</span>(<span class="string">&quot;%s,%d,%d\n&quot;</span>,<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>gcc编译后会提示<code>format argument is not a pointer</code>的警告。若去掉<code>__attribute__((format(printf,1,2)))</code>，则会正常编译。需要注意的是，编译器只能识别类似printf的标准输出库函数。</p>
<p>还有一个<code>__attribute__ noreturn</code>，该属性通知编译器函数从不返回值，当遇到类似函数需要返回值而却不可能运行到返回值处就已经退出来的情况，该属性可以避免出现错误信息。C库函数中的<code>abort()</code>和<code>exit()</code>的声明格式就采用了这种格式，如下所示：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">exit</span><span class="params">(<span class="type">int</span>)</span> __<span class="title">attribute__</span><span class="params">((noreturn))</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">abort</span><span class="params">(<span class="type">void</span>)</span> __<span class="title">attribute__</span><span class="params">((noreturn))</span></span>;</span><br></pre></td></tr></table></figure>
<p>为了方便理解，大家可以参考如下的例子：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//name: noreturn.c ；测试__attribute__((noreturn))</span></span><br><span class="line">  <span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myexit</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">test</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ( n &gt; <span class="number">0</span> )</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">myexit</span>();</span><br><span class="line">      <span class="comment">/* 程序不可能到达这里*/</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>//name: noreturn.c ；测试__attribute__((noreturn))</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">myexit</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">test</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> ( n &gt; <span class="number">0</span> )</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">myexit</span>();</span><br><span class="line">    <span class="comment">/* 程序不可能到达这里*/</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译后的输出结果如下：</p>
<p><code>$gcc –Wall –c noreturn.c</code></p>
<p>noreturn.c: In function `test':</p>
<p>noreturn.c:12: warning: control reaches end of non-void function</p>
<p>很显然，这是因为一个被定义为有返回值的函数却没有返回值。加上_<em>attribute_</em>((noreturn))则可以解决此问题的出现。</p>
<p>后面还有<code>__attribute__const</code>、<code>-finstrument-functions</code>、<code>no_instrument_function</code>等的属性描述，就不多转了，感兴趣的可以看原文。</p>
<h2 id="变量属性variable-attribute">变量属性(Variable Attribute)</h2>
<p>关键字<code>__attribute__</code>也可以对变量或结构体成员进行属性设置。这里给出几个常用的参数的解释，更多的参数可参考原文给出的连接。</p>
<p>在使用<code>__attribute__</code>参数时，你也可以在参数的前后都加上“__”（两个下划线），例如，使用<code>__attribute__</code>而不是aligned，这样，你就可以在相应的头文件里使用它而不用关心头文件里是否有重名的宏定义。</p>
<h3 id="aligned-alignment">aligned (alignment)</h3>
<p>该属性规定变量或结构体成员的最小的对齐格式，以字节为单位。例如：</p>
<p><code>int x __attribute__ ((aligned (16))) = 0;</code></p>
<p>编译器将以16字节（注意是字节byte不是位bit）对齐的方式分配一个变量。也可以对结构体成员变量设置该属性，例如，创建一个双字对齐的int对，可以这么写：</p>
<p><code>struct foo &#123; int x[2] __attribute__ ((aligned (8))); &#125;;</code></p>
<p>如上所述，你可以手动指定对齐的格式，同样，你也可以使用默认的对齐方式。如果aligned后面不紧跟一个指定的数字值，那么编译器将依据你的目标机器情况使用最大最有益的对齐方式。例如：</p>
<p><code>short array[3] __attribute__ ((aligned));</code></p>
<ol type="1">
<li><p>选择针对目标机器最大的对齐方式，可以提高拷贝操作的效率。aligned属性使被设置的对象占用更多的空间，相反的，使用packed可以减小对象占用的空间。</p></li>
<li><p>需要注意的是，attribute属性的效力与你的连接器也有关，如果你的连接器最大只支持16字节对齐，那么你此时定义32字节对齐也是无济于事的。</p></li>
<li><p>使用该属性可以使得变量或者结构体成员使用最小的对齐方式，即对变量是一字节对齐，对域（field）是位对齐。</p></li>
</ol>
<p>下面的例子中，x成员变量使用了该属性，则其值将紧放置在a的后面：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">test</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">char</span> a;</span><br><span class="line">    <span class="type">int</span> x[<span class="number">2</span>] __attribute__ ((packed));</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其它可选的属性值还可以是：<code>cleanup，common，nocommon，deprecated，mode，section，shared，tls_model，transparent_union，unused，vector_size，weak，dllimport，dlexport</code>等。</p>
<h2 id="类型属性type-attribute">类型属性（Type Attribute）</h2>
<p>关键字<code>__attribute__</code>也可以对结构体（struct）或共用体（union）进行属性设置。大致有六个参数值可以被设定，即：<code>aligned, packed, transparent_union, unused, deprecated</code>和
<code>may_alias</code>。</p>
<p>在使用<code>__attribute__</code>参数时，你也可以在参数的前后都加上“__”（两个下划线），例如，使用<code>__aligned__</code>而不是<code>aligned</code>，这样，你就可以在相应的头文件里使用它而不用关心头文件里是否有重名的宏定义。</p>
<h3 id="aligned-alignment-1">aligned (alignment)</h3>
<p>该属性设定一个指定大小的对齐格式（以字节为单位），例如：</p>
<p><code>struct S &#123; short f[3]; &#125; __attribute__ ((aligned (8)));</code></p>
<p><code>typedef int more_aligned_int __attribute__ ((aligned (8)));</code></p>
<pre><code>该声明将强制编译器确保（尽它所能）变量类型为struct S或者more-aligned-int的变量在分配空间时采用8字节对齐方式。</code></pre>
<p>如上所述，你可以手动指定对齐的格式，同样，你也可以使用默认的对齐方式。如果aligned后面不紧跟一个指定的数字值，那么编译器将依据你的目标机器情况使用最大最有益的对齐方式。例如：</p>
<p><code>struct S &#123; short f[3]; &#125; __attribute__ ((aligned));</code></p>
<p>这里，如果sizeof（short）的大小为2（byte），那么，S的大小就为6。取一个2的次方值，使得该值大于等于6，则该值为8，所以编译器将设置S类型的对齐方式为8字节。</p>
<ol type="1">
<li><p>aligned属性使被设置的对象占用更多的空间，相反的，使用packed可以减小对象占用的空间。</p></li>
<li><p>需要注意的是，attribute属性的效力与你的连接器也有关，如果你的连接器最大只支持16字节对齐，那么你此时定义32字节对齐也是无济于事的。</p></li>
<li><p>使用该属性对struct或者union类型进行定义，设定其类型的每一个变量的内存约束。当用在enum类型定义时，暗示了应该使用最小完整的类型（it
indicates that the smallest integral type should be used）。</p></li>
</ol>
<p>下面的例子中，my-packed-struct类型的变量数组中的值将会紧紧的靠在一起，但内部的成员变量s不会被“pack”，如果希望内部的成员变量也被packed的话，my-unpacked-struct也需要使用packed进行相应的约束。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">my_unpacked_struct</span>&#123;</span><br><span class="line"><span class="type">char</span> c;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">my_packed_struct</span>&#123;</span><br><span class="line">  <span class="type">char</span> c;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">my_unpacked_struct</span> s;</span><br><span class="line">&#125;__attribute__ ((__packed__));</span><br></pre></td></tr></table></figure>
<h2 id="变量属性与类型属性举例">变量属性与类型属性举例</h2>
<p>下面的例子中使用<code>__attribute__</code>属性定义了一些结构体及其变量，并给出了输出结果和对结果的分析。</p>
<p>程序代码为：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  程序代码为：</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">p</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">char</span> b;</span><br><span class="line">    <span class="type">char</span> c;</span><br><span class="line">  &#125;__attribute__((<span class="built_in">aligned</span>(<span class="number">4</span>))) pp;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">q</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">char</span> b;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">n</span> qn;</span><br><span class="line">    <span class="type">char</span> c;</span><br><span class="line">  &#125;__attribute__((<span class="built_in">aligned</span>(<span class="number">8</span>))) qq;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;sizeof(int)=%d,sizeof(short)=%d.sizeof(char)=%d\n&quot;</span>,<span class="built_in">sizeof</span>(<span class="type">int</span>),<span class="built_in">sizeof</span>(<span class="type">short</span>),<span class="built_in">sizeof</span>(<span class="type">char</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;pp=%d,qq=%d \n&quot;</span>, <span class="built_in">sizeof</span>(pp),<span class="built_in">sizeof</span>(qq));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><p>输出结果： sizeof(int)=4,sizeof(short)=2.sizeof(char)=1
pp=8,qq=24</p></li>
<li><p>结果分析： sizeof(int)=4,sizeof(short)=2.sizeof(char)=1
pp=8,qq=24 sizeof(pp): sizeof(a)+ sizeof(b)+ sizeof(c)=4+1+1=6&lt;23=8=
sizeof(pp) sizeof(qq): sizeof(a)+ sizeof(b)=4+1=5
sizeof(qn)=8;即qn是采用8字节对齐的，所以要在a，b后面添3个空余字节，然后才能存储qn，
4+1+（3）+8+1=17
因为qq采用的对齐是8字节对齐，所以qq的大小必定是8的整数倍，即qq的大小是一个比17大又是8的倍数的一个最小值，由此得到
17&lt;24+8=24= sizeof(qq)</p></li>
</ul>
<h2 id="declspec"><code>__declspec</code></h2>
<table>
<colgroup>
<col style="width: 18%" />
<col style="width: 35%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Compiler</th>
<th style="text-align: left;">Simple deprecation</th>
<th style="text-align: left;">Deprecation with message</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">gcc and clang</td>
<td
style="text-align: left;"><code>__attribute__((deprecated)) int a;</code></td>
<td
style="text-align: left;"><code>__attribute__((deprecated("message"))) int a;</code></td>
</tr>
<tr class="even">
<td style="text-align: left;">Visual Studio</td>
<td
style="text-align: left;"><code>__declspec(deprecated) int a;</code></td>
<td
style="text-align: left;"><code>__declspec(deprecated("message")) int a;</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Embarcadero(1)</td>
<td style="text-align: left;"><code>int a [[deprecated]];</code></td>
<td
style="text-align: left;"><code>int a [[deprecated("message")]];</code></td>
</tr>
</tbody>
</table>
<p><a
href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3760.html">table
from</a> <a
href="http://www.cnblogs.com/ylhome/archive/2010/07/10/1774770.html"><code>__declspec</code>
blog</a></p>
<h2 id="gcc-__attribute__关键字举例之visibility">gcc
<code>__attribute__</code>关键字举例之<code>visibility</code></h2>
<p>看opencv的源代码的时候，发现<code>CV_EXPORT</code>的宏定义是</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">if</span> (defined WIN32 || defined _WIN32 || defined WINCE || defined __CYGWIN__) &amp;&amp; defined CVAPI_EXPORTS</span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> CV_EXPORTS __declspec(dllexport)</span></span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined __GNUC__ &amp;&amp; __GNUC__ &gt;= 4</span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> CV_EXPORTS __attribute__ ((visibility (<span class="string">&quot;default&quot;</span>)))</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> CV_EXPORTS</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<p>我就发现了新大陆似的开始找这个属性的特点。这个在工程中尤其重要，我们实现的函数要想被其他用户调用，就必须使用<code>visibility</code>让
用户可见，否则我们的实现的功能函数对用户隐藏，出现"undefined
reference".</p>
<blockquote>
<p>visibility用于设置动态链接库中函数的可见性，将变量或函数设置为hidden，则该符号仅在本so中可见，在其他库中则不可见。</p>
</blockquote>
<p>g++在编译时，可用参数<code>-fvisibility</code>指定所有符号的可见性(不加此参数时默认外部可见，参考man
g++中<code>-fvisibility</code>部分)；若需要对特定函数的可见性进行设置，需在代码中使用<code>__attribute__</code>设置visibility属性。</p>
<p>编写大型程序时，可用<code>-fvisibility=hidden</code>设置符号默认隐藏，针对特定变量和函数，在代码中使用<code>__attribute__ ((visibility("default")))</code>另该符号外部可见，这种方法可用有效避免so之间的符号冲突。</p>
<p>下面是visibility的实例，这里extern “C”可以省略（另外两篇文章 gcc
<code>__attribute__</code>关键字举例之alias 和 C++覆盖系统函数的方法
中extern "C"不可用省略）。</p>
<p>值得注意的是，visibility2.cc中可以调用fun1，原因是visibility1.o和visibility2.o同属于一个so文件。</p>
<blockquote>
<p>visibility1.cc：</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun1</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in %s\n&quot;</span>,__FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__attribute__ ((<span class="built_in">visibility</span>(<span class="string">&quot;hidden&quot;</span>))) <span class="function"><span class="type">void</span> <span class="title">fun1</span><span class="params">()</span></span>;<span class="comment">//</span></span><br></pre></td></tr></table></figure>
<p>若编译此文件时使用了参数<code>-fvisibility=hidden</code>，则此行可以省略</p>
<blockquote>
<p>visibility2.cc：</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun1</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">fun1</span>();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in %s\n&quot;</span>,__FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line">__attribute__ ((<span class="built_in">visibility</span>(<span class="string">&quot;default&quot;</span>))) <span class="function"><span class="type">void</span> <span class="title">fun2</span><span class="params">()</span></span>;<span class="comment">//若编译此文件时没有使用参数-fvisibility或设置参数-fvisibility=default，则此行可以省略</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>main.cpp</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun1</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function"><span class="type">void</span> <span class="title">fun2</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">fun1</span>();</span><br><span class="line">  <span class="built_in">fun2</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Makefile：</p>
</blockquote>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">all:test</span></span><br><span class="line"><span class="section">test:main.o libvisibility.so</span></span><br><span class="line">        g++ -o test main.o -lvisibility -L .</span><br><span class="line"><span class="section">main.o::main.cc</span></span><br><span class="line">        g++ -c main.cc</span><br><span class="line"><span class="section">libvisibility.so:visibility1.o visibility2.o</span></span><br><span class="line">        g++ -shared -o libvisibility.so visibility1.o visibility2.o</span><br><span class="line"><span class="section">visibility1.o:visibility1.cc</span></span><br><span class="line">        g++ -fvisibility=hidden -fPIC -c visibility1.cc</span><br><span class="line"><span class="section">visibility2.o:visibility2.cc</span></span><br><span class="line">        g++ -fvisibility=hidden -fPIC -c visibility2.cc</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">        rm -f *.o *.so test</span><br></pre></td></tr></table></figure>
<blockquote>
<p>编译和输出： <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ make</span><br><span class="line">g++ -c main.cc</span><br><span class="line">g++ -fvisibility=hidden -fPIC -c visibility1.cc</span><br><span class="line">g++ -fvisibility=hidden -fPIC -c visibility2.cc</span><br><span class="line">g++ -shared -o libvisibility.so visibility1.o visibility2.o</span><br><span class="line">g++ -o <span class="built_in">test</span> main.o -lvisibility -L .</span><br><span class="line">main.o: In <span class="keyword">function</span> `main<span class="string">&#x27;:</span></span><br><span class="line"><span class="string">main.cc:(.text+0x5): undefined reference to `fun1&#x27;</span></span><br><span class="line">collect2: ld returned 1 <span class="built_in">exit</span> status</span><br><span class="line">make: *** [<span class="built_in">test</span>] Error 1</span><br></pre></td></tr></table></figure>
可以看到，<code>main()</code>中可以不可用调用<code>fun1</code>,可以调用<code>fun2</code>，因为<code>fun1</code>已经设置为外部不可见，<code>fun2</code>设置为外部可见。</p>
</blockquote>
<p>使用readelf对各个.o文件分析可以看到，fun1的Vis属性为HIDDEN，fun2的Vis属性为DEFAULT：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ readelf -s visibility1.o|grep fun</span><br><span class="line">6: 0000000000000007    5 OBJECT  LOCAL  DEFAULT    6 _ZZ4fun1E12__FUNCTION__</span><br><span class="line">12: 0000000000000000    30 FUNC    GLOBAL HIDDEN    2 fun1</span><br><span class="line"></span><br><span class="line">$ readelf -s visibility2.o|grep fun</span><br><span class="line">6: 0000000000000007    5 OBJECT  LOCAL  DEFAULT    6 _ZZ4fun2E12__FUNCTION__</span><br><span class="line">12: 0000000000000000    35 FUNC    GLOBAL DEFAULT    2 fun2</span><br><span class="line">15: 0000000000000000    0 NOTYPE  GLOBAL DEFAULT  UND fun1</span><br><span class="line"></span><br><span class="line">$ readelf -s libvisibility.so|grep fun</span><br><span class="line">9: 00000000000006ac    35 FUNC    GLOBAL DEFAULT  12 fun2</span><br><span class="line">41: 000000000000071d    5 OBJECT  LOCAL  DEFAULT  14 _ZZ4fun1E12__FUNCTION__</span><br><span class="line">43: 0000000000000729    5 OBJECT  LOCAL  DEFAULT  14 _ZZ4fun2E12__FUNCTION__</span><br><span class="line">48: 000000000000068c    30 FUNC    LOCAL  HIDDEN  12 fun1</span><br><span class="line">54: 00000000000006ac    35 FUNC    GLOBAL DEFAULT  12 fun2</span><br></pre></td></tr></table></figure>
<h1 id="linux-内核中的-gcc-特性">Linux 内核中的 GCC 特性</h1>
<ul>
<li>功能性 扩展提供新功能。</li>
<li>优化 扩展帮助生成更高效的代码。</li>
</ul>
<h2 id="功能性扩展">功能性扩展</h2>
<h3 id="类型发现">类型发现</h3>
<p>GCC 允许通过变量的引用识别类型。这种操作支持泛型编程。在 C++、Ada 和
Java™ 语言等许多现代编程语言中都可以找到相似的功能。Linux 使用 typeof
构建 min 和 max 等依赖于类型的操作。清单 1 演示如何使用 typeof
构建一个泛型宏（见 ./linux/include/linux/kernel.h）。</p>
<p>清单 1. 使用 typeof 构建一个泛型宏 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define min(x, y) (&#123;                \</span><br><span class="line">    typeof(x) _min1 = (x);          \</span><br><span class="line">    typeof(y) _min2 = (y);          \</span><br><span class="line">    (void) (&amp;_min1 == &amp;_min2);      \</span><br><span class="line">    _min1 &lt; _min2 ? _min1 : _min2; &#125;)</span><br></pre></td></tr></table></figure></p>
<h3 id="范围扩展">范围扩展</h3>
<p>GCC 支持范围，在 C 语言的许多方面都可以使用范围。其中之一是
switch/case 块中的 case 语句。在复杂的条件结构中，通常依靠嵌套的 if
语句实现与清单 2（见 ./linux/drivers/scsi/sd.c）相同的结果，但是清单 2
更简洁。使用 switch/case 也可以通过使用跳转表实现进行编译器优化。</p>
<p>清单 2. 在 case 语句中使用范围 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">sd_major</span><span class="params">(<span class="type">int</span> major_idx)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">switch</span> (major_idx) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> SCSI_DISK0_MAJOR;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">1</span> ... <span class="number">7</span>:</span><br><span class="line">        <span class="keyword">return</span> SCSI_DISK1_MAJOR + major_idx - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">8</span> ... <span class="number">15</span>:</span><br><span class="line">        <span class="keyword">return</span> SCSI_DISK8_MAJOR + major_idx - <span class="number">8</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        BUG();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;   <span class="comment">/* shut up gcc */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
还可以使用范围进行初始化，如下所示（见<code>./linux/arch/cris/arch-v32/kernel/smp.c</code>）。在这个示例中，<code>spinlock_t</code>
创建一个大小为<code>LOCK_COUNT</code>
的数组。数组的每个元素初始化为<code>SPIN_LOCK_UNLOCKED</code> 值。
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Vector of locks used for various atomic operations */</span></span><br><span class="line"><span class="type">spinlock_t</span> cris_atomic_locks[] = &#123; [<span class="number">0</span> ... LOCK_COUNT - <span class="number">1</span>] = SPIN_LOCK_UNLOCKED&#125;;</span><br></pre></td></tr></table></figure>
范围还支持更复杂的初始化。例如，以下代码指定数组中几个子范围的初始值。
<code>int widths[] = &#123; [0 ... 9] = 1, [10 ... 99] = 2, [100] = 3 &#125;;</code></p>
<h3 id="零长度的数组">零长度的数组</h3>
<p>在 C
标准中，必须定义至少一个数组元素。这个需求往往会使代码设计复杂化。但是，GCC
支持零长度数组的概念，这对于结构定义尤其有用。这个概念与 ISO C99
中灵活的数组成员相似，但是使用不同的语法。</p>
<p>下面的示例在结构的末尾声明一个没有成员的数组（见
<code>./linux/drivers/ieee1394/raw1394-private.h</code>）。这允许结构中的元素引用结构实例后面紧接着的内存。在需要数量可变的数组成员时，这个特性很有用。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct iso_block_store &#123;</span><br><span class="line">        atomic_t refcount;</span><br><span class="line">        size_t data_size;</span><br><span class="line">        quadlet_t data[0];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<h3 id="判断调用地址">判断调用地址</h3>
<p>在许多情况下，需要判断给定函数的调用者。GCC 提供用于此用途的内置函数
<code>__builtin_return_address</code>。这个函数通常用于调试，但是它在内核中还有许多其他用途。</p>
<p>如下面的代码所示，<code>__builtin_return_address</code> 接收一个称为
level 的参数。这个参数定义希望获取返回地址的调用堆栈级别。例如，如果指定
level 为 0，那么就是请求当前函数的返回地址。如果指定 level 为
1，那么就是请求进行调用的函数的返回地址，依此类推。
<code>void * __builtin_return_address( unsigned int level );</code>
在下面的示例中（见
./linux/kernel/softirq.c），<code>local_bh_disable</code>
函数在本地处理器上禁用软中断，从而禁止在当前处理器上运行
<code>softirqs</code>、<code>tasklets</code>和
<code>bottom halves</code>。使用<code>__builtin_return_address</code>
捕捉返回地址，以便在以后进行跟踪时使用这个地址。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void local_bh_disable(void)&#123;</span><br><span class="line">        __local_bh_disable((unsigned long)__builtin_return_address(0));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="常量检测">常量检测</h3>
<p>在编译时，可以使用 GCC
提供的一个内置函数判断一个值是否是常量。这种信息非常有价值，因为可以构造出能够通过常量叠算（constant
folding）优化的表达式。<code>__builtin_constant_p</code>
函数用来检测常量。</p>
<p><code>__builtin_constant_p</code>
的原型如下所示。注意，<code>__builtin_constant_p</code>
并不能检测出所有常量，因为 GCC 不容易证明某些值是否是常量。
<code>int __builtin_constant_p( exp )</code> Linux
相当频繁地使用常量检测。在清单 3 所示的示例中（见
./linux/include/linux/log2.h），使用常量检测优化
<code>roundup_pow_of_two</code>
宏。如果发现表达式是常量，那么就使用可以优化的常量表达式。如果表达式不是常量，就调用另一个宏函数把值向上取整到
2 的幂。</p>
<p>清单 3. 使用常量检测优化宏函数 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define roundup_pow_of_two(n)           \</span><br><span class="line">(                       \</span><br><span class="line">    __builtin_constant_p(n) ? (     \</span><br><span class="line">        (n == 1) ? 1 :          \</span><br><span class="line">        (1UL &lt;&lt; (ilog2((n) - 1) + 1)) \</span><br><span class="line">                   ) :      \</span><br><span class="line">    __roundup_pow_of_two(n)         \</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<h3 id="函数属性">函数属性</h3>
<p>GCC
提供许多函数级属性，可以通过它们向编译器提供更多数据，帮助编译器执行优化。本节描述与功能相关联的一些属性。下一节描述
影响优化的属性。</p>
<p>如清单 4
所示，属性通过其他符号定义指定了别名。可以以此帮助阅读源代码参考，了解属性的使用方法（见
./linux/include/linux/compiler-gcc3.h）。</p>
<p>清单 4. 函数属性定义 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># define __inline__  __inline__  __attribute__((always_inline))</span><br><span class="line"># define __deprecated           __attribute__((deprecated))</span><br><span class="line"># define __attribute_used__     __attribute__((__used__))</span><br><span class="line"># define __attribute_const__     __attribute__((__const__))</span><br><span class="line"># define __must_check            __attribute__((warn_unused_result))</span><br></pre></td></tr></table></figure> 清单 4 所示的定义是 GCC
中可用的一些函数属性。它们也是在 Linux
内核中最有用的函数属性。下面解释如何使用这些属性： -
<code>always_inline</code> 让 GCC
以内联方式处理指定的函数，无论是否启用了优化。 - <code>deprecated</code>
指出函数已经被废弃，不应该再使用。如果试图使用已经废弃的函数，就会收到警告。还可以对类型和变量应用这个属性，促使开发人员尽可能少使用它们。
- <code>__used__</code> 告诉编译器无论 GCC
是否发现这个函数的调用实例，都要使用这个函数。这对于从汇编代码中调用 C
函数有帮助。 - <code>__const__</code>
告诉编译器某个函数是无状态的（也就是说，它使用传递给它的参数生成要返回的结果）。
- <code>warn_unused_result</code>
让编译器检查所有调用者是否都检查函数的结果。这确保调用者适当地检验函数结果，从而能够适当地处理错误。</p>
<p>下面是在 Linux 内核中使用这些属性的示例。deprecated
示例来自与体系结构无关的内核（./linux/kernel/resource.c），const
示例来自 IA64 内核源代码（./linux/arch/ia64/kernel/unwind.c）。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> __deprecated __check_region(<span class="keyword">struct</span> resource </span><br><span class="line">    *parent, <span class="type">unsigned</span> <span class="type">long</span> start, <span class="type">unsigned</span> <span class="type">long</span> n)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">enum</span> unw_register_index __attribute_const__ </span></span><br><span class="line"><span class="function">    <span class="title">decode_abreg</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> abreg, <span class="type">int</span> memory)</span></span></span><br></pre></td></tr></table></figure>
<h2 id="优化扩展">优化扩展</h2>
<p>现在，讨论有助于生成更好的机器码的一些 GCC 特性。</p>
<h3 id="分支预测提示">分支预测提示</h3>
<p>在 Linux
内核中最常用的优化技术之一是<code>__builtin_expect</code>。在开发人员使用有条件代码时，常常知道最可能执行哪个分支，而哪个分支很少执行。如果编译器知道这种预测信息，就可以围绕最可能执行的分支生成最优的代码。</p>
<p>如下所示，<code>__builtin_expect</code> 的使用方法基于两个宏 likely
和 unlikely（见 ./linux/include/linux/compiler.h）。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define likely(x)   __builtin_expect(!!(x), 1)</span><br><span class="line">#define unlikely(x) __builtin_expect(!!(x), 0)</span><br></pre></td></tr></table></figure>
通过使用
<code>__builtin_expect</code>，编译器可以做出符合提供的预测信息的指令选择决策。这使执行的代码尽可能接近实际情况。它还可以改进缓存和指令流水线。</p>
<p>例如，如果一个条件标上了 “likely”，那么编译器可以把代码的 True
部分直接放在分支指令后面（这样就不需要执行分支指令）。通过分支指令访问条件结构的
False
部分，这不是最优的方式，但是访问它的可能性不大。按照这种方式，代码对于最可能出现的情况是最优的。</p>
<p>清单 5 给出一个使用 likely 和 unlikely 宏的函数（见
./linux/net/core/datagram.c）。这个函数预测 sum 变量将是零（数据包的
checksum 是有效的），而且 ip_summed 变量不等于 CHECKSUM_HW。</p>
<p>清单 5. likely 和 unlikely 宏的使用示例 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> __skb_checksum_complete(<span class="keyword">struct</span> sk_buff *skb)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">int</span> sum;</span><br><span class="line"> </span><br><span class="line">        sum = (u16)<span class="built_in">csum_fold</span>(<span class="built_in">skb_checksum</span>(skb, <span class="number">0</span>, skb-&gt;len, skb-&gt;csum));</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">likely</span>(!sum)) &#123;</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">unlikely</span>(skb-&gt;ip_summed == CHECKSUM_HW))</span><br><span class="line">                        <span class="built_in">netdev_rx_csum_fault</span>(skb-&gt;dev);</span><br><span class="line">                skb-&gt;ip_summed = CHECKSUM_UNNECESSARY;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="预抓取">预抓取</h3>
<p>另一种重要的性能改进方法是把必需的数据缓存在接近处理器的地方。缓存可以显著减少访问数据花费的时间。大多数现代处理器都有三类内存：
* 一级缓存通常支持单周期访问 * 二级缓存支持两周期访问 *
系统内存支持更长的访问时间</p>
<p>为了尽可能减少访问延时并由此提高性能，最好把数据放在最近的内存中。手工执行这个任务称为预抓取。GCC
通过内置函数 <code>__builtin_prefetch</code>
支持数据的手工预抓取。在需要数据之前，使用这个函数把数据放到缓存中。如下所示，<code>__builtin_prefetch</code>
函数接收三个参数：</p>
<ul>
<li>数据的地址</li>
<li>rw 参数，使用它指明预抓取数据是为了执行读操作，还是执行写操作</li>
<li>locality
参数，使用它指定在使用数据之后数据应该留在缓存中，还是应该清除
<code>void __builtin_prefetch( const void *addr, int rw, int locality );</code></li>
</ul>
<p>Linux 内核经常使用预抓取。通常是通过宏和包装器函数使用预抓取。清单 6
是一个辅助函数示例，它使用内置函数的包装器（见
./linux/include/linux/prefetch.h）。这个函数为流操作实现预抓取机制。使用这个函数通常可以减少缓存缺失和停顿，从而提高性能。</p>
<p>清单 6. 范围预抓取的包装器函数 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> ARCH_HAS_PREFETCH</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> prefetch(x) __builtin_prefetch(x)</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title">prefetch_range</span><span class="params">(<span class="type">void</span> *addr, <span class="type">size_t</span> len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> ARCH_HAS_PREFETCH</span></span><br><span class="line">    <span class="type">char</span> *cp;</span><br><span class="line">    <span class="type">char</span> *end = addr + len;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> (cp = addr; cp &lt; end; cp += PREFETCH_STRIDE)</span><br><span class="line">        <span class="built_in">prefetch</span>(cp);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="变量属性">变量属性</h3>
<p>除了本文前面讨论的函数属性之外，GCC
还为变量和类型定义提供了属性。最重要的属性之一是 <code>aligned</code>
属性，它用于在内存中实现对象对齐。除了对于性能很重要之外，某些设备或硬件配置也需要对象对齐。<code>aligned</code>
属性有一个参数，它指定所需的对齐类型。</p>
<p>下面的示例用于软件暂停（见
./linux/arch/i386/mm/init.c）。在需要页面对齐时，定义
<code>PAGE_SIZE</code> 对象。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">char __nosavedata swsusp_pg_dir[PAGE_SIZE]</span><br><span class="line">    __attribute__ ((aligned (PAGE_SIZE)));</span><br></pre></td></tr></table></figure> 清单 7
中的示例说明关于优化的两点：</p>
<p><code>packed</code>
属性打包一个结构的元素，从而尽可能减少它们占用的空间。这意味着，如果定义一个
char 变量，它占用的空间不会超过一字节（8
位）。位字段压缩为一位，而不会占用更多存储空间。
这段源代码使用一个<code>__attribute__</code>
声明进行优化，它用逗号分隔的列表定义多个属性。 清单 7.
结构打包和设置多个属性 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">swsusp_header</span> &#123;</span><br><span class="line">        <span class="type">char</span> reserved[PAGE_SIZE - <span class="number">20</span> - <span class="built_in">sizeof</span>(<span class="type">swp_entry_t</span>)];</span><br><span class="line">        <span class="type">swp_entry_t</span> image;</span><br><span class="line">        <span class="type">char</span>    orig_sig[<span class="number">10</span>];</span><br><span class="line">        <span class="type">char</span>    sig[<span class="number">10</span>];</span><br><span class="line">&#125; __attribute__((packed, <span class="built_in">aligned</span>(PAGE_SIZE))) swsusp_header;</span><br></pre></td></tr></table></figure></p>
<h2 id="参考链接">参考链接</h2>
<ol type="1">
<li><p><a
href="https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html#Function-Attributes">Function
Attributes</a></p></li>
<li><p><a
href="https://gcc.gnu.org/onlinedocs/gcc/Visibility-Pragmas.html#Visibility-Pragmas">Visibility
Pragmas</a></p></li>
<li><p><a
href="http://liulixiaoyao.blog.51cto.com/1361095/814329">GCC扩展
<strong>attribute</strong> ((visibility("hidden")))</a></p></li>
<li><p><a
href="https://www.ibm.com/developerworks/cn/linux/l-gcc-hacks/">【IBM】Linux
内核中的 GCC 特性</a></p></li>
</ol>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>开发</tag>
      </tags>
  </entry>
  <entry>
    <title>Detection算法Overview</title>
    <url>/201907/20190714-detection/</url>
    <content><![CDATA[<h1 id="物体检测算法概述">物体检测算法概述</h1>
<p>深度学习让物体检测从实验室走到生活。基于深度学习的物体检测算法分类两大类。一类是像RCNN类似的两stage方法，将ROI的选择和对ROI的分类score过程。
另外一类是类似YOLO将ROI的选择和最终打分实现端到端一步完成。前者是先由算法生成一系列作为样本的候选框，再通过卷积神经网络进行样本分类；后者则不用产生候选框，直接将目标边框定位的问题转化为回归问题处理。正是由于两种方法的差异，在性能上也有不同，前者在检测准确率和定位精度上占优，后者在算法速度上占优。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326458.png"
alt="@物体检测算法概览图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="物体检测算法概览图">@物体检测算法概览图</span></figcaption>
</figure>
<p><a
href="https://www.jianshu.com/p/0586fdb412bf?utm_source=oschina-app">各种检测算法之间的性能对比，准确率，速度，以及一些可能加速的tips</a></p>
<h2 id="r-cnn的前世">R-CNN的前世</h2>
<ul>
<li>HOG</li>
<li>DPM</li>
<li>Selective Search</li>
<li><a
href="https://zhuanlan.zhihu.com/p/32564990">深度学习应用到物体检测以前</a></li>
</ul>
<h1 id="基于region-proposals的方法two-stage方法">基于region
proposals的方法（Two-Stage方法）</h1>
<ul>
<li>RCNN =&gt; Fast RCNN =&gt; Faster RCNN =&gt; FPN <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326078.png"
alt="@R-CNN、Fast R-CNN、Faster R-CNN三者关系" /></li>
</ul>
<h2 id="rcnn">RCNN</h2>
<p>在早期深度学习技术发展进程中，主要都是围绕分类问题展开研究，这是因为神经网络特有的结构输出将概率统计和分类问题结合，提供一种直观易行的思路。国内外研究人员虽然也在致力于将其他如目标检测领域和深度学习结合，但都没有取得成效，这种情况直到R-CNN算法出现才得以解决。</p>
<ul>
<li>论文链接：https://arxiv.org/pdf/1311.2524.pdf</li>
<li>作者：Ross Girshick Jeff Donahue Trevor Darrell Jitendra Malik
之前的视觉任务大多数考虑使用SIFT和HOG特征，而近年来CNN和ImageNet的出现使得图像分类问题取得重大突破，那么这方面的成功能否迁移到PASCAL
VOC的目标检测任务上呢？基于这个问题，论文提出了R-CNN。 R-CNN
(Region-based CNN features) 性能：RCNN在VOC2007上的mAP是58%左右。</li>
</ul>
<h3 id="主要工作流程">主要工作流程</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326762.png"
alt="@R-CNN要完成目标定位，其流程主要分为四步" />
R-CNN要完成目标定位，其流程主要分为四步：</p>
<ul>
<li>输入图像</li>
<li>利用选择性搜索(Selective Search)这样的区域生成算法提取Region
Proposal 提案区域(2000个左右)</li>
<li>将每个Region
Proposal分别resize(因为训练好的CNN输入是固定的)后(也即下图中的warped
region，文章中是归一化为227×227)作为CNN网络的输入。</li>
<li>CNN网络提取到经过resize的region
proposal的特征送入每一类的SVM分类器，判断是否属于该类</li>
</ul>
<h3 id="rcnn的缺点">RCNN的缺点</h3>
<ul>
<li>对于提取的每个Region
Proposal，多数都是互相重叠，重叠部分会被多次重复提取feature)，都要分别进行CNN前向传播一次(相当于进行了2000吃提特征和SVM分类的过程)，计算量较大。</li>
<li>CNN的模型确定的情况下只能接受固定大小的输入(也即wraped
region的大小固定)</li>
</ul>
<h3 id="优化思路">优化思路</h3>
<p>既然所有的Region
Proposal都在输入图像中，与其提取后分别作为CNN的输入，为什么不考虑将带有Region
Proposal的原图像直接作为CNN的输入呢？原图像在经过CNN的卷积层得到feature
map，原图像中的Region
Proposal经过特征映射(也即CNN的卷积下采样等操作)也与feature
map中的一块儿区域相对应。</p>
<h2 id="spp-net">SPP net</h2>
<ul>
<li>论文链接：]https://arxiv.org/abs/1406.4729</li>
<li>作者：Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun 简述：SPP
net中Region
Proposal仍然是在原始输入图像中选取的，不过是通过CNN映射到了feature
map中的一片区域。</li>
</ul>
<h3 id="spp-net的主要思想">SPP-NET的主要思想</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326247.png"
alt="@SPPNet架构图" /> * 对卷积层的feature map上的Region
Proposal映射区域分别划分成1×1，2×2，4×4的窗口(window)， *
在每个窗口内做max pooling，这样对于一个卷积核产生的feature
map，就可以由SPP得到一个(1×1+2×2+4×4)维的特征向量。 *
论文中采用的网络结构最后一层卷积层共有256个卷积核，所以最后会得到一个固定维度的特征向量(1×1+2×2+4×4)×256维)，并用此特征向量作为全连接层的输入后做分类。</p>
<h3 id="相对于r-cnnspp-net的优势">相对于R-CNN，SPP-net的优势</h3>
<ul>
<li>使用原始图像作为CNN网络的输入来计算feature map(R-CNN中是每个Region
Proposal都要经历一次CNN计算)，大大减少了计算量。</li>
<li>RCNN要resize，易于失真，而SPP-net不需要，原因是，SPP net中Region
Proposal仍然是通过选择性搜索等算法在输入图像中生成的，通过映射的方式得到feature
map中对应的区域，并对Region Proposal在feature
map中对应区域做空间金字塔池化。通过空间金字塔池化操作，对于任意尺寸的候选区域，经过SPP后都会得到固定长度的特征向量。</li>
</ul>
<!-- ### SPP-net缺点
* 训练分多个阶段，步骤繁琐(微调网络+训练SVM+训练边框回归器)
* SPP net在微调网络的时候固定了卷积层，只对全连接层进行微调 -->
<h2 id="fast-rcnn">Fast RCNN</h2>
<ul>
<li><a
href="https://arxiv.org/abs/1504.08083"><code>Fast R-CNN</code></a></li>
<li>作者：Ross Girshick 性能：在VOC2007上的mAP也提高到了68%</li>
</ul>
<h3 id="算法框架图">算法框架图</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326585.png" />
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326400.png" /></p>
<h3 id="优点贡献">优点&amp;贡献</h3>
<ul>
<li>Fast R-CNN引入了RoI 池化层(相当于是一层SPP)，对于图像中的Region
Poposal(也即RoI)，通过映射关系(图中的RoI projection)可以得到feature
map中Region Proposal对应的区域。</li>
<li>RoI Pooling层的操作是将feature
map上的RoI区域划分为7×7的窗口，在每个窗口内进行max
pooling，然后得到(7×7)×256的输出，最后连接到全连接层得到固定长度的RoI特征向量。</li>
<li>前面得到的RoI特征向量再通过全连接层作为Softmax和Regressor的输入,训练过程可以更新所有的网络层</li>
<li>训练过程是端到端的(Sigle-stage),并使用了一个多任务的损失函数(也即将边框回归直接加入到CNN网络中后,Fast
R-CNN网络的损失函数包含了Softmax的损失和Regressor的损失)</li>
</ul>
<h3 id="小结">小结</h3>
<p>在前面三种目标检测框架中(R-CNN，SPP net，Fast R-CNN)，Region
Proposal都是通过区域生成的算法(选择性搜索等)在原始输入图像中产生的，不过在SPP
net及Fast R-CNN中都是输入图像中的Region
Proposal通过映射关系映射到CNN中feature map上再操作的。Fast
R-CNN中RoI池化的对象是输入图像中产生的proposal在feature
map上的映射区域</p>
<h2 id="faster-rcnn">Faster RCNN</h2>
<ul>
<li>论文链接：https://arxiv.org/pdf/1506.01497.pdf</li>
<li>作者：Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun</li>
</ul>
<h3 id="faster-rcnn算法框架">Faster RCNN算法框架</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326734.png"
alt="@faster RCNN的算法框架" />
我们先整体的介绍下上图中各层主要的功能</p>
<ul>
<li><strong>卷积网络提取特征图</strong>：</li>
</ul>
<p>作为一种CNN网络目标检测方法，Faster
RCNN首先使用一组基础的conv+relu+pooling层提取input image的feature
maps,该feature maps会用于后续的RPN层和全连接层。</p>
<ul>
<li><strong>RPN(Region Proposal Networks,区域提议网络)</strong>:</li>
</ul>
<p>RPN网络主要用于生成region proposals， - 首先生成一堆Anchor
box，对其进行裁剪过滤后通过softmax判断anchors属于前景(foreground)或者后景(background)，即是物体or不是物体，所以这是一个二分类；
- 另一分支bounding box regression修正anchor
box，形成较精确的proposal（注：这里的较精确是相对于后面全连接层的再一次box
regression而言）</p>
<p>Feature Map进入RPN后，先经过一次<span
class="math inline">\(3*3\)</span>的卷积，同样，特征图大小依然是<span
class="math inline">\(60*40\)</span>,数量512，这样做的目的应该是进一步集中特征信息，接着看到两个全卷积,即kernel_size=1*1,p=0,stride=1;
- cls layer 逐像素对其9个Anchor box进行二分类 - reg layer
逐像素得到其9个Anchor box四个坐标信息</p>
<p>特征图大小为60<em>40，所以会一共生成60</em>40*9=21600个Anchor box</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326675.png"
alt="@FasterRCNN-RPN" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FasterRCNN-RPN">@FasterRCNN-RPN</span></figcaption>
</figure>
<ul>
<li><strong>Roi Pooling</strong>：</li>
</ul>
<p>该层利用RPN生成的proposals和VGG16最后一层得到的feature
map，得到固定大小的proposal feature
map,进入到后面可利用全连接操作来进行目标识别和定位</p>
<ul>
<li><strong>Classifier</strong>：</li>
</ul>
<p>会将ROI Pooling层形成固定大小的feature
map进行全连接操作，利用Softmax进行具体类别的分类，同时，利用SmoothL1Loss完成bounding
box regression回归操作获得物体的精确位置。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030326181.png"
alt="@FasterRCNN算法详细过程图" /> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327384.png"
alt="@FasterRCNN proposal&amp;RPN Netscope" /></p>
<h3 id="参考链接">参考链接</h3>
<ul>
<li>[1]. https://www.cnblogs.com/wangyong/p/8513563.html</li>
<li>[2]. https://www.jianshu.com/p/00a6a6efd83d</li>
<li>[3]. https://www.cnblogs.com/liaohuiqiang/p/9740382.html</li>
<li>[4]. https://blog.csdn.net/u011436429/article/details/80414615</li>
<li>[5]. https://blog.csdn.net/xiaoye5606/article/details/71191429</li>
</ul>
<figure>
<img src="../../images/detection/RCNN-types.png"
alt="@RCNN系列对比总结表" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="RCNN系列对比总结表">@RCNN系列对比总结表</span></figcaption>
</figure>
<p>向<a href="http://www.rossgirshick.info/">RGB大神</a>,<a
href="http://kaiminghe.com/">He Kaiming</a>致敬！</p>
<h2 id="fpnfeature-pyramid-networks-for-object-detection">FPN(feature
pyramid networks for object detection)</h2>
<ul>
<li>论文链接：https://arxiv.org/abs/1612.03144</li>
<li>poster链接：
https://vision.cornell.edu/se3/wp-content/uploads/2017/07/fpn-poster.pdf</li>
<li>caffe实现: https://github.com/unsky/FPN</li>
<li>作者：Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath
Hariharan, Serge Belongie</li>
</ul>
<h3 id="图像金字塔">图像金字塔</h3>
<p>图像金字塔,在很多的经典算法里面都有它的身影，比如SIFT、HOG等算法。
我们常用的是高斯金字塔，所谓的高斯金字塔是通过高斯平滑和亚采样获得
一些下采样图像，也就是说第K层高斯金字塔通过平滑、亚采样操作就可以
获得K+1层高斯图像，高斯金字塔包含了一系列低通滤波器，其截止频率从
上一层到下一层是以因子2逐渐增加，所以高斯金字塔可以跨越很大的频率范围。
总之，我们输入一张图片，我们可以获得多张不同尺度的图像，我们将这些
不同尺度的图像的4个顶点连接起来，就可以构造出一个类似真实金字塔的一
个图像金字塔。通过这个操作，我们可以为2维图像增加一个尺度维度（或者说是深度），
这样我们可以从中获得更多的有用信息。整个过程类似于人眼看一个目标由远及近的
过程（近大远小原理）。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327905.jpg"
alt="@图像金字塔" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="图像金字塔">@图像金字塔</span></figcaption>
</figure>
<h3 id="论文概述">论文概述：</h3>
<p>作者提出的多尺度的object detection算法：FPN（feature pyramid
networks）。原来多数的object
detection算法都是只采用顶层特征做预测，但我们知道低层的特征语义信息比较少，但是目标位置准确；高层的特征语义信息比较丰富，但是目标位置比较粗略。另外虽然也有些算法采用多尺度特征融合的方式，但是一般是采用融合后的特征做预测，而本文不一样的地方在于预测是在不同特征层独立进行的。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327418.png"
alt="@FPN架构图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FPN架构图">@FPN架构图</span></figcaption>
</figure>
<p>前面已经提到了高斯金字塔，由于它可以在一定程度上面提高算法的性能，
因此很多经典的算法中都包含它。但是这些都是在传统的算法中使用，当然也可以将
这种方法直应用在深度神经网络上面，但是由于它需要大量的运算和大量的内存。
但是我们的特征金字塔可以在速度和准确率之间进行权衡，可以通过它获得更加鲁棒
的语义信息，这是其中的一个原因。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327379.png"
alt="@FPN不同层识别的目标不同" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FPN不同层识别的目标不同">@FPN不同层识别的目标不同</span></figcaption>
</figure>
<p>如上图所示，我们可以看到我们的图像中存在不同尺寸的目标，而不同的目标具有不同的特征，
利用浅层的特征就可以将简单的目标的区分开来；
利用深层的特征可以将复杂的目标区分开来；这样我们就需要这样的一个特征金字塔来完成这件事。
图中我们在第1层（请看绿色标注）输出较大目标的实例分割结果，
在第2层输出次大目标的实例检测结果，在第3层输出较小目标的实例分割结果。
检测也是一样，我们会在第1层输出简单的目标，第2层输出较复杂的目标，第3层输出复杂的目标。</p>
<h3 id="小结-1">小结</h3>
<p>作者提出的FPN（Feature Pyramid
Network）算法同时利用低层特征高分辨率和高层特征的高语义信息，通过融合这些不同层的特征达到预测的效果。并且预测是在每个融合后的特征层上单独进行的，这和常规的特征融合方式不同。</p>
<h2 id="mask-rcnn">Mask-RCNN</h2>
<ul>
<li>论文地址：https://arxiv.org/abs/1703.06870</li>
<li>作者：Kaiming He，Georgia Gkioxari，Piotr Dollar，Ross Girshick</li>
<li>FAIR Detectron：https://github.com/facebookresearch/Detectron</li>
<li>tensorflow: https://github.com/matterport/Mask_RCNN</li>
</ul>
<h2 id="mask-scoring-r-cnn">Mask Scoring R-CNN</h2>
<ul>
<li>论文地址：https://arxiv.org/abs/1903.00241</li>
<li>github: https://github.com/zjhuang22/maskscoring_rcnn</li>
</ul>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327335.png"
alt="@Mask Scoring RCNN的架构图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="Mask">@Mask</span> Scoring RCNN的架构图</figcaption>
</figure>
<h1 id="one-stage方法">One-stage方法</h1>
<p>以R-CNN算法为代表的two
stage的方法由于RPN结构的存在，虽然检测精度越来越高，但是其速度却遇到瓶颈，比较难于满足部分场景实时性的需求。
因此出现一种基于回归方法的one stage的目标检测算法，不同于two
stage的方法的分步训练共享检测结果，one stage的方法能实现完整单次
训练共享特征，且在保证一定准确率的前提下，速度得到极大提升。</p>
<h3 id="ssd原理与实现">SSD原理与实现</h3>
<p>https://blog.csdn.net/u010712012/article/details/86555814
https://github.com/amdegroot/ssd.pytorch
http://www.cs.unc.edu/~wliu/papers/ssd_eccv2016_slide.pdf</p>
<h2 id="cornernet-人体姿态检测">CornerNet 人体姿态检测</h2>
<ul>
<li>paper出处：https://arxiv.org/abs/1808.01244</li>
<li>https://zhuanlan.zhihu.com/p/46505759</li>
</ul>
<h2 id="rpn中的anchor">RPN中的Anchor</h2>
<p>Anchor是RPN网络的核心。需要确定每个滑窗中心对应感受野内存在目标与否。由于目标大小和长宽比例不一，需要多个尺度的窗。Anchor即给出一个基准窗大小，按照倍数和长宽比例得到不同大小的窗。有了Anchor之后，才能通过Select
Search的方法Windows方法进行选取ROI的。</p>
<p>首先我们需要知道anchor的本质是什么，本质是SPP(spatial pyramid
pooling)思想的逆向。而SPP本身是做什么的呢，就是将不同尺寸的输入resize成为相同尺寸的输出。所以SPP的逆向就是，将相同尺寸的输出，倒推得到不同尺寸的输入。</p>
<p>接下来是anchor的窗口尺寸，这个不难理解，三个面积尺寸（128<sup>2，256</sup>2，512^2），然后在每个面积尺寸下，取三种不同的长宽比例（1:1,1:2,2:1）.这样一来，我们得到了一共9种面积尺寸各异的anchor。示意图如下：
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327309.png"
alt="@9个Anchor示意图" />
至于这个anchor到底是怎么用的，这个是理解整个问题的关键。</p>
<ul>
<li>Faster RCNN</li>
<li>SSD</li>
<li>YOLO</li>
<li>Guided Anchor: https://arxiv.org/abs/1901.03278</li>
</ul>
<h2 id="目标检测算法研究问题小结">目标检测算法研究问题小结</h2>
<p>目标检测领域的深度学习算法，需要进行目标定位和物体识别，算法相对来说还是很复杂的。当前各种新算法也是层不出穷，但模型之间有很强的延续性，大部分模型算法都是借鉴了前人的思想，站在巨人的肩膀上。我们需要知道经典模型的特点，这些tricks是为了解决什么问题，以及为什么解决了这些问题。这样才能举一反三，万变不离其宗。综合下来，目标检测领域主要的难点如下:</p>
<ul>
<li>检测速度：实时性要求高，故网络结构不能太复杂，参数不能太多，卷积层次也不能太多。</li>
<li><strong>位置准确率</strong>：<code>(x y w h)</code>参数必须准确，也就是检测框大小尺寸要匹配，且重合度IOU要高。SSD和faster
RCNN通过多个bounding box来优化这个问题</li>
<li><strong>漏检率</strong>：必须尽量检测出所有目标物体，特别是靠的近的物体和尺寸小的物体。SSD和faster
RCNN通过多个bounding box来优化这个问题</li>
<li><strong>物体宽高比例不常见</strong>：SSD通过不同尺寸feature
map，yoloV2通过不同尺寸输入图片，来优化这个问题。</li>
<li>靠的近的物体准确率低</li>
<li>小尺寸物体准确率低：SSD取消全连接层，yoloV2增加pass through
layer，采用高分辨率输入图片，来优化这个问题</li>
</ul>
<h1 id="目标检测特殊层">目标检测特殊层</h1>
<h2 id="roipooling">ROIpooling</h2>
<p>ROIs
Pooling顾名思义，是Pooling层的一种，而且是针对RoIs的Pooling，他的特点是输入特征图尺寸不固定，但是输出特征图尺寸固定；</p>
<blockquote>
<p>ROI是Region of Interest的简写，指的是在“特征图上的框”; * 在Fast
RCNN中， RoI是指Selective
Search完成后得到的“候选框”在特征图上的映射，如下图中的红色框所示； *
在Faster
RCNN中，候选框是经过RPN产生的，然后再把各个“候选框”映射到特征图上，得到RoIs。</p>
</blockquote>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327869.png"
alt="@" />
<figcaption aria-hidden="true">@</figcaption>
</figure>
<p>参考faster rcnn中的ROI
Pool层，功能是将不同size的ROI区域映射到固定大小的feature map上。</p>
<h3 id="缺点由于两次量化带来的误差">缺点：由于两次量化带来的误差；</h3>
<ul>
<li>将候选框边界量化为整数点坐标值。</li>
<li>将量化后的边界区域平均分割成<span class="math inline">\(k\times
k\)</span>个单元(bin),对每一个单元的边界进行量化。</li>
</ul>
<h3 id="案例说明">案例说明</h3>
<p>下面我们用直观的例子具体分析一下上述区域不匹配问题。如 图1
所示，这是一个Faster-RCNN检测框架。输入一张<span
class="math inline">\(800\times 800\)</span>的图片，图片上有一个<span
class="math inline">\(665\times
665\)</span>的包围框(框着一只狗)。图片经过主干网络提取特征后，特征图缩放步长（stride）为32。因此，图像和包围框的边长都是输入时的1/32。800正好可以被32整除变为25。但665除以32以后得到20.78，带有小数，于是ROI
Pooling 直接将它量化成20。接下来需要把框内的特征池化<span
class="math inline">\(7\times7\)</span>的大小，因此将上述包围框平均分割成<span
class="math inline">\(7\times7\)</span>个矩形区域。显然，每个矩形区域的边长为2.86，又含有小数。于是ROI
Pooling
再次把它量化到2。经过这两次量化，候选区域已经出现了较明显的偏差（如图中绿色部分所示）。更重要的是，该层特征图上0.1个像素的偏差，缩放到原图就是3.2个像素。那么0.8的偏差，在原图上就是接近30个像素点的差别，这一差别不容小觑。</p>
<p><a
href="https://github.com/ShaoqingRen/caffe/blob/062f2431162165c658a42d717baf8b74918aa18e/src/caffe/layers/roi_pooling_layer.cpp"><code>caffe中实现roi_pooling_layer.cpp</code></a></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="type">void</span> ROIPoolingLayer&lt;Dtype&gt;::<span class="built_in">Forward_cpu</span>(<span class="type">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">      <span class="type">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  <span class="comment">//输入有两部分组成，data和rois</span></span><br><span class="line">  <span class="type">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;<span class="built_in">cpu_data</span>();</span><br><span class="line">  <span class="type">const</span> Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;<span class="built_in">cpu_data</span>();</span><br><span class="line">  <span class="comment">// ROIs的个数</span></span><br><span class="line">  <span class="type">int</span> num_rois = bottom[<span class="number">1</span>]-&gt;<span class="built_in">num</span>();</span><br><span class="line">  <span class="type">int</span> batch_size = bottom[<span class="number">0</span>]-&gt;<span class="built_in">num</span>();</span><br><span class="line">  <span class="type">int</span> top_count = top[<span class="number">0</span>]-&gt;<span class="built_in">count</span>();</span><br><span class="line">  Dtype* top_data = top[<span class="number">0</span>]-&gt;<span class="built_in">mutable_cpu_data</span>();</span><br><span class="line">  <span class="built_in">caffe_set</span>(top_count, <span class="built_in">Dtype</span>(-FLT_MAX), top_data);</span><br><span class="line">  <span class="type">int</span>* argmax_data = max_idx_.<span class="built_in">mutable_cpu_data</span>();</span><br><span class="line">  <span class="built_in">caffe_set</span>(top_count, <span class="number">-1</span>, argmax_data);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For each ROI R = [batch_index x1 y1 x2 y2]: max pool over R</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; num_rois; ++n) &#123;</span><br><span class="line">    <span class="type">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// 把原图的坐标映射到feature map上面</span></span><br><span class="line">    <span class="type">int</span> roi_start_w = <span class="built_in">round</span>(bottom_rois[<span class="number">1</span>] * spatial_scale_);</span><br><span class="line">    <span class="type">int</span> roi_start_h = <span class="built_in">round</span>(bottom_rois[<span class="number">2</span>] * spatial_scale_);</span><br><span class="line">    <span class="type">int</span> roi_end_w = <span class="built_in">round</span>(bottom_rois[<span class="number">3</span>] * spatial_scale_);</span><br><span class="line">    <span class="type">int</span> roi_end_h = <span class="built_in">round</span>(bottom_rois[<span class="number">4</span>] * spatial_scale_);</span><br><span class="line">    <span class="comment">// 计算每个roi在feature map上面的大小</span></span><br><span class="line">    <span class="type">int</span> roi_height = <span class="built_in">max</span>(roi_end_h - roi_start_h + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> roi_width = <span class="built_in">max</span>(roi_end_w - roi_start_w + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="comment">//pooling之后的feature map的一个值对应于pooling之前的feature map上的大小</span></span><br><span class="line">    <span class="comment">//注：由于roi的大小不一致，所以每次都需要计算一次</span></span><br><span class="line">    <span class="type">const</span> Dtype bin_size_h = <span class="built_in">static_cast</span>&lt;Dtype&gt;(roi_height)</span><br><span class="line">                             / <span class="built_in">static_cast</span>&lt;Dtype&gt;(pooled_height_);</span><br><span class="line">    <span class="type">const</span> Dtype bin_size_w = <span class="built_in">static_cast</span>&lt;Dtype&gt;(roi_width)</span><br><span class="line">                             / <span class="built_in">static_cast</span>&lt;Dtype&gt;(pooled_width_);</span><br><span class="line">    <span class="comment">//找到对应的roi的feature map，如果input data的batch size为1</span></span><br><span class="line">    <span class="comment">//那么roi_batch_ind=0</span></span><br><span class="line">    <span class="type">const</span> Dtype* batch_data = bottom_data + bottom[<span class="number">0</span>]-&gt;<span class="built_in">offset</span>(roi_batch_ind);</span><br><span class="line">    <span class="comment">//pooling的过程是针对每一个channel的，所以需要循环遍历</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; channels_; ++c) &#123;</span><br><span class="line">      <span class="comment">//计算output的每一个值，所以需要遍历一遍output，然后求出所有值</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> ph = <span class="number">0</span>; ph &lt; pooled_height_; ++ph) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> pw = <span class="number">0</span>; pw &lt; pooled_width_; ++pw) &#123;</span><br><span class="line">          <span class="comment">// Compute pooling region for this output unit:</span></span><br><span class="line">          <span class="comment">//  start (included) = floor(ph * roi_height / pooled_height_)</span></span><br><span class="line">          <span class="comment">//  end (excluded) = ceil((ph + 1) * roi_height / pooled_height_)</span></span><br><span class="line">          <span class="comment">// 计算output上的一点对应于input上面区域的大小[hstart, wstart, hend, wend]</span></span><br><span class="line">          <span class="type">int</span> hstart = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>(<span class="built_in">static_cast</span>&lt;Dtype&gt;(ph)</span><br><span class="line">                                              * bin_size_h));</span><br><span class="line">          <span class="type">int</span> hend = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">ceil</span>(<span class="built_in">static_cast</span>&lt;Dtype&gt;(ph + <span class="number">1</span>)</span><br><span class="line">                                           * bin_size_h));</span><br><span class="line">          <span class="type">int</span> wstart = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>(<span class="built_in">static_cast</span>&lt;Dtype&gt;(pw)</span><br><span class="line">                                              * bin_size_w));</span><br><span class="line">          <span class="type">int</span> wend = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">ceil</span>(<span class="built_in">static_cast</span>&lt;Dtype&gt;(pw + <span class="number">1</span>)</span><br><span class="line">                                           * bin_size_w));</span><br><span class="line">          <span class="comment">//将映射后的区域平动到对应的位置[hstart, wstart, hend, wend]</span></span><br><span class="line">          hstart = <span class="built_in">min</span>(<span class="built_in">max</span>(hstart + roi_start_h, <span class="number">0</span>), height_);</span><br><span class="line">          hend = <span class="built_in">min</span>(<span class="built_in">max</span>(hend + roi_start_h, <span class="number">0</span>), height_);</span><br><span class="line">          wstart = <span class="built_in">min</span>(<span class="built_in">max</span>(wstart + roi_start_w, <span class="number">0</span>), width_);</span><br><span class="line">          wend = <span class="built_in">min</span>(<span class="built_in">max</span>(wend + roi_start_w, <span class="number">0</span>), width_);</span><br><span class="line">          <span class="comment">//如果映射后的矩形框不符合</span></span><br><span class="line">          <span class="type">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line">          <span class="comment">//pool_index指的是此时计算的output的值对应于output的位置</span></span><br><span class="line">          <span class="type">const</span> <span class="type">int</span> pool_index = ph * pooled_width_ + pw;</span><br><span class="line">          <span class="comment">//如果矩形不符合，此处output的值设为0，此处的对应于输入区域的最大值为-1</span></span><br><span class="line">          <span class="keyword">if</span> (is_empty) &#123;</span><br><span class="line">            top_data[pool_index] = <span class="number">0</span>;</span><br><span class="line">            argmax_data[pool_index] = <span class="number">-1</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//遍历output的值对应于input的区域块</span></span><br><span class="line">          <span class="keyword">for</span> (<span class="type">int</span> h = hstart; h &lt; hend; ++h) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> w = wstart; w &lt; wend; ++w) &#123;</span><br><span class="line">             <span class="comment">// 对应于input上的位置</span></span><br><span class="line">              <span class="type">const</span> <span class="type">int</span> index = h * width_ + w;</span><br><span class="line">              <span class="comment">//计算区域块的最大值，保存在output对应的位置上</span></span><br><span class="line">              <span class="comment">//同时记录最大值的索引</span></span><br><span class="line">              <span class="keyword">if</span> (batch_data[index] &gt; top_data[pool_index]) &#123;</span><br><span class="line">                top_data[pool_index] = batch_data[index];</span><br><span class="line">                argmax_data[pool_index] = index;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Increment all data pointers by one channel</span></span><br><span class="line">      batch_data += bottom[<span class="number">0</span>]-&gt;<span class="built_in">offset</span>(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">      top_data += top[<span class="number">0</span>]-&gt;<span class="built_in">offset</span>(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">      argmax_data += max_idx_.<span class="built_in">offset</span>(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Increment ROI data pointer</span></span><br><span class="line">    bottom_rois += bottom[<span class="number">1</span>]-&gt;<span class="built_in">offset</span>(<span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="roi-align">ROI Align</h2>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327154.png"
alt="@ROIAlign模块使用示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="ROIAlign模块使用示意图">@ROIAlign模块使用示意图</span></figcaption>
</figure>
<p>为了解决ROI Pooling的上述缺点，作者提出了ROI Align这一改进的方法。ROI
Align的思路很简单：取消量化操作，使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值,从而将整个特征聚集过程转化为一个连续的操作。值得注意的是，在具体的算法操作上，ROI
Align并不是简单地补充出候选区域边界上的坐标点，然后将这些坐标点进行池化，而是重新设计了一套比较优雅的流程，如下图所示：
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327566.png"
alt="@浮点坐标计算过程" /></p>
<ul>
<li>遍历每一个候选区域，保持浮点数边界不做量化。</li>
<li>将候选区域分割成<span class="math inline">\(k\times
k\)</span>个单元，每个单元的边界也不做量化。</li>
<li>在每个单元中计算固定四个坐标位置，用双线性内插的方法计算出这四个位置的值，然后进行最大池化操作。</li>
</ul>
<p>这里对上述步骤的第三点作一些说明：这个固定位置是指在每一个矩形单元（bin）中按照固定规则确定的位置。比如，如果采样点数是1，那么就是这个单元的中心点。如果采样点数是4，那么就是把这个单元平均分割成四个小方块以后它们分别的中心点。显然这些采样点的坐标通常是浮点数，所以需要使用插值的方法得到它的像素值。在相关实验中，作者发现将采样点设为4会获得最佳性能，甚至直接设为1在性能上也相差无几。
事实上，ROIAlign在遍历取样点的数量上没有ROIPooling那么多，但却可以获得更好的性能，这主要归功于解决了<strong>misalignment</strong>的问题。值得一提的是，我在实验时发现，ROIAlign在<code>VOC2007</code>数据集上的提升效果并不如在<code>COCO</code>上明显。经过分析，造成这种区别的原因是<code>COCO</code>上小目标的数量更多，而小目标受<strong>misalignment</strong>问题的影响更大（比如，同样是0.5个像素点的偏差，对于较大的目标而言显得微不足道，但是对于小目标，误差的影响就要高很多）。ROIAlign层要将feature
map固定为2*2大小，那些蓝色的点即为采样点，然后每个bin中有4个采样点，则这四个采样点经过MAX得到ROI
output；</p>
<blockquote>
<p>通过双线性插值避免了量化操作，保存了原始ROI的空间分布，有效避免了误差的产生；小目标效果比较好</p>
</blockquote>
<h2 id="nms算法优化的必要性">NMS算法优化的必要性</h2>
<h3 id="nms算法的功能">NMS算法的功能</h3>
<p>非极大值抑制（NMS）非极大值抑制顾名思义就是抑制不是极大值的元素，搜索局部的极大值。例如在对象检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分类及分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是某类对象的概率最大），并且抑制那些分数低的窗口。印象最为深刻的就是Overfeat算法中的狗熊抓鱼图了。</p>
<h3 id="从r-cnn到sppnet">从R-CNN到SPPNet</h3>
<p><span
class="math inline">\(RCNN\)</span>主要作用就是用于物体检测，就是首先通过<span
class="math inline">\(selective search\)</span>选择<span
class="math inline">\(2000\)</span>个候选区域，这些区域中有我们需要的所对应的物体的bounding-box，然后对于每一个region
proposal都wrap到固定的大小的scale, <span
class="math inline">\(227\times227\)</span>(AlexNet
Input),对于每一个处理之后的图片，把他都放到CNN上去进行特征提取，得到每个region
proposal的feature map,这些特征用固定长度的特征集合feature vector来表示。
最后对于每一个类别，我们都会得到很多的feature
vector，然后把这些特征向量直接放到SVM现行分类器去判断，当前region所对应的实物是background还是所对应的物体类别，每个region都会给出所对应的score，因为有些时候并不是说这些region中所包含的实物就一点都不存在，有些包含的多有些包含的少，包含的多少还需要合适的bounding
box，所以我们才会对于每一region给出包含实物类别多少的分数，选出前几个对大数值，然后再用非极大值抑制canny来进行边缘检测，最后就会得到所对应的bounding
box.</p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030327946.png"
alt="Alt text" /> 同样，SPPNet作者观察得，对selective
search(ss)提供的2000多个候选区域都逐一进行卷积处理，势必会耗费大量的时间，
所以SPPNet中先对一整张图进行卷积得到特征图，然后再将ss算法提供的2000多个候选区域的位置记录下来，通过比例映射到整张图的feature
map上提取出候选区域的特征图B,然后将B送入到金字塔池化层中，进行权重计算.
然后经过尝试，这种方法是可行的，于是在RCNN基础上，进行了这两个优化得到了这个新的网络SPPNet.</p>
<h4 id="faster-rcnn-1">Faster RCNN</h4>
<p>NMS算法，非极大值抑制算法，引入NMS算法的目的在于：根据事先提供的score向量，以及regions(由不同的bounding
boxes，矩形窗口左上和右下点的坐标构成)
的坐标信息，从中筛选出置信度较高的bounding boxes。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030328115.jpeg"
alt="@FasterRCNN中的NMS的作用" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FasterRCNN中的NMS的作用">@FasterRCNN中的NMS的作用</span></figcaption>
</figure>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030328393.jpeg"
alt="@FasterRCNN中anchor推荐框的个数" /> Faster
RCNN中输入s=600时，采用了三个尺度的anchor进行推荐，分别时128,256和512，其中推荐的框的个数为<span
class="math inline">\(1106786\)</span>，需要将这<span
class="math inline">\(1100k\)</span>的推荐框合并为<span
class="math inline">\(2k\)</span>个。这个过程其实正是<span
class="math inline">\(RPN\)</span>神经网络模型。</p>
<h3 id="ssd">SSD</h3>
<p>https://blog.csdn.net/wfei101/article/details/78176322
SSD算法中是分为default box(下图中(b)中为default box示意图)和prior
box(实际推荐的框) <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030328935.png"
alt="@SSD算法中的anchor box和default box示意图" /></p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030328355.png"
alt="@SSD算法架构图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="SSD算法架构图">@SSD算法架构图</span></figcaption>
</figure>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030328896.png"
alt="SSD算法推荐框的个数" />
<figcaption aria-hidden="true">SSD算法推荐框的个数</figcaption>
</figure>
<h3 id="注意">注意</h3>
<p>在图像处理领域，几点经验： 1.
输入的图像越大，结果越准确，但是计算量也更多 2.
推荐的框越多，定位准确的概率更高，但是计算量也是会增多 3.
推荐的框往往远大于最终的定位的个数</p>
<p>那么NMS存在什么问题呢，其中最主要的问题有这么几个： -
物体重叠：如下面第一张图，会有一个最高分数的框，如果使用nms的话就会把其他置信度稍低，但是表示另一个物体的预测框删掉（由于和最高置信度的框overlap过大）
-
某些情况下，所有的bbox都预测不准，对于下面第二张图我们看到，不是所有的框都那么精准，有时甚至会出现某个物体周围的所有框都标出来了，但是都不准的情况
-
传统的NMS方法是基于分类分数的，只有最高分数的预测框能留下来，但是大多数情况下IoU和分类分数不是强相关，很多分类标签置信度高的框都位置都不是很准</p>
<h3 id="参考文献">参考文献</h3>
<ol type="1">
<li><a
href="https://www.cnblogs.com/makefile/p/nms.html">NMS的解释</a></li>
<li><a
href="http://www.cnblogs.com/rocbomb/p/4428946.html">附录中ROI的解释</a></li>
<li><a
href="https://blog.csdn.net/u013989576/article/details/73439202/">SSD算法</a></li>
<li><a
href="https://towardsdatascience.com/review-retinanet-focal-loss-object-detection-38fba6afabe4">One-Stage
Detector, With Focal Loss and RetinaNet Using ResNet+FPN, Surpass the
Accuracy of Two-Stage Detectors, Faster R-CNN</a></li>
<li><a
href="https://blog.csdn.net/lcczzu/article/details/86518615">非极大值抑制算法的两个改进算法
&amp; 传统NMS的问题</a></li>
<li><a
href="http://blog.prince2015.club/2018/07/23/NMS/">非极大值抑制算法（NMS）与源码分析</a></li>
</ol>
<h2
id="one-stage和two-stage的anchor-base-detection">one-stage和two-stage的anchor-base
detection</h2>
<p>它们的主要区别 * one-stage网络速度要快很多 *
one-stage网络的准确性要比two-stage网络要低</p>
<h3
id="为什么one-stage网络速度要快很多">为什么one-stage网络速度要快很多？</h3>
<p>首先来看第一点这个好理解，one-stage网络生成的anchor框只是一个逻辑结构，或者只是一个数据块，只需要对这个数据块进行分类和回归就可以，不会像two-stage网络那样，生成的
anchor框会映射到feature
map的区域（rcnn除外），然后将该区域重新输入到全连接层进行分类和回归，每个anchor映射的区域都要进行这样的分类和回归，所以它非常耗时</p>
<h3
id="为什么one-stage网络的准确性要比two-stage网络要低">为什么one-stage网络的准确性要比two-stage网络要低？</h3>
<p>我们来看RCNN，它是首先在原图上生成若干个候选区域，这个候选区域表示可能会是目标的候选区域，注意，这样的候选区域肯定不会特别多，假如我一张图像是<span
class="math inline">\(100\times100\)</span>的，它可能会生成<code>2000</code>个候选框，然后再把这些候选框送到分类和回归网络中进行分类和回归，Fast
R-CNN其实差不多，只不过它不是最开始将原图的这些候选区域送到网络中，而是在最后一个feature
map将这个候选区域提出来，进行分类和回归，它可能最终进行分类和回归的候选区域也只有<code>2000</code>多个并不多。再来看Faster
R-CNN，虽然Faster R-CNN它最终一个feature
map它是每个像素点产生9个anchor，那么<span
class="math inline">\(100\times100\)</span>假如到最终的feature
map变成了<span
class="math inline">\(26\times26\)</span>了，那么生成的anchor就是<span
class="math display">\[26\times 26 \times 9 =
6084\]</span>个，虽然看似很多，但是其实它在RPN网络结束后，它会不断的筛选留下<code>2000</code>多个，然后再从<code>2000</code>多个中筛选留下<code>300</code>多个，然后再将这<code>300</code>多个候选区域送到最终的分类和回归网络中进行训练，所以不管是R-CNN还是Fast-RCNN还是Faster-RCNN，它们最终进行训练的anchor其实并不多，几百到几千，不会存在特别严重的正负样本不均衡问题.
但是我们再来看yolo系列网络，就拿yolo3来说吧，它有三种尺度，<span
class="math inline">\(13\times 13\)</span>，<span
class="math inline">\(26\times 26\)</span>，<span
class="math inline">\(52\times
52\)</span>，每种尺度的每个像素点生成三种anchor，那么它最终生成的anchor数目就是
<span class="math display">\[(13\times 13+26\times 26+52\times52)\times
3 =
10647\]</span>个anchor，而真正负责预测的可能每种尺度的就那么几个，假如一张图片有3个目标，那么每种尺度有三个anchor负责预测，那么10647个anchor中总共也只有9个anchor负责预测，也就是正样本，其余的10638个anchor都是背景anchor，这存在一个严重的正负样本失衡问题，虽然位置损失，类别损失，这10638个anchor不需要参与，但是目标置信度损失，背景anchor参与了，因为</p>
<p><span class="math display">\[总的损失 = 位置损失 + 目标置信度损失 +
类别损失\]</span></p>
<p>所以背景anchor对总的损失有了很大的贡献，但是我们其实不希望这样的，我们更希望的是非背景的anchor对总的损失贡献大一些，这样不利于正常负责预测anchor的学习，而two-stage网络就不存在这样的问题，two-stage网络最终参与训练的或者计算损失的也只有<code>2000</code>个或者<code>300</code>个，它不会有多大的样本不均衡问题，不管是正样本还是负样本对损失的贡献几乎都差不多，所以网络会更有利于负责预测anchor的学习，所以它最终的准确性肯定要高些</p>
<blockquote>
<p>总结</p>
</blockquote>
<p>one-stage网络最终学习的anchor有很多，但是只有少数anchor对最终网络的学习是有利的，而大部分anchor对最终网络的学习都是不利的，这部分的anchor很大程度上影响了整个网络的学习，拉低了整体的准确率；而two-stage网络最终学习的anchor虽然不多，但是背景anchor也就是对网络学习不利的anchor也不会特别多，它虽然也能影响整体的准确率，但是肯定没有one-stage影响得那么严重，所以它的准确率比one-stage肯定要高。</p>
<h3
id="那么什么情况下背景anchor不会拉低这个准确率呢">那么什么情况下背景anchor不会拉低这个准确率呢？</h3>
<p>设置阀值，与真实GrundTruth
IOU阀值设得小一点，只要大于这个阀值，就认为你是非背景anchor（注意这部分anchor只负责计算目标置信度损失，而位置、类别损失仍然还是那几个负责预测的anchor来负责）或者假如一个图片上有非常多的位置都是目标，这样很多anchor都不是背景anchor；总之保证背景anchor和非背景anchor比例差不多，那样可能就不会拉低这个准确率，但是只要它们比例相差比较大，那么就会拉低这个准确率，只是不同的比例，拉低的程度不同而已</p>
<h3
id="解决one-stage网络背景anchor过多导致的不均衡问题方案">解决one-stage网络背景anchor过多导致的不均衡问题方案</h3>
<ul>
<li>采用focal loss，将目标置信度这部分的损失换成focal loss</li>
<li>增大非背景anchor的数量</li>
</ul>
<p>某个像素点生成的三个anchor，与真实GrundTruth重合最大那个负责预测，它负责计算位置损失、目标置信度损失、类别损失，这些不管，它还有另外两个anchor，虽然另外两个anchor不是与真实GrundTruth重合最大，但是只要重合大于某个阀值比如大于<code>0.7</code>，我就认为它是非背景anchor，但注意它只计算目标置信度损失，位置和类别损失不参与计算，而小于<code>0.3</code>的我直接不让它参与目标置信度损失的计算，实现也就是将它的权重置0，这个思想就类似two-stage网络那个筛选机制，从<code>2000</code>多个anchor中筛选<code>300</code>个参与训练或者计算目标置信度损失，相当于我把小于<code>0.3</code>的anchor我都筛选掉了，让它不参与损失计算</p>
<ul>
<li>设置权重
在目标置信度损失计算时，将背景anchor的权重设置得很小，非背景anchor的权重设置得很大。</li>
</ul>
<h3 id="四步交替训练faster-rcnn">四步交替训练Faster RCNN</h3>
<p><a href="https://zhuanlan.zhihu.com/p/34327246">训练RPN网络</a></p>
<p>Faster
RCNN有两种训练方式，一种是四步交替训练法，一种是end-to-end训练法。主文件位于/tools/train_fast_rcnn_alt_opt.py。</p>
<p>第一步，训练RPN，该网络用ImageNet预训练的模型初始化，并端到端微调，用于生成region
proposal;</p>
<p>第二步，由imageNet model初始化，利用第一步的RPN生成的region
proposals作为输入数据，训练Fast
R-CNN一个单独的检测网络，这时候两个网络还没有共享卷积层;</p>
<p>第三步，用第二步的fast-rcnn
model初始化RPN再次进行训练，但固定共享的卷积层，并且只微调RPN独有的层，现在两个网络共享卷积层了;</p>
<p>第四步，由第三步的RPN
model初始化fast-RCNN网络，输入数据为第三步生成的proposals。保持共享的卷积层固定，微调Fast
R-CNN的fc层。这样，两个网络共享相同的卷积层，构成一个统一的网络。</p>
<h2
id="faster-rcnn和yolo的anchor有什么区别">Faster-RCNN和YOLO的anchor有什么区别</h2>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030328516.jpeg"
alt="@FasterRCNN generator anchor" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="FasterRCNN">@FasterRCNN</span> generator anchor</figcaption>
</figure>
<p>可以看到yolov3是直接对你的训练样本进行k-means聚类，由训练样本得来的先验框（anchor），也就是对样本聚类的结果。Kmeans因为初始点敏感，所以每次运行得到的anchor值不一样，但是对应的avg
iou稳定。用于训练的话就需要统计多组anchor，针对固定的测试集比较了。</p>
<ul>
<li><p>https://blog.csdn.net/xiqi4145/article/details/86516511</p></li>
<li><p>https://blog.csdn.net/cgt19910923/article/details/82154401</p></li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>detection</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>认识神经网络：卷积，归一化，优化和语料</title>
    <url>/201907/20190722-deeplearning-note/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>一个基于神经网络模型的视觉模型中，<em>卷积</em>和<em>归一化层</em>是最为耗时的两种layer。卷积数据计算密集类型，今年来大量的优化主要集中在各种设备上的卷积加速。
归一化层通过计算一个批量中的均值与方差来进行特征归一化。众多实践证明，它利于优化且使得深度网络易于收敛。批统计的随机不确定性也作为一个有利于泛化的正则化项。BN
已经成为了许多顶级计算机视觉算法的基础。添加归一化层作为提高算法性能的很好的一种策略，但由于像BN遭受数据同步延时的问题，现在逐渐被一些新的normalization方式所替代。</p>
<h2 id="卷积">卷积</h2>
<h3 id="认识卷积">认识卷积</h3>
<blockquote>
<p>卷积定义</p>
</blockquote>
<p><span class="math display">\[h(x) = f(x)*g(x) = \int_{ - \infty }^{ +
\infty } {f(t)g(x - t)dt}\]</span></p>
<p><span class="math inline">\(f(t)\)</span>先不动， <span
class="math inline">\(g(-t)\)</span>相当于<span
class="math inline">\(g(t)\)</span>函数的图像沿y轴（t=0）做了一次翻转。<span
class="math inline">\(g(x-t)\)</span>相当于<span
class="math inline">\(g(-t)\)</span>的整个图像沿着t轴进行了平移，向右平移了x个单位。他们相乘之后围起来的面积就是<span
class="math inline">\(h(x)\)</span>。</p>
<blockquote>
<p>离散卷积的定义</p>
</blockquote>
<p><span class="math display">\[h(x) = f(x)*g(x) = \sum_{\tau =
-\infty}^{+\infty}f(\tau)g(x-\tau)\]</span></p>
<p>其实，深度学习中的卷积对应于数学中的cross correlation.
从卷积的定义来看，我们当前在深度学习中训练的卷积核是<strong>翻转之后的卷积核</strong>。</p>
<p>下面是一些介绍卷积的文章和常见卷积类型统计表： * <a
href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215">A
Comprehensive Introduction to Different Types of Convolutions in Deep
Learning</a> * <a href="https://blog.yani.io/filter-group-tutorial/">A
Tutorial on Filter Groups (Grouped Convolution)</a> * AlexNet *
MobileNet * <a
href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">An
Introduction to different Types of Convolutions in Deep Learning</a> *
<a href="https://github.com/vdumoulin/conv_arithmetic">Convolution
arithmetic</a> * <a
href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and
Checkerboard Artifacts</a></p>
<table>
<colgroup>
<col style="width: 34%" />
<col style="width: 20%" />
<col style="width: 22%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Convolution Name</th>
<th style="text-align: left;">参考文献</th>
<th style="text-align: left;">典型代表</th>
<th style="text-align: left;">附录</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Convolution</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">AlexNet, VGG</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">1x1</td>
<td style="text-align: left;"><a
href="https://arxiv.org/abs/1312.4400">Network in Network</a></td>
<td style="text-align: left;">GoogLeNet, Inception</td>
<td style="text-align: left;">(1). Dimensionality reduction for
efficient computations;<br>(2).Efficient low dimensional embedding, or
feature pooling; <br>(3). Applying nonlinearity again after
convolution</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Dilated convolution</td>
<td style="text-align: left;"><a
href="https://arxiv.org/abs/1511.07122">Multi-Scale Context Aggregation
by Dilated Convolutions</a></td>
<td style="text-align: left;">语义分割</td>
<td style="text-align: left;">support exponentially expanding receptive
fields without losing resolution or coverage.
Upsampling/poolinglayer(e.g. bilinear interpolation) is deterministic.
(a.k.a. not learnable); <br> 内部数据结构丢失, 空间层级化信息丢失;
<br>小物体信息无法重建 (假设有四个pooling layer则任何小于<span
class="math inline">\(2^4=16\)</span>pixel的物体信息将理论上无法重建。)<br><a
href="https://www.jianshu.com/p/aa1027f95b90">如何理解空洞卷积</a></td>
</tr>
<tr class="even">
<td style="text-align: left;">Group Convolution</td>
<td style="text-align: left;"><a
href="https://arxiv.org/pdf/1605.06489.pdf">Deep Roots:Improving CNN
Efficiency with Hierarchical Filter Groups</a></td>
<td style="text-align: left;">MobileNet, <a
href="https://arxiv.org/abs/1611.05431">ResNeXt</a></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pointwise grouped convolution</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">ShuffleNet</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Depthwise separable convolution</td>
<td style="text-align: left;"><a
href="https://arxiv.org/abs/1610.02357">Xception: Deep Learning with
Depthwise Separable Convolutions</a></td>
<td style="text-align: left;">Xception</td>
<td
style="text-align: left;">MobileNet是典型的代表，通过该卷积，大大降低了计算复杂度和模型大小。也是现在落地产品中移动端常用的操作。</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Deconvolutions</td>
<td style="text-align: left;"><a
href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and
Checkerboard Artifacts</a></td>
<td style="text-align: left;">DSSD</td>
<td
style="text-align: left;">Deconvolution也是一种常用的上采样方式，在物体分割和多尺度检测都可用到</td>
</tr>
<tr class="even">
<td style="text-align: left;">Flattened convolutions</td>
<td style="text-align: left;"><a
href="https://arxiv.org/abs/1412.5474">Flattened convolutional neural
networks for feedforward acceleration</a></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">computation costs due to the significant
reduction of learning parameters.</td>
</tr>
</tbody>
</table>
<h3 id="卷积的实现">卷积的实现</h3>
<p>计算卷积的方法有很多种，常见的有以下几种方法: *
滑窗：这种方法是最直观最简单的方法。但是，该方法不容易实现大规模加速，因此，通常情况下不采用这种方法
(但是也不是绝对不会用，在一些特定的条件下该方法反而是最高效的.) *
im2col: 目前几乎所有的主流计算框架包括[Caffe]<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>,
MXNet等都实现了该方法。该方法把整个卷积过程转化成了GEMM过程，而GEMM在各种BLAS库中都是被极致优化的，一般来说，速度较快.
* FFT:
傅里叶变换和快速傅里叶变化是在经典图像处理里面经常使用的计算方法，但是，在
ConvNet 中通常不采用，主要是因为在 ConvNet
中的卷积模板通常都比较小，例如3×3 等，这种情况下，FFT
的时间开销反而更大. * [Winograd]<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a>: Winograd
是存在已久最近被重新发现的方法，在大部分场景中，Winograd
方法都显示和较大的优势，目前cudnn中计算卷积就使用了该方法.</p>
<h3 id="计算复杂度分析">计算复杂度分析</h3>
<ul>
<li>假设输入<span class="math inline">\(I = R^{C_0H_0W_0}\)</span>,
卷积核大小为<span class="math inline">\(k\)</span>, 输出<span
class="math inline">\(O = R^{C_1H_1W_1}\)</span>，
则卷积过程的计算量为：</li>
</ul>
<p><span class="math display">\[(k^2C_0*H_1W_1)*C_1\]</span></p>
<p>使用Depthwise separable convolution卷积的计算量为:</p>
<p><span class="math display">\[(k^2*H_1W_1*C_0 +
C_0C_1*H_1W_1)\]</span></p>
<p>那么计算量之比为</p>
<p><span class="math display">\[
\frac{(k^2*H_1W_1*C_0 + C_0C_1*H_1W_1)}{(k^2C_0*H_1W_1)*C_1}
=\frac{1}{C_1} + \frac{1}{k^2} \approx \frac{1}{k^2}
\]</span></p>
<p>一般情况下，<span class="math inline">\(k^2 &lt;&lt; C_1\)</span>,
所以当<span
class="math inline">\(k=3\)</span>的时候，计算量之比约为原来的<span
class="math inline">\(\frac{1}{9}\)</span>.</p>
<ul>
<li>假设input的<span class="math inline">\(H_0 = W_0\)</span>，用<span
class="math inline">\(w\)</span>表示，<span
class="math inline">\(k\)</span>是卷积核的大小，<span
class="math inline">\(p\)</span>表示填充的大小，<span
class="math inline">\(s\)</span>表示stride步长</li>
</ul>
<p><span class="math display">\[o = \frac{w - k + 2p}{s} +
1\]</span></p>
<h2 id="normalization">Normalization</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030329562.jpg"
alt="@归一化方法" /> 每个子图表示一个feature map张量，以<span
class="math inline">\(N\)</span>为批处理轴，<span
class="math inline">\(C\)</span>为通道轴，<span
class="math inline">\((H,W)\)</span>作为空间轴。其中蓝色区域内的像素使用相同的均值和方差进行归一化，并通过聚合计算获得这些像素的值。从示意图中可以看出，GN没有在N维度方向上进行拓展，因此batch
size之间是独立的，GPU并行化容易得多。</p>
<ul>
<li>batchNorm是在batch上，对NHW做归一化，对小batchsize效果不好；</li>
<li>layerNorm在通道方向上，对CHW归一化，主要对RNN作用明显；</li>
<li>instanceNorm在图像像素上，对HW做归一化，用在风格化迁移；</li>
<li>GroupNorm将channel分组，然后再做归一化；</li>
<li>SwitchableNorm是将BN、LN、IN结合，赋予权重，让网络自己去学习归一化层应该使用什么方法。</li>
</ul>
<h3 id="batch-normalization">Batch Normalization</h3>
<p>需要比较大的Batch Size，需要更强的计算硬件的支持。</p>
<blockquote>
<p>A small batch leads to inaccurate estimation of the batch statistics,
and reducing BN’s batch size increases the model error dramatically</p>
</blockquote>
<p>尤其是在某些需要高精度输入的任务中，BN有很大局限性。同时，BN的实现是在Batch
size之间进行的，需要大量的数据交换。</p>
<blockquote>
<p>batch normalization存在以下缺点：</p>
</blockquote>
<ul>
<li>对batchsize的大小比较敏感，由于每次计算均值和方差是在一个batch上，所以如果batchsize太小，则计算的均值、方差不足以代表整个数据分布；</li>
<li>BN实际使用时需要计算并且保存某一层神经网络batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其他sequence长很多，这样training时，计算很麻烦。（参考于https://blog.csdn.net/lqfarmer/article/details/71439314）</li>
</ul>
<h3 id="layer-normalizaiton">Layer Normalizaiton</h3>
<p>LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；
BN中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。</p>
<p>所以，LN不依赖于batch的大小和输入sequence的深度，因此可以用于batchsize为1和RNN中对边长的输入sequence的normalize操作。</p>
<h3 id="instance-normalization">Instance Normalization</h3>
<p>BN注重对每个batch进行归一化，保证数据分布一致，因为判别模型中结果取决于数据整体分布。</p>
<p>但是图像风格化中，生成结果主要依赖于某个图像实例，所以对整个batch归一化不适合图像风格化中，因而对HW做归一化。可以加速模型收敛，并且保持每个图像实例之间的独立。</p>
<h3 id="group-normalization">Group Normalization</h3>
<blockquote>
<p>GN does not exploit the batch dimension, and its computation is
independent of batch sizes.</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030329654.png"
alt="@BN,LN,IN,GN result comparison" />
从实验结果中可以看出在训练集合上GN的valid
error低于BN，但是测试结果上逊色一些。这个
可能是因为BN的均值和方差计算的时候，通过<em>随机批量抽样（stochastic
batch sampling)</em>引入了不确定性因素，这有助于模型参数正则化。
<strong>而这种不确定性在GN方法中是缺失的，这个将来可能通过使用不同的正则化算法进行改进。</strong></p>
<h3 id="lrnlocal-response-normalization">LRN（Local Response
Normalization）</h3>
<blockquote>
<p>动机</p>
</blockquote>
<p>在神经深武学有一个概念叫做侧抑制(lateral
inhibitio)，指的是被激活的神经元抑制相邻的神经元。
归一化的目的就是“抑制”，局部响应归一化就是借鉴侧抑制的思想来实现局部抑制，尤其是当我们使用ReLU
的时候，这种侧抑制很管用。</p>
<blockquote>
<p>好处</p>
</blockquote>
<p>有利于增加泛化能力，做了平滑处理，识别率提高1~2%</p>
<h3 id="参考文献">参考文献</h3>
<ul>
<li><a href="https://arxiv.org/abs/1502.03167v2">Batch Normalization:
Accelerating Deep Network Training by Reducing Internal Covariate
Shift</a></li>
<li><a href="https://arxiv.org/abs/1607.06450">Jimmy Lei Ba, Jamie Ryan
Kiros, Geoffrey E. Hinton. Layer normalization.</a></li>
<li><a href="https://arxiv.org/pdf/1803.08494.pdf">Group
Normalization</a></li>
<li><a
href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">AlexNet中提出的LRN</a></li>
<li><a href="https://arxiv.org/abs/1409.1556">VGG：Very Deep
Convolutional Networks for Large-Scale Image Recognition</a></li>
<li><a
href="https://blog.csdn.net/liuxiao214/article/details/81037416">BatchNormalization、LayerNormalization、InstanceNorm、GroupNorm、SwitchableNorm总结</a></li>
<li><a href="https://arxiv.org/abs/1509.09308v2">Fast Algorithms for
Convolutional Neural Networks</a></li>
</ul>
<h2 id="优化">优化</h2>
<h3 id="梯度下降法gradient-descent">梯度下降法（Gradient Descent）</h3>
<p>梯度下降法是最早最简单，也是最为常用的最优化方法。梯度下降法实现简单，当目标函数是凸函数时，梯度下降法的解是全局解。
一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，
因为该方向为当前位置的最快下降方向，所以也被称为是"最速下降法"。最速下降法越接近目标值，步长越小，前进越慢。
梯度下降法的搜索迭代示意图如下图所示：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030329148.png"
alt="@梯度下降法的搜索迭代示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="梯度下降法的搜索迭代示意图">@梯度下降法的搜索迭代示意图</span></figcaption>
</figure>
<p>梯度下降法的缺点： * 靠近极小值时收敛速度减慢，如下图所示； *
直线搜索时可能会产生一些问题； * 可能会“之字形”地下降。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030329863.png"
alt="@梯度下降法的之字形示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="梯度下降法的之字形示意图">@梯度下降法的之字形示意图</span></figcaption>
</figure>
<h3 id="参考文献-1">参考文献</h3>
<ul>
<li><a
href="https://www.quora.com/What-is-the-purpose-for-the-use-of-gradient-descent-in-machine-learning?__filter__=&amp;__nsrc__=2&amp;__snid3__=2889908801&amp;redirected_qid=31223828">梯度下降(gradient
descent)</a></li>
<li><a
href="http://ruder.io/optimizing-gradient-descent/">梯度下降优化算法</a></li>
<li><a
href="http://www.cnblogs.com/shixiangwan/p/7532830.html">常见的几种最优化方法</a></li>
</ul>
<h2 id="其他参考文献">其他参考文献</h2>
<h3 id="深度学习教程">深度学习教程</h3>
<p><a href="https://cs231n.github.io/">CS231n: Convolutional Neural
Networks for Visual Recognition.</a></p>
<h3 id="计算平台">计算平台</h3>
<ol type="1">
<li><a
href="https://en.wikipedia.org/wiki/ARM_architecture">arm平台</a></li>
<li><a
href="https://www.acmesystems.it/arm9_toolchain">linux上编译arm交叉编译链</a></li>
<li><a
href="http://preshing.com/20141119/how-to-build-a-gcc-cross-compiler/">How
to Build a GCC Cross-Compiler</a></li>
</ol>
<h2 id="常用数据集合">常用数据集合</h2>
<p>https://www.analyticsvidhya.com/blog/2018/03/comprehensive-collection-deep-learning-datasets/
这里我们列出了一组高质量的数据集，研究这些数据集将使你成为一个更好的数据科学家。
我们可以使用这些数据集来学习各种深度学习技术，也可以使用它们来磨练您的技能，理解如何识别和构造每个问题，考虑独特的应用场景!</p>
<h3 id="图像类">图像类</h3>
<table>
<colgroup>
<col style="width: 22%" />
<col style="width: 13%" />
<col style="width: 42%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: center;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
<td style="text-align: left;">50MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1710.09829.pdf">Dynamic Routing Between
Capsules</a></td>
<td
style="text-align: center;">手写数字识别，包含60000个训练数据及10000个测试数据，可分为10类</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://cocodataset.org/#home">MSCOCO</a></td>
<td style="text-align: left;">~25G</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1703.06870.pdf">Mask RCNN</a></td>
<td style="text-align: center;">COCO is a large-scale and rich for
object detection, segmentation and captioning dataset. 330K images, 1.5
million object instances, 80 object categories, 5 captions per image,
250,000 people with key points</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://www.image-net.org/">ImageNet</a></td>
<td style="text-align: left;">150GB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1611.05431.pdf">ResNeXt</a></td>
<td style="text-align: center;">ImageNet is a dataset of images that are
organized according to the WordNet hierarchy. WordNet contains
approximately 100,000 phrases and ImageNet has provided around 1000
images on average to illustrate each phrase. Number of Records: Total
number of images: ~1,500,000; each with multiple bounding boxes and
respective class labels</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://github.com/openimages/dataset#download-the-data">Open
Image Dataset</a></td>
<td style="text-align: left;">500GB</td>
<td style="text-align: center;"><a href="">ResNet</a></td>
<td style="text-align: center;">一个包含近900万个图像URL的数据集。
这些图像拥有数千个类别及边框进行了注释。
该数据集包含9,011219张图像的训练集，41,260张图像的验证集以及125,436张图像的测试集。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://www.visualqa.org/">VisualQA</a></td>
<td style="text-align: left;">25GB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1708.02711">Tips and Tricks for Visual
Question Answering: Learnings from the 2017 Challenge</a></td>
<td style="text-align: center;">图像的问答系统数据集 265,016 images, at
least 3 questions per image, 10 ground truth answers per question</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://ufldl.stanford.edu/housenumbers/">The Street View House
Numbers(SVHN)</a></td>
<td style="text-align: left;">2.5GB</td>
<td style="text-align: center;"><a href="">Distributional Smoothing With
Virtual Adversarial Training</a></td>
<td
style="text-align: center;">门牌号数据集，可用来做物体检测与识别</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
<td style="text-align: left;">170MB</td>
<td style="text-align: center;"><a
href="https://openreview.net/pdf?id=S1NHaMW0b">ShakeDrop
regularization</a></td>
<td style="text-align: center;">图像识别数据集，包含
50000张训练数据，10000张测试数据，可分为10类</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a></td>
<td style="text-align: left;">30MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1708.04896">Random Erasing Data
Augmentation</a></td>
<td
style="text-align: center;">包含60000训练样本和10000测试样本的用于服饰识别的数据集，可分为10类。</td>
</tr>
</tbody>
</table>
<h3 id="自然语言处理类">自然语言处理类</h3>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 13%" />
<col style="width: 43%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: left;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
href="http://ai.stanford.edu/~amaas/data/sentiment/">IMDB
影评数据</a></td>
<td style="text-align: left;">80MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1705.09207">Learning Structured Text
Representations</a></td>
<td
style="text-align: left;">可以实现对情感的分类，除了训练集和测试集示例之外，还有更多未标记的数据。原始文本和预处理的数据也包括在内。25,000
highly polar movie reviews for training, and 25,000 for testing</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups">Twenty
Newsgroups</a></td>
<td style="text-align: left;">20MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1606.01781">Very Deep Convolutional Networks
for Text Classification</a></td>
<td
style="text-align: left;">包含20类新闻的文章信息，内类包含1000条数据</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://help.sentiment140.com/for-students/">Sentiment140</a></td>
<td style="text-align: left;">80MB</td>
<td style="text-align: center;"><a
href="http://www.aclweb.org/anthology/W17-5202">Assessing
State-of-the-Art Sentiment Models on State-of-the-Art Sentiment
Datasets</a></td>
<td style="text-align: left;">1,60,000 tweets,用于情感分析的数据集</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://wordnet.princeton.edu/">WordNet</a></td>
<td style="text-align: left;">10MB</td>
<td style="text-align: center;"><a
href="https://aclanthology.info/pdf/R/R11/R11-1097.pdf">Wordnets: State
of the Art and Perspectives</a></td>
<td style="text-align: left;">117,000 synsets is linked to other synsets
by means of a small number of “conceptual relations.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="https://www.yelp.com/dataset">Yelp点评数据集</a></td>
<td style="text-align: left;">2.66GB JSON文件,2.9GB
SQL文件,7.5GB图片数据</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1710.00519.pdf">Attentive
Convolution</a></td>
<td
style="text-align: left;">包括470万条用户评价，15多万条商户信息，20万张图片，12个大都市。此外，还涵盖110万用户的100万条tips，超过120万条商家属性（如营业时间、是否有停车场、是否可预订和环境等信息），随着时间推移在每家商户签到的总用户数。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://nlp.cs.nyu.edu/wikipedia-data/">维基百科语料库（英语）</a></td>
<td style="text-align: left;">20MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1711.03953.pdf">Breaking The Softmax
Bottelneck: A High-Rank RNN language Model</a></td>
<td style="text-align: left;">包含4400000篇文章
及19亿单词，可用来做语言建模</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm">博客作者身份语料库</a></td>
<td style="text-align: left;">300MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1609.06686.pdf">Character-level and
Multi-channel Convolutional Neural Networks for Large-scale Authorship
Attribution</a></td>
<td
style="text-align: left;">从blogger.com收集到的19,320名博主的博客，其中博主的信息包括博主的ID、性别、年龄、行业及星座</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://statmt.org/wmt18/index.html">各种语言的机器翻译数据集</a></td>
<td style="text-align: left;">15GB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/abs/1706.03762">Attention Is All You
Need</a></td>
<td style="text-align: left;">包含英-汉、英-法、英-捷克、英语-
爱沙尼亚、英 - 芬兰、英-德、英 - 哈萨克、英 - 俄、英 -
土耳其之间互译的数据集</td>
</tr>
</tbody>
</table>
<h3 id="语音类">语音类</h3>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 13%" />
<col style="width: 43%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">dataset名称</th>
<th style="text-align: left;">大小</th>
<th style="text-align: center;">State-of-Art</th>
<th style="text-align: left;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a
href="https://github.com/Jakobovski/free-spoken-digit-dataset">Free
Spoken Digit Dataset</a></td>
<td style="text-align: left;">10MB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1712.00866">Raw Waveform-based Audio
Classification Using Sample-level CNN Architectures</a></td>
<td
style="text-align: left;">数字语音识别数据集，包含3个人的声音，每个数字说50遍，共1500条数据</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://github.com/mdeff/fma">Free Music Archive (FMA)</a></td>
<td style="text-align: left;">1000GB</td>
<td style="text-align: center;"><a
href="https://arxiv.org/pdf/1803.05337.pdf">Learning to Recognize
Musical Genre from Audio</a></td>
<td
style="text-align: left;">可以用于对音乐进行分析的数据集，数据集中包含歌曲名称、音乐类型、曲目计数等信息。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="http://mtg.upf.edu/ismir2004/contest/tempoContest/node5.html">Ballroom</a></td>
<td style="text-align: left;">14GB</td>
<td style="text-align: center;"><a href="">A Multi-Model Approach To
Beat Tracking Considering Heterogeneous Music Styles</a></td>
<td
style="text-align: left;">舞厅舞曲数据集，可对舞曲风格进行识别。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="https://labrosa.ee.columbia.edu/millionsong/">Million Song
Dataset</a></td>
<td style="text-align: left;">280GB</td>
<td style="text-align: center;"><a href="">Preliminary Study on a
Recommender System for the Million Songs Dataset Challenge</a></td>
<td style="text-align: left;">Echo
Nest提供的一百万首歌曲的特征数据.该数据集不包含任何音频，但是可以使用他们提供的代码下载音频</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a
href="ttp://www.openslr.org/12/">LibriSpeech</a></td>
<td style="text-align: left;">60GB</td>
<td style="text-align: center;"><a href="">Letter-Based Speech
Recognition with Gated ConvNets</a></td>
<td
style="text-align: left;">包含1000小时采样频率为16Hz的英语语音数据及所对应的文本，可用作语音识别</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a
href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/">VoxCeleb</a></td>
<td style="text-align: left;">150MB</td>
<td style="text-align: center;">VoxCeleb: a large-scale speaker
identification dataset]()</td>
<td style="text-align: left;">大型的说话人识别数据集。
它包含约1,200名来自YouTube视频的约10万个话语。
数据在性别是平衡的（男性占55％）。说话人跨越不同的口音，职业和年龄。
可用来对说话者的身份进行识别。</td>
</tr>
</tbody>
</table>
<h3 id="analytics-vidhya实践问题">Analytics Vidhya实践问题</h3>
<ul>
<li><a
href="https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/register">Twitter情绪分析</a>
<ul>
<li>描述：识别是否包含种族歧视及性别歧视的推文。</li>
<li>大小：3MB</li>
<li>31,962 tweets</li>
</ul></li>
<li><a
href="https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/">印度演员的年龄识别数据集</a>
<ul>
<li>描述：根据人的面部属性，识别人的年龄的数据集。</li>
<li>大小：48MB</li>
<li>19,906 images in the training set and 6636 in the test set</li>
</ul></li>
<li><a
href="https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/">城市声音分类数据集</a>
<ul>
<li>描述：该数据集包含来自10个类的城市声音的8732个标记的声音片段，每个片段时间小于4秒。</li>
<li>大小：训练数据集3GB，训练数据集2GB。</li>
<li>8732 labeled sound excerpts (&lt;=4s) of urban sounds from 10
classes</li>
</ul></li>
</ul>
<h3 id="more-dataset">more dataset</h3>
<ul>
<li><a
href="https://www.jiqizhixin.com/articles/2018-09-05-2">机器之心整理的数据集合</a></li>
<li><a
href="https://github.com/Prasanna1991/DHCD_Dataset">DHCD_Dataset</a></li>
</ul>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://github.com/BVLC/caffe/blob/master/src/caffe/util/im2col.cpp<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>https://arxiv.org/abs/1509.09308v2<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>The history of C++</title>
    <url>/202004/20200401-cplusplus-history/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>在阅读C++相关的技术书籍或博客时，常常会提到一些日常开发中不常接触的名词，如cfront
2.0或者TR1等，这些名词在C++的历史发展中属于里程碑式的的名词。从C++不同时期的发展中可以看出对于程序员的开发需求逐渐满足，伴随着C++的标准的变化，编译器对语言的支持也逐渐完善。</p>
<h2 id="c-历史大事件">C++ 历史大事件</h2>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030335629.png"
alt="wg21-timeline-2019-07" />
<figcaption aria-hidden="true">wg21-timeline-2019-07</figcaption>
</figure>
<h2 id="关键事件总结">关键事件总结</h2>
<table>
<colgroup>
<col style="width: 31%" />
<col style="width: 18%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">date</th>
<th>feature</th>
<th>details</th>
<th>sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1979</td>
<td>首次实现引入类的C</td>
<td>C with Classes first implemented<br>1.
新特性：<strong>类、成员函数、继承类</strong>、独立编译、<strong>公共和私有访问控制、友元、函数参数类型检查、默认参数、内联函数、赋值符号重载、构造函数、析构函数</strong>、f()相当于f(void)、调用函数和返回函数（同步机制，不是在C++中）</br>
2. 库：并发任务程序库（不是在C++中）</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">1985</td>
<td>编译器cfront 1.0</td>
<td>1.
新特性：<strong>虚函数、函数和操作符重载</strong>、<strong>引用</strong>、<strong>new和delete操作符</strong>、<strong>const关键词</strong>、范围解析运算符::<br>2.
新加入的库：复数（complex）、字符串（string）、输入输出流（iostream）</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">1985</td>
<td>《C++编程语言第一版》</td>
<td>The C++ Programming Language, 1st edition</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">1989</td>
<td>编译器cfront 2.0</td>
<td>1.新特性：多重继承、成员指针、保护访问控制、类型安全联接、抽象类、静态和常量成员函数、特定类的new和delete
<br> 2. 新库：I/O 操作器 <br></td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">1990</td>
<td>ANSI C++委员会成立（ANSI C++ Committee founded）</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">1990</td>
<td>《C++参考手册注解》</td>
<td>The Annotated C++ Reference Manual was released.</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">1991</td>
<td>ISO C++委员会成立（ISO C++ Committee founded）</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">1998</td>
<td>C++98</td>
<td>1. 新特性：<strong>运行时类型信息［RTTI（dynamic_cast,
typeid）］</strong>、协变返回类型（covariant return types）、cast
操作符、可变型、布尔型、声明情况、模板例示、成员模板、导出 <br> 2.
新库：容器、算法、迭代器、函数对象（STL中）、区域设置、位集合、值向量、自动指针（auto_ptr）、模块化字符串、输入输出流和复数<br>
the C++ standards committee published the first international standard
for C++ ISO/IEC 14882:1998, which would be informally known as C++98.
The Annotated C++ Reference Manual was said to be a large influence in
the development of the standard. <strong>The Standard Template
Library</strong>, which began its conceptual development in 1979, was
also included.</td>
<td>*****</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1999</td>
<td>Boost由委员会成员成立，旨在开发新的高质量库以作为标准库的候选库</td>
<td>Boost founded by the committee members to produce new high-quality
candidate libraries for the standard</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2003</td>
<td>C++03 (ISO/IEC 14882:2003)</td>
<td>The committee responded to multiple problems that were reported with
their 1998 standard, and revised it accordingly. The changed language
was dubbed <strong>C++03</strong>.
这是一个次要修订版本，修正了一些错误。</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">2006</td>
<td>Performance TR (ISO/IEC TR 18015:2006) (ISO Store ) (2006 draft
)</td>
<td>性能技术报告</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2007</td>
<td>2007 Library extension TR1 (ISO/IEC TR 19768:2007) (ISO store )
(2005 draft )</td>
<td>1. 源自Boost：<strong>引用包装器（Reference
wrapper）</strong>、<strong>智能指针（Smart
pointers）</strong>、成员函数（Member function）、Result of
、绑定（Binding）、函数（Function）、类型特征（type
traits）、随机（Random）、数学特殊函数（Mathematical Special
Functions）、元组（Tuple）、数组（Array）、无序容器［Unordered
Containers包括哈希（Hash）］还有<strong>正则表达式（Regular
Expressions）</strong> <br> 2.
源自C99：math.h中同时也是新加入C99的数学函数、空白字符类、浮点环境（Floating-point
environment）、十六进制浮点I/O操作符（hexfloat I/O
Manipulator）、固定大小整数类型（fixed-size integral
types）、长整型（the long long type）、va_copy、snprintf()
和vscanf()函数族，还有C99 的printf()与scanf()函数族的指定转换。
TR1除了一些特殊函数，大部分都被囊括进C++11。</td>
<td>*****</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2010</td>
<td>数学特殊函数技术报告［2010 Mathematical special functions TR
(ISO/IEC 29124:2010)(ISO Store)］</td>
<td>此TR是一个C++标准库扩展，加入了TR1中的部分特殊函数，但那些函数之前没有被包括进C++11：椭圆积分、指数积分、拉盖尔多项式（Laguerre
polynomials）、勒让徳多项式（Legendre
polynomials）、艾尔米特多项式（Hermite
polynomials）、贝塞尔（Bessel）函数、纽曼（Newmann）函数、<span
class="math inline">\(\beta\)</span>函数和黎曼（Riemann）<span
class="math inline">\(\zeta\)</span>函数</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2011</td>
<td>C++11 (ISO/IEC 14882:2011) (ISO Store) (ANSI Store )</td>
<td>1.
新语言特性：<strong>自动（auto）和类型获取（decltype）</strong>、默认和已删除函数（defaulted
and deleted
functions）、<strong>不可更改（final）和重载（override）</strong>、<strong>拖尾返回类型（trailing
return type）</strong>、<strong>右值引用（rvalue
references）</strong>、<strong>移动构造函数（move
constructors）/移动赋值（move assignment）</strong>、作用域枚举（scoped
enums）、常量表达式（constexpr）和文字类型（literal
types）、<strong>列表初始化（list
initialization）</strong>、授权（delegating）和<strong>继承构造器（inherited
constructors）</strong>、大括号或等号（brace-or-equal）初始化器、<strong>空指针（nullptr）</strong>、长整型（long
long）、char16_t和char32_t、类型别名（type
aliases）、<strong>可变参数模板（variadic
templates）</strong>、广义联合体（generalized
unions）、广义POD、Unicode字符串文字（Unicode string
literals）、自定义文字（user-defined
literals）、属性（attributes）、<strong><span
class="math inline">\(\lambda\)</span>表达式（lambda
expressions）</strong>、无异常（noexcept）、对齐查询（alignof）和对齐指定（alignas）、<strong>多线程内存模型（multithreaded
memory model）、线程本地存储（thread-local
storage）</strong>、<strong>GC接口（GC interface）</strong>、range
for(based on a Boost library)、静态断言［static assertions（based on a
Boost library）］<br> 2.新库特性：原子操作库（atomic operations
library）、<strong>emplace()</strong>和贯穿整个现有库的右值引用的使用、std::initializer_list、状态性的和作用域内的分配器（stateful
and scoped
allocators）、前向列表（forward_list）、<strong>计时库（chrono
library）</strong>、分数库（ratio library）、新算法（new
algorithms）、Unicode conversion facets
<br>3.源自TR1：除了特殊的函数，TR1中全部都被囊括进来
<br>4.源自Boost：线程库（The thread
library）、异常指针（exception_ptr）、错误码（error_code）和错误情况（error_condition）、迭代器改进［iterator
improvements（std::begin, std::end, std::next,
std::prev）］<br>5.源自C：C风格的Unicode转换函数<br>6.搜集错误报告修复：363个错误在2008草案中被解决，另外有322个错误接着被修复。其中的错误包括530号，它使得std::basic_string对象相连。</td>
<td>*****</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2011</td>
<td>十进制浮点技术报告［Decimal floating-point TR (ISO/IEC TR
24733:2011) (ISO Store ) (2009 draft )］</td>
<td>这个TR根据IEEE 754-2008浮点算数标准（Floating Point
Arithmetic）：std::decimal::decimal32、std::decimal::decimal64、std::decimal::decimal128</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2012</td>
<td>标准C++基金会成立</td>
<td>The Standard C++ Foundation founded</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">2013</td>
<td>《C++编程语言第四版》</td>
<td>The C++ Programming Language, 4th edition</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2014</td>
<td>C++14 (2014 final draft )</td>
<td>1. 新语言特性：变量模板（variable
templates）、多态lambda（polymorphic lambdas）、λ动捕获（move capture
for lambdas）、<strong>new/delete
elision</strong>、常量表达式函数放宽限制（relax restrictions on
constexpr functions）、二值文本（binary literals）、数字分隔符（digit
separators）、函数返回类型推演（return type deduction for
functions）、用大括号或等号初始符集合初始化类<br> 2.
新库特性：std::make_unique、std::shared_mutex和std::shared_lock、std::index_sequence、std::exchange、std::quoted，还有许多针对现有库的小改进，比如一些算法的双距离重载（two-range
overloads for some algorithms）、类型特征的类型别名版本（type alias
versions of type traits）、用户定义字符串（user-defined
string）、持续期（duration）和复杂数字文本（complex number
literals）等等<br> 3.搜集错误报告修复：149号库（149 library issues）
基础库技术规范（Library fundamentals TS）, 文件系统技术规范（Filesystem
TS）和其他专业技术规范（ experimental technical specifications）</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="不同编译器对c标准的支持">不同编译器对c++标准的支持</h2>
<p>cfront x.x就是Bjarne
Stroustrup的第一个C++编译器，将C++转换成C语言。在1993年，cfront
4.0因为尝试支持异常机制失败而被取消。我们开发者最长打交道的工具就是编译器了。我们只要通过编写程序语言，编译器会翻译成具体的更底层命令来控制计算机去实现我们的需要的功能。但C++语言标准是一个庞大的特性集合，而不同编译器厂商在根据这个统一标准做编译器的过程中，由于各种原因，不可能支持全部的标准中列举出来的特性。
例如，C++11已经流行多年，很多特性是随着编译器版本release才逐渐支持的，如下图：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030335369.jpg"
alt="@" />
<figcaption aria-hidden="true">@</figcaption>
</figure>
<ul>
<li><p><a
href="https://en.cppreference.com/w/cpp/compiler_support">关于不同编译器对C++不同时期的语言特性的支持程度</a></p></li>
<li><p><a href="https://gcc.gnu.org/projects/cxx-status.html">gnu
gcc对C++语言特定的支持情况以及最低支持版本等信息</a></p></li>
</ul>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="https://gcc.gnu.org/onlinedocs/libstdc++/faq.html">gnu
gcc常见问题</a></li>
<li><a
href="http://www.cplusplus.com/info/history/">C++官方的history页面</a></li>
<li><a
href="https://www.cnblogs.com/fickleness/p/3154937.html">中文博客C++的历史与现状</a></li>
<li><a
href="https://isocpp.org/std/standing-documents/sd-6-sg10-feature-test-recommendations">Feature-Test
Macros and Policies</a></li>
<li><a
href="https://isocpp.org/get-started">各编译器下载地址，包括vs2017社区版</a></li>
</ul>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Inference Framework based TensorRT</title>
    <url>/201911/20191120-TensorRT/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>视觉算法经过几年高速发展，大量的算法被提出。为了能真正将算法在实际应用场景中更好地应用，高性能的
inference框架层出不穷。从手机端上的ncnn到tf-lite，NVIDIA在cudnn之后，推出专用于神经网络推理的TensorRT.
经过几轮迭代，支持的操作逐渐丰富，补充的插件已经基本满足落地的需求。笔者觉得，尤其是tensorrt
5.0之后，无论是接口还是使用samples都变得非常方便集成。</p>
<h2 id="版本选型与基本概念">版本选型与基本概念</h2>
<h3 id="fp16-int8">FP16 INT8</h3>
<p>The easiest way to benefit from mixed precision in your application
is to take advantage of the support for FP16 and INT8 computation in
NVIDIA GPU libraries. Key libraries from the NVIDIA SDK now support a
variety of precisions for both computation and storage.</p>
<p>Table shows the current support for FP16 and INT8 in key CUDA
libraries as well as in PTX assembly and CUDA C/C++ intrinsics.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Feature</th>
<th style="text-align: center;">FP16x2</th>
<th style="text-align: center;">INT8/16 DP4A/DP2A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PTX instructions</td>
<td style="text-align: center;">CUDA 7.5</td>
<td style="text-align: center;">CUDA 8</td>
</tr>
<tr class="even">
<td style="text-align: center;">CUDA C/C++ intrinsics</td>
<td style="text-align: center;">CUDA 7.5</td>
<td style="text-align: center;">CUDA 8</td>
</tr>
<tr class="odd">
<td style="text-align: center;">cuBLAS GEMM</td>
<td style="text-align: center;">CUDA 7.5</td>
<td style="text-align: center;">CUDA 8</td>
</tr>
<tr class="even">
<td style="text-align: center;">cuFFT</td>
<td style="text-align: center;">CUDA 7.5</td>
<td style="text-align: center;">I/O via cuFFT callbacks</td>
</tr>
<tr class="odd">
<td style="text-align: center;">cuDNN</td>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">TensorRT</td>
<td style="text-align: center;">v1</td>
<td style="text-align: center;">v2 Tech Preview</td>
</tr>
</tbody>
</table>
<h3 id="ptx">PTX</h3>
<p>PTX(parallel-thread-execution，并行线程执行)
预编译后GPU代码的一种形式，开发者可以通过编译选项
“-keep”选择输出PTX代码，当然开发人员也可以直接编写PTX级代码。另外，PTX是独立于GPU架构的，因此可以重用相同的代码适用于不同的GPU架构。
具体可参考CUDA-PDF之<a
href="https://docs.nvidia.com/cuda/parallel-thread-execution/">《PTX ISA
reference document》</a></p>
<p>建议我们的CUDA 版本为CUDA 8.0以上,
显卡至少为<code>GeForce 1060</code>,
如果想支持Int8/DP4A等feature，还是需要<code>RTX 1080</code>或者<code>P40</code>。</p>
<h2 id="tensorrt特性助力高性能算法">TensorRT特性助力高性能算法</h2>
<h3 id="优化原理">优化原理</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030332591.png"
alt="@优化原理" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="优化原理">@优化原理</span></figcaption>
</figure>
<h3 id="网络模型的裁剪与重构">网络模型的裁剪与重构</h3>
<figure>
<img src="https://miro.medium.com/max/965/1*PyNcjHKZ8rQ48QCPsdQ9wA.png"
alt="@原始网络" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="原始网络">@原始网络</span></figcaption>
</figure>
<p><img src="https://miro.medium.com/max/951/1*bJts223Qo55toZ9AY60Ruw.png" alt="@vertical fusion｜" style="zoom:67%;" /></p>
<p>The above figures explain the vertical fusion optimization that TRT
does. The Convolution (C), Bias(B) and Activation(R, ReLU in this case)
are all collapsed into one single node (implementation wise this would
mean a single CUDA kernel launch for C, B and R).</p>
<p><img src="https://miro.medium.com/max/2000/0*UKwCx_lq-oHcLYkI.png" alt="@horizontal fusion｜" style="zoom:67%;" /></p>
<p>There is also a horizontal fusion where if multiple nodes with same
operation are feeding to multiple nodes then it is converted to one
single node feeding multiple nodes. The three 1x1 CBRs are fused to one
and their output is directed to appropriate nodes. Other optimizations
Apart from the graph optimizations, TRT, through experiments and based
on parameters like batch size, convolution kernel(filter) sizes, chooses
efficient algorithms and kernels(CUDA kernels) for operations in
network.</p>
<h3 id="低精度计算的支持">低精度计算的支持</h3>
<ul>
<li>FP16 &amp; Int8指令的支持</li>
<li>DP4A(Dot Product of 4 8-bits Accumulated to a 32-bit)</li>
</ul>
<p>TensorRT 进行优化的方式是 DP4A (Dot Product of 4 8-bits Accumulated
to a 32-bit)，如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030332475.png"
alt="@DP4A原理过程" /> 这是PASCAL
系列GPU的硬件指令，INT8卷积就是使用这种方式进行的卷积计算。更多关于DP4A的信息可以参考<a
href="https://devblogs.nvidia.com/mixed-precision-programming-cuda-8/">Mixed-Precision
Programming with CUDA 8</a></p>
<p>INT8 vector dot products (DP4A) improve the efficiency of radio
astronomy cross-correlation by a large factor compared to FP32
computation.</p>
<figure>
<img
src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/10/cross-correlation-efficiency-p40-624x453.png"
alt="@INT8 vector dot products (DP4A) improve the efficiency of radio astronomy cross-correlation by a large factor compared to FP32 computation" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="INT8">@INT8</span> vector dot products (DP4A) improve the
efficiency of radio astronomy cross-correlation by a large factor
compared to FP32 computation</figcaption>
</figure>
<h3 id="硬件方面tensor-core的支持优化卷积运算">硬件方面Tensor
Core的支持，优化卷积运算</h3>
<p>这个需要硬件的支持，如果没有类似Volta架构的GPU就不要强求。</p>
<h2 id="framework-todo-schedule">Framework TODO SCHEDULE</h2>
<ul>
<li><strong>model load sample</strong>
模型初始化当前包括通过parser初始化和通过模型流初始化的方式。通过parser初始化过程相比较来说比较慢，因为包含parser过程
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
caffe model</li>
<li><input type="checkbox" disabled="" checked="" />
gie model</li>
</ul></li>
<li>plugin &amp; extend layers
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
设计plugin的管理机制,更新初始化流程</li>
<li><input type="checkbox" disabled="" />
<a href="https://github.com/hszhao/PSPNet">interp</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a
href="https://github.com/rbgirshick/caffe-fast-rcnn/tree/0dcd397b29507b8314e252e850518c5695efbb83">ROIPooling</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="">RPNProposal</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="">PriorBox</a></li>
<li><input type="checkbox" disabled="" />
<a href="">ChannelShuffle</a></li>
<li><input type="checkbox" disabled="" />
<a href="">CTC</a></li>
<li><input type="checkbox" disabled="" />
<a href="">SLLSTM</a></li>
</ul></li>
<li>int8 quantity inference
<ul class="task-list">
<li><input type="checkbox" disabled="" />
矫正算法的设计</li>
<li><input type="checkbox" disabled="" />
量化数据集合的管理，这个可以和NNIE的量化数据统一起来管理</li>
<li><input type="checkbox" disabled="" />
与研究侧共同确定各个层量化的范围</li>
<li><input type="checkbox" disabled="" />
最后更新inference模式</li>
</ul></li>
</ul>
<h2 id="document-for-reference">Document for Reference</h2>
<ul>
<li><a href="http://nvdla.org/">NVDLA官网</a></li>
<li><a
href="https://devblogs.nvidia.com/production-deep-learning-nvidia-gpu-inference-engine/">NVIDIA
blog: Production Deep Learning with NVIDIA GPU Inference Engine</a></li>
<li><a
href="https://developer.download.nvidia.cn/compute/machine-learning/tensorrt/docs/5.1/rc/TensorRT-Support-Matrix-Guide.pdf">TensorRT
5.1的技术参数文档</a></li>
<li><a
href="http://nvdla.org/sw/runtime_environment.html">nvdla-sw-Runtime
environment</a></li>
<li><a
href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">Szymon
Migacz, NVIDIA: 8-bit Inference with TensorRT</a></li>
<li><a
href="https://arleyzhang.github.io/articles/923e2c40/">INT8量化校准原理</a></li>
<li><a
href="https://devblogs.nvidia.com/mixed-precision-programming-cuda-8/">Mixed-Precision
Programming with CUDA 8</a></li>
<li><a
href="https://medium.com/tensorflow/high-performance-inference-with-tensorrt-integration-c4d78795fbfe">Tensorflow使用TensorRT高速推理</a></li>
<li><a
href="https://on-demand.gputechconf.com/gtc/2019/video/_/S9431/">Tensorflow使用TensorRT高速推理视频</a></li>
</ul>
<h2 id="附录">附录</h2>
<h3 id="init.caffemodel">Init.CaffeModel</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[I] Output &quot;prob&quot;: 1000x1x1</span><br><span class="line">[I] [TRT] Applying generic optimizations to the graph for inference.</span><br><span class="line">[I] [TRT] Original: 141 layers</span><br><span class="line">[I] [TRT] After dead-layer removal: 141 layers</span><br><span class="line">[I] [TRT] After scale fusion: 141 layers</span><br><span class="line">[I] [TRT] Fusing conv1/7x7_s2 with conv1/relu_7x7</span><br><span class="line">[I] [TRT] Fusing conv2/3x3_reduce with conv2/relu_3x3_reduce</span><br><span class="line">。。。</span><br><span class="line">[I] [TRT] Fusing inception_5b/pool_proj with inception_5b/relu_pool_proj</span><br><span class="line">[I] [TRT] After vertical fusions: 84 layers</span><br><span class="line">[I] [TRT] After swap: 84 layers</span><br><span class="line">[I] [TRT] After final dead-layer removal: 84 layers</span><br><span class="line">[I] [TRT] Merging layers: inception_3a/1x1 + inception_3a/relu_1x1 || inception_3a/3x3_reduce + inception_3a/relu_3x3_reduce || inception_3a/5x5_reduce + inception_3a/relu_5x5_reduce</span><br><span class="line">[I] [TRT] Merging layers: inception_3b/1x1 + inception_3b/relu_1x1 || inception_3b/3x3_reduce + inception_3b/relu_3x3_reduce || inception_3b/5x5_reduce + inception_3b/relu_5x5_reduce</span><br><span class="line">。。。</span><br><span class="line">[I] [TRT] Merging layers: inception_5b/1x1 + inception_5b/relu_1x1 || inception_5b/3x3_reduce + inception_5b/relu_3x3_reduce || inception_5b/5x5_reduce + inception_5b/relu_5x5_reduce</span><br><span class="line">[I] [TRT] After tensor merging: 66 layers</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_3a/output</span><br><span class="line">[I] [TRT] Generating copy for inception_3a/1x1 + inception_3a/relu_1x1 || inception_3a/3x3_reduce + inception_3a/relu_3x3_reduce || inception_3a/5x5_reduce + inception_3a/relu_5x5_reduce to inception_3a/output</span><br><span class="line">[I] [TRT] Retargeting inception_3a/3x3 to inception_3a/output</span><br><span class="line">[I] [TRT] Retargeting inception_3a/5x5 to inception_3a/output</span><br><span class="line">[I] [TRT] Retargeting inception_3a/pool_proj to inception_3a/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_3b/output</span><br><span class="line">[I] [TRT] Generating copy for inception_3b/1x1 + inception_3b/relu_1x1 || inception_3b/3x3_reduce + inception_3b/relu_3x3_reduce || inception_3b/5x5_reduce + inception_3b/relu_5x5_reduce to inception_3b/output</span><br><span class="line">[I] [TRT] Retargeting inception_3b/3x3 to inception_3b/output</span><br><span class="line">[I] [TRT] Retargeting inception_3b/5x5 to inception_3b/output</span><br><span class="line">[I] [TRT] Retargeting inception_3b/pool_proj to inception_3b/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4a/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4a/1x1 + inception_4a/relu_1x1 || inception_4a/3x3_reduce + inception_4a/relu_3x3_reduce || inception_4a/5x5_reduce + inception_4a/relu_5x5_reduce to inception_4a/output</span><br><span class="line">[I] [TRT] Retargeting inception_4a/3x3 to inception_4a/output</span><br><span class="line">[I] [TRT] Retargeting inception_4a/5x5 to inception_4a/output</span><br><span class="line">[I] [TRT] Retargeting inception_4a/pool_proj to inception_4a/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4b/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4b/1x1 + inception_4b/relu_1x1 || inception_4b/3x3_reduce + inception_4b/relu_3x3_reduce || inception_4b/5x5_reduce + inception_4b/relu_5x5_reduce to inception_4b/output</span><br><span class="line">[I] [TRT] Retargeting inception_4b/3x3 to inception_4b/output</span><br><span class="line">[I] [TRT] Retargeting inception_4b/5x5 to inception_4b/output</span><br><span class="line">[I] [TRT] Retargeting inception_4b/pool_proj to inception_4b/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4c/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4c/1x1 + inception_4c/relu_1x1 || inception_4c/3x3_reduce + inception_4c/relu_3x3_reduce || inception_4c/5x5_reduce + inception_4c/relu_5x5_reduce to inception_4c/output</span><br><span class="line">[I] [TRT] Retargeting inception_4c/3x3 to inception_4c/output</span><br><span class="line">[I] [TRT] Retargeting inception_4c/5x5 to inception_4c/output</span><br><span class="line">[I] [TRT] Retargeting inception_4c/pool_proj to inception_4c/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4d/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4d/1x1 + inception_4d/relu_1x1 || inception_4d/3x3_reduce + inception_4d/relu_3x3_reduce || inception_4d/5x5_reduce + inception_4d/relu_5x5_reduce to inception_4d/output</span><br><span class="line">[I] [TRT] Retargeting inception_4d/3x3 to inception_4d/output</span><br><span class="line">[I] [TRT] Retargeting inception_4d/5x5 to inception_4d/output</span><br><span class="line">[I] [TRT] Retargeting inception_4d/pool_proj to inception_4d/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_4e/output</span><br><span class="line">[I] [TRT] Generating copy for inception_4e/1x1 + inception_4e/relu_1x1 || inception_4e/3x3_reduce + inception_4e/relu_3x3_reduce || inception_4e/5x5_reduce + inception_4e/relu_5x5_reduce to inception_4e/output</span><br><span class="line">[I] [TRT] Retargeting inception_4e/3x3 to inception_4e/output</span><br><span class="line">[I] [TRT] Retargeting inception_4e/5x5 to inception_4e/output</span><br><span class="line">[I] [TRT] Retargeting inception_4e/pool_proj to inception_4e/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_5a/output</span><br><span class="line">[I] [TRT] Generating copy for inception_5a/1x1 + inception_5a/relu_1x1 || inception_5a/3x3_reduce + inception_5a/relu_3x3_reduce || inception_5a/5x5_reduce + inception_5a/relu_5x5_reduce to inception_5a/output</span><br><span class="line">[I] [TRT] Retargeting inception_5a/3x3 to inception_5a/output</span><br><span class="line">[I] [TRT] Retargeting inception_5a/5x5 to inception_5a/output</span><br><span class="line">[I] [TRT] Retargeting inception_5a/pool_proj to inception_5a/output</span><br><span class="line">[I] [TRT] Eliminating contatenation inception_5b/output</span><br><span class="line">[I] [TRT] Generating copy for inception_5b/1x1 + inception_5b/relu_1x1 || inception_5b/3x3_reduce + inception_5b/relu_3x3_reduce || inception_5b/5x5_reduce + inception_5b/relu_5x5_reduce to inception_5b/output</span><br><span class="line">[I] [TRT] Retargeting inception_5b/3x3 to inception_5b/output</span><br><span class="line">[I] [TRT] Retargeting inception_5b/5x5 to inception_5b/output</span><br><span class="line">[I] [TRT] Retargeting inception_5b/pool_proj to inception_5b/output</span><br><span class="line">[I] [TRT] After concat removal: 66 layers</span><br><span class="line">[I] [TRT] Graph construction and optimization completed in 0.00874238 seconds.</span><br><span class="line">[I] [TRT] </span><br><span class="line">[I] [TRT] --------------- Timing conv1/7x7_s2 + conv1/relu_7x7(3)</span><br><span class="line">[I] [TRT] Tactic 0 time 0.370688</span><br><span class="line">[I] [TRT] </span><br><span class="line">[I] [TRT] --------------- Timing conv1/7x7_s2 + conv1/relu_7x7(14)</span><br><span class="line">[I] [TRT] Tactic 3146172331490511787 time 0.694752</span><br><span class="line">[I] [TRT] Tactic 3528302785056538033 time 0.429056</span><br><span class="line">[I] [TRT] Tactic -6618588952828687390 time 0.419296</span><br><span class="line">[I] [TRT] Tactic -6362554771847758902 time 0.371168</span><br><span class="line">[I] [TRT] Tactic -2701242286872672544 time 0.685056</span><br><span class="line">[I] [TRT] Tactic -675401754313066228 time 0.365568</span><br><span class="line">[I] [TRT] </span><br><span class="line">。。。</span><br><span class="line">[I] [TRT] Tactic 5 time 0.032192</span><br><span class="line">[I] [TRT] </span><br><span class="line">[I] [TRT] --------------- Timing loss3/classifier(15)</span><br><span class="line">[I] [TRT] Tactic 2624962759642542471 time 0.07424</span><br><span class="line">[I] [TRT] Tactic 6241535668063793554 time 0.094688</span><br><span class="line">[I] [TRT] Tactic 8292480392881939394 time 0.074752</span><br><span class="line">[I] [TRT] Tactic 8436800165353340181 time 0.059936</span><br><span class="line">[I] [TRT] Tactic -7597689592892725774 time 0.09216</span><br><span class="line">[I] [TRT] --------------- Chose 6 (5)</span><br><span class="line">[I] [TRT] </span><br><span class="line">[I] [TRT] --------------- Timing prob(11)</span><br><span class="line">[I] [TRT] Tactic 0 is the only option, timing skipped</span><br><span class="line">[I] [TRT] Formats and tactics selection completed in 10.0197 seconds.</span><br><span class="line">[I] [TRT] After reformat layers: 66 layers</span><br><span class="line">[I] [TRT] Block size 1073741824</span><br><span class="line">[I] [TRT] Block size 12845056</span><br><span class="line">[I] [TRT] Block size 9633792</span><br><span class="line">[I] [TRT] Block size 3211264</span><br><span class="line">[I] [TRT] Block size 3211264</span><br><span class="line">[I] [TRT] Total Activation Memory: 1102643200</span><br><span class="line">[I] [TRT] Detected 1 input and 1 output network tensors.</span><br><span class="line">[I] [TRT] Data initialization and engine generation completed in 0.0458818 seconds.</span><br><span class="line">loadmodel time: 10322 ms</span><br><span class="line">infer time: 8.20 ms</span><br></pre></td></tr></table></figure>
<h3 id="init.giemodel">Init.GIEModel</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[I] [TRT] Glob Size is 40869280 bytes.</span><br><span class="line">[I] [TRT] Added linear block of size 3211264</span><br><span class="line">[I] [TRT] Added linear block of size 2408448</span><br><span class="line">[I] [TRT] Added linear block of size 802816</span><br><span class="line">[I] [TRT] Added linear block of size 802816</span><br><span class="line">[I] [TRT] Deserialize required 13227 microseconds.</span><br><span class="line">[I] googlenet_gie.bin has been successfully loaded.</span><br><span class="line">loadmodel time: 36 ms</span><br><span class="line">infer time: 2.80 ms</span><br></pre></td></tr></table></figure>
<h3
id="iplugin接口中需要被重载的函数">IPlugin接口中需要被重载的函数</h3>
<ol type="1">
<li><p>确定输出：一个是通过<code>int getNbOutput()</code>得到output输出的数目，即用户所定义的一层有几个输出。另一个是通过<code>Dims getOutputDimensions (int index, const Dims* inputs, int nbInputDims)</code>
得到整个输出的维度信息，大家可能不一定遇到有多个输出，一般来讲只有一个输出，但是大家在做检测网络的时候可能会遇到多个输出，一个输出是实际的检测目标是什么，另一个输出是目标的数目，可能的过个输出需要设定Dimension的大小。</p></li>
<li><p>层配置：通过<code>void configure()</code>
实现构建推断（Inference）
engine时模型中相应的参数大小等配置，configure()只是在构建的时候调用，这个阶段确定的东西是在运行时作为插件参数来存储、序列化/反序列化的。</p></li>
<li><p>资源管理：通过<code>void Initialize()</code>来进行资源的初始化，<code>void terminate()</code>来销毁资源，甚至中间可能会有一些临时变量，也可以使用这两个函数进行初始化或销毁。需要注意的是，void
Initialize()和void
terminate()是在整个运行时都被调用的，并不是做完一次推断（Inference）就去调用terminate。相当于在线的一个服务，服务起的时候会调用void
Initialize()，而服务止的时候调用void
terminate()，但是服务会进进出出很多sample去做推断（Inference）。</p></li>
<li><p>执行(Execution)：<code>void enqueue()</code>来定义用户层的操作</p></li>
<li><p>序列化和反序列化：这个过程是将层的参数写入到二进制文件中，需要定义一些序列化的方法。通过<code>size_t getSerializationSize()</code>获得序列大小，通过void
serialize()将层的参数序列化到缓存中，通过PluginSample()从缓存中将层参数反序列化。需要注意的是，TensorRT没有单独的反序列化的API，因为不需要，在实习构造函数的时候就完成了反序列化的过程</p></li>
<li><p>从Caffe
Parser添加Plugin：首先通过<code>Parsernvinfer1::IPlugin* createPlugin()</code>实现nvcaffeparser1::IPlugin
接口，然后传递工厂实例到<code>ICaffeParser::parse()</code>，Caffe的Parser才能识别</p></li>
<li><p>运行时创建插件：通过<code>IPlugin* createPlugin()</code>实现nvinfer1::IPlugin接口，传递工厂实例到<code>IInferRuntime::deserializeCudaEngine()</code></p></li>
</ol>
<h3 id="tensorrt-中已经实现的plugin">TensorRT 中已经实现的Plugin</h3>
<p>打开verbose logger之后可以看到如下输出，相关的调用接口如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[V] [TRT] Plugin Creator registration succeeded - GridAnchor_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - NMS_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - Reorg_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - Region_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - Clip_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - LReLU_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - PriorBox_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - Normalize_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - RPROI_TRT</span><br><span class="line">[V] [TRT] Plugin Creator registration succeeded - BatchedNMS_TRT</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief Create a plugin layer that fuses the RPN and ROI pooling using user-defined parameters.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;RPROI_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param featureStride Feature stride.</span></span><br><span class="line"><span class="comment">//! \param preNmsTop Number of proposals to keep before applying NMS.</span></span><br><span class="line"><span class="comment">//! \param nmsMaxOut Number of remaining proposals after applying NMS.</span></span><br><span class="line"><span class="comment">//! \param iouThreshold IoU threshold.</span></span><br><span class="line"><span class="comment">//! \param minBoxSize Minimum allowed bounding box size before scaling.</span></span><br><span class="line"><span class="comment">//! \param spatialScale Spatial scale between the input image and the last feature map.</span></span><br><span class="line"><span class="comment">//! \param pooling Spatial dimensions of pooled ROIs.</span></span><br><span class="line"><span class="comment">//! \param anchorRatios Aspect ratios for generating anchor windows.</span></span><br><span class="line"><span class="comment">//! \param anchorScales Scales for generating anchor windows.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \return Returns a FasterRCNN fused RPN+ROI pooling plugin. Returns nullptr on invalid inputs.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createRPNROIPlugin</span><span class="params">(<span class="type">int</span> featureStride, <span class="type">int</span> preNmsTop,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                                <span class="type">int</span> nmsMaxOut, <span class="type">float</span> iouThreshold, <span class="type">float</span> minBoxSize,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                                <span class="type">float</span> spatialScale, nvinfer1::DimsHW pooling,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                                nvinfer1::Weights anchorRatios, nvinfer1::Weights anchorScales)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Normalize plugin layer normalizes the input to have L2 norm of 1 with scale learnable.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;Normalize_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param scales Scale weights that are applied to the output tensor.</span></span><br><span class="line"><span class="comment">//! \param acrossSpatial Whether to compute the norm over adjacent channels (acrossSpatial is true) or nearby spatial locations (within channel in which case acrossSpatial is false).</span></span><br><span class="line"><span class="comment">//! \param channelShared Whether the scale weight(s) is shared across channels.</span></span><br><span class="line"><span class="comment">//! \param eps Epsilon for not diviiding by zero.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createNormalizePlugin</span><span class="params">(<span class="type">const</span> nvinfer1::Weights* scales, <span class="type">bool</span> acrossSpatial, <span class="type">bool</span> channelShared, <span class="type">float</span> eps)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The PriorBox plugin layer generates the prior boxes of designated sizes and aspect ratios across all dimensions (H x W).</span></span><br><span class="line"><span class="comment">//! PriorBoxParameters defines a set of parameters for creating the PriorBox plugin layer.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;PriorBox_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createPriorBoxPlugin</span><span class="params">(nvinfer1::plugin::PriorBoxParameters param)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Grid Anchor Generator plugin layer generates the prior boxes of</span></span><br><span class="line"><span class="comment">//! designated sizes and aspect ratios across all dimensions (H x W) for all feature maps.</span></span><br><span class="line"><span class="comment">//! GridAnchorParameters defines a set of parameters for creating the GridAnchorGenerator plugin layer.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;GridAnchor_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createAnchorGeneratorPlugin</span><span class="params">(nvinfer1::plugin::GridAnchorParameters* param, <span class="type">int</span> numLayers)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The DetectionOutput plugin layer generates the detection output based on location and confidence predictions by doing non maximum suppression.</span></span><br><span class="line"><span class="comment">//! DetectionOutputParameters defines a set of parameters for creating the DetectionOutput plugin layer.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;NMS_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createNMSPlugin</span><span class="params">(nvinfer1::plugin::DetectionOutputParameters param)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The LReLu plugin layer performs leaky ReLU for 4D tensors. Give an input value x, the PReLU layer computes the output as x if x &gt; 0 and negative_slope //! x if x &lt;= 0.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;LReLU_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param negSlope Negative_slope value.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createLReLUPlugin</span><span class="params">(<span class="type">float</span> negSlope)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Reorg plugin reshapes input of shape CxHxW into a (C*stride*stride)x(H/stride)x(W/stride) shape, used in YOLOv2.</span></span><br><span class="line"><span class="comment">//! It does that by taking 1 x stride x stride slices from tensor and flattening them into (stridexstride) x 1 x 1 shape.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;Reorg_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param stride Strides in H and W, it should divide both H and W. Also stride * stride should be less than or equal to C.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createReorgPlugin</span><span class="params">(<span class="type">int</span> stride)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Region plugin layer performs region proposal calculation: generate 5 bounding boxes per cell (for yolo9000, generate 3 bounding boxes per cell).</span></span><br><span class="line"><span class="comment">//! For each box, calculating its probablities of objects detections from 80 pre-defined classifications (yolo9000 has 9416 pre-defined classifications,</span></span><br><span class="line"><span class="comment">//! and these 9416 items are organized as work-tree structure).</span></span><br><span class="line"><span class="comment">//! RegionParameters defines a set of parameters for creating the Region plugin layer.</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;Region_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createRegionPlugin</span><span class="params">(nvinfer1::plugin::RegionParameters params)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The Clip Plugin performs a clip operation on the input tensor. It</span></span><br><span class="line"><span class="comment">//! clips the tensor values to a specified min and max. Any value less than clipMin are set to clipMin.</span></span><br><span class="line"><span class="comment">//! Any values greater than clipMax are set to clipMax. For example, this plugin can be used</span></span><br><span class="line"><span class="comment">//! to perform a Relu6 operation by specifying clipMin=0.0 and clipMax=6.0</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;Clip_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//! \param layerName The name of the TensorRT layer.</span></span><br><span class="line"><span class="comment">//! \param clipMin The minimum value to clip to.</span></span><br><span class="line"><span class="comment">//! \param clipMax The maximum value to clip to.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createClipPlugin</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* layerName, <span class="type">float</span> clipMin, <span class="type">float</span> clipMax)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief The BatchedNMS Plugin performs non_max_suppression on the input boxes, per batch, across all classes.</span></span><br><span class="line"><span class="comment">//! It greedily selects a subset of bounding boxes in descending order of</span></span><br><span class="line"><span class="comment">//! score. Prunes away boxes that have a high intersection-over-union (IOU)</span></span><br><span class="line"><span class="comment">//! overlap with previously selected boxes. Bounding boxes are supplied as [y1, x1, y2, x2],</span></span><br><span class="line"><span class="comment">//! where (y1, x1) and (y2, x2) are the coordinates of any</span></span><br><span class="line"><span class="comment">//! diagonal pair of box corners and the coordinates can be provided as normalized</span></span><br><span class="line"><span class="comment">//! (i.e., lying in the interval [0, 1]) or absolute.</span></span><br><span class="line"><span class="comment">//! The plugin expects two inputs.</span></span><br><span class="line"><span class="comment">//! Input0 is expected to be 4-D float boxes tensor of shape [batch_size, num_boxes,</span></span><br><span class="line"><span class="comment">//! q, 4], where q can be either 1 (if shareLocation is true) or num_classes.</span></span><br><span class="line"><span class="comment">//! Input1 is expected to be a 3-D float scores tensor of shape [batch_size, num_boxes, num_classes]</span></span><br><span class="line"><span class="comment">//! representing a single score corresponding to each box.</span></span><br><span class="line"><span class="comment">//! The plugin returns four outputs.</span></span><br><span class="line"><span class="comment">//! num_detections : A [batch_size] int32 tensor indicating the number of valid</span></span><br><span class="line"><span class="comment">//! detections per batch item. Can be less than keepTopK. Only the top num_detections[i] entries in</span></span><br><span class="line"><span class="comment">//! nmsed_boxes[i], nmsed_scores[i] and nmsed_classes[i] are valid.</span></span><br><span class="line"><span class="comment">//! nmsed_boxes : A [batch_size, max_detections, 4] float32 tensor containing</span></span><br><span class="line"><span class="comment">//! the co-ordinates of non-max suppressed boxes.</span></span><br><span class="line"><span class="comment">//! nmsed_scores : A [batch_size, max_detections] float32 tensor containing the</span></span><br><span class="line"><span class="comment">//! scores for the boxes.</span></span><br><span class="line"><span class="comment">//! nmsed_classes :  A [batch_size, max_detections] float32 tensor containing the</span></span><br><span class="line"><span class="comment">//! classes for the boxes.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! Registered plugin type &quot;BatchedNMS_TRT&quot;. Registered plugin version &quot;1&quot;.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI nvinfer1::IPluginV2* <span class="title">createBatchedNMSPlugin</span><span class="params">(nvinfer1::plugin::NMSParameters param)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! \brief Initialize and register all the existing TensorRT plugins to the Plugin Registry with an optional namespace.</span></span><br><span class="line"><span class="comment">//! The plugin library author should ensure that this function name is unique to the library.</span></span><br><span class="line"><span class="comment">//! This function should be called once before accessing the Plugin Registry.</span></span><br><span class="line"><span class="comment">//! \param logger Logger object to print plugin registration information</span></span><br><span class="line"><span class="comment">//! \param libNamespace Namespace used to register all the plugins in this library</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="function">TENSORRTAPI <span class="type">bool</span> <span class="title">initLibNvInferPlugins</span><span class="params">(<span class="type">void</span>* logger, <span class="type">const</span> <span class="type">char</span>* libNamespace)</span></span>;</span><br></pre></td></tr></table></figure>
<p>https://medium.com/<span class="citation"
data-cites="r7vme/converting-neural-network-to-tensorrt-part-1-using-existing-plugins-edd9c2b9e42a">@r7vme/converting-neural-network-to-tensorrt-part-1-using-existing-plugins-edd9c2b9e42a</span></p>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>inference</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title>自然场景文本检测与识别</title>
    <url>/201908/20190809-scene-text-detection-component/</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<p>基于深度学习算法的的自然场景文本检测，经过几年的研究，针对解决实际问题中的某些问题，涌现出CTC,
LSTM等大量的单元。在深度学习之前，已经有大量的优秀工作如SWT，MSER等算法被提出，这里我将先对一些OCR领域的经典作品进行介绍，然后再引入OCR中的深度学习算法。</p>
<h1 id="经典算法在ocr应用中的问题9">经典算法在OCR应用中的问题<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h1>
<ul>
<li>文本定位，尤其是非水平的文本定位问题，例如SWT算子是比较常用的文本定位算法，但针对非水平文本定位存在一定的局限性。</li>
<li>无法处理序列不定长的问题</li>
<li>文字大小不一的问题</li>
</ul>
<h1 id="开源数据集合">开源数据集合</h1>
<figure>
<img src="../../images/ocr/ocr-opendataset.png"
alt="@数据集合用途统计" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="数据集合用途统计">@数据集合用途统计</span></figcaption>
</figure>
<figure>
<img src="../../images/ocr/ocr-opendataset2.png"
alt="@数据集合标注属性统计" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="数据集合标注属性统计">@数据集合标注属性统计</span></figcaption>
</figure>
<h1 id="swt算子1">SWT算子<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></h1>
<ul>
<li><a
href="http://cmp.felk.cvut.cz/~cernyad2/TextCaptchaPdf/Detecting%20Text%20in%20Natural%20Scenes%20with%20Stroke%20Width%20Transform.pdf"><code>Paper: Detecting Text in Natural Scenes with Stroke Width Transform</code></a></li>
<li><a
href="https://github.com/aperrau/DetectText"><code>github: https://github.com/aperrau/DetectText</code></a></li>
</ul>
<p>下面根据原文的结构和上述提供的代码详细的解读一下该算法。总的来说该算法分为四步：
* 利用<code>canny</code>算子检测图片的边界 * 笔画宽度变换-Stroke Width
Transform（这一步输出的图像我们称为SWT图像） *
通过<code>SWT</code>图像得到多个连通域 *
通过自定义的规则过滤一些连通域，得到候选连通域 *
将连通域合并得到文本行</p>
<h3 id="step-1利用canny算子检测图片的边界">Step
1：利用canny算子检测图片的边界</h3>
<p>这步不用多说，基础的图像处理知识，利用OpenCV
的Canny函数可以得到图片边缘检测的结果。</p>
<h3 id="step-2笔画宽度变换stroke-width-transform">Step
2：笔画宽度变换（Stroke Width Transform）</h3>
<p>这一步输出图像和输入图像大小一样，只是输出图像像素为笔画的宽度，具体如下。
<img src="../../images/ocr/SWT_01.png" /></p>
<p>如上图所示，通过边缘检测得到上图a，假设现在从边缘上的点p开始，根据p点梯度的反方向找到边缘另一边的点q，如果p点的梯度与q点梯度的反方向夹角在<span
class="math inline">\(\pm\pi/6\)</span>之间，那么这两点间的距离为一个笔画宽度，那么p点和q点以及它们之间的像素在SWT输出图像中对应位置的值为p和q点的距离大小。</p>
<p>按照上述的计算方法会有两种情况需要考虑。如下图所示，</p>
<p><img src="../../images/ocr/SWT_02.png" /></p>
<p>下图a表示一个笔画中的像素可能得到两个笔画宽度，这种情况下将红点出的笔画宽度设置为最小的那个值，下图b表示当一个笔画出现更为复杂情况，b图中的红点计算出的两个笔画宽度用两个红线表示，这两红线都无法真正表示笔画的宽度，这时候笔画宽度取这里面所有像素计算得到的笔画宽度的中值作为红点出的笔画宽度。</p>
<p>因为有文字比背景更亮和背景比文字更亮两种情况，这样会导致边缘的梯度方向相反，所以这一个步骤要执行两遍。这个步骤结束后得到一张SWT图像。</p>
<h3 id="step-3通过swt图像得到多个连通域">Step
3：通过SWT图像得到多个连通域</h3>
<p>在通过上述步骤得到SWT输出图像后，该图像大小与原图像大小一致，图像中的像素值为对应像素所在笔画的宽度（下面称为SWT值）。现将相邻像素SWT值比不超过3.0的归为一个连通域。这样就能得到多个连通域。</p>
<h3 id="step-4过滤连通域">Step 4：过滤连通域</h3>
<p>上述步骤输出的多个连通域中，并不是所有的连通域都被认为是笔画候选区域，需要过滤一些噪声的影响，过滤的规则有：
*
如果某连通域的方差过大（方差大于连通域的一半为方差过大为过大），则认为该连通域不是有效的
*
如果某连通域过大（宽大于300）或者过小（宽小于10），则认为该连通域不是有效的（代码中只过滤了过大的连通域，连通域的长宽为连通域外接矩形的长宽）
*
如果某连通域的长宽比不在0.1-10的范围内，则认为该连通域不是有效的（连通域的长宽为连通域外接矩形的长宽）
*
如果某连通域的外接矩形包含其他两个连通域，则认为该连通域不是有效的（代码中判定，如果某个连通域的外接矩形包含两个或两个以上连通域外接矩形的中心时，认为其包含了两个连通域）
上述条件都满足的连通域，认为是笔画候选区域，用于输入给下一步操作。</p>
<h3 id="step-5将连通域合并得到文本行">Step
5：将连通域合并得到文本行</h3>
<p>文中认为，在自然场景中，一般不会只有单个字母出现，所有将连通域合并为文本有利于进一步将噪声排除。</p>
<p>当两个连通域满足下面条件时，认为这两个连通域是一对： *
两个连通域中值的比小于2.0（连通域中值，指的是连通域中所有像素值的中值）
* 两个连通域高的比小于2.0（连通域的高，指其外界矩形的高） *
两个连通域之间的距离小于较宽的连通域宽度的3倍（连通域之间的距离为连通域外界矩形中心点之间的距离）
*
两个连通域的颜色相似（代码用两个连通域对应于原图区域的像素均值代表该连通域的颜色）</p>
<p>得到两两连通域组成的多对连通域后，如果有两对连通域有共享的连通域，共享的连通域都在连通域对的一端（即连通域的首端或者尾端），且方向相同（方向用一个连通域中心到另一个连通域中心的方向），就将这两对连通域合并为一个新的连通域组，依次进行，知道没有连通域对需要合并则合并结束。</p>
<p>最后将合并完的结果中滤除小于3的连通域的连通域组得到的最终结果，认为是一行文字。</p>
<h1 id="最大极值稳定区域mser分析2">最大极值稳定区域MSER分析<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></h1>
<p>最大稳定极值区域MSER是一种类似分水岭图像的分割与匹配算法，它具有仿射不变性。极值区域反映的就是集合中的像素灰度值总大于或小于其邻域区域像素的灰度值。对于最大稳定区域，通过局部阈值集操作，区域内的像素数量变化是最小的。</p>
<p>MSER的基本原理是对一幅灰度图像（灰度值为0～255）取阈值进行二值化处理，阈值从0到255依次递增。阈值的递增类似于分水岭算法中的水面的上升，随着水面的上升，有一些较矮的丘陵会被淹没，如果从天空往下看，则大地分为陆地和水域两个部分，这类似于二值图像。在得到的所有二值图像中，图像中的某些连通区域变化很小，甚至没有变化，则该区域就被称为最大稳定极值区域。这类似于当水面持续上升的时候，有些被水淹没的地方的面积没有变化。</p>
<p>上述做法只能检测出灰度图像的黑色区域，不能检测出白色区域，因此还需要对原图进行反转，然后再进行阈值从0～255的二值化处理过程。这两种操作又分别称为MSER+和MSER-。</p>
<p>MSER是当前认为性能最好的仿射不变性区域的检测方法，其使用不同灰度阈值对图像进行二值化来得到最稳定区域，表现特征有以下三点：
* 对图像灰度仿射变化具有不变性， * 对区域支持相对灰度变化具有稳定性， *
对区域不同精细程度的大小区域都能进行检测。</p>
<p>MSER最大极值稳定区域的提取步骤： * 像素点排序 * 极值区域生成 *
稳定区域判定 * 区域拟合 * 区域归一化</p>
<h1 id="hmm-ctc">HMM &amp; CTC</h1>
<h3 id="问题">问题</h3>
<p>序列学习任务需要从未分割的输入数据中预测序列的结果。HMM模型与CRF模型是序列标签任务中主要使用的框架，这些方法对于许多问题已经获得了较好的效果，但是它们也有缺点：</p>
<ul>
<li>需要大量任务相关的知识，例如，HMM中的状态模型，CRF中的输入特征选择</li>
<li>需要有独立性假设作为支撑；</li>
<li>对于标准的HMM模型，它是生成式的，但是序列标签时判别式的。</li>
</ul>
<p>RNN网络除了输入与输出的表达方式需要选择之外不需要任何数据的先验。
它可以进行判别训练，它的内部状态为构建时间序列提供了强大的通用机制。
此外，其对时间和空间噪声具有很强的鲁棒性。</p>
<p>但是对于RNN呢，它是不能拿来做序列预测的，这是<strong>因为RNN只能去预测一些独立标签的分类，因而就需要进行序列预分割</strong>。要解决该问题，那么将RNN与HMM结合起来被称之为hybrid
approach。在该方法中使用HMM为长序列结构数据建立模型，神经网络就提供局部分类。加入HMM之后可以使得在训练中自动分割序列，并且将原本的网络分类转换到标签序列。然而，它并没有避免上述内容中HMM使用缺点。</p>
<h3 id="引入ctc">引入CTC</h3>
<p>CTC( Connectionist Temporal
Classification)，可以解决前面提到的两点局限，直接使用序列进行训练。CTC引入了一个<strong>新的损失函数</strong>，可以使得RNN网络可以直接使用未切分的序列记性训练。为了使用这个损失函数，
为RNN引入其可以输出的"BLANK"标签, RNN的输出是所有标签的概率。
这里将Temporal Classification定义为<span
class="math inline">\(h\)</span>，训练数据集合<span
class="math inline">\(S\)</span>中数据是成对存在的<span
class="math inline">\((\mathbf{x},z)\)</span>，其中<span
class="math inline">\(\mathbf{x}\)</span>是训练的时序数据，<span
class="math inline">\(z\)</span>是标签数据。目标就是找到一个时序分类器<span
class="math inline">\(h\)</span>使得<span
class="math inline">\(S\)</span>中的<span
class="math inline">\(x\)</span>被分类到<span
class="math inline">\(z\)</span>。训练这个分类器，就需要一个错误度量，这里就借鉴了编辑（ED）距离度量，而引入了label
error rate（LER）。在这里还对其进行了归一化，从而得到了如下的形式：</p>
<p><span class="math display">\[LER(h, S) =
\frac{1}{Z}\sum_{(\mathbf{x},z)\in S} ED(h(\mathbf{x}))\]</span></p>
<p>将网络输出转换成为基于标签序列的条件概率，从而可以使用分类器对输入按照概率大小进行分类。</p>
<h3 id="从网络输出到连续标签">从网络输出到连续标签</h3>
<p>在CTC网络中拥有一个<span
class="math inline">\(softmax\)</span>输出层，其输出的个数为<span
class="math inline">\(∣L∣+1\)</span>，<span
class="math inline">\(L\)</span>是标签元素的集合，额外的一个那当然就是"BLANK"标签了。这些输出定义了将所有可能的标签序列与输入序列对齐的所有可能路径的概率。任何一个标签序列的总概率可以通过对其不同排列的概率求和得到。
首先对于一条可行的路径<span
class="math inline">\(p(\pi|x)\)</span>被定义为对应路径上的各个时刻输出预测概率的乘积。其定义如下：</p>
<p><span class="math display">\[p(\pi|x) = \prod^T_{t=1}y_{\pi_t}^t,
\quad \forall \pi \in L&#39;^T\]</span></p>
<p>对于预测结果中的一条路径的标签，论文中假设这些不同时刻网络的输出是相互独立的，而这种独立性是通过输出层与自身或网络之间不存在反馈连接来确保实现的。</p>
<p>在此基础上还定义了映射函数<span
class="math inline">\(B\)</span>，它的职责就是去除"BLANK"与重复的标签。因而给定的一个标签其输出概率就可以描述为几个可行路径相加和的形式:</p>
<p><span class="math display">\[ p(l|\mathbf{x}) = \sum_{\pi \in
B^{-1}(l)} p(\pi|\mathbf{x}) \]</span></p>
<h3 id="构建分类器">构建分类器</h3>
<p>从上面的内容中已经得到了一个序列标签的输出条件概率，那么怎么才能找到输入数据最匹配的标签呢？最为直观的便是求解</p>
<p><span class="math display">\[h(X) = \arg\max_{l\in L \le T}
p(l|\mathbf{x})\]</span></p>
<p>在给定输入情况下找到其最可能的标签序列，这样的过程使用HMM中的术语叫做解码。目前，还没有一种通过易理解的解码算法，但下面的两种方法在实践过程中也取得了不错的效果。</p>
<h4 id="最佳路径解码">最佳路径解码</h4>
<p>该方法是建立在概率最大的路径与最可能的标签时对应的，因而分类器就被描述为如下形式：</p>
<p><span class="math display">\[h(\mathbf{x}) \approx
B(\pi^*)\]</span></p>
<p><span class="math display">\[where\quad \pi^* = \arg\max_{\pi \in
N^t}p(\pi|\mathbf{x})\]</span></p>
<p>从上面的形式中就可以看出，最佳路径解码的计算式很容易的，因为最佳路径中的元素是各个时刻输出的级联。但是呢，这是不能保证找到最可能的标签的。</p>
<h4 id="前缀解码">前缀解码</h4>
<p>前缀解码在足够时间的情况下会找到最可能的标签，但是随着输入序列长度的增强时间也会指数增加。如果输入的概率分布是尖状的，那么可以在合理的时间内找到最可能的路径。</p>
<p>实践中，前缀搜索在这个启发式下工作得很好，通常超过了最佳路径解码，但是在有些情况下，效果不佳。</p>
<h1 id="ctc网络训练">CTC网络训练</h1>
<p>目标函数是由极大似然原理导出的。也就是说，最小化它可以最大化目标标签的对数可能性。有了损失函数之后就可以使用依靠梯度进行优化的算法进行最优化。</p>
<p>CTC在网络中放置在双向递归网络的后面作为序列预测的损失来源。CTC会在RNN网络中传播梯度，进而使得其学习一条好路径。</p>
<h3 id="ctc前向传播算法">CTC前向传播算法</h3>
<p>需要一种有效的方法来计算单个标签的条件概率<span
class="math inline">\(p(l|\mathbf{x})\)</span>。对于这样的问题，其实就是对应于给定标签的所有路径的综合。通常有很多这样的路径。这里我们采用动态规划的算法计算所有可能路径的概率和，其思想是，与标签对应的路径和可以分解为与标签前缀对应的路径的迭代和。
然后，可以使用递归向前和向后变量有效地计算迭代。
以下是本文设计到的一些符号定义：</p>
<ul>
<li><span class="math inline">\(y_{k}^{t}\)</span>, 时刻t的输出字符<span
class="math inline">\(k\)</span></li>
<li><span class="math inline">\(l\)</span>, 标签序列对应的损失。</li>
<li><span
class="math inline">\(l^{\prime}\)</span>，相同的标签序列，但是在字符之间添加了"BLANK"标签</li>
</ul>
<p><span class="math display">\[\alpha_t(s) \overset{def}{=} \sum_{\pi
\in N^T: \atop B(\pi_{1:t}) = l_{1:s}} \prod^t_{t^{\prime} = 1}
y_{\pi_{t^{\prime}}}^{t^{\prime}}.\]</span></p>
<p>其中B是溢出所有"BLANK"与重复字符的变换；<span
class="math inline">\({\pi \in N^T:B(\pi_{1:t}) = l_{1:s}}\)</span>
是时刻1到t的预测矩阵中，给出经过变换<span
class="math inline">\(B\)</span>之后与标签有前s个一致的所有可行路径；<span
class="math inline">\(y^{t^{\prime}}\)</span> 是指时刻<span
class="math inline">\(t^{\prime}\)</span>时RNN的输出。而且<span
class="math inline">\(\alpha_{t}(s)\)</span>可以通过<span
class="math inline">\(\alpha_{t-1}(s)\)</span>与<span
class="math inline">\(\alpha_{t-1}(s-1)\)</span>迭代计算出来。</p>
<p>图3中描述的状态转移图与上面公式的含义是相同的。为了能够在输出路径中出现"BLANK"标签，将标签修改成了<span
class="math inline">\(l^{\prime}\)</span>，也就是在标签的前后与字符之前插入空白标签，因而生成的标签长度就变成了<span
class="math inline">\(2|l|+1\)</span>的长度，使其可以再空白标签与非空白标签之间转换，也可以使非空白标签之间发生转换。
上面的公式1中已经给出了其计算的内容，但其计算并不具有可行性。但是可以根据图3中<span
class="math inline">\(\alpha_{t}(s)\)</span>的递归定义使用动态规划算法去解决该问题，仔细看这幅图，是不是有点像HMM的前向计算过程。</p>
<p>对于解决该问题使用动态规划的算法进行解决，首先来分析时刻1时候的情况：</p>
<p><span class="math display">\[\alpha_1(1) = y_b^1\]</span></p>
<p><span class="math display">\[\alpha_1(2) =
y_{l^{\prime}}^1\]</span></p>
<p><span class="math display">\[\alpha_1(s) = 0, \forall s &gt;
2\]</span></p>
<p><span class="math display">\[\alpha_t(s) = \begin{cases}
a_t(s)y_{l_{s}^{\prime}}^t, \quad if\quad l_s^{\prime} = b\quad
or\quad  l_{s-2}^{\prime} = l_s^{\prime}\\
(\bar{\alpha_t}(s) +\alpha_{t-1}(s -2))y_{l_{s}^{\prime}}^t, \quad
otherwise
\end{cases}\]</span></p>
<p>where <span class="math inline">\(\alpha_t(s) \overset{def}{=}
\alpha_{t-1}(s) + \alpha_{t-1}(s-1)\)</span>
最后就可以得到一个序列的输出概率</p>
<p><span class="math display">\[p(l|\mathbf{x}) = \alpha_T(|l^{\prime}|)
+ \alpha_T(|l^{\prime}| -1)\]</span></p>
<h3 id="反向传播算法">反向传播算法</h3>
<p>反向传播的变量<span
class="math inline">\(\beta_{t}(s)\)</span>被定义为<span
class="math inline">\(t\)</span>时刻<span
class="math inline">\(l_{s:|l|}\)</span>的总概率 <span
class="math display">\[
\beta_{t}(s) \stackrel{\mathrm{def}}{=} \sum_{\pi \in N^{T} \atop
\mathcal{B}(\pi_{t : T}) = l_{s:|l|}} \prod_{t^{\prime}=t}^{T}
y_{\pi_{t^{\prime}}^{\prime}}^{t^{\prime}}
\]</span></p>
<p><span class="math display">\[
\beta_{T}\left(\left|\mathbf{l}^{\prime}\right|\right)=y_{b}^{T}            \\
\beta_{T}\left(\left|\mathbf{l}^{\prime}\right|-1\right)=y_{l_{|l|}}^{T}    \\
\beta_{T}(s)=0, \quad \forall
s&lt;\left|\mathbf{l}^{\prime}\right|-1          \\
\beta_{t}(s)=\left\{
    \begin{array}{ll}{
        \overline{\beta}_{t}(s) y_{1 s}^{t}} &amp; {\text { if }
1_{s}^{\prime}=b \text { or } 1_{s+2}^{\prime}=1_{s}^{\prime}} \\
        {\left(\overline{\beta}_{t}(s)+\beta_{t+1}(s+2)\right)
y_{1_{s}^{t}}} &amp; {\text { otherwise }}
    \end{array}
\right.
\]</span></p>
<p><span class="math display">\[
\begin{array}{l}{
\text {where}}
{\quad\overline{\beta}_{t}(s) \stackrel{\mathrm{def}}{=}
\beta_{t+1}(s)+\beta_{t+1}(s+1)}
\end{array}
\]</span></p>
<h3 id="最大似然训练">最大似然训练</h3>
<p>最大似然训练的目的是同时最大化训练集中所有正确分类的对数概率。因而这里可以将损失函数定义为：</p>
<p><span class="math display">\[
O^{M L}\left(S, \mathcal{N}_{w}\right)=-\sum_{(\mathbf{x}, \mathbf{z})
\in S} \ln (p(\mathbf{z} | \mathbf{x}))
\]</span></p>
<p>为了使用梯度进行网络训练，因而就需要对网络的输出进行微分，且训练样本是相互独立的，也就是说可以单独考虑了，因而可以将微分写为：</p>
<p><span class="math display">\[
\frac{\partial O^{M L}\left(\{(\mathbf{x}, \mathbf{z})\},
\mathcal{N}_{w}\right)}{\partial y_{k}^{t}}=-\frac{\partial \ln
(p(\mathbf{z} | \mathbf{x}))}{\partial y_{k}^{t}}
\]</span></p>
<p>这里可以用前向后向算法计算上式。主要思想是：对于一个标记l，在给定s和t的情况下，前向和后向变量的内积是对应l所有可能路径的概率。表达式为：</p>
<p><span class="math display">\[
\alpha_{t}(s) \beta_{t}(s)=\sum_{\pi \in \mathcal{B}^{-1}(1) : \atop
{\pi_t = l_s^{\prime}}} y_{1_{s}}^{t} \prod_{t=1}^{T} y_{\pi_{t}}^{t}
\]</span></p>
<p>且根据上面的公式（2）联合可以得到：</p>
<p><span class="math display">\[
\frac{\alpha_{t}(s) \beta_{t}(s)}{y_{1_{s}^{t}}^{t}}=\sum_{\pi \in
\mathcal{B}^{-1}(1): \atop {\pi_t = l_s^{\prime}}} p(\pi | \mathbf{x})
\]</span></p>
<p>再与前面的公式（3）联合可以得到</p>
<p><span class="math display">\[
p(\mathbf{l} | \mathbf{x})=\sum_{s=1}^{\left|\mathbf{l}^{\prime}\right|}
\frac{\alpha_{t}(s) \beta_{t}(s)}{y_{1_{s}^{\prime}}^{t}}
\]</span></p>
<h1 id="rlstmreverse-lstm">RLSTM(Reverse LSTM)</h1>
<ul>
<li>RNN<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></li>
<li>LSTM<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a><a href="#fn6" class="footnote-ref"
id="fnref6" role="doc-noteref"><sup>6</sup></a></li>
</ul>
<h3 id="reverse-lstm">Reverse LSTM</h3>
<p>整体架构如下，其中需要用到Reverse这种Layer</p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030331430.png" /></p>
<h1 id="channelshuffle">ChannelShuffle</h1>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030331220.png" /></p>
<p>一般的分组卷积(如ResNeXt的)仅对<span
class="math inline">\(3\times3\)</span>的层进行了分组操作，然而<span
class="math inline">\(1\times1\)</span>的pointwise卷积占据了绝大多数的乘加操作，在小模型中为了减少运算量只能减少通道数，然而减少通道数会大幅损害模型精度。作者提出了对<span
class="math inline">\(1\times1\)</span>也进行分组操作，但是如图１(a)所示，输出只由部分输入通道决定。为了解决这个问题，作者提出了图(c)中的通道混淆(channel
shuffle)操作来分享组间的信息，假设一个卷基层有g
groups，每个group有n个channel，因此shuffle后会有<span
class="math inline">\(g\times
n\)</span>个通道，首先将输出的通道维度变形为(g,
n)，然后转置(transpose)、展平(flatten)，shuffle操作也是可导的。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030331913.png" /></p>
<p>图2 (a)是一个将卷积替换为depthwise卷积<a href="#fn7"
class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a>的residual block，(b)中将两个<span
class="math inline">\(1\times1\)</span>卷积都换为pointwise group
convolution，然后添加了channel shuffle，为了简便，没有在第二个pointwise
group convolution后面加channel
shuffle。根据Xception的论文，depthwise卷积后面没有使用ReLU。(c)为stride
&gt; 1的情况，此时在shotcut path上使用<span
class="math inline">\(3\times3\)</span>的平均池化，并将加法换做通道concatenation来增加输出通道数(一般的设计中，stride=2的同时输出通道数乘2)。</p>
<p>对于<span class="math inline">\(c \times h \times
w\)</span>的输入大小，bottleneck channels为m，则ResNet unit需要<span
class="math inline">\(hw(2cm + 9m^2)FLOPs\)</span>，ResNeXt需要<span
class="math inline">\(hw(2cm + 9m^2/g)FLOPs\)</span>，ShuffleNet
unit只需要<span class="math inline">\(hw(2cm/g +
9m)FLOPs\)</span>，g表示卷积分组数。换句话说，在有限计算资源有限的情况下，ShuffleNet可以使用更宽的特征图，作者发现对于小型网络这很重要。</p>
<p>即使depthwise卷积理论上只有很少的运算量，但是在移动设备上的实际实现不够高效，和其他密集操作(dense
operation)相比，depthwise卷积的computation/memory access
ratio很糟糕。因此作者只在bottleneck里实现了depthwise卷积。</p>
<h1 id="ctpn4">CTPN<a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a></h1>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030331690.png"
alt="@The-Arch-of-CTPN" /> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_planes, out_planes,</span></span><br><span class="line"><span class="params">                 kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 dilation=<span class="number">1</span>, groups=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 relu=<span class="literal">True</span>, bn=<span class="literal">True</span>, bias=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicConv, self).__init__()</span><br><span class="line">        self.out_channels = out_planes</span><br><span class="line">        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)</span><br><span class="line">        self.bn = nn.BatchNorm2d(out_planes, eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>) <span class="keyword">if</span> bn <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>) <span class="keyword">if</span> relu <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="keyword">if</span> self.bn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.bn(x)</span><br><span class="line">        <span class="keyword">if</span> self.relu <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">Commom_C = <span class="number">512</span></span><br><span class="line">anchor_k = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CTPN_Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        base_model = models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">        layers = <span class="built_in">list</span>(base_model.features)[:-<span class="number">1</span>]</span><br><span class="line">        self.base_layers = nn.Sequential(*layers)  <span class="comment"># block5_conv3 output</span></span><br><span class="line">        self.prelstm = BasicConv(Commom_C, Commom_C, <span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>,bn=<span class="literal">False</span>)</span><br><span class="line">        self.bilstm = nn.GRU(Commom_C, Commom_C/<span class="number">2</span>, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.lstm_fc = BasicConv(Commom_C, Commom_C, <span class="number">1</span>, <span class="number">1</span>, relu=<span class="literal">True</span>, bn=<span class="literal">False</span>)</span><br><span class="line">        self.rpn_class = BasicConv(Commom_C, anchor_k*<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, relu=<span class="literal">False</span>,bn=<span class="literal">False</span>)</span><br><span class="line">        self.rpn_regress = BasicConv(Commom_C, anchor_k*<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, relu=<span class="literal">False</span>, bn=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># basebone network run</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        x = self.base_layers(x)</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># Convert feature map to lstm input</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        x = self.prelstm(x)</span><br><span class="line">        x1 = x.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous()  <span class="comment"># channels last</span></span><br><span class="line">        b = x1.size()  <span class="comment"># batch_size, h, w, c</span></span><br><span class="line">        x1 = x1.view(b[<span class="number">0</span>]*b[<span class="number">1</span>], b[<span class="number">2</span>], b[<span class="number">3</span>])</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># BiLSTM</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        x2, _ = self.bilstm(x1)</span><br><span class="line"></span><br><span class="line">        xsz = x.size()</span><br><span class="line">        x3 = x2.view(xsz[<span class="number">0</span>], xsz[<span class="number">2</span>], xsz[<span class="number">3</span>], <span class="number">256</span>)  <span class="comment"># torch.Size([4, 20, 20, 256])</span></span><br><span class="line"></span><br><span class="line">        x3 = x3.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous()  <span class="comment"># channels first</span></span><br><span class="line">        x3 = self.lstm_fc(x3)</span><br><span class="line">        x = x3</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># RPN</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        rpn_cls = self.rpn_class(x)</span><br><span class="line">        rpn_regr = self.rpn_regress(x)</span><br><span class="line"></span><br><span class="line">        rpn_cls = rpn_cls.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous()</span><br><span class="line">        rpn_regr = rpn_regr.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous()</span><br><span class="line"></span><br><span class="line">        rpn_cls = rpn_cls.view(rpn_cls.size(<span class="number">0</span>), rpn_cls.size(<span class="number">1</span>)*rpn_cls.size(<span class="number">2</span>)*anchor_k, <span class="number">2</span>)</span><br><span class="line">        rpn_regr = rpn_regr.view(rpn_regr.size(<span class="number">0</span>), rpn_regr.size(<span class="number">1</span>)*rpn_regr.size(<span class="number">2</span>)*anchor_k, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> rpn_cls, rpn_regr</span><br></pre></td></tr></table></figure></p>
<p>解释一下conv5 feature map如何从<span class="math inline">\(N\times C
\times H \times W\)</span>变为<span class="math inline">\(N \times 9C
\times H \times W\)</span> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030331728.jpg" /></p>
<p>在原版caffe代码中是用im2col提取每个点附近的9点临近点，然后每行都如此处理：</p>
<p><span class="math inline">\(H\times W \rightarrow 9 \times H \times
W\)</span></p>
<p>接着每个通道都如此处理： <span class="math inline">\(C\times H\times
W \rightarrow 9C\times H \times W\)</span></p>
<p>而im2col是用于卷积加速的操作，即将卷积变为矩阵乘法，从而使用Blas库快速计算。到了tf，没有这种操作，所以一般是用conv2d代替im2col，即强行卷积<span
class="math inline">\(C\rightarrow 9C\)</span> 。</p>
<p>再将这个feature map进行Reshape</p>
<p><span class="math display">\[N \times 9C \times H \times W
\xrightarrow{\text{reshape}} (NH)\times W\times 9C\]</span></p>
<p>然后以Batch = NH 且最大时间长度<span class="math inline">\(T_{max} =
W\)</span>的数据流输入双向LSTM,学习每一行的序列特征。双向LSTM输出为<span
class="math inline">\((NH)\times W\times
256\)</span>,再经Reshape恢复形状 <span class="math inline">\((NH)\times
W \times 256 \xrightarrow{reshape} N \times 256 \times H \times
W\)</span></p>
<p>该特征即包含空间特性，也包含LSTM学到的序列特征。</p>
<p>然后经过"FC"卷积层，变为<span class="math inline">\(N\times512\times
H \times W\)</span>的特征 最后经过类似Faster R-CNN的RPN网络，获得text
proposals.</p>
<h2 id="文本线构造算法">文本线构造算法</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030331183.jpeg" /></p>
<p>为了说明问题，假设某张图有图9所示的2个text
proposal，即蓝色和红色2组Anchor，CTPN采用如下算法构造文本线：</p>
<p>按照水平<span class="math inline">\(x\)</span>坐标排序anchor
按照规则依次计算每个anchor <span
class="math inline">\(box_i\)</span>的<span
class="math inline">\(pair(box_j)\)</span>，组成<span
class="math inline">\(pair(box_i, box_j)\)</span> 通过<span
class="math inline">\(pair(box_i, box_j)\)</span>建立一个Connect
graph，最终获得文本检测框</p>
<p>下面详细解释。假设每个anchor index如绿色数字，同时每个anchor Softmax
score如黑色数字。</p>
<p>文本线构造算法通过如下方式建立每个anchor <span
class="math inline">\(box_i\)</span>的<span
class="math inline">\(pair(box_i, box_j)\)</span>:</p>
<blockquote>
<p>正向寻找:</p>
</blockquote>
<ul>
<li>沿水平正方向，寻找和<span
class="math inline">\(box_i\)</span>水平距离小于50的候选anchor</li>
<li>从候选anchor中，挑出与<span
class="math inline">\(box_i\)</span><strong>竖直方向</strong><span
class="math inline">\(overlap_v \gt 0.7\)</span>的anchor</li>
<li>挑出符合条件2中Softmax score最大的<span
class="math inline">\(box_j\)</span></li>
</ul>
<blockquote>
<p>反向寻找:</p>
</blockquote>
<ul>
<li>沿水平负方向，寻找和<span
class="math inline">\(box_j\)</span>水平距离小于50的候选Anchor</li>
<li>从候选Anchor中，挑出与<span
class="math inline">\(box_j\)</span>竖直方向<span
class="math inline">\(overlap_v \gt 0.7\)</span>的anchor</li>
<li>挑出符合条件2中Softmax score最大的<span
class="math inline">\(box_k\)</span></li>
</ul>
<blockquote>
<p>对比<span class="math inline">\(score_i\)</span>和<span
class="math inline">\(score_k\)</span>:</p>
</blockquote>
<p>如果<span class="math inline">\(score_i \ge
score_k\)</span>，则这是一个最长连接，那么设置<span
class="math inline">\(Graph(i, j) = True\)</span> 如果<span
class="math inline">\(score_i \lt
score_k\)</span>，说明这不是一个最长的连接（即该连接肯定包含在另外一个更长的连接中）。</p>
<h1 id="text-recognition">Text Recognition</h1>
<ul>
<li><a
href="https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7">Beam
Search Decoding in CTC-trained Neural Networks</a></li>
</ul>
<h1 id="其他相关算法">其他相关算法</h1>
<p><code>Levenshtein distances</code><a href="#fn9" class="footnote-ref"
id="fnref9" role="doc-noteref"><sup>9</sup></a>是俄罗斯科学家Vladimir
Levenshtein在1965年发明的，也叫做编辑距离（实际上编辑距离代表一大类算法），距离代表着从s到t需要删、插、代替单个字符的最小步骤数。主要应用：
* <code>Spell checking</code> 检查拼写 * <code>Speech recognition</code>
语音识别 * <code>DNA analysis</code> DNA分析 *
<code>Plagiarism detection</code> 检测抄袭</p>
<h1 id="参考文献">参考文献</h1>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"
role="doc-endnote"><p>https://www.jianshu.com/p/56f8c714f372
"自然场景文本检测识别技术综述"<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"
role="doc-endnote"><p>https://blog.csdn.net/liuxiaoheng1992/article/details/85305871
"SWT博客"<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>https://www.cnblogs.com/shangd/p/6164916.html
"MSER 博客"<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://zybuluo.com/hanbingtao/note/541458
"循环神经网络"<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>http://colah.github.io/posts/2015-08-Understanding-LSTMs/
"理解LSTM"<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://www.jianshu.com/p/4b4701beba92
"理解LSTM中文"<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>https://arxiv.org/pdf/1610.02357.pdf
"Xception"<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>https://zhuanlan.zhihu.com/p/34757009
"场景文字检测—CTPN原理与实现" ​ tf code:
https://github.com/eragonruan/text-detection-ctpn<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>http://www.levenshtein.net/index.html
"编辑距离"<a href="#fnref9" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>OCR</tag>
      </tags>
  </entry>
  <entry>
    <title>中文文本纠错</title>
    <url>/202107/20210723-csc-survey/</url>
    <content><![CDATA[<h2 id="常见错误类型">常见错误类型</h2>
<p>在中文中，常见的错误类型大概有如下几类：</p>
<p>由于字音字形相似导致的错字形式：体脂称—&gt;体脂秤 多字错误：iphonee
—&gt; iphone 少字错误：爱有天意 --&gt; 假如爱有天意 顺序错误: 表达难以
--&gt; 难以表达 ## 纠错组成模块 纠错一般分两大模块：</p>
<p>错误检测：识别错误发生的位置
错误纠正：对疑似的错误词，根据字音字形等对错词进行候选词召回，并且根据语言模型等对纠错后的结果进行排序，选择最优结果。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030335669.png"
alt="Alt text" /></p>
<h2 id="赛事">赛事</h2>
<p>几届中文纠错评测，例如CGED与NLPCC - Chinese Spelling Check Evaluation
at SIGHAN Bake-off 2013 [Wu et al., 2013]<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> -
CLP-2014 Chinese Spelling Check Evaluation (Yu et al., 2014) <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030336162.png"
alt="Alt text" /></p>
<h2 id="数据集">数据集</h2>
<p>1、Academia Sinica Balanced Corpus (ASBC for short hereafter, cf.
Chen et al., 1996). 2、混淆词数据集[^A Hybrid Approach to Automatic
Corpus Generation for Chinese Spelling Check]</p>
<p>[^A Hybrid Approach to Automatic Corpus Generation for Chinese
Spelling Check]: Wang, D. , Song, Y. , Li, J. , Han, J. , &amp; Zhang,
H. . (2018). A Hybrid Approach to Automatic Corpus Generation for
Chinese Spelling Check. Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing.
https://aclanthology.org/D18-1273.pdf</p>
<p>3、Chinese Grammatical Error Diagnosis NLPTEA 2016 Shared Task:
http://ir.itc.ntnu.edu.tw/lre/nlptea16cged.htm NLPTEA 2015 Shared Task:
http://ir.itc.ntnu.edu.tw/lre/nlptea15cged.htm NLPTEA 2014 Shared Task:
http://ir.itc.ntnu.edu.tw/lre/nlptea14cfl.htm</p>
<p>4、Chinese Spelling Check SIGHAN 2015 Bake-off:
http://ir.itc.ntnu.edu.tw/lre/sighan8csc.html CLP 2014 Bake-off:
http://ir.itc.ntnu.edu.tw/lre/clp14csc.html SIGHAN 2013 Bake-off:
http://ir.itc.ntnu.edu.tw/lre/sighan7csc.html</p>
<p>http://nlp.ee.ncu.edu.tw/resource/csc.html</p>
<h4 id="构造方法">构造方法</h4>
<p>1、对字进行增删、交换位置、混淆词替换 2、常见混淆集整理 &gt;
视觉上和语音上的相似字是造成汉语文本错误的主要因素。通过定义适当的相似性度量，考虑扩展仓颉代码，我们可以在几分之一秒内识别视觉上相似的字符。根据汉语词汇中单个汉字的发音信息，我们可以计算出一个与给定汉字在语音上相似的汉字列表。我们收集了网络上出现的621个错误的中文词汇，并分析了这些错误的原因。其中83%的错误与语音相似性有关，48%的错误与所涉及的字符之间的视觉相似性有关。生成语音和视觉上相似的字符列表，我们的程序能够包含报告错误中超过90%的错误字符。<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></p>
<p>3、基于说文解字、四角码计算[^Using Confusion Sets and N-gram
Statistics]</p>
<p>[^Using Confusion Sets and N-gram Statistics]: Lin C J, Chu W C. A
Study on Chinese Spelling Check Using Confusion Sets and N-gram
Statistics[J]. International Journal of Computational Linguistics &amp;
Chinese Language Processing, Volume 20, Number 1, June 2015-Special
Issue on Chinese as a Foreign Language, 2015, 20(1).</p>
<h3 id="编辑距离">编辑距离</h3>
<p>编辑距离的经典应用就是用于拼写检错，如果用户输入的词语不在词典中，自动从词典中找出编辑距离小于某个数<span
class="math inline">\(n\)</span>的单词，让用户选择正确的那一个，<span
class="math inline">\(n\)</span>通常取到2或者3。</p>
<p>这个问题的难点在于，怎样才能快速在字典里找出最相近的单词？可以像
使用贝叶斯做英文拼写检查里是那样，通过单词自动修改一个单词，检查是否在词典里，这样有暴力破解的嫌疑，是否有更优雅的方案呢？</p>
<p>1973年，Burkhard和Keller提出的BK树有效地解决了这个问题。BK树<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a><a href="#fn4" class="footnote-ref"
id="fnref4" role="doc-noteref"><sup>4</sup></a>的核心思想是： &gt;
令<span
class="math inline">\(d(x,y)\)</span>表示字符串x到y的Levenshtein距离，那么显然：
&gt; <span class="math inline">\(d(x,y) = 0\)</span> 当且仅当 <span
class="math inline">\(x=y\)</span> （Levenshtein距离为0 &lt;==&gt;
字符串相等） &gt; <span class="math inline">\(d(x,y) = d(y,x)\)</span>
（从x变到y的最少步数就是从y变到x的最少步数） &gt; <span
class="math inline">\(d(x,y) + d(y,z) &gt;= d(x,z)\)</span>
（从x变到z所需的步数不会超过x先变成y再变成z的步数）</p>
<p>最后这一个性质叫做三角形不等式。就好像一个三角形一样，两边之和必然大于第三边。</p>
<h2 id="发展历史概述">发展历史概述</h2>
<h4 id="依赖条件">依赖条件</h4>
<p>纠错技术相对于词法分析，句法分析等受到的关注一直较小，一方面是因为<strong>文本出错的比例比较小</strong>，在一些重要场合，也有专门人员进行校验；另一方面<strong>本身问题也相对较难</strong>，其要求计算机对语言规则以及文本语义有深刻的理解。</p>
<p>我们把中文常见错误总结分为三类： -
用词错误，由于输入法等原因导致的选词错误，其主要表现为音近，形近等； -
文法/句法错误，该类错误主要是由于对语言不熟悉导致的如多字、少字、乱序等错误，其错误片段相对较大；
-
知识类错误，该类错误可能由于对某些知识不熟悉导致的错误，要解决该类问题，通常得引入外部知识、常识等。</p>
<h4 id="发展历程">发展历程</h4>
<ul>
<li>2000年以前，业界主要依靠长期积累的纠错规则和纠错词典来进行纠错，比如微软的文档编辑产品WORD即采用这种方法</li>
<li>随着机器学习技术的发展，纠错问题受到了学术界和工业界越来越多的关注，其中有两大主流方法：
<ul>
<li>一种解决思路是将语言错误归类，然后采用Maxent（最大熵模型）、SVM等分类方法对这些类别进行重点识别；</li>
<li>另外一种思路是借鉴统计机器翻译（SMT）的思想，将语言纠错等价为机器翻译的过程，即错误文本翻译为正确文本，并随之出现了一系列的优化方法。</li>
</ul></li>
</ul>
<h4 id="调研的必要性">调研的必要性</h4>
<p>近年来，随着新媒体行业的快速发展，中国自媒体从业人数逐年增长，至2017年有近260万。但是相对于传统媒体，其缺少人工校稿环节，编辑好的文章即刻发表，导致文章的错误比例较高。比如一些新媒体平台的正文错误率在2%以上，标题错误率在1%左右。同时，语音智能硬件产品的兴起，也暴露出语音识别技术的错误率高企问题，在某些场景语音识别中，错误率可能达到8%-10%，影响了后续的query理解及对话效果。因此研发优质的中文纠错技术，便成为了必须。</p>
<h2 id="技术调研">技术调研</h2>
<p>整体上，将纠错流程，分解为错误检测、候选召回、纠错排序三个关键步骤。通过引入语言知识、上下文理解和知识计算的核心技术，提升不同类型错误的解决能力。最后，支持SMT
based和NMT based两套Framework，形成完整的系统架构。 ###
关键步骤（错误检测-&gt;候选召回-&gt;纠错排序） <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030336143.png"
alt="Alt text" /></p>
<p><strong>错误检测</strong>的目标是识别输入句子可能存在的问题，采用序列表示（Transformer/LSTM）+CRF的序列预测模型，这个模型的创新点主要包括：
- 词法/句法分析等语言先验知识的充分应用； -
特征设计方面，除了DNN相关这种泛化能力比较强的特征，还结合了大量hard统计特征，既充分利用DNN模型的泛化能力，又对低频与OOV（Out
of Vocabulary）有一定的区分； -
最后，根据字粒度和词粒度各自的特点，在模型中对其进行融合，解决词对齐的问题。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030336539.png"
alt="Alt text" /></p>
<p><strong>候选召回</strong>指的是，识别出具体的错误点之后，需要进行错误纠正，为了达到更好的效果以及性能，需要结合历史错误行为，以及音形等特征召回纠错候选。主要可分为两部分工作：离线的候选挖掘，在线的候选预排序。离线候选挖掘利用大规模多来源的错误对齐语料，通过对齐模型，得到不同粒度的错误混淆矩阵。在线候选预排序主要是针对当前的错误点，对离线召回的大量纠错候选，结合语言模型以及错误混淆矩阵的特征，控制进入纠错排序阶段的候选集数量与质量。</p>
<h3
id="核心技术语言知识-上下文理解-知识计算">核心技术（语言知识-&gt;上下文理解-&gt;知识计算）</h3>
<h4 id="采用翻译技术纠错">采用翻译技术纠错</h4>
<blockquote>
<p>优点</p>
</blockquote>
<p>将纠错当做翻译任务去做，可以对不同类型的错误形式：错词，少词，多词等进行纠错</p>
<blockquote>
<p>缺点</p>
</blockquote>
<p>模型没有对字音字形相似关系的学习，纠错后的结果不受约束，很容易出现过纠错和误纠问题</p>
<h3 id="soft-masked-bert">Soft-Masked BERT</h3>
<p>Soft-Masked BERT：文本纠错与BERT的最新结合 - 头条 - ACL 2020</p>
<blockquote>
<p>给定<span class="math inline">\(n\)</span>个字或词构成的序列<span
class="math inline">\(X=(x_1, x_2,...,
x_n)\)</span>，目标是把它转化为另一个相同长度的字序列<span
class="math inline">\(Y=(y_1,y_2,...,y_n)\)</span>， <span
class="math inline">\(X\)</span>中的错字用正确的字替换得到<span
class="math inline">\(Y\)</span>
。该任务可看作序列标注问题，模型是映射函数<span
class="math inline">\(f:X\rightarrow Y\)</span>。</p>
</blockquote>
<p>这篇文章中的纠错模型是由基于Bi-GRU序列二进制标注检测模型和基于BERT的序列多类标注纠正模型组成，
其中soft-masked embedding: <span class="math inline">\(e_i’ = p_i \cdot
e_{mask} + (1-p_i) \cdot e_i\)</span>
可以实现将错字概率传递给后续纠正网络，使得纠正网络专注在预测正确字上。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030336784.png"
alt="Soft-Masked BERT纠错算法框架" /></p>
<p>https://zhuanlan.zhihu.com/p/144995580 ### SpellGCN[^SpellGCN:
Incorporating Phonological and Visual Similarities into Language Models
for Chinese Spelling Check]</p>
<p>3、https://zhuanlan.zhihu.com/p/145825024?from_voters_page=true
[^SpellGCN: Incorporating Phonological and Visual Similarities into
Language Models for Chinese Spelling Check]:
https://aclanthology.org/2020.acl-main.81.pdf</p>
<h3
id="confusionset-ptrnet---cscconfusionset-guided-pointer-networks-for-chinese-spelling-check">ConfusionSet
+PtrNet -&gt; CSC[^Confusionset-guided Pointer Networks for Chinese
Spelling Check]</h3>
<p>[^Confusionset-guided Pointer Networks for Chinese Spelling Check]:
https://www.aclweb.org/anthology/P19-1578.pdf</p>
<p>4、基于统计语言模型的文本纠错方法研究
https://www.cnblogs.com/baobaotql/p/13358035.html</p>
<p>规则类：哪些更适合规则类？ 语言模型 混淆集</p>
<h2 id="todo">TODO</h2>
<p>ACL2021 Global Attention Decoder for Chinese Spelling Error
Correction Correcting Chinese Spelling Errors with Phonetic Pre-training
Dynamic Connected Networks for Chinese Spelling Check
https://github.com/gitabtion/SoftMaskedBert-PyTorch</p>
<p>https://github.com/gitabtion/BertBasedCorrectionModels</p>
<h2 id="gec">GEC</h2>
<p>Encoder-Decoder Models Can Benefit from Pre-trained Masked Language
Models in Grammatical Error Correction
https://aclanthology.org/2020.acl-main.391.pdf</p>
<p>Do Grammatical Error Correction Models Realize Grammatical
Generalization? https://arxiv.org/abs/2106.03031</p>
<h2 id="互联网企业papers">互联网企业Papers</h2>
<p>1、腾讯云:基于语言模型的拼写纠错：https://cloud.tencent.com/developer/article/1156792</p>
<p>2、平安寿险AI https://zhuanlan.zhihu.com/p/159101860</p>
<p>3、爱奇艺:
https://blog.csdn.net/BGoodHabit/article/details/114589007#21_FASPell_20</p>
<table>
<colgroup>
<col style="width: 18%" />
<col style="width: 27%" />
<col style="width: 27%" />
<col style="width: 27%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">模型</th>
<th style="text-align: left;">发表位置</th>
<th style="text-align: left;">创新点</th>
<th style="text-align: center;">总结</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">FASPell(爱奇艺)</td>
<td style="text-align: left;">ACL2020</td>
<td
style="text-align: left;">融合字音字形相似度分数，拟合最佳分割曲线</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">SpellGCN(阿里)</td>
<td style="text-align: left;"></td>
<td
style="text-align: left;">用GCN学习字音字形关系结构向量，让错词更倾向于纠错为混淆集中的字</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Soft-Mask BERT(字节)</td>
<td style="text-align: left;"></td>
<td
style="text-align: left;">增加纠错检测模块，用错误检测概率控制纠错模块，减少过纠问题</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">SCFL(ebay)</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">seq2seq</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">HeadFit(加利福尼亚)</td>
<td style="text-align: left;"></td>
<td
style="text-align: left;">treeLSTM模型学习字形向量，取代固定的混淆集</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<h3 id="业务中主要存在的问题">业务中主要存在的问题</h3>
<p>1、多数方案通过将字音字形信息融入到模型学习中，解决纠错问题主要因为字音字形相似等带来的错误
2、在输入连续出错等纠错问题上，还面临着很多的挑战</p>
<h2 id="参考文献">参考文献</h2>
<p>[1]Lee L H, Yu L C, Chang L P. Guest Editoral: Special Issue on
Chinese as a Foreign Language[J]. International Journal of Computational
Linguistics &amp; Chinese Language Processing, Volume 20, Number 1, June
2015-Special Issue on Chinese as a Foreign Language, 2015, 20(1).</p>
<p>[2]Yu J, Li Z. Chinese spelling error detection and correction based
on language model, pronunciation, and shape[C]//Proceedings of The Third
CIPS-SIGHAN Joint Conference on Chinese Language Processing. 2014:
220-223.</p>
<p>[3] Lv, Y.Y.; Deng, Y.I.; Liu, M.L.; Lu, Q.Y. Automatic error
checking and correction of electronic medical records. Front. Artif.
Intell. Appl. 2016, 281, 32–40. 无法下载，需要钱</p>
<p>[4] Liu X, Cheng K, Luo Y, et al. A hybrid Chinese spelling
correction using language model and statistical machine translation with
reranking[C]//Proceedings of the Seventh SIGHAN Workshop on Chinese
Language Processing. 2013: 54-58.</p>
<p>[5]Chen K Y, Lee H S, Lee C H, et al. A study of language modeling
for Chinese spelling check[C]//Proceedings of the Seventh SIGHAN
Workshop on Chinese Language Processing. 2013: 79-83.</p>
<p>[6]Xie W, Huang P, Zhang X, et al. Chinese spelling check system
based on n-gram model[C]//Proceedings of the Eighth SIGHAN Workshop on
Chinese Language Processing. 2015: 128-136.</p>
<p>[7] Zhao J, Liu H, Bao Z, et al. N-gram Model for Chinese Grammatical
Error Diagnosis[C]//Proceedings of the 4th Workshop on Natural Language
Processing Techniques for Educational Applications (NLPTEA 2017). 2017:
39-44.</p>
<p>[8] Jui-Feng Yeh, Sheng-Feng Li, Mei-Rong Wu, Wen-Yi Chen, and
Mao-Chuan Su. 2013. Chinese word spelling correction based on N-gram
ranked inverted index list. In Proceedings of the 7th SIGHAN Workshop on
Chinese Language Processing. 43–48.</p>
<p>[9] Zheng B, Che W, Guo J, et al. Chinese Grammatical Error Diagnosis
with Long Short-Term Memory Networks[C]//Proceedings of the 3rd Workshop
on Natural Language Processing Techniques for Educational Applications
(NLPTEA2016). 2016: 49-56.</p>
<p>[10] Xie P. Alibaba at IJCNLP-2017 Task 1: Embedding Grammatical
Features into LSTMs for Chinese Grammatical Error Diagnosis Task[J].
Proceedings of the IJCNLP 2017, Shared Tasks, 2017: 41-46.</p>
<p>[11] Wang, D. , Song, Y. , Li, J. , Han, J. , &amp; Zhang, H. .
(2018). A Hybrid Approach to Automatic Corpus Generation for Chinese
Spelling Check. Proceedings of the 2018 Conference on Empirical Methods
in Natural Language Processing.</p>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Wu, S. , Liu, C. , &amp; Lee, L. .
(2014). Chinese Spelling Check Evaluation at SIGHAN Bake-off 2013.
Sighan Workshop on Chinese Language Processing.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Liu, C. L. , Lai, M. H. , Tien, K. W.
, Chuang, Y. H. , S.-H., W. U. , &amp; Lee, C. Y. . (2011). Visually and
phonologically similar characters in incorrect chinese words: analyses,
identification, and applications. Acm Transactions on Asian Language
Information Processing, 10(2), 1-39.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"
role="doc-endnote"><p>https://www.cnblogs.com/xiaoqi/p/BK-Tree.html<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>ttps://en.wikipedia.org/wiki/BK-tree<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Label Noise Learning</title>
    <url>/202203/20220304-label-noise-learning/</url>
    <content><![CDATA[<h2 id="序言">序言</h2>
<p>过参数化在深度学习时代常常被提到，它的神经网络参数个数甚至超过了
training sample
的个数，在实验中也体现出了非常好的效果。但是，一旦training
samples中带有一些噪声，整个模型就趋向于过拟合，没有办法很好地泛化到测试集。一般而言，training
samples带噪声的方式有两种，一是在 data points上加 Gaussian noise，二是
label noise. 我们这里主要探究第二种。</p>
<h2 id="存在噪声标注数据">存在噪声标注数据</h2>
<p>诸如数据增强、权重衰减、dropout和批量归一化等流行的正则化技术已经被广泛应用，但是它们本身并不能完全克服在噪声数据上过拟合问题。
### 1、噪声的类别</p>
<ol type="1">
<li><code>instance-independent label noise</code>:
现有大部分算算法都是针对这种类型的带噪数据进行的研究建模的，因为instance-dependent
建模比较复杂。</li>
</ol>
<ul>
<li>symmetric noise: 一个标签标错为其他类别的标签概率一样</li>
<li>asymmetric noise: 一个标签标错为其他类别的标签概率不一样</li>
<li>pair noise: 一个标签只会错标为对应的另外一种标签,
标错的是在这些标签对形式存在(a, b) <img
src="../../images/nlp/Label-Noise-Learning/1646207730120.png"
alt="Alt text" /></li>
</ul>
<ol start="2" type="1">
<li><code>instance-dependent label noise</code> ### 2、困难
（1）深度学习模型因为其高阶的表达方式，更容易受到label
noise的影响。</li>
</ol>
<h3
id="要获得一个鲁棒性的模型方法可以大致分为三类">3、要获得一个鲁棒性的模型，方法可以大致分为三类：</h3>
<p>（1）设计使用好的损失函数 （2）训练方式: Training architectures
methods （3）减少错误标注: Label correction methods.
噪声数据比重占比在8.0% ~38.5%范围内。</p>
<h3 id="常用概念">4、常用概念</h3>
<h4 id="label-transition"><strong>Label Transition</strong></h4>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/1646132202285.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030336131.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<h4 id="memorization-effect"><strong>Memorization Effect</strong></h4>
<p><span class="math display">\[
||W_t - W_0||_F \lesssim (\sqrt K  + (K^2 \epsilon_0 / ||C||^2)t )
\]</span></p>
<p>结果表明，DNN的权值在训练开始时仍保持在初始权值附近，在对noise
label过度拟合时开始偏离初始权值很远，这一现象也被称为DNN的记忆效应，即DNN倾向于首先学习简单和概括的模式，然后逐渐过度适应所有的噪声模式。因此，为了实现更好的泛化，通常采用提前停止和偏爱小损失训练实例来设计健壮的训练方法
<strong>Risk Minimization</strong> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030346413.png"
alt="Alt text" />
一般采用经验风险最小化的迭代优化如下，而在非clean的dataset上直接使用该优化方法，将在泛化数据集上测试结果退化。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030346546.png"
alt="Alt text" />
一般情况下通过优化过程中降低或者屏蔽噪音sample影响以实现缓解退化的问题。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030346962.png"
alt="Alt text" /> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030346843.png"
alt="Alt text" /></p>
<hr />
<h2 id="文献调研">文献调研</h2>
<h3 id="naf">1、NAF</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030346935.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li>paper: Named Entity Recognition via Noise Aware Training Mechanism
with Data Filter（ACL-IJCNLP 2021 Findings）</li>
<li>论文链接：https://aclanthology.org/2021.findings-acl.423.pdf</li>
</ul>
<h4 id="问题定义">问题定义</h4>
<p>区分难样本和噪声样本仍然是一个挑战，特别是在过拟合的情况下变得更具挑战性。
存在歧义的hard sample与noise sample是比较难以分开的，因为hard
sample在训练初期也是具有较大loss的。 <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030346534.png"
alt="Alt text|400x400" /></p>
<h4 id="logit-maximum-difference-lmd-mechanism">Logit-Maximum-Difference
(LMD) mechanism</h4>
<p>（0）一般我们是NN之后的logist矩阵加softmax和损失，由于softmax是归一化的指数函数，这就使得logist矩阵中的值的变化不是通过线性变化反映出来，这给我们识别noise
sample带来了不公平。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030346293.png"
alt="Alt text" /> （1)上图中需要注意的是，noise
sample的情况下，相对差距比较其他两类：hard/easy sample 较小。</p>
<p><span class="math display">\[LMD(x, y) =
\frac{1}{T}\sum^T_{t=1}(min(Z_y^{(t)} -
max_{i!=y}Z_i^{(t)}))\]</span></p>
<figure>
<img src="../../images/nlp/Label-Noise-Learning/1646035706110.png"
alt="Alt text|center|400x300" />
<figcaption aria-hidden="true">Alt text|center|400x300</figcaption>
</figure>
<p>（2）训练过程中，刚开始几个epoch，模型总是倾向于学习正确的样品。这意味着即使有些样本即使贴上了错误的标签，模型仍然可以预测正确的结果。随着训练epoch过长，会出现overfitting的问题。如上图所示，在hard和noise
sample 中训练发现损失趋于一致。这就是在noise
sample中overfitting的一种现象。</p>
<h4 id="noise-tolerant-term-named-distrust-cross-entropydce">noise
tolerant term named Distrust-Cross-Entropy(DCE)</h4>
<p>（0）主要想法 - 在CRF的损失函数中添加DCE
项，用来平衡是否接受模型输出还是标注 - 超参数<span
class="math inline">\(\delta\)</span>越大，则越相信预测结果</p>
<p>（1）预测结果的分布 <span class="math display">\[
\begin{align*}
p &amp;= p(k\mid x)     \\
\end{align*}
\]</span> （2）标注结果分布是one-hot的分布，分布如下 <span
class="math display">\[
\begin{align*}
q &amp;= q(k\mid x)      \\
\end{align*}
\]</span> （3）则应用KL散度可以衡量预测与实际输出的分布差异。 <span
class="math display">\[
\begin{align*}
KL(q\mid\mid p)&amp;= H(q, p) - H(q) \\
\end{align*}
\]</span> （4）通过在基本损失函数基础上，引入DCE项，来 <span
class="math display">\[
\begin{align*}
L_{DCE} &amp;= - plog(\delta p+(1- \delta)q) \\
L_{In\_trust} &amp;= \alpha L_{CRF}+\beta L_{DCE}
\end{align*}
\]</span></p>
<blockquote>
<p>结论</p>
</blockquote>
<p>通过分析发现，<span
class="math inline">\(\delta\)</span>越大，那么就通过输出结果<span
class="math inline">\(p\)</span>学习，<span
class="math inline">\(\delta\)</span>越小，就通过<span
class="math inline">\(q\)</span>学些。 &gt; We observe that when is
larger, the model tends to learn from the p of the model output, and
when is smaller, the model tends to learn from the label q</p>
<blockquote>
<p>小结:
该方法通过分析难例与噪声标注之间的差异，添加额外项优化损失函数，减少noise
label对模型优化的影响。</p>
</blockquote>
<hr />
<h3 id="aum">2、AUM</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030347462.png"
alt="Alt text" /> - paper: Identifying mislabeled data using the area
under the margin ranking</p>
<p>首先通过经验角度分析提出的noise label与hard
label之间的差异，得出经验判别条件。 <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030347414.png"
alt="Alt text" /></p>
<p>Margin的定义如下所示，其中t代表是第t个epoch，x代表是输入的数据，y代表annotation
labe，z代表的是最终prediction的logits。由式子定义可知其可能会去到负数，当为负数的时候，代表模型预测的结果可能和真值结果存在不同，因此当前样本可能是噪声。
<span class="math display">\[M^{t}(x,y) = z^{t}_{y}(x) - max_{i !=
y}z^{t}_{i}(x)\]</span> 考虑到不同epoch
margin值可能是不一样的，因此作者定义了如下所示的AUM值，它相当于对前T个epoch的Margin值计算了平均。
<span class="math display">\[AUM(x, y) =
\frac{1}{T}\sum_{t=1}^T{M^t(x,y)}\]</span></p>
<p>AUM值越小代表这个样本越有可能是噪声数据，但是只根据ranking是没有办法得到一个绝对的划分。因此需要一个绝对的划分。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030347132.png"
alt="Alt text|center|500x400" />
<figcaption aria-hidden="true">Alt text|center|500x400</figcaption>
</figure>
<p>作者提出使用threshold
samples，作者从训练集合中抽样一部分数据出来作为threshold
samples，这部分数据会人为的指定噪声标签，并且加入训练。最终这部分数据的AUM前从高到底排序的90分位值即可以作为AUM的阈值，用于划分噪声数据和非噪声数据。</p>
<blockquote>
<p>该方法通过最大化margin的角度，减少噪声的影响。</p>
</blockquote>
<hr />
<h3 id="早停">早停</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030347824.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li>paper: Hwanjun Song, Minseok Kim, Dongmin Park, &amp; Jae-Gil Lee
(2019). How does Early Stopping Help Generalization against Label Noise
arXiv: Learning.</li>
<li>链接地址:
https://ui.adsabs.harvard.edu/link_gateway/2019arXiv191108059S/arxiv:1911.08059</li>
</ul>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030347381.png"
alt="Alt text" />
探究了<code>Best point to early stop</code>与<code>Criterion of a maximal safe set</code></p>
<p>1、Best point to early stop</p>
<ul>
<li>Validation Heuristic: 准备一个干净的验证集<span
class="math inline">\(\mathcal{V}\)</span> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030347714.png"
alt="Alt text" /></li>
<li>Noise-Rate Heuristic: 需要知道数据集的噪声率<span
class="math inline">\(\tau\)</span>， 但是在真实业务场景不容易获得。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030347442.png"
alt="Alt text" /></li>
</ul>
<p>2、Criterion of a maximal safe set</p>
<blockquote>
<p>该方法挖掘cleandata进行训练，规避noise label数据对模型的影响</p>
</blockquote>
<hr />
<h3 id="sop">4、SOP</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348149.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li>github: https://github.com/shengliu66/SOP</li>
<li>paper: Robust Training under Label Noise by
Over-parameterization</li>
</ul>
<p>这篇文章的思路其实并不复杂，我们需要在原有模型的基础上，对于每一个数据点增加一个
variable <span class="math inline">\(s_i\)</span>，它代表该数据点的
label noise，最后的目标函数就是 <img
src="../../images/nlp/Label-Noise-Learning/1646205879003.png"
alt="Alt text|center" />
其中，由于这个noise是具有sparse性质的，因此作者们沿用了先前若干文章中的技巧，采用了一种特殊的参数化方式：
<span class="math inline">\(s_i = u_i \odot u_i - v_i \odot v_i\)</span>
，当然其中还需要规定一下 <span class="math inline">\(u_i,
v_i\)</span>的取值范围，最终的优化问题是： <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348727.png"
alt="Alt text" /></p>
<hr />
<h3 id="小结">5、小结</h3>
<ul>
<li>hard sample与noise label
sample是我们这块更关注的，但是这对难兄难弟又杂糅在一起，本文中多篇文章中对二者差异进行了经验结果分析，这个对于我们在实际业务数据上实验的时候可以提供一些思路。例如难例挖掘是不是就可以考虑利用这个特点？</li>
<li>如果业务数据中有噪声，可以考虑清理一个干净的validate
dataset。训练过程中的一些测评结果，对于评估模型设计是否合理，数据是否干净还是比较有用的。但是可能因为交付时间等外部原因，我们往往忽略这些中间结果。</li>
<li>这一块除了早停或者清洗验证集之外，还有就是训练时候能够将损失函数将noise
label的数据权重降低，而标样本的权重高一些。</li>
</ul>
<hr />
<h2 id="关于noise-label更多文献">关于noise label更多文献</h2>
<h3 id="矫正noise样本">矫正noise样本</h3>
<blockquote>
<p>Hwanjun Song, Minseok Kim, &amp; Jae-Gil Lee (2019). SELFIE:
Refurbishing Unclean Samples for Robust Deep Learning International
Conference on Machine Learning.</p>
</blockquote>
<p>我们的核心思想是有选择地更新和利用可高精度校正的不干净样本，从而逐步增加可用训练样本的数量</p>
<h3 id="关于noisy-labels-learning的综述">关于Noisy labels
learning的综述</h3>
<blockquote>
<p>Hwanjun Song, Minseok Kim, Dongmin Park, &amp; Jae-Gil Lee (2020).
Learning from Noisy Labels with Deep Neural Networks: A Survey arXiv:
Learning.</p>
</blockquote>
<p>通过有监督的学习使得模型对于有噪声的标签具有更好的鲁棒性。鲁棒损失函数和损失调整是为了修改损失函数或其损失值；鲁棒结构是为了更改体系结构以对噪声数据集的噪声转换矩阵进行建模；鲁棒正则化是为了使DNN减少对错误标记样本的过度拟合；样本选择是为了从带有噪声的训练数据中识别出带有真实标签的样本。除了监督学习之外，研究人员最近还尝试通过采用元学习和半监督学习来进一步提高噪声鲁棒性。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348656.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<h3 id="其他资料">其他资料</h3>
<ul>
<li>https://github.com/songhwanjun/Awesome-Noisy-Labels</li>
<li>https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise</li>
<li>Open-set Label Noise Can Improve Robustness Against Inherent Label
Noise</li>
<li>Song, H., Kim, M., and Lee, J.-G. SELFIE: Refurbishing unclean
samples for robust deep learning. In ICML, pp.5907–5915, 2019.</li>
<li>Han, B. , Yao, Q. , Liu, T. , Niu, G. , Tsang, I. W. , &amp; Kwok,
J. T. , et al. (2020). A survey of label-noise representation learning:
past, present and future. https://arxiv.org/pdf/2011.04406v1.pdf</li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ Object Model</title>
    <url>/202004/20200407-cpp-object-model/</url>
    <content><![CDATA[<h2 id="引言">引言</h2>
<p>面向对象的三大特征是抽象、继承、多态。《深度探索C++对象模型》一书中从数据的排布，C++对象函数的调用设计等等。
我尝试以一个编译器的设计者的角度去理解C++对象，该书中也提到了多种编译器，有的时候也会涉及一些不同编译器厂商在设计过程中的不同，虽然没有深入探究不同的原因以及优劣对比，
但对于我这个新手来说已经开了很大的窗户。</p>
<p>整个书籍通过横向切割方式，分别从构造、数据成员、成员函数、运行时C++对象的特点来介绍，从缔造者的视角来理解C++对象的设计，有利于我们写出更加高效、简洁的程序。</p>
<h2 id="关于对象">关于对象</h2>
<h3 id="c对象比c-struct对象在空间与时间的有额外负担吗">C++对象比C
struct对象在空间与时间的有额外负担吗？</h3>
<p>封装的后布局成本与C struct是一样的。member
functions虽然旱灾class的声明之内，却不出现在的object中。每一个non-inline
memberfunction 只会诞生一个函数实例。
C++在布局以及存取时间上的主要的额外负担是由virtual引起的，包括： *
virtual function机制，引入vptr以及vtbl，支持一个有效率的"执行期绑定" *
virtual base class，用以实现"多次出现在继承体系中的base
class，有一个单一而被共享的实例" *
多重继承下，派生类跟第二个以及后续基类之间的转换</p>
<h3 id="c对象模型">C++对象模型</h3>
<p>在C++中，有两种数据成员（class data members）：static
和nonstatic,以及三种类成员函数（class member
functions）:static、nonstatic和virtual: <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Base</span>(<span class="type">int</span> i) :<span class="built_in">baseI</span>(i)&#123;&#125;;    </span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">getI</span><span class="params">()</span></span>&#123; <span class="keyword">return</span> baseI; &#125; </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">countI</span><span class="params">()</span></span>&#123;&#125;;   <span class="comment">//static</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">print</span><span class="params">(<span class="type">void</span>)</span></span>&#123; cout &lt;&lt; <span class="string">&quot;Base::print()&quot;</span>; &#125; <span class="comment">// virtual</span></span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">Base</span>()&#123;&#125;         <span class="comment">// virtual</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> baseI;  <span class="comment">// no static </span></span><br><span class="line">    <span class="type">static</span> <span class="type">int</span> baseS;  <span class="comment">// static</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>在此模型下，nonstatic
数据成员被置于每一个类对象中，而static数据成员被置于类对象之外。static与nonstatic函数也都放在类对象之外，而对于virtual
函数，则通过虚函数表+虚指针来支持，具体如下： -
每个类生成一个表格，称为虚表（virtual
table，简称vtbl）。虚表中存放着一堆指针，这些指针指向该类每一个虚函数。虚表中的函数地址将按声明时的顺序排列，不过当子类有多个重载函数时例外，后面会讨论。
-
每个类对象都拥有一个虚表指针(vptr)，由编译器为其生成。虚表指针的设定与重置皆由类的复制控制（也即是构造函数、析构函数、赋值操作符）来完成。vptr的位置为编译器决定，传统上它被放在所有显示声明的成员之后，不过现在许多编译器把vptr放在一个类对象的最前端。关于数据成员布局的内容，在后面会详细分析。
- 另外，虚函数表的前面设置了一个指向type_info的指针，用以支持RTTI（Run
Time Type
Identification，运行时类型识别）。RTTI是为多态而生成的信息，包括对象继承关系，对象本身的描述等，只有具有虚函数的对象在会生成。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030335247.png"
alt="@vs2015下对象的内存结构" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="vs2015下对象的内存结构">@vs2015下对象的内存结构</span></figcaption>
</figure>
<p>这个模型的优点在于它的空间和存取时间的效率；缺点如下：如果应用程序本身未改变，但当所使用的类的non
static数据成员添加删除或修改时，需要重新编译。</p>
<blockquote>
<p>Note:
针对析构函数，g++中的实现有一些令人疑惑的地方，~Base在虚表中出现了两次，我表示不能理解，网上也没有找到相关说明。</p>
<p>Vtable for Base Base::_ZTV4Base: 6u entries 0 (int (<em>)(...))0 4
(int (</em>)(...))(&amp; _ZTI4Base) 8 (int (<em>)(...))Base::print 12
(int (</em>)(...))Base::~Base 16 (int (*)(...))Base::~Base</p>
</blockquote>
<p>我猜测可能是我们使用g++编译中合成根据我添加的~Base()合成了一个用于动态内存分配释放的析构函数和静态释放的析构函数。当然如果有大佬知道这个是为什么，请务必指导一番，不胜感激。</p>
<h3 id="多重继承">多重继承</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base1</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">virtual</span> ~<span class="built_in">Base1</span>() &#123;&#125;;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">speakClearly</span><span class="params">()</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Base1::speakClearly()&quot;</span>&lt;&lt;endl;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> Base1 *<span class="title">clone</span><span class="params">()</span> <span class="type">const</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Base1::clone()&quot;</span>&lt;&lt;endl; <span class="keyword">return</span> <span class="keyword">new</span> Base1;&#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">	<span class="type">float</span> data_Base1;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base2</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">virtual</span> ~<span class="built_in">Base2</span>() &#123;&#125;;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">mumble</span><span class="params">()</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Base2::mumble()&quot;</span>&lt;&lt;endl;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> Base2 *<span class="title">clone</span><span class="params">()</span> <span class="type">const</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Base2::clone()&quot;</span>&lt;&lt;endl; <span class="keyword">return</span> <span class="keyword">new</span> Base2;&#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">	<span class="type">float</span> data_Base2;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="keyword">public</span> Base1,<span class="keyword">public</span> Base2</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">virtual</span> ~<span class="built_in">Derived</span>()  &#123;cout&lt;&lt;<span class="string">&quot;Derived::~Derived()&quot;</span>&lt;&lt;endl;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> Derived *<span class="title">clone</span><span class="params">()</span> <span class="type">const</span> </span>&#123;cout&lt;&lt;<span class="string">&quot;Derived::clone()&quot;</span>&lt;&lt;endl; <span class="keyword">return</span> <span class="keyword">new</span> Derived;&#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">	<span class="type">float</span> data_Derived;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030335937.png"
alt="@逻辑上的图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="逻辑上的图">@逻辑上的图</span></figcaption>
</figure>
<p>类似问题在vs2010中也有，<a
href="https://blog.csdn.net/Microsues/article/details/6452249?depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-1&amp;utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-1">主要是多重继承的时，将派生类赋值给第二个基类时</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1&gt;  Derived::$vftable@Base1@:</span><br><span class="line">1&gt;   | &amp;Derived_meta</span><br><span class="line">1&gt;   |  0</span><br><span class="line">1&gt;   0 | &amp;Derived::&#123;dtor&#125;</span><br><span class="line">1&gt;   1 | &amp;Base1::speakClearly</span><br><span class="line">1&gt;   2 | &amp;Derived::clone</span><br><span class="line">1&gt;  </span><br><span class="line">1&gt;  Derived::$vftable@Base2@:</span><br><span class="line">1&gt;   | -8</span><br><span class="line">1&gt;   0 | &amp;thunk: this-=8; goto Derived::&#123;dtor&#125;</span><br><span class="line">1&gt;   1 | &amp;Base2::mumble</span><br><span class="line">1&gt;   2 | &amp;thunk: this-=8; goto Base2* Derived::clone</span><br><span class="line">1&gt;   3 | &amp;thunk: this-=8; goto Derived* Derived::clone</span><br></pre></td></tr></table></figure>
<ul>
<li><p>派生类的虚函数表数目是它所有基类的虚函数数目之和，基类的虚函数表被复制到派生类的对应的虚函数表中。</p></li>
<li><p>派生类中重写基类的虚拟函数时，该被重写的函数在派生类的虚函数列表中得到更新，派生类的虚析构函数覆盖基类的虚析构函数。</p></li>
<li><p>派生类中新增加的虚函数被添加到与第一个基类相对应的虚函数表中。</p></li>
<li><p>virtual
table[1]中的clone分别为：<code>Base2* Derived::clone</code> 和 Derived*
Derived::clone
。这里为什么会比table[0]多一个<code>Base2* Derived::clone</code>呢？
因为：如果将一个Derived对象地址指定给一个Base1指针或者Derived指针是，虚拟机制使用的是virtual
table[0]
；如果将一个Derived对象地址指定给一个Base2指针时，虚拟机制使用的是virtual
table[1]。 （&lt;&lt;C++对象模型&gt;&gt; P164)</p></li>
</ul>
<!-- 1. "指针的类型"会教导编译器如何解释某个特定地址中的内存内容以及其大小（void*指针只能够持有一个地址，而不能通过它操作所指向的object）
2. C++通过class的pointers和references来支持多态，付出的代价就是额外的间接性。它们之所以支持多态是因为它们并不引发内存中任何"与类型有关的内存委托操作(type-dependent commitment)"，会受到改变的，只有他们所指向的内存的"大小和内容的解释方式"而已。
 -->
<h2 id="构造函数">构造函数</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030335656.png" /></p>
<h3 id="构造函数一般不定义为虚函数">构造函数一般不定义为虚函数</h3>
<ul>
<li>从存储空间的角度考虑：构造函数是在实例化对象的时候进行调用，如果此时将构造函数定义成虚函数，需要<strong>通过访问该对象所在的内存空间才能进行虚函数的调用</strong>（因为需要通过指向虚函数表的指针调用虚函数表，虽然虚函数表在编译时就有了，但是没有虚函数的指针，虚函数的指针只有在创建了对象才有），<strong>但是此时该对象还未创建</strong>，便无法进行虚函数的调用。所以构造函数不能定义成虚函数。</li>
<li>从使用的角度考虑：虚函数是基类的指针指向派生类的对象时，通过该指针实现对派生类的虚函数的调用，构造函数是在创建对象时自动调用的。</li>
<li>从实现上考虑：虚函数表是在创建对象之后才有的，因此不能定义成虚函数。</li>
<li>从类型上考虑：在创建对象时需要明确其类型。</li>
</ul>
<h3 id="析构函数一般定义成虚函数">析构函数一般定义成虚函数</h3>
<p>析构函数定义成虚函数是为了防止内存泄漏，因为当基类的指针或者引用指向或绑定到派生类的对象时，如果未将基类的析构函数定义成虚函数，会调用基类的析构函数，那么只能将基类的成员所占的空间释放掉，派生类中特有的就会无法释放内存空间导致内存泄漏。</p>
<p>每个析构函数结束时会自动（隐含地）调用父类的析构函数，而普通虚函数不会。</p>
<h2 id="参考链接">参考链接</h2>
<p><a
href="https://docs.microsoft.com/zh-cn/archive/blogs/zhanli/c-tips-adjustor-thunk-what-is-it-why-and-how-it-works">MSVC应对多重继承中的thunk技术</a>
<a
href="https://www.cnblogs.com/tgycoder/p/5426628.html">C++对象模型详解</a>
<a
href="https://www.cnblogs.com/QG-whz/p/4909359.html">图说C++对象模型：对象内存布局详解</a>
<a
href="https://blog.csdn.net/heyuhang112/article/details/41982929">RTTI实现详解</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP 文本场景的数据优化</title>
    <url>/202203/20220310-nlp-text-data-augmentation/</url>
    <content><![CDATA[<h2 id="序言">序言</h2>
<p>数据增强（Data
Augmentation，简称DA），是指根据现有数据，合成新数据的一类方法。毕竟数据才是真正的效果天花板，有了更多数据后可以提升效果、增强模型泛化能力、提高鲁棒性等。数据增强主要在CV应用中比较常见，然而由于NLP任务天生的难度，类似CV的裁剪方法可能会改变语义，既要保证数据质量又要保证多样性，所以大家在做数据增强时要十分谨慎。</p>
<h3 id="数据增强的目的">数据增强的目的</h3>
<ul>
<li>在很多机器学习场景下，没有足够的数据（数据稀缺场景）来训练高质量的模型。</li>
<li>提高训练数据的多样性，从而得到在真实场景下（很多没有见过的数据）更好的泛化效果。</li>
<li>样本不均衡</li>
<li>为了模型安全，应对模型的对抗攻击。</li>
</ul>
<h3 id="nlp数据增强研究基本现状1">NLP数据增强研究基本现状<a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h3>
<ul>
<li>在CV上很成功，逐渐在NLP任务上发现有效</li>
<li>在文本分类<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>领域数据增强方法也比较多，其他任务例如NER，多标签分类等就相对少一些;</li>
<li>语言输入是离散，而且一定的文本改变容易引起文本分布的巨大改变，无法做到像图片那样不可见的抖动;</li>
<li>一般算法都可以从输入文本空间和文本编码空间进行数据增强。</li>
<li>对抗攻击:
相比较CV的对抗，文本的对抗存在很大差异。文本输入为离散的</li>
</ul>
<p>问题： -
数据增广在当前迁移学习大背景下的大规模预训练模型上有用吗？</p>
<hr />
<h2 id="data-augmentation-in-nlp">Data Augmentation in NLP</h2>
<p>Paraphrasing：对句子中的词、短语、句子结构做一些更改，保留原始的语义
Noising：在保证label不变的同时，增加一些离散或连续的噪声，对语义的影响不大
Sampling：旨在根据目前的数据分布选取新的样本，会生成更多样的数据</p>
<blockquote>
<p>Data Augmentation Approaches in Natural LanguageProcessing: A
Survey<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></p>
</blockquote>
<h3 id="paraphrasing">Paraphrasing</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348551.png"
alt="Alt text|center|600x350" />
<figcaption aria-hidden="true">Alt text|center|600x350</figcaption>
</figure>
<p>小结:
在尽可能保留句子整体语义的情况下，增加文本丰富度，包括让每个词拥有更加丰富的上下文context，让相似的语义表达有更多样的语法构成，词汇构成等等</p>
<h3 id="noiseing">Noiseing</h3>
<p>作者给出了以下5种增加噪声的方法： <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348404.png"
alt="Alt text|center|600x600" /></p>
<ul>
<li><strong>Swapping</strong>：除了交换词之外，在分类任务中也可以交换instance或者sentence</li>
<li><strong>Deletion</strong>：可以根据tf-idf等词的重要程度进行删除</li>
<li><strong>Insertion</strong>：可以把同义词随机插入句子中</li>
<li><strong>Substitution</strong>：把一些词随机替换成其他词（非同义），模拟misspelling的场景。为了避免改变label，可以使用label-independent的词，或者利用训练数据中的其他句子</li>
<li><strong>Mixup</strong>：这个方法最近两年比较火，把句子表示和标签分别以一定权重融合，引入连续噪声，可以生成不同label之间的数据，但可解释性较差
总的来说，引入噪声的DA方法使用简单，但会对句子结构和语义造成影响，多样性有限，主要还是提升鲁棒性。
ConSERT时用到的方法：</li>
<li>对抗样本</li>
<li><strong>Dropout</strong>：也是SimCSE用到的，还有R-drop，都是通过dropout来加入连续噪声</li>
<li><strong>Feature
Cut-off</strong>：比如BERT的向量都是768维，可以随机把一些维度置为0，这个效果也不错</li>
</ul>
<p>小结： 增加模型稳健性，在不过多影响training
error的前提下，降低模型的复杂度从而降低generalization error,
类比dropout，l2，random noise injection</p>
<h3 id="sampling">Sampling</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348885.png"
alt="Alt text|center|750x500" />
Sampling是指从数据分布中采样出新的样本，不同于较通用的paraphrasing，<strong>采样更依赖任务，需要在保证数据可靠性的同时增加更多多样性</strong>，比前两个数据增强方法更难。作者整理了4种方法：</p>
<ul>
<li>Rules：用规则定义新的样本和label，比如把句子中的主谓进行变换</li>
<li>Seq2Seq
Models：根据输入和label生成新的句子，比如在NLI任务中，有研究者先为每个label（entailment，contradiction，neutral）训一个生成模型，再给定新的句子，生成对应label的。对比之下，paraphrasing主要是根据当前训练样本进行复述</li>
<li>Language
Models：给定label，利用语言模型生成样本，有点像前阵子看的谷歌UDG。有些研究会加个判别模型过滤</li>
<li>Self-training：先有监督训练一个模型，再给无监督数据打一些标签，有点蒸馏的感觉</li>
</ul>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349468.png"
alt="Alt text|center|600x250" />
<figcaption aria-hidden="true">Alt text|center|600x250</figcaption>
</figure>
<h3 id="增强方法选择依据">增强方法选择依据</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349203.png"
alt="三种类别的数据增强方法特点总结" />
<figcaption
aria-hidden="true">三种类别的数据增强方法特点总结</figcaption>
</figure>
<p>Method Stacking
实际应用时可以应用多种方法、或者一种方法的不同粒度。</p>
<p>作者推荐了两款工具eda<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>和uda<a href="#fn5"
class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>,
eda_chinese<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a>, nlpaug<a href="#fn7"
class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>第一，在使用增强的数据时，如果数据质量不高，可以先让模型在增强后的数据上pre-train，之后再用有标注数据训练。如果要一起训练，在增强数据量过大的情况下，可以对原始训练数据过采样</p>
<p>第二，在进行数据增强时注意这些超参数的调整： <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349147.png"
alt="各种方法的超参数" />
第三，其实增强很多简单数据的提升有限，可以注重困难样本的生成。比如有研究加入对抗训练、强化学习、在loss上下文章等。如果用生成方法做数据增强，也可以在生成模型上做功夫，提升数据多样性。</p>
<p>第四，如果生成错数据可能引入更多噪声，可以增加其他模型对准确性进行过滤。</p>
<hr />
<h2 id="分类任务">分类任务</h2>
<p>1、Mixup: Mixup-Transformer: Dynamic Data Augmentation for NLP
Tasks</p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349722.png"
alt="Alt text" /> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349283.png"
alt="Alt text|center|500x60" /></p>
<p>在数据不足的情况下，只用40%的数据就可以比不应用增强方案的全量数据好。应用Mixup增强方法可以提升2.46%</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349677.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>2、On Data Augmentation for Extreme Multi-label Classification</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350873.png"
alt="Alt text|center|700x300" />
<figcaption aria-hidden="true">Alt text|center|700x300</figcaption>
</figure>
<p>3、分类算法中的数据增强方法：综述 <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350998.png"
alt="Alt text|center|600x400" /> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350887.png"
alt="Alt text" /></p>
<p>这些在线blog或者paper<a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a><a href="#fn9" class="footnote-ref"
id="fnref9" role="doc-noteref"><sup>9</sup></a><a href="#fn10"
class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a>中提到了很多增强方法，主要有如下特点
- 多分类任务，为英文任务 -
有针对不同应用场景进行分析的增强方法。虽然现在都用预训练模型，但是在数据增强方法中，通过额外的静态词embedding进行数据增强也是常见的方法。</p>
<p>4、EDA <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350625.png"
alt="Alt text" /></p>
<ul>
<li>paper:EDA: Easy Data Augmentation Techniques for Boosting
Performance on Text Classification Tasks</li>
<li>github: http://github.com/jasonwei20/eda_nlp</li>
</ul>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350431.png"
alt="Alt text" /></th>
<th><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350097.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>EDA主要采用表一中的同义词替换，随机插入，随机交换，随机删除，从可视化结果中来看，增强样本与原始样本分布基本是一致的。
作者给出了在实际使用EDA方法的建议，表格的左边是数据的规模<span
class="math inline">\(N_{train}\)</span>, 右边<span
class="math inline">\(\alpha\)</span>是概率、比率
比如同义词替换中，替换的单词数<span class="math inline">\(n=\alpha *
l\)</span> , <span
class="math inline">\(l\)</span>是句子长度。随机插入、随机替换类似.
<span class="math inline">\(p=\alpha * n_{aug}\)</span>
代表使用EDA方法从每一个句子拓展出的句子数量。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350995.png"
alt="@作者的一些建议|center|400x250" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="作者的一些建议">@作者的一些建议</span>|center|400x250</figcaption>
</figure>
<p>之后，又有新的AEDA <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350389.png"
alt="Alt text" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350145.png"
alt="Alt text" /> <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351859.png"
alt="Alt text" /></p>
<h3 id="text-smoothing">Text Smoothing</h3>
<figure>
<img src="../../images/nlp/NLP文本场景的数据优化/1646230538691.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351711.png"
alt="Alt text" /></th>
<th><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351853.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentence = <span class="string">&quot;My favorite fruit is pear .&quot;</span></span><br><span class="line">lambd = <span class="number">0.1</span> <span class="comment"># interpolation hyperparameter</span></span><br><span class="line">mlm.train() <span class="comment"># enable dropout, dynamically mask</span></span><br><span class="line">tensor_input = tokenizer(sentence, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">onehot_repr = convert_to_onehot(**tensor_input)</span><br><span class="line">smoothed_repr = softmax(mlm(**tensor_input).logits[<span class="number">0</span>])</span><br><span class="line">interpolated_repr = lambd * onehot_repr + (<span class="number">1</span> - lambd) * smoothed_repr</span><br></pre></td></tr></table></figure>
<p>-code: https://github.com/1024er/cbert_aug</p>
<h3 id="promda">PromDA</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351964.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li>paper:https://arxiv.org/pdf/2202.12230.pdf</li>
<li>论文目的: low-resource Natural Language Understanding (NLU)
tasks</li>
</ul>
<p>少数据的场景，可能使用PLM不是最优的方案 我们期望构造的数据<span
class="math inline">\(\mathcal{T}_{LM}\)</span>与已有的数据集<span
class="math inline">\(\mathcal{T}\)</span>不同，能够从中学习到一些新的信息。
冻结PLMs参数可能有助于在训练过程中进行泛化。然而，寻找合适的离散任务引入并不容易以端到端方式进行优化，而且需要额外的人力。</p>
<p>引入<strong><span class="math inline">\(soft Prompt\)</span></strong>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351292.png"
alt="Alt text" /></p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351728.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<table>
<colgroup>
<col style="width: 42%" />
<col style="width: 57%" />
</colgroup>
<thead>
<tr class="header">
<th><img src="../../images/nlp/NLP文本场景的数据优化/1646293978880.png"
alt="Alt text" /></th>
<th><img src="../../images/nlp/NLP文本场景的数据优化/1646293992580.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<h3 id="dualcl">DualCL</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352998.png"
alt="Alt text" /> - paper: Dual Contrastive Learning: Text
Classification via Label-Aware Data Augmentation - github:
https://github.com/hiyouga/Dual-Contrastive-Learning - 设计主要思想:
将类别与文本表征map到同一个空间</p>
<p>传统自监督对比学习损失函数定义如下左侧公式，但是没有利用标注信息。将标注信息考虑进去，
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352067.png"
alt="Alt text" /> | <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352672.png"
alt="Alt text" />
------------------------------------------------------------ |
------------------------------------------------------------</p>
<p>到目前为止发展起来的监督对比学习似乎是对分类问题的无监督对比学习的一种简单朴素的适配。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352328.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352671.png"
alt="Alt text" /> - K+1+ 其他文本 -
学习到多个表征，其中1个原来的[CLS],另外K个是用来判断分类的结果的。<span
class="math display">\[ \hat{y}_i = \arg\max_k(\theta_i^k \cdot
z_i)\]</span></p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352326.png"
alt="Alt text" /></th>
<th><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352085.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>算法对比结果，少样本与全样本的对比： <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352508.png"
alt="Alt text" /></p>
<h3
id="sample-efficiency-of-data-augmentation-consistency-regularization">Sample
Efficiency of Data Augmentation Consistency Regularization</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353087.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>DA-ERM（data augmentation empirical risk minimization）:
DAC可以使用未标记的样本，因为可以在不知道真实标签的情况下增加训练样本并执行一致的预测。这绕过了传统算法只能增加标记样本并将其添加到训练集的限制
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353158.png"
alt="Alt text" /></p>
<p>少量数据+data augmentation 少量数据+unlabel data</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353466.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353005.png"
alt="Alt text|center" /> 我们可以看到对标注样本<span
class="math inline">\(\phi(x_i)\)</span>和增强产生的样本<span
class="math inline">\(\phi(x_{i,j})\)</span>之间的差异作为惩罚项。</p>
<p>我们从经验和理论上论证了DAC与DA-ERM(用增强样本扩展训练集)相比的优点。理论上，线性回归和逻辑回归的泛化误差更小，两层神经网络的泛化上界更紧。另一个好处是，DAC可以更好地处理由强扩充数据引起的模型错误规范。在经验上，我们提供了关于增广ERM和一致性正则化的比较。这些共同证明了一致性规则化优于DA-ERM的有效性</p>
<h3
id="alp-data-augmentation-using-lexicalized-pcfgs-for-few-shot-text-classification">ALP:
Data Augmentation using Lexicalized PCFGs for Few-Shot Text
Classification</h3>
<ul>
<li>标题：ALP：基于词汇化PCFGS的Few-Shot文本分类数据增强</li>
<li>链接：https://arxiv.org/abs/2112.11916</li>
<li>作者：Hazel Kim,Daecheol Woo,Seong Joon Oh,Jeong-Won Cha,Yo-Sub
Han</li>
<li>机构： Yonsei University, Seoul, Republic of Korea, NAVER AI Lab,
Changwon National University, Changwon, Republic of Korea</li>
<li>备注：Accepted to AAAI2022</li>
</ul>
<p>这个是基于文法分析树的方式进行数据增强的</p>
<h2 id="nerprompt-base在ner中的应用">NER[^prompt base在NER中的应用]</h2>
<p>该任务中需要生成句子和token级别的标签。且序列标注为细粒度的文本任务。
现有的生成模型智能生成没有标签的序列；
启发式的数据增强方法不可行，直接对标签替换或者上下文替换，被注入错误的可能性比较大，相比较分类任务更容易破坏序列上下文关系。</p>
<h3
id="an-analysis-of-simple-data-augmentation-for-named-entity-recognition">An
Analysis of Simple Data Augmentation for Named Entity Recognition</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353604.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353756.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li><strong>Label-wise token replacement (LwTR)
</strong>：即同标签token替换，对于每一token通过二项分布来选择是否被替换；如果被替换，则从训练集中选择相同的token进行替换。</li>
<li><strong>Synonym replacement (SR)
</strong>：即同义词替换，利用WordNet查询同义词，然后根据二项分布随机替换。如果替换的同义词大于1个token，那就依次延展BIO标签。</li>
<li><strong>Mention replacement (MR)
</strong>：即实体提及替换，与同义词方法类似，利用训练集中的相同实体类型进行替换，如果替换的mention大于1个token，那就依次延展BIO标签，如上图：「headache」替换为「neuropathic
pain syndrome」，依次延展BIO标签。</li>
<li><strong>Shuffle within segments (SiS)</strong>
：按照mention来切分句子，然后再对每个切分后的片段进行shuffle。如上图，共分为5个片段：
[She did not complain of], [headache], [or], [any other neurological
symptoms], [.].
。也是通过二项分布判断是否被shuffle（mention片段不会被shuffle），如果shuffle，则打乱片段中的token顺序。</li>
</ul>
<figure>
<img src="../../images/nlp/NLP文本场景的数据优化/1646362972193.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>由上图可以看出： -
各种数据增强方法都超过不使用任何增强时的baseline效果。 -
对于RNN网络，实体提及替换优于其他方法；对于Transformer网络，同义词替换最优。
- 总体上看，所有增强方法一起使用（ALL）会优于单独的增强方法。 -
低资源条件下，数据增强效果增益更加明显；充分数据条件下，数据增强可能会带来噪声，甚至导致指标下降；</p>
<h3
id="daga-data-augmentatino-with-a-generation-approach-for-low-resource-tagging-tasks">DAGA:
Data Augmentatino with a Generation Approach for Low-resource Tagging
Tasks</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353938.png"
alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>DAGA的思想简单来讲就是标签线性化：即将原始的<strong>「序列标注标签」与「句子token」进行混合，也就是变成「Tag-Word」</strong>的形式，如下图：将「B-PER」放置在「Jose」之前，将「E-PER」放置在「Valentin」之前；对于标签「O」则不与句子混合。标签线性化后就可以生成一个句子了，文章基于此句子就可以进行「语言模型生成」了。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353943.png"
alt="Alt text" /></p>
<h3 id="seqmix">SeqMix</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353921.png"
alt="Alt text" /> - 标题: SeqMix: Augmenting Active Sequence Labeling
via Sequence Mixup - 链接:
https://rongzhizhang.org/pdf/emnlp20_SeqMix.pdf - 开源代码:
https://github.com/rz-zhang/SeqMix - 备注: EMNLP 2020 <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353427.png"
alt="Alt text" /></p>
<h3 id="boundary-smoothing-for-named-entity-recognition">Boundary
Smoothing for Named Entity Recognition</h3>
<p><img src="../../images/nlp/NLP文本场景的数据优化/1646817503789.png"
alt="Alt text" /> - 标题: 针对命名实体识别的span类的算法的边界平滑 -
code: https://github.com/syuoni/eznlp</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353619.png"
alt="Alt text" /></th>
<th><img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030354558.png"
alt="Alt text" /></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>An example of hard and smoothed boundaries. The example sentence has
ten tokens and two entities of spans (1, 2) and (3, 7), colored in red
and blue, respectively. The first subfigure presents the entity
recognition targets of hard boundaries. The second subfigure presents
the corresponding targets of smoothed boundaries, where the span (1, 2)
is smoothed by a size of 1, and the span (3, 7) is smoothed by a size of
2. 其中周边区域有<span
class="math inline">\(\epsilon\)</span>的概率会被赋值，此时原标注位置值为<span
class="math inline">\(1 - \epsilon\)</span>，周边区域<span
class="math inline">\(D\)</span>赋值<span class="math inline">\(\epsilon
/ D\)</span>,</p>
<p>对NER标签位置的平滑处理，提升模型的泛化性。边界平滑可以防止模型对预测实体过于自信，从而获得更好的定标效果。D一般不用太大，1或者2即可，
<span class="math inline">\(\epsilon\)</span>一般取[0.1, 0.2, 0.3] <img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353317.png"
alt="Alt text" /></p>
<p>[^prompt
base在NER中的应用]:https://zhuanlan.zhihu.com/p/462332297</p>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Steven Y. Feng, Varun Gangal, Jason
Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, &amp; Eduard
Hovy (2021). A Survey of Data Augmentation Approaches for NLP Meeting of
the Association for Computational Linguistics.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Markus Bayer, Marc-André Kaufhold,
&amp; Christian Reuter (2021). A Survey on Data Augmentation for Text
Classification.. arXiv: Computation and Language.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Li, B. , Hou, Y. , &amp; Che, W. .
(2021). Data augmentation approaches in natural language processing: a
survey.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://github.com/jasonwei20/eda_nlp<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>https://github.com/google-research/uda<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://github.com/zhanlaoban/eda_nlp_for_Chinese<a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"
role="doc-endnote"><p>https://github.com/makcedward/nlpaug<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Steven Y. Feng, Varun Gangal, Jason
Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, &amp; Eduard
Hovy (2021). A Survey of Data Augmentation Approaches for NLP Meeting of
the Association for Computational Linguistics.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Markus Bayer, Marc-André Kaufhold,
&amp; Christian Reuter (2021). A Survey on Data Augmentation for Text
Classification.. arXiv: Computation and Language.<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Amit Chaudhary(2020). A Visual
Survey of Data Augmentation in NLP.
https://amitness.com/2020/05/data-augmentation-for-nlp<a href="#fnref10"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA并行编程学习笔记</title>
    <url>/202208/20220831-basic-cuda-interface/</url>
    <content><![CDATA[<h2 id="名词">名词</h2>
<ul>
<li>SIMD： 单指令多数据，是基于一个处理器核的，128位</li>
<li>MMX：多媒体拓展</li>
<li>AVX 高级适量拓展， 256位</li>
</ul>
<h2 id="计算机架构">计算机架构</h2>
<h3 id="冯诺依曼计算机架构">冯诺依曼计算机架构</h3>
<ul>
<li>内存受限型</li>
<li>QPI (quick path interconnect) 快速通道互联</li>
</ul>
<h3 id="连接机">连接机</h3>
<p>采用4096个16核的CPU组装到一台机器上，也就是说64K个处理器来完成一个任务。连接机采用SIMD型并行处理，但是处理器之间的同步和通讯是很大的问题</p>
<h3 id="cell处理器众核">Cell处理器(众核)</h3>
<p>用一个常规处理器作为监管处理器(PowerPC)，该处理器与大量高速流处理(SPE)相连。
* 每个流处理单元SPE调用执行一个程序 *
通过共享的网络，SPE之间和SPE与PowerPC之间进行相互通讯 * <img
src="https://cwlseu.github.io/images/cuda/cell_arch.png"
alt="国产申威 26010 处理器架构图" /></p>
<h3 id="多点计算">多点计算</h3>
<p>集群，当前最流行的莫过于Hadoop和spark了，一个是分布式文件系统，一个是分布式计算框架，这两个工具使得多点计算的方法充分发挥。</p>
<h3 id="gpu架构">GPU架构</h3>
<p><img
src="https://cdn.jsdelivr.net/cwlseu/deepindeed_repo@main/images/nvidia-device-arch.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/cwlseu/deepindeed_repo@main/images/nvidia-gpu-stream-arch.png" /></p>
<h2 id="cuda编程基础知识">CUDA编程基础知识</h2>
<p>学习CUDA
C，可以在异构计算平台中实现高性能的应用。CUD的编译原则--基于虚拟指令集的运行时编译。</p>
<h2 id="计算能力高性能硬件与技术">计算能力—高性能硬件与技术</h2>
<p>GPU在高性能计算和深度学习加速中扮演着非常重要的角色，
GPU的强大的并行计算能力，大大提升了运算性能。随着运算数据量的不断攀升，GPU间需要大量的交换数据，GPU通信性能成为了非常重要的指标。NVIDIA推出的GPUDirect就是一组提升GPU通信性能的技术。但GPUDirect受限于PCI
Expresss总线协议以及拓扑结构的一些限制，无法做到更高的带宽，为了解决这个问题，NVIDIA提出了NVLink总线协议。</p>
<h3 id="gpudirect-p2p">GPUDirect P2P</h3>
<p>GPUDirect Peer-to-Peer(P2P)
技术主要用于单机GPU间的高速通信，它使得GPU可以通过PCI
Express直接访问目标GPU的显存，避免了通过拷贝到CPU host
memory作为中转，大大降低了数据交换的延迟。
以深度学习应用为例，主流的开源深度学习框架如TensorFlow、MXNet都提供了对GPUDirect
P2P的支持，NVIDIA开发的NCCL(NVIDIA Collective Communications
Library)也提供了针对GPUDirect P2P的特别优化。 通过使用GPUDirect
P2P技术可以大大提升深度学习应用单机多卡的扩展性，使得深度学习框架可以获得接近线性的训练性能加速比</p>
<ul>
<li><a
href="http://server.it168.com/a2018/0604/3206/000003206891.shtml">浅析GPU通信技术（上）--GPUDirect
P2P</a></li>
</ul>
<h3 id="nvlink-拓扑结构图">NVLink 拓扑结构图</h3>
<p>首先我们简单看下NVIDIA对NVLink的介绍：NVLink能在多GPU之间和GPU与CPU之间实现非凡的连接带宽。带宽有多大?2016发布的P100是搭载NVLink的第一款产品，单个GPU具有160GB/s的带宽，相当于PCIe
Gen3 * 16带宽的5倍。去年GTC 2017上发布的V100搭载的NVLink
2.0更是将GPU带宽提升到了300G/s，差不多是PCIe的10倍了。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/cwlseu/deepindeed_repo@main/images/NVLINK.png"
alt="NVLINK网络拓扑结构" />
<figcaption aria-hidden="true">NVLINK网络拓扑结构</figcaption>
</figure>
<ul>
<li><a href="https://www.nvidia.com/zh-cn/data-center/nvlink/">NVIDIA
NVLINK</a></li>
<li><a
href="http://server.it168.com/a2018/0604/3206/000003206894.shtml">浅析GPU通信技术（中）-NVLink总线协议</a></li>
</ul>
<h3 id="rdma原理介绍">RDMA原理介绍</h3>
<p>前面介绍的GPUDirect
P2P和NVLink技术可以大大提升GPU服务器单机的GPU通信性能，当前深度学习模型越来越复杂，计算数据量暴增，对于大规模深度学习训练任务，单机已经无法满足计算要求，多机多卡的分布式训练成为了必要的需求，这个时候多机间的通信成为了分布式训练性能的重要指标。</p>
<p><img
src="https://cdn.jsdelivr.net/cwlseu/deepindeed_repo@main/images/nvidia-RMDA-arch.png"
alt="多机通讯RMDA架构图" />
如上图所示，传统的TCP/IP协议，应用程序需要要经过多层复杂的协议栈解析，才能获取到网卡中的数据包，而使用RDMA协议，应用程序可以直接旁路内核获取到网卡中的数据包。RDMA可以简单理解为利用相关的硬件和网络技术，服务器1的网卡可以直接读写服务器2的内存，最终达到高带宽、低延迟和低资源利用率的效果。
<img
src="https://cdn.jsdelivr.net/cwlseu/deepindeed_repo@main/images/nvidia-RMDA-All.png"
alt="应用RMDA技术的应用拓扑图" /> 所谓GPUDirect
RDMA，就是计算机1的GPU可以直接访问计算机2的GPU内存。而在没有这项技术之前，GPU需要先将数据从GPU内存搬移到系统内存，然后再利用RDMA传输到计算机2，计算机2的GPU还要做一次数据从系统内存到GPU内存的搬移动作。GPUDirect
RDMA技术使得进一步减少了GPU通信的数据复制次数，通信延迟进一步降低。</p>
<ul>
<li><a
href="https://yq.aliyun.com/articles/603617">浅析GPU通信技术（下）-GPUDirect
RDMA</a></li>
</ul>
<h2 id="cuda的基础入门">CUDA的基础入门</h2>
<h3 id="函数的类型">函数的类型</h3>
<p><code>__host__ float HostFunc()</code>
默认情况下，被host函数调用在CPU上执行</p>
<p><code>__devide__ float DeviceFunc()</code> 被GPU设备执行调用</p>
<p><code>__global__ void Kernelfunc()</code>
被host函数调用，在设备上执行</p>
<pre><code>Note：
* __global__函数返回值必须为void
* 在设备上执行的函数不能是递归，函数参数是固定的，不能再函数内部使用static变量</code></pre>
<h3 id="变量类型">变量类型</h3>
<p><code>__shared__ A[4]</code>；//在share memory，块内线程共享。
设备上的函数，声明的变量都是存在register上的，存不下的放到local memory；
<code>cudaMalloc()</code>的空间是在设备的global memory上的。</p>
<h3 id="cuda几个头文件">CUDA几个头文件</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span>  <span class="comment">// cuda程序运行必须的头文件</span></span></span><br></pre></td></tr></table></figure>
<h3 id="cuda-routine">CUDA routine</h3>
<ol type="1">
<li><p><code>cudaError_t err = cudaSuccess;</code>
<code>cudaError_t</code>类型，表示错误类型。<code>cudaSuccess</code>表示成功。一般cuda
routine的返回值都是<code>cudaError_t</code>类型，表示函数是否执行成功。</p></li>
<li><p><code>printf("%s\n", cudaGetErrorString(cudaGetLastError()));</code>
输出错误时，使用以上函数转化为string。</p></li>
<li><p><code>err = cudaMalloc((void **)&amp;d_A, size);</code>
动态内存申请函数，在设备的global memory上申请size个字节空间。</p></li>
<li><p><code>err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);</code>or
<code>err = cudaMemcpy(h_A, d_A, size, cudaMemcpyDeviceToHost);</code>
//内存拷贝函数：从cpu上的内存h_A上拷贝size个字节数据到gpu上的内存d_A。反之，一样。</p></li>
<li><p><code>int threadsPerBlock = 256;</code>
<code>int blocksPerGrid =(nElements + threadsPerBlock - 1) / threadsPerBlock;     vectorAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, nElements);</code>
//前2句，表示Grid，block都是1维时，设置网格内的块数，每块内的线程数。
//最后一句，启动kernel（运行在gpu端的函数）函数。
//注意前2句可以改成。dim3 threadsPerBlock(256);这种形式。</p></li>
<li><p><code>err = cudaGetLastError();</code>
//启动kernel函数时，并没有返回值，通过这个调用这个函数，查看kernel函数是否启动成功。</p></li>
<li><p><code>err = cudaFree(d_A);</code>
//释放使用cudaMalloc申请的空间。</p></li>
<li><p><code>err = cudaMemset(d_a, 0, size)</code>
//类似于memset函数。将d_A的size个字节置0.</p></li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * CUDA device properties</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">__device_builtin__</span> cudaDeviceProp</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">char</span>   name[<span class="number">256</span>];                  <span class="comment">/**&lt; ASCII string identifying device */</span></span><br><span class="line">    <span class="type">size_t</span> totalGlobalMem;             <span class="comment">/**&lt; Global memory available on device in bytes */</span></span><br><span class="line">    <span class="type">size_t</span> sharedMemPerBlock;          <span class="comment">/**&lt; Shared memory available per block in bytes */</span></span><br><span class="line">    <span class="type">int</span>    regsPerBlock;               <span class="comment">/**&lt; 32-bit registers available per block */</span></span><br><span class="line">    <span class="type">int</span>    warpSize;                   <span class="comment">/**&lt; Warp size in threads */</span></span><br><span class="line">    <span class="type">size_t</span> memPitch;                   <span class="comment">/**&lt; Maximum pitch in bytes allowed by memory copies */</span></span><br><span class="line">    <span class="type">int</span>    maxThreadsPerBlock;         <span class="comment">/**&lt; Maximum number of threads per block */</span></span><br><span class="line">    <span class="type">int</span>    maxThreadsDim[<span class="number">3</span>];           <span class="comment">/**&lt; Maximum size of each dimension of a block */</span></span><br><span class="line">    <span class="type">int</span>    maxGridSize[<span class="number">3</span>];             <span class="comment">/**&lt; Maximum size of each dimension of a grid */</span></span><br><span class="line">    <span class="type">int</span>    clockRate;                  <span class="comment">/**&lt; Clock frequency in kilohertz */</span></span><br><span class="line">    <span class="type">size_t</span> totalConstMem;              <span class="comment">/**&lt; Constant memory available on device in bytes */</span></span><br><span class="line">    <span class="type">int</span>    major;                      <span class="comment">/**&lt; Major compute capability */</span></span><br><span class="line">    <span class="type">int</span>    minor;                      <span class="comment">/**&lt; Minor compute capability */</span></span><br><span class="line">    <span class="type">size_t</span> textureAlignment;           <span class="comment">/**&lt; Alignment requirement for textures */</span></span><br><span class="line">    <span class="type">size_t</span> texturePitchAlignment;      <span class="comment">/**&lt; Pitch alignment requirement for texture references bound to pitched memory */</span></span><br><span class="line">    <span class="type">int</span>    deviceOverlap;              <span class="comment">/**&lt; Device can concurrently copy memory and execute a kernel. Deprecated. Use instead asyncEngineCount. */</span></span><br><span class="line">    <span class="type">int</span>    multiProcessorCount;        <span class="comment">/**&lt; Number of multiprocessors on device */</span></span><br><span class="line">    <span class="type">int</span>    kernelExecTimeoutEnabled;   <span class="comment">/**&lt; Specified whether there is a run time limit on kernels */</span></span><br><span class="line">    <span class="type">int</span>    integrated;                 <span class="comment">/**&lt; Device is integrated as opposed to discrete */</span></span><br><span class="line">    <span class="type">int</span>    canMapHostMemory;           <span class="comment">/**&lt; Device can map host memory with cudaHostAlloc/cudaHostGetDevicePointer */</span></span><br><span class="line">    <span class="type">int</span>    computeMode;                <span class="comment">/**&lt; Compute mode (See ::cudaComputeMode) */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture1D;               <span class="comment">/**&lt; Maximum 1D texture size */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture1DMipmap;         <span class="comment">/**&lt; Maximum 1D mipmapped texture size */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture1DLinear;         <span class="comment">/**&lt; Maximum size for 1D textures bound to linear memory */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture2D[<span class="number">2</span>];            <span class="comment">/**&lt; Maximum 2D texture dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture2DMipmap[<span class="number">2</span>];      <span class="comment">/**&lt; Maximum 2D mipmapped texture dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture2DLinear[<span class="number">3</span>];      <span class="comment">/**&lt; Maximum dimensions (width, height, pitch) for 2D textures bound to pitched memory */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture2DGather[<span class="number">2</span>];      <span class="comment">/**&lt; Maximum 2D texture dimensions if texture gather operations have to be performed */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture3D[<span class="number">3</span>];            <span class="comment">/**&lt; Maximum 3D texture dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture3DAlt[<span class="number">3</span>];         <span class="comment">/**&lt; Maximum alternate 3D texture dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxTextureCubemap;          <span class="comment">/**&lt; Maximum Cubemap texture dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture1DLayered[<span class="number">2</span>];     <span class="comment">/**&lt; Maximum 1D layered texture dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxTexture2DLayered[<span class="number">3</span>];     <span class="comment">/**&lt; Maximum 2D layered texture dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxTextureCubemapLayered[<span class="number">2</span>];<span class="comment">/**&lt; Maximum Cubemap layered texture dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxSurface1D;               <span class="comment">/**&lt; Maximum 1D surface size */</span></span><br><span class="line">    <span class="type">int</span>    maxSurface2D[<span class="number">2</span>];            <span class="comment">/**&lt; Maximum 2D surface dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxSurface3D[<span class="number">3</span>];            <span class="comment">/**&lt; Maximum 3D surface dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxSurface1DLayered[<span class="number">2</span>];     <span class="comment">/**&lt; Maximum 1D layered surface dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxSurface2DLayered[<span class="number">3</span>];     <span class="comment">/**&lt; Maximum 2D layered surface dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxSurfaceCubemap;          <span class="comment">/**&lt; Maximum Cubemap surface dimensions */</span></span><br><span class="line">    <span class="type">int</span>    maxSurfaceCubemapLayered[<span class="number">2</span>];<span class="comment">/**&lt; Maximum Cubemap layered surface dimensions */</span></span><br><span class="line">    <span class="type">size_t</span> surfaceAlignment;           <span class="comment">/**&lt; Alignment requirements for surfaces */</span></span><br><span class="line">    <span class="type">int</span>    concurrentKernels;          <span class="comment">/**&lt; Device can possibly execute multiple kernels concurrently */</span></span><br><span class="line">    <span class="type">int</span>    ECCEnabled;                 <span class="comment">/**&lt; Device has ECC support enabled */</span></span><br><span class="line">    <span class="type">int</span>    pciBusID;                   <span class="comment">/**&lt; PCI bus ID of the device */</span></span><br><span class="line">    <span class="type">int</span>    pciDeviceID;                <span class="comment">/**&lt; PCI device ID of the device */</span></span><br><span class="line">    <span class="type">int</span>    pciDomainID;                <span class="comment">/**&lt; PCI domain ID of the device */</span></span><br><span class="line">    <span class="type">int</span>    tccDriver;                  <span class="comment">/**&lt; 1 if device is a Tesla device using TCC driver, 0 otherwise */</span></span><br><span class="line">    <span class="type">int</span>    asyncEngineCount;           <span class="comment">/**&lt; Number of asynchronous engines */</span></span><br><span class="line">    <span class="type">int</span>    unifiedAddressing;          <span class="comment">/**&lt; Device shares a unified address space with the host */</span></span><br><span class="line">    <span class="type">int</span>    memoryClockRate;            <span class="comment">/**&lt; Peak memory clock frequency in kilohertz */</span></span><br><span class="line">    <span class="type">int</span>    memoryBusWidth;             <span class="comment">/**&lt; Global memory bus width in bits */</span></span><br><span class="line">    <span class="type">int</span>    l2CacheSize;                <span class="comment">/**&lt; Size of L2 cache in bytes */</span></span><br><span class="line">    <span class="type">int</span>    maxThreadsPerMultiProcessor;<span class="comment">/**&lt; Maximum resident threads per multiprocessor */</span></span><br><span class="line">    <span class="type">int</span>    streamPrioritiesSupported;  <span class="comment">/**&lt; Device supports stream priorities */</span></span><br><span class="line">    <span class="type">int</span>    globalL1CacheSupported;     <span class="comment">/**&lt; Device supports caching globals in L1 */</span></span><br><span class="line">    <span class="type">int</span>    localL1CacheSupported;      <span class="comment">/**&lt; Device supports caching locals in L1 */</span></span><br><span class="line">    <span class="type">size_t</span> sharedMemPerMultiprocessor; <span class="comment">/**&lt; Shared memory available per multiprocessor in bytes */</span></span><br><span class="line">    <span class="type">int</span>    regsPerMultiprocessor;      <span class="comment">/**&lt; 32-bit registers available per multiprocessor */</span></span><br><span class="line">    <span class="type">int</span>    managedMemory;              <span class="comment">/**&lt; Device supports allocating managed memory on this system */</span></span><br><span class="line">    <span class="type">int</span>    isMultiGpuBoard;            <span class="comment">/**&lt; Device is on a multi-GPU board */</span></span><br><span class="line">    <span class="type">int</span>    multiGpuBoardGroupID;       <span class="comment">/**&lt; Unique identifier for a group of devices on the same multi-GPU board */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="常见问题">常见问题</h2>
<p>NVCC没有配置，导致undefined reference HEADER
DIR没有配置，导致找不到头文件</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>GPU编程</tag>
      </tags>
  </entry>
  <entry>
    <title>算法的乐趣：递归和指针</title>
    <url>/201707/20170710-based-algorithm-4/</url>
    <content><![CDATA[<h2 id="node的定义">Node的定义</h2>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">TreeNode</span> &#123;</span><br><span class="line">	<span class="type">int</span> val;</span><br><span class="line">	<span class="keyword">struct</span> <span class="title class_">TreeNode</span> *left;</span><br><span class="line">	<span class="keyword">struct</span> <span class="title class_">TreeNode</span> *right;</span><br><span class="line">	<span class="built_in">TreeNode</span>(<span class="type">int</span> x) :</span><br><span class="line">			<span class="built_in">val</span>(x), <span class="built_in">left</span>(<span class="literal">NULL</span>), <span class="built_in">right</span>(<span class="literal">NULL</span>) &#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ListNode</span> &#123;</span><br><span class="line">	<span class="type">int</span> val;</span><br><span class="line">	<span class="keyword">struct</span> <span class="title class_">ListNode</span> *next;</span><br><span class="line">	<span class="built_in">ListNode</span>(<span class="type">int</span> x) :</span><br><span class="line">			<span class="built_in">val</span>(x), <span class="built_in">next</span>(<span class="literal">NULL</span>) &#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="一些比较trick的问题">一些比较trick的问题</h2>
<h3 id="删除list中的一个节点">删除List中的一个节点</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">delete_node</span><span class="params">(ListNode* curr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(curr-&gt;next)</span><br><span class="line">	&#123;</span><br><span class="line">		curr-&gt;val = curr-&gt;next-&gt;val;</span><br><span class="line">		curr-&gt;next = curr-&gt;next-&gt;next;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="将二叉树转化为双向链表">将二叉树转化为双向链表</h2>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030319970.jpg"
alt="@算法示意图" />
<figcaption aria-hidden="true"><span class="citation"
data-cites="算法示意图">@算法示意图</span></figcaption>
</figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***************************************************************************</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 将一颗二叉树转化为双向链表的操作</span></span><br><span class="line"><span class="comment"> * 思路：</span></span><br><span class="line"><span class="comment"> * 采用中序遍历的想法的，对二叉树进行中序遍历，遍历过程就是最终的结果过程，然后将</span></span><br><span class="line"><span class="comment"> * 前后进行指针的重新设置即可。</span></span><br><span class="line"><span class="comment"> * 本题目主要考察递归和指针的操作</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> **************************************************************************/</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">TreeNode* <span class="title">Convert</span><span class="params">(TreeNode* pRootOfTree)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(pRootOfTree == <span class="literal">NULL</span>) <span class="keyword">return</span> pRootOfTree;</span><br><span class="line">        pRootOfTree = <span class="built_in">ConvertNode</span>(pRootOfTree);</span><br><span class="line">        <span class="comment">// 获取头节点的地址，最小的值对应的指针地址</span></span><br><span class="line">        <span class="keyword">while</span>(pRootOfTree-&gt;left) pRootOfTree = pRootOfTree-&gt;left;</span><br><span class="line">        <span class="keyword">return</span> pRootOfTree;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 进行中序遍历</span></span><br><span class="line">    <span class="function">TreeNode* <span class="title">ConvertNode</span><span class="params">(TreeNode* root)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) <span class="keyword">return</span> root;</span><br><span class="line">		<span class="comment">// 中序遍历左子树</span></span><br><span class="line">        <span class="keyword">if</span>(root-&gt;left)</span><br><span class="line">        &#123;</span><br><span class="line">            TreeNode *left = <span class="built_in">ConvertNode</span>(root-&gt;left);</span><br><span class="line">            <span class="keyword">while</span>(left-&gt;right) left = left-&gt;right;</span><br><span class="line">            left-&gt;right = root;</span><br><span class="line">            root-&gt;left = left;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 中序遍历右子树</span></span><br><span class="line">        <span class="keyword">if</span>(root-&gt;right)</span><br><span class="line">        &#123;</span><br><span class="line">            TreeNode *right = <span class="built_in">ConvertNode</span>(root-&gt;right);</span><br><span class="line">            <span class="keyword">while</span>(right-&gt;left) right = right-&gt;left;</span><br><span class="line">            right-&gt;left = root;</span><br><span class="line">            root-&gt;right = right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="从链表中查找倒数kth个">从链表中查找倒数Kth个</h2>
<p>本题的思路就是通过两个指针，一个快一个慢，中间相差k个，当其中快指针指向结尾的时候，慢指针指向的位置就是所求。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">FindKthToTail</span><span class="params">(ListNode* pListHead, <span class="type">unsigned</span> <span class="type">int</span> k)</span> </span>&#123;  </span><br><span class="line">    	ListNode* fast = pListHead;</span><br><span class="line">    	<span class="type">int</span> i = k;</span><br><span class="line">    	<span class="keyword">while</span>(fast &amp;&amp; i &gt; <span class="number">0</span>)</span><br><span class="line">    	&#123;</span><br><span class="line">    		fast = fast-&gt;next;</span><br><span class="line">    		i--;</span><br><span class="line">    	&#125;</span><br><span class="line">    	<span class="keyword">if</span>(i != <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    	ListNode* slow = pListHead;</span><br><span class="line">    	<span class="keyword">while</span>(fast &amp;&amp; slow)</span><br><span class="line">    	&#123;</span><br><span class="line">    		fast  = fast-&gt;next;</span><br><span class="line">    		slow = slow-&gt;next;</span><br><span class="line">    	&#125;</span><br><span class="line">    	<span class="keyword">return</span> slow;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="红黑树">红黑树</h2>
<p>https://blog.csdn.net/weewqrer/article/details/51866488</p>
<h3 id="用途">用途</h3>
<p>红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保。对于查找、插入、删除、最大、最小等动态操作的时间复杂度为O(lgn).常见的用途有以下几种：</p>
<p>STL（标准模板库）中在set map是基于红黑树实现的。
Java中在TreeMap使用的也是红黑树。
epoll在内核中的实现，用红黑树管理事件块。 linux进程调度Completely Fair
Scheduler,用红黑树管理进程控制块</p>
<h3 id="红黑树-vs-avl树">红黑树 VS AVL树</h3>
<p>常见的平衡树有红黑树和AVL平衡树，为什么STL和linux都使用红黑树作为平衡树的实现？大概有以下几个原因：</p>
<p>从实现细节上来讲，如果插入一个结点引起了树的不平衡，AVL树和红黑树都最多需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度</p>
<p>从两种平衡树对平衡的要求来讲，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。</p>
<p>总体来说，RB-tree的统计性能是高于AVL的</p>
<h2 id="参考链接">参考链接</h2>
<p>[1].<a
href="https://blog.csdn.net/weewqrer/article/details/51866488">关于红黑树的介绍</a></p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
</search>

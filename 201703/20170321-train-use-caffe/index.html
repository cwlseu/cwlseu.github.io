<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CTimes+New+Roman:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.deepindeed.cn","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":28},"copycode":false,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="使用caffe框架进行实验过程中的一些心得">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习：玩转Caffe">
<meta property="og:url" content="http://www.deepindeed.cn/201703/20170321-train-use-caffe/index.html">
<meta property="og:site_name" content="Deepindeed">
<meta property="og:description" content="使用caffe框架进行实验过程中的一些心得">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2017-03-21T12:00:00.000Z">
<meta property="article:modified_time" content="2022-09-02T20:05:26.049Z">
<meta property="article:author" content="CharlesCao">
<meta property="article:tag" content="framework">
<meta property="article:tag" content="caffe">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://www.deepindeed.cn/201703/20170321-train-use-caffe/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://www.deepindeed.cn/201703/20170321-train-use-caffe/","path":"201703/20170321-train-use-caffe/","title":"深度学习：玩转Caffe"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>深度学习：玩转Caffe | Deepindeed</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-86501439-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-86501439-1","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>




<link rel="dns-prefetch" href="https://waline.vercel.app"><link rel="stylesheet" href="https://lib.baomitu.com/social-share.js/1.0.16/css/share.min.css">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Deepindeed</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">心有猛虎，细嗅蔷薇</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tools"><a href="/tools/" rel="section"><i class="fa fa-globe fa-fw"></i>tools</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%95%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#imagenet%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">ImageNet的数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81image-list"><span class="nav-number">2.1.</span> <span class="nav-text">1. 常见image list</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E6%88%90backend%E4%B8%BAleveldb%E6%88%96%E8%80%85lmdb"><span class="nav-number">2.2.</span> <span class="nav-text">2.
生成backend为leveldb或者lmdb</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#proto%E4%B8%AD%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8"><span class="nav-number">2.3.</span> <span class="nav-text">3. proto中配置使用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="nav-number">3.1.</span> <span class="nav-text">1、学习率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#caffe%E8%AE%AD%E7%BB%83%E6%97%B6loss%E5%8F%98%E4%B8%BAnan%E7%9A%84%E5%8E%9F%E5%9B%A02"><span class="nav-number">3.2.</span> <span class="nav-text">2、caffe训练时Loss变为nan的原因1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%B1%E5%B0%8F%E5%8F%98%E5%A4%A7%E6%98%93%E5%87%BAnan"><span class="nav-number">3.2.1.</span> <span class="nav-text">由小变大易出nan</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8resnet-block%E6%88%96%E8%80%85inception%E6%8A%80%E6%9C%AF%E6%9C%80%E5%90%8E%E7%9A%84%E7%BB%93%E6%9E%9C%E9%80%9A%E8%BF%87bitwise-operation%E8%BF%9B%E8%A1%8C%E7%BB%84%E5%90%88%E8%80%8C%E4%B8%8D%E6%98%AF%E9%87%87%E7%94%A8%E6%8C%89channel-concatenate%E8%BF%9B%E8%A1%8C%E7%9A%84"><span class="nav-number">3.2.2.</span> <span class="nav-text">使用ResNet-Block或者Inception技术，最后的结果通过Bitwise
Operation进行组合，而不是采用按channel Concatenate进行的。</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8"><span class="nav-number">3.3.</span> <span class="nav-text">3、梯度爆炸</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8D%E5%BD%93%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.3.1.</span> <span class="nav-text">不当的损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8D%E5%BD%93%E7%9A%84%E8%BE%93%E5%85%A5"><span class="nav-number">3.3.2.</span> <span class="nav-text">不当的输入</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#caffe-debug-info34"><span class="nav-number">3.4.</span> <span class="nav-text">4、Caffe Debug info23</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#caffe-blob-data-structure"><span class="nav-number">3.4.1.</span> <span class="nav-text">Caffe Blob data structure</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#forward-pass"><span class="nav-number">3.4.2.</span> <span class="nav-text">Forward pass</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#loss-and-gradient"><span class="nav-number">3.4.3.</span> <span class="nav-text">Loss and gradient</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#backward-pass"><span class="nav-number">3.4.4.</span> <span class="nav-text">Backward pass</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#finally"><span class="nav-number">3.4.5.</span> <span class="nav-text">Finally</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#what-should-i-look-for"><span class="nav-number">3.4.6.</span> <span class="nav-text">What should I look for?</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tools%E4%BA%8B%E5%8D%8A%E5%8A%9F%E5%80%8D"><span class="nav-number">4.</span> <span class="nav-text">Tools事半功倍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#caffe-tools"><span class="nav-number">4.1.</span> <span class="nav-text">1、caffe tools</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E6%9E%90train-log"><span class="nav-number">4.2.</span> <span class="nav-text">2、分析train log</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%98%BE%E7%A4%BA%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%9C"><span class="nav-number">4.3.</span> <span class="nav-text">3、显示模型结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E5%A4%9A%E4%B8%AAsnapshot%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E6%89%93%E5%88%86"><span class="nav-number">4.4.</span> <span class="nav-text">4、对多个snapshot模型进行打分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#inference-time5"><span class="nav-number">4.5.</span> <span class="nav-text">5、Inference Time4</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8google-protocol-buffer%E5%BA%8F%E5%88%97%E5%8C%96%E5%8D%8F%E8%AE%AE6"><span class="nav-number">5.</span> <span class="nav-text">为什么要用Google
Protocol Buffer序列化协议？5</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98"><span class="nav-number">6.</span> <span class="nav-text">开发过程中一些问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E6%9E%9C%E4%B8%80%E7%9B%B4%E5%9C%A8%E5%A6%82%E4%B8%8B%E4%BD%8D%E7%BD%AE%E5%A4%AF%E4%BD%8F%E4%B8%8D%E7%BB%A7%E7%BB%AD%E8%BF%90%E8%A1%8C%E4%BA%86%E7%9A%84%E8%AF%9D"><span class="nav-number">6.1.</span> <span class="nav-text">1.
如果一直在如下位置夯住，不继续运行了的话：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8Bfunetune%E7%9A%84%E6%97%B6%E5%80%99prototxt%E5%92%8C.caffemodel%E4%B8%80%E5%AE%9A%E8%A6%81%E5%AF%B9%E5%BA%94%E5%90%A6%E5%88%99%E7%9C%9F%E7%9A%84%E4%BC%9A%E5%87%BA%E7%8E%B0%E5%90%84%E7%A7%8Dshape-size%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">6.2.</span> <span class="nav-text">2.
进行模型funetune的时候，prototxt和.caffemodel一定要对应，否则真的会出现各种shape
size不匹配的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E5%86%99prototxt%E7%9A%84%E6%97%B6%E5%80%99%E8%A6%81%E9%A3%8E%E6%A0%BC%E7%BB%9F%E4%B8%80%E4%B8%8D%E8%A6%81layers%E5%92%8Clayer%E6%A8%A1%E5%BC%8F%E6%B7%B7%E7%94%A8"><span class="nav-number">6.3.</span> <span class="nav-text">3.
编写prototxt的时候要风格统一。不要layers和layer模式混用。</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">7.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="CharlesCao"
      src="/images/bird.png">
  <p class="site-author-name" itemprop="name">CharlesCao</p>
  <div class="site-description" itemprop="description">In me the tiger sniffs the rose.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">43</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="mailto:caowenlong92@gmail.com" title="E-Mail → mailto:caowenlong92@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/5221628" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;5221628" rel="noopener" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i>StackOverflow</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/cwlseu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;cwlseu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://pytorch.org/" title="https:&#x2F;&#x2F;pytorch.org" rel="noopener" target="_blank">Pytorch</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://cplusplus.com/reference" title="https:&#x2F;&#x2F;cplusplus.com&#x2F;reference" rel="noopener" target="_blank">CppReference</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://docs.nvidia.com/cuda/index.html" title="https:&#x2F;&#x2F;docs.nvidia.com&#x2F;cuda&#x2F;index.html" rel="noopener" target="_blank">NVIDIA CUDA</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/cwlseu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.deepindeed.cn/201703/20170321-train-use-caffe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/bird.png">
      <meta itemprop="name" content="CharlesCao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deepindeed">
      <meta itemprop="description" content="In me the tiger sniffs the rose.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="深度学习：玩转Caffe | Deepindeed">
      <meta itemprop="description" content="使用caffe框架进行实验过程中的一些心得">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习：玩转Caffe
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-03-21 20:00:00" itemprop="dateCreated datePublished" datetime="2017-03-21T20:00:00+08:00">2017-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-09-03 04:05:26" itemprop="dateModified" datetime="2022-09-03T04:05:26+08:00">2022-09-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/blog/" itemprop="url" rel="index"><span itemprop="name">blog</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">评论数：</span>
  
    <a title="waline" href="/201703/20170321-train-use-caffe/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/201703/20170321-train-use-caffe/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>13k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>22 分钟</span>
    </span>
</div>

            <div class="post-description">使用caffe框架进行实验过程中的一些心得</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="引言">引言</h2>
<p>最近实验中又跟caffe打交道，虽然caffe好用，但是要想让caffe启动训练起来，还真得费一番功夫。数据处理，模型文件编写，预训练模型的选择等等。</p>
<h2 id="imagenet的数据预处理">ImageNet的数据预处理</h2>
<h3 id="常见image-list">1. 常见image list</h3>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">root_dir=$HOME/data/VOCdevkit/</span><br><span class="line">sub_dir=ImageSets/Main</span><br><span class="line">bash_dir=&quot;$(cd &quot;$(dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot;)&quot; &amp;&amp; pwd)&quot;</span><br><span class="line">for dataset in trainval test</span><br><span class="line">do</span><br><span class="line">  dst_file=$bash_dir/$dataset.txt</span><br><span class="line">  if [ -f $dst_file ]</span><br><span class="line">  then</span><br><span class="line">    rm -f $dst_file</span><br><span class="line">  fi</span><br><span class="line">  for name in VOC2007 VOC2012</span><br><span class="line">  do</span><br><span class="line">    if [[ $dataset == &quot;test&quot; &amp;&amp; $name == &quot;VOC2012&quot; ]]</span><br><span class="line">    then</span><br><span class="line">      continue</span><br><span class="line">    fi</span><br><span class="line">    echo &quot;Create list for $name $dataset...&quot;</span><br><span class="line">    dataset_file=$root_dir/$name/$sub_dir/$dataset.txt</span><br><span class="line"></span><br><span class="line">    img_file=$bash_dir/$dataset&quot;_img.txt&quot;</span><br><span class="line">    cp $dataset_file $img_file</span><br><span class="line">    sed -i &quot;s/^/$name\/JPEGImages\//g&quot; $img_file</span><br><span class="line">    sed -i &quot;s/$/.jpg/g&quot; $img_file</span><br><span class="line"></span><br><span class="line">    label_file=$bash_dir/$dataset&quot;_label.txt&quot;</span><br><span class="line">    cp $dataset_file $label_file</span><br><span class="line">    sed -i &quot;s/^/$name\/Annotations\//g&quot; $label_file</span><br><span class="line">    sed -i &quot;s/$/.xml/g&quot; $label_file</span><br><span class="line"></span><br><span class="line">    paste -d&#x27; &#x27; $img_file $label_file &gt;&gt; $dst_file</span><br><span class="line"></span><br><span class="line">    rm -f $label_file</span><br><span class="line">    rm -f $img_file</span><br><span class="line">  done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Generate image name and size infomation.</span></span><br><span class="line">  if [ $dataset == &quot;test&quot; ]</span><br><span class="line">  then</span><br><span class="line">    $bash_dir/../../build/tools/get_image_size $root_dir $dst_file $bash_dir/$dataset&quot;_name_size.txt&quot;</span><br><span class="line">  fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Shuffle trainval file.</span></span><br><span class="line">  if [ $dataset == &quot;trainval&quot; ]</span><br><span class="line">  then</span><br><span class="line">    rand_file=$dst_file.random</span><br><span class="line">    cat $dst_file | perl -MList::Util=shuffle -e &#x27;print shuffle(&lt;STDIN&gt;);&#x27; &gt; $rand_file</span><br><span class="line">    mv $rand_file $dst_file</span><br><span class="line">  fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h3 id="生成backend为leveldb或者lmdb">2.
生成backend为leveldb或者lmdb</h3>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env sh</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Create the imagenet lmdb inputs</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">N.B. <span class="built_in">set</span> the path to the imagenet train + val data <span class="built_in">dirs</span></span></span><br><span class="line">set -e</span><br><span class="line"></span><br><span class="line">DATA=$HOME/data/VOCdevkit</span><br><span class="line">TOOLS=$HOME/caffe/build/tools</span><br><span class="line"></span><br><span class="line">EXAMPLE=$&#123;DATA&#125;/VOC0712/lmdb</span><br><span class="line">TRAIN_DATA_ROOT=$&#123;DATA&#125;/</span><br><span class="line">VAL_DATA_ROOT=$&#123;DATA&#125;/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Set RESIZE=<span class="literal">true</span> to resize the images to 256x256. Leave as <span class="literal">false</span> <span class="keyword">if</span> images have</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">already been resized using another tool.</span></span><br><span class="line">RESIZE=true</span><br><span class="line">if $RESIZE; then</span><br><span class="line">  RESIZE_HEIGHT=256</span><br><span class="line">  RESIZE_WIDTH=256</span><br><span class="line">else</span><br><span class="line">  RESIZE_HEIGHT=0</span><br><span class="line">  RESIZE_WIDTH=0</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo &quot;Creating train lmdb...&quot;</span><br><span class="line"></span><br><span class="line">GLOG_logtostderr=1 $TOOLS/convert_imageset \</span><br><span class="line">    --resize_height=$RESIZE_HEIGHT \</span><br><span class="line">    --resize_width=$RESIZE_WIDTH \</span><br><span class="line">    --shuffle \</span><br><span class="line">    $TRAIN_DATA_ROOT \</span><br><span class="line">    $DATA/trainval.txt \</span><br><span class="line">    $EXAMPLE/voc0712_train_lmdb</span><br><span class="line"></span><br><span class="line">echo &quot;Creating val lmdb...&quot;</span><br><span class="line"></span><br><span class="line">GLOG_logtostderr=1 $TOOLS/convert_imageset \</span><br><span class="line">    --resize_height=$RESIZE_HEIGHT \</span><br><span class="line">    --resize_width=$RESIZE_WIDTH \</span><br><span class="line">    --shuffle \</span><br><span class="line">    $VAL_DATA_ROOT \</span><br><span class="line">    $DATA/test.txt \</span><br><span class="line">    $EXAMPLE/voc0712_val_lmdb</span><br><span class="line"></span><br><span class="line">echo &quot;Done.&quot;</span><br></pre></td></tr></table></figure>
<h3 id="proto中配置使用">3. proto中配置使用</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Data&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    source: &quot;/home/lixx/data/VOCdevkit/VOC0712/lmdb/voc0712_train_lmdb&quot;</span><br><span class="line">    #source: &quot; /home/lixx/data/VOCdevkit/VOC0712/voc0712_train_leveldb&quot;</span><br><span class="line">    mean_file: &quot;/home/lixx/data/VOCdevkit/VOC0712/voc0712_mean.binaryproto&quot;</span><br><span class="line">    batch_size: 16 </span><br><span class="line">    crop_size: 227 </span><br><span class="line">    # 数据类型，默认情况下为leveldb</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param&#123;</span><br><span class="line">    mirror: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中具体的参数需要参考caffe.proto文件进行查看，进行正确的配置</p>
<h2 id="训练模型">训练模型</h2>
<h3 id="学习率">1、学习率</h3>
<p>步长的选择：你走的距离长短，越短当然不会错过，但是耗时间。步长的选择比较麻烦。步长越小，越容易得到局部最优化（到了比较大的山谷，就出不去了），而大了会全局最优。一般来说，如ResNet前32k步，很大，0.1；到了后面，迭代次数增高，下降0.01，再多，然后再小一些。
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/lr.png"
alt="@lr 随着epoch的增加变化曲线" /></p>
<h3 id="caffe训练时loss变为nan的原因2">2、caffe训练时Loss变为nan的原因<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h3>
<h4 id="由小变大易出nan">由小变大易出nan</h4>
<p><strong>原因</strong>：有小变大过程中，某个梯度值变得特别大，使得学习过程难以为继</p>
<p>例如：<code>10x10x256</code>的输入，输出如果是<code>20x20x256</code>或者<code>10x10x512</code>，如果是使用Inception-ResNet-v2或者直接进行卷积操作，很容易出现nan的情况。</p>
<blockquote>
<p>具体解决方案： - 参考<a
target="_blank" rel="noopener" href="http://cwlseu.github.io/Inception">Inception的设计原则</a>重新设计网络
- 添加Batch normalization试试</p>
</blockquote>
<h4
id="使用resnet-block或者inception技术最后的结果通过bitwise-operation进行组合而不是采用按channel-concatenate进行的">使用ResNet-Block或者Inception技术，最后的结果通过Bitwise
Operation进行组合，而不是采用按channel Concatenate进行的。</h4>
<blockquote>
<p>尤其是BitWise
multi进行组合的时候，往往会产生很大的数据悬殊，会导致梯度爆炸现象从而出现Loss
为nan</p>
</blockquote>
<h3 id="梯度爆炸">3、梯度爆炸</h3>
<p><strong>原因</strong>：梯度变得非常大，使得学习过程难以继续</p>
<p><strong>现象</strong>：观察log，注意每一轮迭代后的loss。loss随着每轮迭代越来越大，最终超过了浮点型表示的范围，就变成了NaN。</p>
<p><strong>措施</strong>： -
减小solver.prototxt中的<code>base_lr</code>，至少减小一个数量级。如果有多个<code>loss layer</code>，需要找出哪个损失层导致了梯度爆炸，并在train_val.prototxt中减小该层的<code>loss_weight</code>，而非是减小通用的<code>base_lr</code>。
- 设置<code>clip gradient</code>，用于限制过大的<code>diff</code></p>
<h4 id="不当的损失函数">不当的损失函数</h4>
<p><strong>原因</strong>：有时候损失层中loss的计算可能导致NaN的出现。比如，给InfogainLoss层（信息熵损失）输入没有归一化的值，使用带有bug的自定义损失层等等。</p>
<p><strong>现象</strong>：观测训练产生的log时一开始并不能看到异常，loss也在逐步的降低，但突然之间NaN就出现了。</p>
<p><strong>措施</strong>：看看你是否能重现这个错误，在loss
layer中加入一些输出以进行调试。
示例：有一次我使用的loss归一化了batch中label错误的次数。如果某个label从未在batch中出现过，loss就会变成NaN。在这种情况下，可以用足够大的batch来尽量避免这个错误。</p>
<h4 id="不当的输入">不当的输入</h4>
<p><strong>原因</strong>：输入中就含有NaN。</p>
<p><strong>现象</strong>：每当学习的过程中碰到这个错误的输入，就会变成NaN。观察log的时候也许不能察觉任何异常，loss逐步的降低，但突然间就变成NaN了。</p>
<p><strong>措施</strong>：重整你的数据集，确保训练集和验证集里面没有损坏的图片。调试中你可以使用一个简单的网络来读取输入层，有一个缺省的loss，并过一遍所有输入，如果其中有错误的输入，这个缺省的层也会产生NaN。</p>
<h3 id="caffe-debug-info34">4、Caffe Debug info<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a><a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></h3>
<p>当我们训练过程面临nan,
loss不收敛的情况，可以打开<code>solver.prototxt</code>中的<code>debuf_info:true</code>进行查错。</p>
<pre><code>    I1109 ...]     [Forward] Layer data, top blob data data: 0.343971    
    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037
    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114
    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0
    I1109 ...]     [Forward] Layer relu1, top blob conv1 data: 0.0337982
    I1109 ...]     [Forward] Layer conv2, top blob conv2 data: 0.0249297
    I1109 ...]     [Forward] Layer conv2, param blob 0 data: 0.00875855
    I1109 ...]     [Forward] Layer conv2, param blob 1 data: 0
    I1109 ...]     [Forward] Layer relu2, top blob conv2 data: 0.0128249
    . 
    .
    .
    I1109 ...]     [Forward] Layer fc1, top blob fc1 data: 0.00728743
    I1109 ...]     [Forward] Layer fc1, param blob 0 data: 0.00876866
    I1109 ...]     [Forward] Layer fc1, param blob 1 data: 0
    I1109 ...]     [Forward] Layer loss, top blob loss data: 2031.85
    I1109 ...]     [Backward] Layer loss, bottom blob fc1 diff: 0.124506
    I1109 ...]     [Backward] Layer fc1, bottom blob conv6 diff: 0.00107067
    I1109 ...]     [Backward] Layer fc1, param blob 0 diff: 0.483772
    I1109 ...]     [Backward] Layer fc1, param blob 1 diff: 4079.72
    .
    .
    .
    I1109 ...]     [Backward] Layer conv2, bottom blob conv1 diff: 5.99449e-06
    I1109 ...]     [Backward] Layer conv2, param blob 0 diff: 0.00661093
    I1109 ...]     [Backward] Layer conv2, param blob 1 diff: 0.10995
    I1109 ...]     [Backward] Layer relu1, bottom blob conv1 diff: 2.87345e-06
    I1109 ...]     [Backward] Layer conv1, param blob 0 diff: 0.0220984
    I1109 ...]     [Backward] Layer conv1, param blob 1 diff: 0.0429201
    E1109 ...]     [Backward] All net params (data, diff): L1 norm = (2711.42, 7086.66); L2 norm = (6.11659, 4085.07) </code></pre>
<p>At first glance you can see this log section divided into two:
<code>[Forward]</code> and <code>[Backward]</code>. Recall that neural
network training is done via forward-backward propagation: A training
example (batch) is fed to the net and a forward pass outputs the current
prediction. Based on this prediction a loss is computed. The loss is
then derived, and a gradient is estimated and propagated backward using
the chain rule.</p>
<h4 id="caffe-blob-data-structure">Caffe Blob data structure</h4>
<p>Just a quick re-cap. Caffe uses Blob data structure to store
data/weights/parameters etc. For this discussion it is important to note
that <code>Blob</code> has two "parts": <code>data</code> and
<code>diff</code>. The values of the Blob are stored in the data part.
The diff part is used to store element-wise gradients for the
backpropagation step.</p>
<h4 id="forward-pass">Forward pass</h4>
<p>You will see all the layers from bottom to top listed in this part of
the log. For each layer you'll see:</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037
    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114
    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0</code></pre>
<p>Layer "conv1" is a convolution layer that has 2 param blobs: the
filters and the bias. Consequently, the log has three lines. The filter
blob (param <code>blob 0</code>) has data</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, param blob 0 data: 0.00899114</code></pre>
<p>That is the current L2 norm of the convolution filter weights is
0.00899. The current bias (param <code>blob 1</code>):</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, param blob 1 data: 0</code></pre>
<p>meaning that currently the bias is set to 0.</p>
<p>Last but not least, "conv1" layer has an output, "top" named "conv1"
(how original...). The L2 norm of the output is</p>
<pre><code>    I1109 ...]     [Forward] Layer conv1, top blob conv1 data: 0.0645037</code></pre>
<p>Note that all L2 values for the [Forward] pass are reported on the
data part of the Blobs in question.</p>
<h4 id="loss-and-gradient">Loss and gradient</h4>
<p>At the end of the [Forward] pass comes the loss layer:</p>
<pre><code>    I1109 ...]     [Forward] Layer loss, top blob loss data: 2031.85
    I1109 ...]     [Backward] Layer loss, bottom blob fc1 diff: 0.124506</code></pre>
<p>In this example the batch loss is 2031.85, the gradient of the loss
w.r.t. <code>fc1</code> is computed and passed to <code>diff</code> part
of fc1 Blob. The L2 magnitude of the gradient is 0.1245.</p>
<h4 id="backward-pass">Backward pass</h4>
<p>All the rest of the layers are listed in this part top to bottom. You
can see that the L2 magnitudes reported now are of the diff part of the
Blobs (params and layers' inputs).</p>
<h4 id="finally">Finally</h4>
<p>The last log line of this iteration:</p>
<pre><code>    [Backward] All net params (data, diff): L1 norm = (2711.42, 7086.66); L2 norm = (6.11659, 4085.07)</code></pre>
<p>reports the total L1 and L2 magnitudes of both data and
gradients.</p>
<h4 id="what-should-i-look-for">What should I look for?</h4>
<ul>
<li>If you have nans in your loss, see at what point your data or diff
turns into nan: at which layer? at which iteration?</li>
<li>Look at the gradient magnitude, they should be reasonable. IF you
are starting to see values with e+8 your data/gradients are starting to
blow off. Decrease your learning rate!</li>
<li>See that the diffs are not zero. Zero diffs mean no gradients = no
updates = no learning.</li>
</ul>
<h2 id="tools事半功倍">Tools事半功倍</h2>
<h3 id="caffe-tools">1、caffe tools</h3>
<p><code>caffe</code>可执行文件可以有不同的选项进行选择功能，功能选择是通过功能函数指针注册的方式实现的，在<code>tools/caffe.cpp</code>中有，其中的<a
target="_blank" rel="noopener" href="http://cwlseu.github.io/Cpp-Relearn">注册功能部分</a>大家有兴趣可以学习一下，这块还是很有趣的。</p>
<h3 id="分析train-log">2、分析train log</h3>
<p>在<code>caffe/tools/extra</code>下有分析log的各种脚本，你可以使用<code>gnuplot</code>继续绘制，也可以采用python的<code>matplot</code></p>
<ol type="1">
<li><p>如果想提取log的关键信息，可以查看<code>parse_log.sh</code>或者<code>parse_log.py</code></p></li>
<li><p>如果想绘制采用绘制
<code>python tools/extra/plot_training_log.py 2 examples/ooxx/result/result.png jobs/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321.log</code></p></li>
</ol>
<p>This script mainly serves as the basis of your customizations.
Customization is a must. You can copy, paste, edit them in whatever way
you want. Be warned that the fields in the training log may change in
the future. You had better check the data files and change the mapping
from field name to field index in create_field_index before designing
your own plots.</p>
<pre><code>Usage:
    ./plot_training_log.py chart_type[0-7] /where/to/save.png /path/to/first.log ...
Notes:
    1. Supporting multiple logs.
    2. Log file name must end with the lower-cased &quot;.log&quot;.
Supported chart types:
    0: Test accuracy  vs. Iters
    1: Test accuracy  vs. Seconds
    2: Test loss  vs. Iters
    3: Test loss  vs. Seconds
    4: Train learning rate  vs. Iters
    5: Train learning rate  vs. Seconds
    6: Train loss  vs. Iters
    7: Train loss  vs. Seconds</code></pre>
<h3 id="显示模型结果">3、显示模型结果</h3>
<blockquote>
<p>classification</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./build/examples/cpp_classification/classification.bin \</span><br><span class="line">  models/bvlc_reference_caffenet/deploy.prototxt \</span><br><span class="line">  models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel \</span><br><span class="line">  data/ilsvrc12/imagenet_mean.binaryproto \</span><br><span class="line">  data/ilsvrc12/synset_words.txt \</span><br><span class="line">  examples/images/cat.jpg</span><br></pre></td></tr></table></figure>
<p>The output should look like this:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">---------- Prediction <span class="keyword">for</span> examples/images/cat.jpg ----------</span><br><span class="line"><span class="number">0.3134</span> - <span class="string">&quot;n02123045 tabby, tabby cat&quot;</span></span><br><span class="line"><span class="number">0.2380</span> - <span class="string">&quot;n02123159 tiger cat&quot;</span></span><br><span class="line"><span class="number">0.1235</span> - <span class="string">&quot;n02124075 Egyptian cat&quot;</span></span><br><span class="line"><span class="number">0.1003</span> - <span class="string">&quot;n02119022 red fox, Vulpes vulpes&quot;</span></span><br><span class="line"><span class="number">0.0715</span> - <span class="string">&quot;n02127052 lynx, catamount&quot;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>ssd_detection</p>
<p><a
target="_blank" rel="noopener" href="https://github.com/cwlseu/caffe/blob/ssdplus/examples/stairsnet/ssd_detect_once.py">ssd_detection脚本</a></p>
</blockquote>
<blockquote>
<p>stairsNet detection</p>
<p><a
target="_blank" rel="noopener" href="https://github.com/cwlseu/caffe/blob/ssdplus/examples/stairsnet/stairsnet_detect.py">stairnet的结果展示脚本</a></p>
</blockquote>
<p>其中需要配置一些依赖文件信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># caffe的root路劲</span></span><br><span class="line">caffe_root=</span><br><span class="line">labelmap_file = <span class="string">&#x27;data/VOC0712/labelmap_voc.prototxt&#x27;</span></span><br><span class="line">model_def = <span class="string">&#x27;models/ResNet/VOC0712/OOXX_321x321/deploy.prototxt&#x27;</span></span><br><span class="line">model_weights = <span class="string">&#x27;models/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321_iter_70000.caffemodel&#x27;</span></span><br><span class="line">image_dir = <span class="string">&quot;examples/ooxx/test&quot;</span></span><br><span class="line">save_dir = <span class="string">&quot;examples/ooxx/result&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="对多个snapshot模型进行打分">4、对多个snapshot模型进行打分</h3>
<ol type="1">
<li>首先运行模型自带的score脚本,
如<code>examples/ssd/score_ssd_pascal.py</code>，该脚本会调用当前最新的model进行评测，在jobs的子目录下生成一个XXXXX_score的路径，其中包含solver.prototxt等等文件。然后ctrl+C暂停运行。</li>
<li>运行脚本<a
target="_blank" rel="noopener" href="https://github.com/cwlseu/caffe/blob/ssdplus/tools/score_model.py"><code>model score script</code></a>(先去玩几个小时，时间很漫长的...)，将会在jobs的某个路径下找到生成的各个模型对应的shell脚本和log文件。</li>
</ol>
<h3 id="inference-time5">5、Inference Time<a href="#fn4"
class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></h3>
<ol type="1">
<li>(These example calls require you complete the LeNet / MNIST example
first.) time LeNet training on CPU for 10 iterations
<code>./build/tools/caffe time -model examples/mnist/lenet_train_test.prototxt -iterations 10</code></li>
<li>time LeNet training on GPU for the default 50 iterations
<code>./build/tools/caffe time -model examples/mnist/lenet_train_test.prototxt -gpu 0</code></li>
<li>time a model architecture with the given weights on no GPU for 10
iterations
<code>./build/tools/caffe time --model=models/ResNet/VOC0712/OOXX_321x321/deploy.prototxt --weights models/ResNet/VOC0712/OOXX_321x321/ResNet_VOC0712_OOXX_321x321_iter_115000.caffemodel --iterations 10</code>
<img
src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/inference_time.JPG"
alt="@inference time result" /></li>
</ol>
<h2 id="为什么要用google-protocol-buffer序列化协议6">为什么要用Google
Protocol Buffer序列化协议？<a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a></h2>
<table>
<colgroup>
<col style="width: 11%" />
<col style="width: 10%" />
<col style="width: 11%" />
<col style="width: 15%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 15%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">#</th>
<th style="text-align: center;">protobuf</th>
<th style="text-align: center;">jackson</th>
<th style="text-align: center;">xstream</th>
<th style="text-align: center;">serialization</th>
<th style="text-align: center;">hessian2</th>
<th style="text-align: center;">hessian2压缩</th>
<th style="text-align: center;">hessian 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">序列化 ns</td>
<td style="text-align: center;">1154</td>
<td style="text-align: center;">5421</td>
<td style="text-align: center;">92406</td>
<td style="text-align: center;">10189</td>
<td style="text-align: center;">26794</td>
<td style="text-align: center;">100766</td>
<td style="text-align: center;">29027</td>
</tr>
<tr class="even">
<td style="text-align: center;">反序列化ns</td>
<td style="text-align: center;">1334</td>
<td style="text-align: center;">8743</td>
<td style="text-align: center;">117329</td>
<td style="text-align: center;">64027</td>
<td style="text-align: center;">37871</td>
<td style="text-align: center;">188432</td>
<td style="text-align: center;">37596</td>
</tr>
<tr class="odd">
<td style="text-align: center;">bytes</td>
<td style="text-align: center;">97</td>
<td style="text-align: center;">311</td>
<td style="text-align: center;">664</td>
<td style="text-align: center;">824</td>
<td style="text-align: center;">374</td>
<td style="text-align: center;">283</td>
<td style="text-align: center;">495</td>
</tr>
</tbody>
</table>
<ul>
<li><p>protobuf
不管是处理时间上，还是空间占用上都优于现有的其他序列化方式。内存暂用是java序列化的1/9，
时间也是差了一个数量级，一次操作在1us左右。缺点：就是对象结构体有限制，只适合于内部系统使用。</p></li>
<li><p>json格式在空间占用还是有一些优势，是java序列化的1/2.6。序列化和反序列化处理时间上差不多，也就在5us。当然这次使用的jackson，如果使用普通的jsonlib可能没有这样好的性能，jsonlib估计跟java序列化差不多。</p></li>
<li><p>xml相比于java序列化来说，空间占用上有点优势，但不明显。处理时间上比java序列化多了一个数量级，在100us左右。</p></li>
<li><p>以前一种的java序列化，表现得有些失望</p></li>
<li><p>hessian测试有点意外，具体序列化数据上还步入json。性能上也不如jackjson，输得比较彻底。</p></li>
<li><p>hessian使用压缩，虽然在字节上有20%以上的空间提升，但性能上差了4,5倍，典型的以时间换空间。总的来说还是google
protobuf比较给力
以后在内部系统，数据cache存储上可以考虑使用protobuf。跟外部系统交互上可以考虑使用json。</p></li>
</ul>
<h2 id="开发过程中一些问题">开发过程中一些问题</h2>
<h3 id="如果一直在如下位置夯住不继续运行了的话">1.
如果一直在如下位置夯住，不继续运行了的话：</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">name: &quot;conv5_1/linear&quot;</span><br><span class="line">type: &quot;Convoluti</span><br><span class="line">I0320 15:59:15.669935 20624 layer_factory.hpp:77] Creating layer data</span><br><span class="line">I0320 15:59:15.670370 20624 net.cpp:100] Creating Layer data</span><br><span class="line">I0320 15:59:15.670387 20624 net.cpp:408] data -&gt; data</span><br><span class="line">I0320 15:59:15.670454 20624 net.cpp:408] data -&gt; label</span><br></pre></td></tr></table></figure>
<p>可能是训练数据类型是对的，但是去取过程中出现了，这个时候就要检查是不是训练数据的使用的是测试数据的地址。我就是犯了
这么错误，找了好久终于找到了。</p>
<h3
id="进行模型funetune的时候prototxt和.caffemodel一定要对应否则真的会出现各种shape-size不匹配的问题">2.
进行模型funetune的时候，prototxt和.caffemodel一定要对应，否则真的会出现各种shape
size不匹配的问题</h3>
<h3 id="编写prototxt的时候要风格统一不要layers和layer模式混用">3.
编写prototxt的时候要风格统一。不要layers和layer模式混用。</h3>
<blockquote>
<p>风格1: Layers开头，type为全部大写不带引号</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">layers &#123;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">  name: &quot;drop7&quot;</span><br><span class="line">  type: DROPOUT</span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: 0.5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>风格2：layer开头，类型为首字母大写的字符串</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 20</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;xavier&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>风格3：layers和layer嵌套类型</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">layers &#123;</span><br><span class="line">  layer &#123;</span><br><span class="line">    name: &quot;conv2&quot;</span><br><span class="line">    type: &quot;conv&quot;</span><br><span class="line">    num_output: 256</span><br><span class="line">    group: 2</span><br><span class="line">    kernelsize: 5</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;gaussian&quot;</span><br><span class="line">      std: 0.01</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">      value: 1.</span><br><span class="line">    &#125;</span><br><span class="line">    blobs_lr: 1.</span><br><span class="line">    blobs_lr: 2.</span><br><span class="line">    weight_decay: 1.</span><br><span class="line">    weight_decay: 0.</span><br><span class="line">  &#125;</span><br><span class="line">  bottom: &quot;pad2&quot;</span><br><span class="line">  top: &quot;conv2&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编写的时候保持风格统一就好。</p>
<h2 id="参考文献">参考文献</h2>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a
target="_blank" rel="noopener" href="http://stackoverflow.com/questions/33962226/common-causes-of-NaNs-during-training">Common
causes of nans during training</a><a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a
target="_blank" rel="noopener" href="http://stackoverflow.com/questions/40510706/how-to-interpret-caffe-log-with-debug-info">Caffe
debug info 的使用</a><a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><a
target="_blank" rel="noopener" href="http://caffe.berkeleyvision.org/tutorial/interfaces.html">caffe
interface manual</a><a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><a
target="_blank" rel="noopener" href="http://stackoverflow.com/questions/36867591/how-to-estimate-inference-time-from-average-forward-pass-time-in-caffe">estimate
Inference time from average forward pass time in caffe</a><a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>http://agapple.iteye.com/blog/859052<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

    </div>

    
    
    
      


    <footer class="post-footer"><div class="post-widgets">
    <div
      class="social-share"
      
        data-sites="weibo,qq,wechat,tencent,douban,qzone,linkedin,diandian,facebook,twitter,google"
      
      
        data-wechat-qrcode-title="share.title"
      
      
        data-wechat-qrcode-helper="share.prompt"
      
    >
    </div>
  </div>
  <script src="https://lib.baomitu.com/social-share.js/1.0.16/js/social-share.min.js"></script>
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>CharlesCao
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://www.deepindeed.cn/201703/20170321-train-use-caffe/" title="深度学习：玩转Caffe">http://www.deepindeed.cn/201703/20170321-train-use-caffe/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/framework/" rel="tag"># framework</a>
              <a href="/tags/caffe/" rel="tag"># caffe</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/201703/20170317-algorithm-optimization/" rel="prev" title="算法优化的一些技巧">
                  <i class="fa fa-chevron-left"></i> 算法优化的一些技巧
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/201703/20170331-based-algorithm-3/" rel="next" title="算法的乐趣：完美的图算法">
                  算法的乐趣：完美的图算法 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CharlesCao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">473k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">13:08</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>
<script class="next-config" data-name="gitter" type="application/json">{"enable":true,"room":null}</script>
<script src="/js/third-party/chat/gitter.js"></script>
<script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@9.0.1/dist/mermaid.min.js","integrity":"sha256-CemUs9ITT7liCZpVMktcEw0BpAOZ1+mujlMB3UyuImU="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://waline.vercel.app","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":false,"libUrl":"https://unpkg.com/@waline/client@v2/dist/waline.js","locale":{"placeholder":"欢迎交流指正"},"emoji":["https://unpkg.com/@waline/emojis@1.0.1/weibo","https://unpkg.com/@waline/emojis@1.0.1/alus","https://unpkg.com/@waline/emojis@1.0.1/bilibili","https://unpkg.com/@waline/emojis@1.0.1/qq","https://unpkg.com/@waline/emojis@1.0.1/tieba","https://unpkg.com/@waline/emojis@1.0.1/tw-emoji"],"meta":["nick","mail"],"requiredMeta":["mail","nick","mail"],"login":"enable","el":"#waline","comment":true,"path":"/201703/20170321-train-use-caffe/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>

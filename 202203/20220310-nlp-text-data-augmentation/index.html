<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CTimes+New+Roman:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.deepindeed.cn","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":28},"copycode":false,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="NLP 文本场景的数据优化">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP 文本场景的数据优化">
<meta property="og:url" content="http://www.deepindeed.cn/202203/20220310-nlp-text-data-augmentation/index.html">
<meta property="og:site_name" content="Deepindeed">
<meta property="og:description" content="NLP 文本场景的数据优化">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348551.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348404.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348885.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349468.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349203.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349147.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349722.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349283.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349677.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350873.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350998.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350887.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350625.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030350431-20221117002001491.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030350097.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350995.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350389.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350145.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351859.png">
<meta property="og:image" content="http://www.deepindeed.cn/images/nlp/NLP文本场景的数据优化/1646230538691.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030351711.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030351853.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351964.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351292.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351728.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/1646293978880.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/1646293992580.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352998.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030352067.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030352672.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352328.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352671.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030352326-20221117002647446.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030352085.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352508.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353087.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353158.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353466.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353005.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353604.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353756.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/1646362972193.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353938.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353943.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353921.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353427.png">
<meta property="og:image" content="http://www.deepindeed.cn/images/nlp/NLP文本场景的数据优化/1646817503789.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030353619-20221117002747265.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030354558.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353317.png">
<meta property="article:published_time" content="2022-03-10T13:05:18.000Z">
<meta property="article:modified_time" content="2022-11-16T16:31:32.225Z">
<meta property="article:author" content="CharlesCao">
<meta property="article:tag" content="自然语言处理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348551.png">


<link rel="canonical" href="http://www.deepindeed.cn/202203/20220310-nlp-text-data-augmentation/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://www.deepindeed.cn/202203/20220310-nlp-text-data-augmentation/","path":"202203/20220310-nlp-text-data-augmentation/","title":"NLP 文本场景的数据优化"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>NLP 文本场景的数据优化 | Deepindeed</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-86501439-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-86501439-1","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>




<link rel="dns-prefetch" href="https://waline.vercel.app"><link rel="stylesheet" href="https://lib.baomitu.com/social-share.js/1.0.16/css/share.min.css">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Deepindeed</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">心有猛虎，细嗅蔷薇</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tools"><a href="/tools/" rel="section"><i class="fa fa-globe fa-fw"></i>tools</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%8F%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">序言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%9A%84%E7%9B%AE%E7%9A%84"><span class="nav-number">1.1.</span> <span class="nav-text">数据增强的目的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nlp%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%A0%94%E7%A9%B6%E5%9F%BA%E6%9C%AC%E7%8E%B0%E7%8A%B61"><span class="nav-number">1.2.</span> <span class="nav-text">NLP数据增强研究基本现状1</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#data-augmentation-in-nlp"><span class="nav-number">2.</span> <span class="nav-text">Data Augmentation in NLP</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#paraphrasing"><span class="nav-number">2.1.</span> <span class="nav-text">Paraphrasing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#noiseing"><span class="nav-number">2.2.</span> <span class="nav-text">Noiseing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sampling"><span class="nav-number">2.3.</span> <span class="nav-text">Sampling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95%E9%80%89%E6%8B%A9%E4%BE%9D%E6%8D%AE"><span class="nav-number">2.4.</span> <span class="nav-text">增强方法选择依据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1"><span class="nav-number">3.</span> <span class="nav-text">分类任务</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#text-smoothing"><span class="nav-number">3.1.</span> <span class="nav-text">Text Smoothing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#promda"><span class="nav-number">3.2.</span> <span class="nav-text">PromDA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dualcl"><span class="nav-number">3.3.</span> <span class="nav-text">DualCL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sample-efficiency-of-data-augmentation-consistency-regularization"><span class="nav-number">3.4.</span> <span class="nav-text">Sample
Efficiency of Data Augmentation Consistency Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#alp-data-augmentation-using-lexicalized-pcfgs-for-few-shot-text-classification"><span class="nav-number">3.5.</span> <span class="nav-text">ALP:
Data Augmentation using Lexicalized PCFGs for Few-Shot Text
Classification</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nerprompt-base%E5%9C%A8ner%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-number">4.</span> <span class="nav-text">NER[^prompt base在NER中的应用]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#an-analysis-of-simple-data-augmentation-for-named-entity-recognition"><span class="nav-number">4.1.</span> <span class="nav-text">An
Analysis of Simple Data Augmentation for Named Entity Recognition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#daga-data-augmentatino-with-a-generation-approach-for-low-resource-tagging-tasks"><span class="nav-number">4.2.</span> <span class="nav-text">DAGA:
Data Augmentatino with a Generation Approach for Low-resource Tagging
Tasks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#seqmix"><span class="nav-number">4.3.</span> <span class="nav-text">SeqMix</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#boundary-smoothing-for-named-entity-recognition"><span class="nav-number">4.4.</span> <span class="nav-text">Boundary
Smoothing for Named Entity Recognition</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">5.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="CharlesCao"
      src="/images/bird.png">
  <p class="site-author-name" itemprop="name">CharlesCao</p>
  <div class="site-description" itemprop="description">In me the tiger sniffs the rose.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">45</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="mailto:caowenlong92@gmail.com" title="E-Mail → mailto:caowenlong92@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/5221628" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;5221628" rel="noopener" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i>StackOverflow</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/cwlseu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;cwlseu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://pytorch.org/" title="https:&#x2F;&#x2F;pytorch.org" rel="noopener" target="_blank">Pytorch</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://cplusplus.com/reference" title="https:&#x2F;&#x2F;cplusplus.com&#x2F;reference" rel="noopener" target="_blank">CppReference</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://docs.nvidia.com/cuda/index.html" title="https:&#x2F;&#x2F;docs.nvidia.com&#x2F;cuda&#x2F;index.html" rel="noopener" target="_blank">NVIDIA CUDA</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/cwlseu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.deepindeed.cn/202203/20220310-nlp-text-data-augmentation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/bird.png">
      <meta itemprop="name" content="CharlesCao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deepindeed">
      <meta itemprop="description" content="In me the tiger sniffs the rose.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="NLP 文本场景的数据优化 | Deepindeed">
      <meta itemprop="description" content="NLP 文本场景的数据优化">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          NLP 文本场景的数据优化
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-10 21:05:18" itemprop="dateCreated datePublished" datetime="2022-03-10T21:05:18+08:00">2022-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-11-17 00:31:32" itemprop="dateModified" datetime="2022-11-17T00:31:32+08:00">2022-11-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper/" itemprop="url" rel="index"><span itemprop="name">paper</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">评论数：</span>
  
    <a title="waline" href="/202203/20220310-nlp-text-data-augmentation/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/202203/20220310-nlp-text-data-augmentation/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

            <div class="post-description">NLP 文本场景的数据优化</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="序言">序言</h2>
<p>数据增强（Data
Augmentation，简称DA），是指根据现有数据，合成新数据的一类方法。毕竟数据才是真正的效果天花板，有了更多数据后可以提升效果、增强模型泛化能力、提高鲁棒性等。数据增强主要在CV应用中比较常见，然而由于NLP任务天生的难度，类似CV的裁剪方法可能会改变语义，既要保证数据质量又要保证多样性，所以大家在做数据增强时要十分谨慎。</p>
<h3 id="数据增强的目的">数据增强的目的</h3>
<ul>
<li>在很多机器学习场景下，没有足够的数据（数据稀缺场景）来训练高质量的模型。</li>
<li>提高训练数据的多样性，从而得到在真实场景下（很多没有见过的数据）更好的泛化效果。</li>
<li>样本不均衡</li>
<li>为了模型安全，应对模型的对抗攻击。</li>
</ul>
<h3 id="nlp数据增强研究基本现状1">NLP数据增强研究基本现状<a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></h3>
<ul>
<li>在CV上很成功，逐渐在NLP任务上发现有效</li>
<li>在文本分类<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>领域数据增强方法也比较多，其他任务例如NER，多标签分类等就相对少一些;</li>
<li>语言输入是离散，而且一定的文本改变容易引起文本分布的巨大改变，无法做到像图片那样不可见的抖动;</li>
<li>一般算法都可以从输入文本空间和文本编码空间进行数据增强。</li>
<li>对抗攻击:
相比较CV的对抗，文本的对抗存在很大差异。文本输入为离散的</li>
</ul>
<p>问题： -
数据增广在当前迁移学习大背景下的大规模预训练模型上有用吗？</p>
<hr />
<h2 id="data-augmentation-in-nlp">Data Augmentation in NLP</h2>
<p>Paraphrasing：对句子中的词、短语、句子结构做一些更改，保留原始的语义
Noising：在保证label不变的同时，增加一些离散或连续的噪声，对语义的影响不大
Sampling：旨在根据目前的数据分布选取新的样本，会生成更多样的数据</p>
<blockquote>
<p>Data Augmentation Approaches in Natural LanguageProcessing: A
Survey<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></p>
</blockquote>
<h3 id="paraphrasing">Paraphrasing</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348551.png" alt="Alt text|center|600x350" style="zoom:67%;" /></p>
<p>小结:
在尽可能保留句子整体语义的情况下，增加文本丰富度，包括让每个词拥有更加丰富的上下文context，让相似的语义表达有更多样的语法构成，词汇构成等等</p>
<h3 id="noiseing">Noiseing</h3>
<p>作者给出了以下5种增加噪声的方法：
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348404.png" alt="Alt text|center|600x600" style="zoom:67%;" /></p>
<ul>
<li><strong>Swapping</strong>：除了交换词之外，在分类任务中也可以交换instance或者sentence</li>
<li><strong>Deletion</strong>：可以根据tf-idf等词的重要程度进行删除</li>
<li><strong>Insertion</strong>：可以把同义词随机插入句子中</li>
<li><strong>Substitution</strong>：把一些词随机替换成其他词（非同义），模拟misspelling的场景。为了避免改变label，可以使用label-independent的词，或者利用训练数据中的其他句子</li>
<li><strong>Mixup</strong>：这个方法最近两年比较火，把句子表示和标签分别以一定权重融合，引入连续噪声，可以生成不同label之间的数据，但可解释性较差
总的来说，引入噪声的DA方法使用简单，但会对句子结构和语义造成影响，多样性有限，主要还是提升鲁棒性。
ConSERT时用到的方法：</li>
<li>对抗样本</li>
<li><strong>Dropout</strong>：也是SimCSE用到的，还有R-drop，都是通过dropout来加入连续噪声</li>
<li><strong>Feature
Cut-off</strong>：比如BERT的向量都是768维，可以随机把一些维度置为0，这个效果也不错</li>
</ul>
<p>小结： 增加模型稳健性，在不过多影响training
error的前提下，降低模型的复杂度从而降低generalization error,
类比dropout，l2，random noise injection</p>
<h3 id="sampling">Sampling</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030348885.png" alt="Alt text|center|750x500" style="zoom:67%;" />
Sampling是指从数据分布中采样出新的样本，不同于较通用的paraphrasing，<strong>采样更依赖任务，需要在保证数据可靠性的同时增加更多多样性</strong>，比前两个数据增强方法更难。作者整理了4种方法：</p>
<ul>
<li>Rules：用规则定义新的样本和label，比如把句子中的主谓进行变换</li>
<li>Seq2Seq
Models：根据输入和label生成新的句子，比如在NLI任务中，有研究者先为每个label（entailment，contradiction，neutral）训一个生成模型，再给定新的句子，生成对应label的。对比之下，paraphrasing主要是根据当前训练样本进行复述</li>
<li>Language
Models：给定label，利用语言模型生成样本，有点像前阵子看的谷歌UDG。有些研究会加个判别模型过滤</li>
<li>Self-training：先有监督训练一个模型，再给无监督数据打一些标签，有点蒸馏的感觉</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349468.png" alt="Alt text|center|600x250" style="zoom:67%;" /></p>
<h3 id="增强方法选择依据">增强方法选择依据</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349203.png" alt="三种类别的数据增强方法特点总结" style="zoom:50%;" /></p>
<p>Method Stacking
实际应用时可以应用多种方法、或者一种方法的不同粒度。</p>
<p>作者推荐了两款工具eda<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>和uda<a href="#fn5"
class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>,
eda_chinese<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a>, nlpaug<a href="#fn7"
class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>第一，在使用增强的数据时，如果数据质量不高，可以先让模型在增强后的数据上pre-train，之后再用有标注数据训练。如果要一起训练，在增强数据量过大的情况下，可以对原始训练数据过采样</p>
<p>第二，在进行数据增强时注意这些超参数的调整：
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349147.png" alt="各种方法的超参数" style="zoom:50%;" />
第三，其实增强很多简单数据的提升有限，可以注重困难样本的生成。比如有研究加入对抗训练、强化学习、在loss上下文章等。如果用生成方法做数据增强，也可以在生成模型上做功夫，提升数据多样性。</p>
<p>第四，如果生成错数据可能引入更多噪声，可以增加其他模型对准确性进行过滤。</p>
<hr />
<h2 id="分类任务">分类任务</h2>
<p>1、Mixup: Mixup-Transformer: Dynamic Data Augmentation for NLP
Tasks</p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349722.png" alt="Alt text" style="zoom:50%;" />
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349283.png" alt="Alt text|center|500x60" style="zoom: 50%;" /></p>
<p>在数据不足的情况下，只用40%的数据就可以比不应用增强方案的全量数据好。应用Mixup增强方法可以提升2.46%</p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030349677.png" alt="Alt text" style="zoom:50%;" /></p>
<p>2、On Data Augmentation for Extreme Multi-label Classification</p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350873.png" alt="Alt text|center|700x300" style="zoom:67%;" /></p>
<p>3、分类算法中的数据增强方法：综述
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350998.png" alt="Alt text|center|600x400" style="zoom:50%;" />
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350887.png" alt="Alt text" style="zoom: 67%;" /></p>
<p>这些在线blog或者paper<a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a><a href="#fn9" class="footnote-ref"
id="fnref9" role="doc-noteref"><sup>9</sup></a><a href="#fn10"
class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a>中提到了很多增强方法，主要有如下特点
- 多分类任务，为英文任务 -
有针对不同应用场景进行分析的增强方法。虽然现在都用预训练模型，但是在数据增强方法中，通过额外的静态词embedding进行数据增强也是常见的方法。</p>
<p>4、EDA
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350625.png" alt="Alt text" style="zoom:67%;" /></p>
<ul>
<li>paper:EDA: Easy Data Augmentation Techniques for Boosting
Performance on Text Classification Tasks</li>
<li>github: http://github.com/jasonwei20/eda_nlp</li>
<li><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030350431-20221117002001491.png" alt="Alt text" style="zoom: 67%;" />
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030350097.png" alt="Alt text" style="zoom: 67%;" /></li>
</ul>
<p>EDA主要采用表一中的同义词替换，随机插入，随机交换，随机删除，从可视化结果中来看，增强样本与原始样本分布基本是一致的。
作者给出了在实际使用EDA方法的建议，表格的左边是数据的规模<span
class="math inline">\(N_{train}\)</span>, 右边<span
class="math inline">\(\alpha\)</span>是概率、比率
比如同义词替换中，替换的单词数<span class="math inline">\(n=\alpha *
l\)</span> , <span
class="math inline">\(l\)</span>是句子长度。随机插入、随机替换类似.
<span class="math inline">\(p=\alpha * n_{aug}\)</span>
代表使用EDA方法从每一个句子拓展出的句子数量。</p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350995.png" alt="@作者的一些建议|center|400x250" style="zoom:67%;" /></p>
<p>之后，又有新的AEDA
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350389.png" alt="Alt text" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030350145.png" alt="Alt text" style="zoom:67%;" />
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351859.png" alt="Alt text" style="zoom:67%;" /></p>
<h3 id="text-smoothing">Text Smoothing</h3>
<p><img src="../../images/nlp/NLP文本场景的数据优化/1646230538691.png" alt="Alt text" style="zoom:50%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030351711.png" alt="Alt text" style="zoom:67%;" /><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030351853.png" alt="Alt text" style="zoom:67%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sentence = <span class="string">&quot;My favorite fruit is pear .&quot;</span></span><br><span class="line">lambd = <span class="number">0.1</span> <span class="comment"># interpolation hyperparameter</span></span><br><span class="line">mlm.train() <span class="comment"># enable dropout, dynamically mask</span></span><br><span class="line">tensor_input = tokenizer(sentence, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">onehot_repr = convert_to_onehot(**tensor_input)</span><br><span class="line">smoothed_repr = softmax(mlm(**tensor_input).logits[<span class="number">0</span>])</span><br><span class="line">interpolated_repr = lambd * onehot_repr + (<span class="number">1</span> - lambd) * smoothed_repr</span><br></pre></td></tr></table></figure>
<p>-code: https://github.com/1024er/cbert_aug</p>
<h3 id="promda">PromDA</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351964.png" alt="Alt text" style="zoom:67%;" /></p>
<ul>
<li>paper:https://arxiv.org/pdf/2202.12230.pdf</li>
<li>论文目的: low-resource Natural Language Understanding (NLU)
tasks</li>
</ul>
<p>少数据的场景，可能使用PLM不是最优的方案 我们期望构造的数据<span
class="math inline">\(\mathcal{T}_{LM}\)</span>与已有的数据集<span
class="math inline">\(\mathcal{T}\)</span>不同，能够从中学习到一些新的信息。
冻结PLMs参数可能有助于在训练过程中进行泛化。然而，寻找合适的离散任务引入并不容易以端到端方式进行优化，而且需要额外的人力。</p>
<p>引入<strong><span class="math inline">\(soft Prompt\)</span></strong>
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351292.png" alt="Alt text" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030351728.png" alt="Alt text" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/1646293978880.png" alt="Alt text" style="zoom:67%;" /><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/1646293992580.png" alt="Alt text" style="zoom:67%;" /></p>
<h3 id="dualcl">DualCL</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352998.png" alt="Alt text" style="zoom:67%;" /></p>
<ul>
<li>paper: Dual Contrastive Learning: Text Classification via
Label-Aware Data Augmentation</li>
<li>github: https://github.com/hiyouga/Dual-Contrastive-Learning</li>
<li>设计主要思想: 将类别与文本表征map到同一个空间</li>
</ul>
<p>传统自监督对比学习损失函数定义如下左侧公式，但是没有利用标注信息。将标注信息考虑进去，</p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030352067.png" alt="Alt text" style="zoom:67%;" /><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030352672.png" alt="Alt text" style="zoom:67%;" /></p>
<p>到目前为止发展起来的监督对比学习似乎是对分类问题的无监督对比学习的一种简单朴素的适配。</p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352328.png" alt="Alt text" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352671.png" alt="Alt text" style="zoom:67%;" /></p>
<ul>
<li><p>K+1+ 其他文本</p></li>
<li><p>学习到多个表征，其中1个原来的[CLS],另外K个是用来判断分类的结果的。<span
class="math display">\[ \hat{y}_i = \arg\max_k(\theta_i^k \cdot
z_i)\]</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030352326-20221117002647446.png" alt="Alt text" style="zoom:67%;" /><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030352085.png" alt="Alt text" style="zoom:67%;" /></p></li>
</ul>
<p>算法对比结果，少样本与全样本的对比：
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030352508.png" alt="Alt text" style="zoom:67%;" /></p>
<h3
id="sample-efficiency-of-data-augmentation-consistency-regularization">Sample
Efficiency of Data Augmentation Consistency Regularization</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353087.png" alt="Alt text" style="zoom:67%;" /></p>
<p>DA-ERM（data augmentation empirical risk minimization）:
DAC可以使用未标记的样本，因为可以在不知道真实标签的情况下增加训练样本并执行一致的预测。这绕过了传统算法只能增加标记样本并将其添加到训练集的限制
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353158.png" alt="Alt text" style="zoom:67%;" /></p>
<p>少量数据+data augmentation 少量数据+unlabel data</p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353466.png" alt="Alt text" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353005.png" alt="Alt text|center" style="zoom:67%;" />
我们可以看到对标注样本<span
class="math inline">\(\phi(x_i)\)</span>和增强产生的样本<span
class="math inline">\(\phi(x_{i,j})\)</span>之间的差异作为惩罚项。</p>
<p>我们从经验和理论上论证了DAC与DA-ERM(用增强样本扩展训练集)相比的优点。理论上，线性回归和逻辑回归的泛化误差更小，两层神经网络的泛化上界更紧。另一个好处是，DAC可以更好地处理由强扩充数据引起的模型错误规范。在经验上，我们提供了关于增广ERM和一致性正则化的比较。这些共同证明了一致性规则化优于DA-ERM的有效性</p>
<h3
id="alp-data-augmentation-using-lexicalized-pcfgs-for-few-shot-text-classification">ALP:
Data Augmentation using Lexicalized PCFGs for Few-Shot Text
Classification</h3>
<ul>
<li>标题：ALP：基于词汇化PCFGS的Few-Shot文本分类数据增强</li>
<li>链接：https://arxiv.org/abs/2112.11916</li>
<li>作者：Hazel Kim,Daecheol Woo,Seong Joon Oh,Jeong-Won Cha,Yo-Sub
Han</li>
<li>机构： Yonsei University, Seoul, Republic of Korea, NAVER AI Lab,
Changwon National University, Changwon, Republic of Korea</li>
<li>备注：Accepted to AAAI2022</li>
</ul>
<p>这个是基于文法分析树的方式进行数据增强的</p>
<h2 id="nerprompt-base在ner中的应用">NER[^prompt base在NER中的应用]</h2>
<p>该任务中需要生成句子和token级别的标签。且序列标注为细粒度的文本任务。
现有的生成模型智能生成没有标签的序列；
启发式的数据增强方法不可行，直接对标签替换或者上下文替换，被注入错误的可能性比较大，相比较分类任务更容易破坏序列上下文关系。</p>
<h3
id="an-analysis-of-simple-data-augmentation-for-named-entity-recognition">An
Analysis of Simple Data Augmentation for Named Entity Recognition</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353604.png" alt="Alt text" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353756.png" alt="Alt text" style="zoom:67%;" /></p>
<ul>
<li><strong>Label-wise token replacement (LwTR)
</strong>：即同标签token替换，对于每一token通过二项分布来选择是否被替换；如果被替换，则从训练集中选择相同的token进行替换。</li>
<li><strong>Synonym replacement (SR)
</strong>：即同义词替换，利用WordNet查询同义词，然后根据二项分布随机替换。如果替换的同义词大于1个token，那就依次延展BIO标签。</li>
<li><strong>Mention replacement (MR)
</strong>：即实体提及替换，与同义词方法类似，利用训练集中的相同实体类型进行替换，如果替换的mention大于1个token，那就依次延展BIO标签，如上图：「headache」替换为「neuropathic
pain syndrome」，依次延展BIO标签。</li>
<li><strong>Shuffle within segments (SiS)</strong>
：按照mention来切分句子，然后再对每个切分后的片段进行shuffle。如上图，共分为5个片段：
[She did not complain of], [headache], [or], [any other neurological
symptoms], [.].
。也是通过二项分布判断是否被shuffle（mention片段不会被shuffle），如果shuffle，则打乱片段中的token顺序。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/1646362972193.png" alt="Alt text" style="zoom:67%;" /></p>
<p>由上图可以看出： -
各种数据增强方法都超过不使用任何增强时的baseline效果。 -
对于RNN网络，实体提及替换优于其他方法；对于Transformer网络，同义词替换最优。
- 总体上看，所有增强方法一起使用（ALL）会优于单独的增强方法。 -
低资源条件下，数据增强效果增益更加明显；充分数据条件下，数据增强可能会带来噪声，甚至导致指标下降；</p>
<h3
id="daga-data-augmentatino-with-a-generation-approach-for-low-resource-tagging-tasks">DAGA:
Data Augmentatino with a Generation Approach for Low-resource Tagging
Tasks</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353938.png" alt="Alt text" style="zoom:67%;" /></p>
<p>DAGA的思想简单来讲就是标签线性化：即将原始的<strong>「序列标注标签」与「句子token」进行混合，也就是变成「Tag-Word」</strong>的形式，如下图：将「B-PER」放置在「Jose」之前，将「E-PER」放置在「Valentin」之前；对于标签「O」则不与句子混合。标签线性化后就可以生成一个句子了，文章基于此句子就可以进行「语言模型生成」了。
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353943.png" alt="Alt text" style="zoom:67%;" /></p>
<h3 id="seqmix">SeqMix</h3>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353921.png" alt="Alt text" style="zoom:67%;" /></p>
<ul>
<li>标题: SeqMix: Augmenting Active Sequence Labeling via Sequence
Mixup</li>
<li>链接: https://rongzhizhang.org/pdf/emnlp20_SeqMix.pdf</li>
<li>开源代码: https://github.com/rz-zhang/SeqMix</li>
<li>备注: EMNLP 2020
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353427.png" alt="Alt text" style="zoom:67%;" /></li>
</ul>
<h3 id="boundary-smoothing-for-named-entity-recognition">Boundary
Smoothing for Named Entity Recognition</h3>
<p><img src="../../images/nlp/NLP文本场景的数据优化/1646817503789.png" alt="Alt text" style="zoom:67%;" /></p>
<ul>
<li>标题: 针对命名实体识别的span类的算法的边界平滑</li>
<li>code: https://github.com/syuoni/eznlp</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030353619-20221117002747265.png" alt="Alt text" style="zoom:50%;" /><img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/images/202209030354558.png" alt="Alt text" style="zoom:50%;" /></p>
<p>An example of hard and smoothed boundaries. The example sentence has
ten tokens and two entities of spans (1, 2) and (3, 7), colored in red
and blue, respectively. The first subfigure presents the entity
recognition targets of hard boundaries. The second subfigure presents
the corresponding targets of smoothed boundaries, where the span (1, 2)
is smoothed by a size of 1, and the span (3, 7) is smoothed by a size of
2. 其中周边区域有<span
class="math inline">\(\epsilon\)</span>的概率会被赋值，此时原标注位置值为<span
class="math inline">\(1 - \epsilon\)</span>，周边区域<span
class="math inline">\(D\)</span>赋值<span class="math inline">\(\epsilon
/ D\)</span>,</p>
<p>对NER标签位置的平滑处理，提升模型的泛化性。边界平滑可以防止模型对预测实体过于自信，从而获得更好的定标效果。D一般不用太大，1或者2即可，
<span class="math inline">\(\epsilon\)</span>一般取[0.1, 0.2, 0.3]
<img src="https://cdn.jsdelivr.net/gh/cwlseu/deepindeed_repo@main/img/202209030353317.png" alt="Alt text" style="zoom:67%;" /></p>
<h2 id="参考文献">参考文献</h2>
<p>[^prompt
base在NER中的应用]:https://zhuanlan.zhihu.com/p/462332297</p>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Steven Y. Feng, Varun Gangal, Jason
Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, &amp; Eduard
Hovy (2021). A Survey of Data Augmentation Approaches for NLP Meeting of
the Association for Computational Linguistics.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Markus Bayer, Marc-André Kaufhold,
&amp; Christian Reuter (2021). A Survey on Data Augmentation for Text
Classification.. arXiv: Computation and Language.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Li, B. , Hou, Y. , &amp; Che, W. .
(2021). Data augmentation approaches in natural language processing: a
survey.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"
role="doc-endnote"><p>https://github.com/jasonwei20/eda_nlp<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"
role="doc-endnote"><p>https://github.com/google-research/uda<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"
role="doc-endnote"><p>https://github.com/zhanlaoban/eda_nlp_for_Chinese<a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"
role="doc-endnote"><p>https://github.com/makcedward/nlpaug<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Steven Y. Feng, Varun Gangal, Jason
Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, &amp; Eduard
Hovy (2021). A Survey of Data Augmentation Approaches for NLP Meeting of
the Association for Computational Linguistics.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Markus Bayer, Marc-André Kaufhold,
&amp; Christian Reuter (2021). A Survey on Data Augmentation for Text
Classification.. arXiv: Computation and Language.<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Amit Chaudhary(2020). A Visual
Survey of Data Augmentation in NLP.
https://amitness.com/2020/05/data-augmentation-for-nlp<a href="#fnref10"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

    </div>

    
    
    
      


    <footer class="post-footer"><div class="post-widgets">
    <div
      class="social-share"
      
        data-sites="weibo,qq,wechat,tencent,douban,qzone,linkedin,diandian,facebook,twitter,google"
      
      
        data-wechat-qrcode-title="share.title"
      
      
        data-wechat-qrcode-helper="share.prompt"
      
    >
    </div>
  </div>
  <script src="https://lib.baomitu.com/social-share.js/1.0.16/js/social-share.min.js"></script>
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>CharlesCao
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://www.deepindeed.cn/202203/20220310-nlp-text-data-augmentation/" title="NLP 文本场景的数据优化">http://www.deepindeed.cn/202203/20220310-nlp-text-data-augmentation/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/NLP/" rel="tag"># 自然语言处理</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/202203/20220304-label-noise-learning/" rel="prev" title="Label Noise Learning">
                  <i class="fa fa-chevron-left"></i> Label Noise Learning
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/202208/20220803-pytorch-1.12/" rel="next" title="认识 PyTorch 1.12 之后的 nvFuser">
                  认识 PyTorch 1.12 之后的 nvFuser <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      <div class="tabs tabs-comment">
        <ul class="nav-tabs">
            <li class="tab"><a href="#comment-waline">waline</a></li>
            <li class="tab"><a href="#comment-gitalk">gitalk</a></li>
        </ul>
        <div class="tab-content">
            <div class="tab-pane waline" id="comment-waline">
              <div class="comments" id="waline"></div>
            </div>
            <div class="tab-pane gitalk" id="comment-gitalk">
              <div class="comments gitalk-container"></div>
            </div>
        </div>
      </div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CharlesCao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">510k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">14:10</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@9.0.1/dist/mermaid.min.js","integrity":"sha256-CemUs9ITT7liCZpVMktcEw0BpAOZ1+mujlMB3UyuImU="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://waline.vercel.app","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":false,"libUrl":"https://unpkg.com/@waline/client@v2/dist/waline.js","locale":{"placeholder":"欢迎交流指正"},"emoji":["https://unpkg.com/@waline/emojis@1.0.1/weibo","https://unpkg.com/@waline/emojis@1.0.1/alus","https://unpkg.com/@waline/emojis@1.0.1/bilibili","https://unpkg.com/@waline/emojis@1.0.1/qq","https://unpkg.com/@waline/emojis@1.0.1/tieba","https://unpkg.com/@waline/emojis@1.0.1/tw-emoji"],"meta":["nick","mail"],"requiredMeta":["mail","nick","mail"],"login":"enable","el":"#waline","comment":true,"path":"/202203/20220310-nlp-text-data-augmentation/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"cwlseu","repo":"blog-comment","client_id":"a3c364d3dade81cbba30","client_secret":"e1093c6387bfa715f2cb4b6aee010c94deb253ee","admin_user":"cwlseu","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"5d18d924ef34e24de2d55f04698701ae"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
